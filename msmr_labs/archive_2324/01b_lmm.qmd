---
title: "1B: Linear Mixed Models/Multi-level Models"
params: 
    SHOW_SOLS: FALSE
    TOGGLE: TRUE
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: setup
#| include: false
source('assets/setup.R')
library(xaringanExtra)
library(tidyverse)
library(patchwork)
xaringanExtra::use_panelset()

schoolmot <- read_csv("https://uoepsy.github.io/data/schoolmot.csv") |>
  mutate(schoolid=factor(schoolid))
srmod <- lm(grade ~ motiv, data = schoolmot)
```


:::lo
This reading:  

- Introducing the multilevel model (MLM)
- How the MLM achieves partial pooling
- Fitting multilevel models in R
- Model estimation and convergence

::: {.callout-tip collapse="true"}
#### different names for the same thing

The methods we're going to start to look at are known by lots of different names (see @fig-wordcloud). The core idea is that **model parameters vary at more than one level.**. 

```{r}
#| echo: false
#| label: fig-wordcloud
#| fig-cap: "size weighted by hits on google scholar search (sept 2020)"  
tribble(
  ~word, ~freq,
  "multi-level model", 154000 + 31300,
  "hierarchical linear model", 24000,
  "mixed-effects model", 56500 + 191000,
  "mixed model", 1500000,
  "random coefficient model", 11200+6920,
  "random-effects model", 101000 + 501000,
  "random parameter model", 2140 + 1460,
  "random-intercept model", 17100 + 2930, 
  "variance components model", 6210 + 5560,
  "partial pooling", 5120,
  "mixed error-component model", 62,
  "random slope model", 4010 + 1620,
  "panel data model", 55400,
  "latent curve model", 1520,
  "growth curve model", 18400
) -> mlmname


mlmname$freq[mlmname$freq > 100000] <- c(85000,85000, 110000,70000,95000)*1.5

#wordcloud2(mlmname, shape="diamond", size=.4)
library(wordcloud)
wordcloud(words = mlmname$word, freq = mlmname$freq, random.order=FALSE,
          min.freq=1,
          scale=c(4,.5),
          rot.per=0,
          fixed.asp=T,
          #ordered.colors=T,
          colors="#a41ae4")
```

:::

:::


# Fixed effects

In the simple linear regression model was written as $\color{red}{y} = \color{blue}{b_0 + b_1x_1 \ + \ ... \ + \ b_px_p} \color{black}{\ + \ \varepsilon}$, the estimated coefficients $\color{blue}{b_0}$, $\color{blue}{b_1}$ etc., are estimated as **fixed** values - i.e. we estimate just one number for $b_0$, and one number for $b_1$, for $b_2$ and so on, and that's it.  

In the example where we model school children's grades as a function of their motivation score, when we fit a simple regression model of `lm(grade ~ motiv)`, the estimated parameters are two values that define a line - an intercept and a slope (as in @fig-schoolplot1).  
 
```{r}
#| echo: false
#| label: fig-schoolplot1
#| fig-cap: "Grade predicted by motivation. The simple linear regression model defines the height and slope of the black line."
library(lme4)
library(ggdist)
library(distributional)
fmod = lm(grade~motiv,schoolmot)
rimod = lmer(grade~motiv+(1|schoolid),schoolmot)
rsmod = lmer(grade~motiv+(1+motiv|schoolid),schoolmot)
basep = ggplot(schoolmot, aes(x=motiv,y=grade))+
  geom_point(alpha=.1,aes(col=schoolid)) +
  guides(col="none")+
  geom_vline(xintercept=0,lty="dashed")+
  scale_x_continuous(limits=c(-1,12),breaks=0:10)

basep + geom_abline(intercept=coef(fmod)[1],slope=coef(fmod)[2], lwd=1) +
  geom_point(alpha=.2,col="black") +
  geom_point(x=0,y=coef(fmod)[1],size=3,col="blue") +
  annotate("text",label=expression(b["0"]),
           col="blue",size=5,
           x=0,y=coef(fmod)[1],hjust=-.2,vjust=1.2)+
  
  annotate("text",label=expression(b["1"]),
           col="blue",size=5,
           x=1.5,y=coef(fmod)[1]+1,hjust=-.2,vjust=1)+
  geom_segment(x=1,xend=1.5,y=coef(fmod)[1]+1,yend=coef(fmod)[1],
               col="blue")+
  geom_segment(x=0,xend=1,
               y=(coef(fmod) %*% c(1,0))[1],
               yend=(coef(fmod) %*% c(1,0))[1]) +
  geom_segment(x=1,xend=2,
               y=(coef(fmod) %*% c(1,1))[1],
               yend=(coef(fmod) %*% c(1,1))[1]) +
  geom_segment(x=2,xend=3,
               y=(coef(fmod) %*% c(1,2))[1],
               yend=(coef(fmod) %*% c(1,2))[1]) + 
  geom_segment(x=3,xend=4,
               y=(coef(fmod) %*% c(1,3))[1],
               yend=(coef(fmod) %*% c(1,3))[1]) + 
  geom_segment(x=1,xend=1,
               y=(coef(fmod) %*% c(1,0))[1],
               yend=(coef(fmod) %*% c(1,1))[1],col="blue",lwd=1) +
  geom_segment(x=2,xend=2,
               y=(coef(fmod) %*% c(1,1))[1],
               yend=(coef(fmod) %*% c(1,2))[1],col="blue",lwd=1) +
  geom_segment(x=3,xend=3,
               y=(coef(fmod) %*% c(1,2))[1],
               yend=(coef(fmod) %*% c(1,3))[1],col="blue",lwd=1) +
  geom_segment(x=4,xend=4,
               y=(coef(fmod) %*% c(1,3))[1],
               yend=(coef(fmod) %*% c(1,4))[1],col="blue",lwd=1) 
  
  
```

The intercept and slope here are 'fixed' in the sense that it does not matter what school a child is from, if they score 0 on the motivation scale, then our model predicts that they will get a grade of `r round(coef(srmod)[1],1)` (the intercept). 

```{r}
schoolmot <- read_csv("https://uoepsy.github.io/data/schoolmot.csv")
srmod <- lm(grade ~ motiv, data = schoolmot)
```
```{r}
#| echo: false
.pp(summary(srmod),l=list(0,9:13))
```

To make this point really clear, we can write our model equation with the addition of a suffix $i$ to indicate that the equation for the $i^{th}$ child is: 

$$
\begin{align}
&\text{For child }i \\
&\text{grade}_i = b_0 + b_1 \cdot \text{motiv}_i + \epsilon_i 
\end{align}
$$
i.e. For any child $i$ that we choose, that child's grade ($\text{grade}_i$) is some fixed number ($b_0$) plus some fixed amount ($b_1$) times that child's motivation ($\text{motiv}_i$).  
  
The issue, as we saw in [1A #clustered-data](01a_clustered.html#clustered-data), is that the children in our study are actually related to one another in that they can be grouped into the schools that we sampled them from. It's entirely possible (and likely) that there are school-level differences might actually account for quite a lot of the variation in grades. In the previous reading we actually estimated this to account for approximately `r round(suppressWarnings(ICC::ICCbare(schoolid, grade, data = schoolmot)),2)*100`% grade variation ([1A #ICC](01a_clustered.html#icc---quantifying-clustering-in-an-outcome-variable)).  

One option we have hinted at is that we could consider adding in the `schoolid` as a predictor to our linear model to estimate all these school-level differences (`lm(grade ~ schoolid + motiv)`). This is a good start, and may oftentimes be perfectly acceptable if our clustering is simply a nuisance thing that we want to account for - adding in the clustering as another predictor will completely account for *all* cluster-level variability in our outcome variable.  

However, more frequently these clusters are themselves additional units of observation that have features of interest to us. For instance, we may be interested in how the funding that a school receives moderates the association between childrens motivation and grades - i.e. we're interested in things that happen both at the child-level (motivation, grades), *and* at the school-level (funding). For these scenarios, we really need a multilevel model.  


::: {.callout-note collapse="true"}
#### clusters as fixed effects

We have already seen that we can include fixed effects for cluster differences (we referred to this as "no pooling").  

e.g. to fit school-level differences in grades, we could use:
```{r}
#| eval: false
femod <- lm(grade ~ motiv + schoolid, data = schoolmot)
```

The model equation for this would look something like:
$$
\begin{align}
\text{For child }i& \\
\text{grade}_i =\, &b_0 + b_1 \cdot \text{motiv}_i + b_2 \cdot \text{isSchool2}_i + b_3 \cdot \text{isSchool3}_i\,\, + \,\, ... \,\, + \\
& ... + \,\, ... \,\, + \,\, ... \,\, + \\
& b_p \cdot \text{isSchoolP}_i\,\, + \epsilon_i 
\end{align}
$$

The school coefficients are a series of dummy variables that essentially toggle on or off depending on which school child $i$ is from. 

Because these set of coefficients account for **all** of the school-level differences in grades, it means we are then unable to consider other school-level variables like `funding` (how much govt funding the school receives). If we try, we can see that a coefficient for `funding` is not able to be estimated because `schoolid` is explaining everything school-related:    

```{r}
#| eval: false
femod2 <- lm(grade ~ motiv + schoolid + funding, data = schoolmot)
summary(femod2)
```
```
Coefficients: (1 not defined because of singularities)
                                  Estimate  Std. Error t value Pr(>|t|)    
(Intercept)                       33.1420   2.8257     11.729  < 2e-16 ***
motiv                             4.8107    0.4145     11.606  < 2e-16 ***
schoolidArdnamurchan High School -9.6072    3.1035    -3.096   0.00203 ** 
schoolidBalwearie High School    -16.6493   3.0922    -5.384   9.36e-08 ***
...                               ...       ...        ...     ... 
...                               ...       ...        ...     ... 
funding                           NA        NA         NA      NA  
```

:::


<div class="divider div-transparent div-dot"></div>

# Introducing the Multilevel Model

The multi-level model is an alternative model structure that accounts for cluster-level differences in a more flexible and parsimonious way. It achieves this by taking some of the estimated coefficients (the $b_?$'s) in our linear regression model and modelling these as randomly varying by clusters (i.e. clusters differ in their value for $b_?$).  


Let's see how this works by starting with the intercept, $b_0$.  

## random intercepts

To extend the single-level regression model to the multi-level regression model, we add in an extra suffix to our equation to indicate which cluster an observation belongs to.^[Some books use "cluster $j$ >> observation $i$", others use "cluster $i$ >> observation $j$". We use the latter here] Then, we can take a coefficient $b_?$ and allow it to be different for each cluster $i$ by adding the suffix $b_{?i}$. Below, we have done this for our intercept $b_0$, which has become $b_{0i}$.    
  
However, we also need to _define_ these differences in some way, and the multilevel model does this by expressing each cluster's intercept as a deviation ($\zeta_{0i}$ for cluster $i$, below) from a fixed number ($\gamma_{00}$, below). Because these differences are to do with the _clusters_ (and not the individual observations within them), we often write these as a "level 2 equation":    

$$
\begin{align}
\text{For observation }j&\text{ in cluster }i \\
\text{Level 1:}& \\
\color{red}y_{ij} &\color{black}= \color{green}b_{0i} \color{blue} + b_1 \cdot x_{ij} \color{black}+ \epsilon_{ij} \\
\text{Level 2:}& \\
\color{green}b_{0i} &\color{black}= \color{blue}\gamma_{00} \color{black}+ \color{orange}\zeta_{0i} \\
\end{align}
$$

::: {.callout-tip collapse="true"}
#### mixed-effects notation  

Instead of writing several equations at multiple levels, we substitute the Level 2 terms into the Level 1 equation to get something that is longer, but all in one:  

$$
\color{red}y_{ij} \color{black}= \underbrace{(\color{blue}\gamma_{00} \color{black}+ \color{orange}\zeta_{0i}\color{black})}_{\color{green}b_{0i}} \cdot 1 + \color{blue}b_{1} \cdot x_{ij} \color{black}+  \varepsilon_{ij}
$$  

This notation typically corresponds with the "mixed effects" terminology because parameters can now be a combination of both a fixed number and a random deviation, as in the intercept below:  

$$
y_{ij} = \underbrace{(\underbrace{\gamma_{00}}_{\textrm{fixed}} + \underbrace{\zeta_{0i}}_{\textrm{random}})}_{\text{intercept, }b_{0i}} \cdot 1 + \underbrace{b_1}_{\textrm{fixed}} \cdot x_{ij} +  \varepsilon_{ij}
$$

:::

Returning to our school children's grade example, we can fit a model with "random intercepts for schools", which would account for some schools having higher grades, some having lower grades, etc.  

$$
\begin{align}
\text{For Child }j\text{ in School }i& \\
\text{Level 1 (child):}& \\
\text{grade}_{ij} &= b_{0i} + b_1 \cdot \text{motiv}_{ij} + \epsilon_{ij} \\
\text{Level 2 (school):}& \\
b_{0i} &= \gamma_{00} + \zeta_{0i} \\
\end{align}
$$
If we consider one of our schools (e.g. "Beeslack Community High School") we can see that our model predicts that this school has higher grades than most other schools (@fig-ri_1school). We can see how this is modelled as a deviation $\zeta_{0\text{B}}$ (B for Beeslack) from some fixed value $\gamma_{00}$.  

```{r}
#| label: fig-ri_1school
#| echo: false
#| fig-cap: "Fitted values from a multilevel model with random intercepts for schools"
library(ggforce)
library(ggfx)
plotlabs = tibble(schoolid=unique(schoolmot$schoolid),motiv=10,x=10)
plotlabs$y = predict(rimod, newdata=plotlabs)


plotlines = 
  as.data.frame(coef(rimod)$schoolid) |> 
  rownames_to_column() |>
  mutate(
    g = 1:n(),
    data = map2(`(Intercept)`,motiv, ~tibble(x = 0:10, .fitted = ..1 + ..2*(0:10)))
  ) |> unnest(data)

specg = plotlines |> filter(g==4) |>
  mutate(f = fixef(rimod)[1])

basep + 
  with_blur(geom_line(data = plotlines, aes(x=x,y=.fitted,group=g),alpha=.3),sigma=2) + 
  geom_line(data = specg,lwd=1,
            aes(x=x,y=.fitted,group=g),alpha=1,col="darkorange3") +
  geom_abline(intercept=fixef(rimod)[1],slope=fixef(rimod)[2], lwd=1,col="#a41ae4") +
  geom_curve(
    data=specg[1,],
    aes(x=0,xend=0,y=.fitted,yend=f),col="darkorange3",
    curvature=.2,lwd=1
  ) +
  geom_point(x=0,y=fixef(rimod)[1],size=3,col="#a41ae4")+
  annotate("text",x=-.1,y=fixef(rimod)[1],
           label=expression(gamma["00"]),size=5,
           hjust=-.25,vjust=1.2,col="#a41ae4") +
  annotate("text",x=-.1,y=mean(unlist(specg[1,6:7])),
           label=expression(zeta["0B"]),size=5,
           hjust=1.2,col="darkorange3")+
  geom_text(data=plotlabs,
             aes(x=x,y=y,label=schoolid),
             hjust=0,alpha=.3)+
  geom_label(data=plotlabs[grepl("Bees",plotlabs$schoolid),],
             aes(x=x,y=y,label=schoolid),
             hjust=0,col="darkorange3")+
  guides(col="none")
```

At this point, you might be wondering how this is any different from simply fitting clusters as an additional predictor in a single level regression (i.e. a clusters-as-fixed-effect approach of `lm(grade ~ motiv + schoolid)`), which would also estimate a difference for each cluster?  

:::sticky
The key to the multilevel model is that we are not actually estimating the cluster-specific lines themselves (although we _can_ get these out). We are estimating a **distribution** of deviations. 
:::

Specifically, the parameters of the multilevel model that are estimated are the mean and the _variance_ of a _normal_ distribution of clusters.  

So the parameters that are estimated from our model with a random intercept by-schools, are:

:::: {.columns}
:::{.column width="35%"}

<br>  

- a fixed intercept $\gamma_{00}$  
- the variance with which schools deviate from the fixed intercept $\sigma^2_0$  
- a fixed slope for `motiv` $b_1$  
- and we also need the residual variance too $\sigma^2_\varepsilon$  


:::
:::{.column width="10%"}
:::
:::{.column width="55%"}
$$
\begin{align}
\text{For Child }j\text{ in School }i& \\
\text{Level 1 (child):}& \\
\text{grade}_{ij} &= b_{0i} + b_1 \cdot \text{motiv}_{ij} + \epsilon_{ij} \\
\text{Level 2 (school):}& \\
b_{0i} &= \gamma_{00} + \zeta_{0i} \\
\text{where: }& \\
&\zeta_{0i} \sim N(0,\sigma_0) \\
&\varepsilon_{ij} \sim N(0,\sigma_\varepsilon) \\
\end{align}
$$
:::
::::

Remember, $\sim N(m,s)$ is a way of writing "are normally distributed with a mean of $m$ and a standard deviation of $s$". So the $\zeta_{0i} \sim N(0,\sigma_0)$ bit is saying that the school deviations from the fixed intercept are modelled as a _normal distribution_, with a mean of 0, and a standard deviation of $\sigma_0$ (which gets estimated by our model).  

This can be seen in @fig-ri_param - the model is actually estimating a fixed intercept; a fixed slope; and the spread of a normal distribution of school-level deviations from the fixed intercept.  

```{r}
#| label: fig-ri_param
#| echo: false
#| fig-cap: "grade predicted by motivation, with a by-school random intercept. The school-level intercepts are modelled as a normal distribution. Parameters estimated by the model are shown in purple (fixed effects) and orange (variance components)."
basep + 
  with_blur(geom_line(data = plotlines, aes(x=x,y=.fitted,group=g),alpha=.2), sigma=2) + 
  stat_eye(side="left",
           data=tibble(motiv=-1,grade=50),
           aes(x=0,ydist=dist_normal(fixef(rimod)[1],sqrt(VarCorr(rimod)[[1]][1]))), 
           alpha=.3, fill="#a41ae4")  +

  geom_abline(intercept=fixef(rimod)[1],slope=fixef(rimod)[2], lwd=1,col="#a41ae4")+
    geom_text(data=plotlabs,
             aes(x=x,y=y,label=schoolid),
             hjust=0,alpha=.1) +
  annotate("text",x=-.1,y=fixef(rimod)[1],
           label=expression(gamma["00"]),size=5,
           hjust=-.25,vjust=1.2,col="#a41ae4",parse=TRUE) + 
  geom_segment(x=-.1,xend=-.1,y=fixef(rimod)[1],
               yend=fixef(rimod)[1]+sqrt(VarCorr(rimod)[[1]][1]),
               col="darkorange3",lwd=1) + 
  annotate("text",x=-.1,y=33,
           label=expression(sigma["0"]),size=5,
           hjust=1.2,col="darkorange3")+
  geom_segment(x=0,xend=1,
               y=(fixef(rimod) %*% c(1,0))[1],
               yend=(fixef(rimod) %*% c(1,0))[1]) +
  geom_segment(x=1,xend=2,
               y=(fixef(rimod) %*% c(1,1))[1],
               yend=(fixef(rimod) %*% c(1,1))[1]) +
  geom_segment(x=2,xend=3,
               y=(fixef(rimod) %*% c(1,2))[1],
               yend=(fixef(rimod) %*% c(1,2))[1]) + 
  geom_segment(x=3,xend=4,
               y=(fixef(rimod) %*% c(1,3))[1],
               yend=(fixef(rimod) %*% c(1,3))[1]) + 
  geom_segment(x=1,xend=1,
               y=(fixef(rimod) %*% c(1,0))[1],
               yend=(fixef(rimod) %*% c(1,1))[1],col="#a41ae4",lwd=1) +
  geom_segment(x=2,xend=2,
               y=(fixef(rimod) %*% c(1,1))[1],
               yend=(fixef(rimod) %*% c(1,2))[1],col="#a41ae4",lwd=1) +
  geom_segment(x=3,xend=3,
               y=(fixef(rimod) %*% c(1,2))[1],
               yend=(fixef(rimod) %*% c(1,3))[1],col="#a41ae4",lwd=1) +
  geom_segment(x=4,xend=4,
               y=(fixef(rimod) %*% c(1,3))[1],
               yend=(fixef(rimod) %*% c(1,4))[1],col="#a41ae4",lwd=1) +
  annotate("text",x=2.5,y=31,
           label=expression(b["1"]),size=4,
           col="#a41ae4")+
  geom_segment(x=2,xend=2.4,
               y=36.5,yend=31,
               col="#a41ae4")
  
```

## random slopes

It is not just the intercept that we can allow to vary by-schools. We can also model cluster-level deviations from other coefficients (i.e. slopes). 
For instance, we can allow the slope of $x$ on $y$ to be different for each cluster, by specifying in our model that $b_{1i}$ is a distribution of cluster deviations $\zeta_{1i}$ around the fixed slope $\gamma_{10}$.  

$$
\begin{align}
\text{For observation }j&\text{ in cluster }i \\
\text{Level 1:}& \\
y_{ij} &= b_{0i} + b_{1i} \cdot x_{ij} + \varepsilon_{ij} \\
\text{Level 2:}& \\
b_{0i} &= \gamma_{00} + \zeta_{0i} \\
b_{1i} &= \gamma_{10} + \zeta_{1i} \\
& \qquad \\
\text{Where:}& \\
& \begin{bmatrix} \zeta_{0i} \\ \zeta_{1i} \end{bmatrix}
\sim N
\left(
    \begin{bmatrix} 0 \\ 0 \end{bmatrix},
    \begin{bmatrix}
        \sigma_0 & \rho \sigma_0 \sigma_1 \\
        \rho \sigma_0 \sigma_1 & \sigma_1
    \end{bmatrix}
\right)
\end{align}
$$

When we have random intercepts _and_ random slopes, our assumption is that both of intercepts and slopes are normally distributed. However, we also typically allow these to be correlated, so the complicated looking bit at the bottom of the equation above is really just saying "random intercepts and slopes are normally distributed with mean of 0 and standard deviations of $\sigma_0$ and $\sigma_1$ respectively, and with a correlation of $\rho \sigma_0 \sigma_1$". We'll see more on this in future weeks, so don't worry too much right now.  

In @fig-rslope, we can see now that both the intercept *and* the slope of grades across motivation are varying by-school.  

```{r}
#| label: fig-rslope
#| fig-cap: "predicted values from the multilevel model that includes by-school random intercepts and by-school random slopes of motivation."
#| echo: false
#| out-width: "100%"
plotlines = 
  as.data.frame(coef(rsmod)$schoolid) |> 
  rownames_to_column() |>
  mutate(
    g = 1:n(),
    data = map2(`(Intercept)`,motiv, ~tibble(x = 0:10, .fitted = ..1 + ..2*(0:10)))
  ) |> unnest(data)

plotlabs = tibble(schoolid=unique(schoolmot$schoolid),motiv=10,x=10)
plotlabs$y = predict(rsmod, newdata=plotlabs)


basep + 
  with_blur(geom_line(data = plotlines, aes(x=x,y=.fitted,group=g,col=rowname),alpha=.5),sigma=1) +
    geom_text(data=plotlabs,
             aes(x=x,y=y,label=schoolid),
             hjust=0,alpha=.3)+
  guides(col="none")+
  geom_abline(intercept=fixef(rsmod)[1],slope=fixef(rsmod)[2], lwd=1, col="#a41ae4")
```

Much like for the random intercepts, we are modelling the random slopes as the distribution of school-level deviations $\zeta_{1i}$ around a fixed estimate $\gamma_{10}$. 

So each group (school) now has, as visualised in @fig-unlmm: 

1) a deviation from the fixed intercept
2) a deviation from the fixed slope  

```{r}
#| echo: false
#| label: fig-unlmm
#| fig-cap: "random intercepts and random slopes"
knitr::include_graphics("images/un_lmm.png")
```

While it's possible to show the distribution of intercepts on the left hand side of our `grade ~ motiv` plot, it's hard to put the distribution of slopes on the same plot, so I have placed these in the bottom panel in @fig-rslopes2. We can see, for instance, that "Hutcheson's Grammar School" has a higher intercept, but a lower slope.  

```{r}
#| label: fig-rslopes2
#| fig-cap: "grade predicted by motivation, with by-school random intercepts and by-school random slopes of motivation. Parameters estimated by the model are shown in purple (fixed effects) and orange (variance components)"
#| echo: false
#| out-width: "100%"
plotlines = 
  as.data.frame(coef(rsmod)$schoolid) |> 
  rownames_to_column() |>
  mutate(
    g = 1:n(),
    data = map2(`(Intercept)`,motiv, ~tibble(x = 0:10, .fitted = ..1 + ..2*(0:10)))
  ) |> unnest(data)

plotlabs = tibble(schoolid=unique(schoolmot$schoolid),motiv=10,x=10)
plotlabs$y = predict(rsmod, newdata=plotlabs)


p1 <- basep + 
  with_blur(geom_line(data = plotlines, aes(x=x,y=.fitted,group=g,col=rowname),alpha=.5),sigma=1) +
    geom_text(data=plotlabs,
             aes(x=x,y=y,label=schoolid),
             hjust=0,alpha=.3)+
  geom_line(data = plotlines[grepl("Hutche",plotlines$rowname),], 
            aes(x=x,y=.fitted,group=g,col=rowname),
            alpha=1,col="green4",lwd=.75) +
  geom_label(data=plotlabs[grepl("Hutche",plotlabs$schoolid),],
             aes(x=x,y=y,label=schoolid),
             hjust=0,alpha=.7,col="green4")+
  guides(col="none")+
  stat_eye(side="left", 
           data=tibble(motiv=-1,grade=50),
           aes(x=0,ydist=dist_normal(fixef(rsmod)[1],sqrt(VarCorr(rsmod)[[1]][1]))), 
           alpha=.3, fill="#a41ae4") + 
  geom_abline(intercept=fixef(rsmod)[1],slope=fixef(rsmod)[2], lwd=1, col="#a41ae4") +
  
  annotate("text",x=-.1,y=fixef(rsmod)[1],
           label=expression(gamma["00"]),size=5,
           hjust=-.2,vjust=1.2,col="#a41ae4",parse=TRUE) + 
  geom_segment(x=-.1,xend=-.1,y=fixef(rsmod)[1],
               yend=fixef(rsmod)[1]+sqrt(VarCorr(rsmod)[[1]][1])-1,col="darkorange3",lwd=1) + 
  annotate("text",x=-.1,y=fixef(rsmod)[1]+5,
           label=expression(sigma["0"]),size=5,
           hjust=1.2,col="darkorange3")+
  geom_segment(x=0,xend=1,
               y=(fixef(rsmod) %*% c(1,0))[1],
               yend=(fixef(rsmod) %*% c(1,0))[1]) +
  geom_segment(x=1,xend=2,
               y=(fixef(rsmod) %*% c(1,1))[1],
               yend=(fixef(rsmod) %*% c(1,1))[1]) +
  geom_segment(x=2,xend=3,
               y=(fixef(rsmod) %*% c(1,2))[1],
               yend=(fixef(rsmod) %*% c(1,2))[1]) + 
  geom_segment(x=3,xend=4,
               y=(fixef(rsmod) %*% c(1,3))[1],
               yend=(fixef(rsmod) %*% c(1,3))[1]) + 
  geom_segment(x=1,xend=1,
               y=(fixef(rsmod) %*% c(1,0))[1],
               yend=(fixef(rsmod) %*% c(1,1))[1],col="#a41ae4",lwd=1) +
  geom_segment(x=2,xend=2,
               y=(fixef(rsmod) %*% c(1,1))[1],
               yend=(fixef(rsmod) %*% c(1,2))[1],col="#a41ae4",lwd=1) +
  geom_segment(x=3,xend=3,
               y=(fixef(rsmod) %*% c(1,2))[1],
               yend=(fixef(rsmod) %*% c(1,3))[1],col="#a41ae4",lwd=1) +
  geom_segment(x=4,xend=4,
               y=(fixef(rsmod) %*% c(1,3))[1],
               yend=(fixef(rsmod) %*% c(1,4))[1],col="#a41ae4",lwd=1) +
  annotate("text",x=2.9,y=33,hjust=0,
           label=expression(gamma["10"]),
           size=5,col="#a41ae4")+
  geom_segment(x=2,xend=2.7,
               y=36,yend=33,
               col="#a41ae4")


p2 <- as.data.frame(ranef(rsmod)$schoolid) |>
  rownames_to_column() |>
  ggplot(aes(x=motiv))+
  geom_area(stat = "function", fun = dnorm,args=list(mean=0,sd=sqrt(VarCorr(rsmod)[[1]][2,2])),fill="#a41ae4",xlim=c(-6,6),alpha=.3)+
  with_blur(geom_rug(alpha=.7,aes(col=rowname),lwd=1,
                     length = unit(0.05, "npc")),sigma=1) +
  geom_segment(x=0,
               xend=sqrt(VarCorr(rsmod)[[1]][2,2]),
               y=0.009,yend=0.009,
               col="darkorange3",lwd=1)+
  annotate("text",label=expression(sigma["1"]),size=5,
           x=1,y=0.021,col="darkorange3")+
  geom_vline(xintercept=0,col="#a41ae4")+
  annotate("text",label=expression(gamma["11"]),size=5,
           x=0,y=0.08,col="#a41ae4",hjust=-.2)+
  scale_y_continuous(NULL,breaks=NULL)+
  scale_x_continuous(expression(zeta["1i"]))+
  guides(col="none")+
  annotate("text",label="Hutchesons'\nGrammar School",
           x=-3.5,y=.03,col="green4",vjust=0)+
  geom_segment(x=-3.02,xend=-3.5,y=0,yend=0.03,
               col="green4")

(p1 / p2) + plot_layout(heights=c(2,1))
```


::: {.callout-caution collapse="true"}
#### optional: joint distribution of intercept and slopes

When we have random intercepts __and__ slopes in our model, we don't just estimate two separate distributions of intercept deviations and slope deviations. We estimate them as related. 
This comes back to the part of the equation we mentioned briefly above, where we used:  

- $\sigma_0$ to represent the standard deviation of intercept deviations
- $\sigma_1$ to represent the standard deviation of slope deviations
- $\rho \sigma_0 \sigma_1$ to represent the correlation between intercept deviations and slope deviations  

$$
\begin{bmatrix} \zeta_{0i} \\ \zeta_{1i} \end{bmatrix}
\sim N
\left(
    \begin{bmatrix} 0 \\ 0 \end{bmatrix},
    \begin{bmatrix}
        \sigma_0 & \rho \sigma_0 \sigma_1 \\
        \rho \sigma_0 \sigma_1 & \sigma_1
    \end{bmatrix}
\right)
$$
For a visual intuition about this, see @fig-randcor, in which the x-axis is the intercept deviations, and the y-axis is the slope deviations. We can see that these are each distributed normally, but are negatively related (schools with higher intercepts tend to have slightly lower slopes).  

```{r}
#| label: fig-randcor
#| fig-cap: "Intercept deviations (x axis) and slope deviations (y axis). One school is highlighted for comparison with previous plot of fitted values"  
#| echo: false

library(ggside)
pdist = MASS::mvrnorm(1e6, mu=c(0,0),Sigma=VarCorr(rsmod)[[1]]) |>
  as_tibble() |>
  mutate(int=`(Intercept)`)
as.data.frame(ranef(rsmod)$schoolid) |>
  rownames_to_column() |>
  mutate(int=`(Intercept)`) |>
  ggplot(aes(x=int,y=motiv)) +
  guides(col="none")+
  with_blur(geom_point(aes(col=rowname),size=3,alpha=.5),sigma=1) + 
  geom_density2d(data=pdist[1:1e5,]) +
  scale_x_continuous(expression(zeta["0i"]))+
  scale_y_continuous(expression(zeta["1i"]))+
  geom_point(x=6.80639854,y=-3.03100767,col="green4",size=3)+
  annotate("text",label="Hutchesons'\nGrammar School",
           x=9,y=-5,col="green4",vjust=1)+
  geom_segment(x=6.8,xend=9,y=-3.03,yend=-5,
               col="green4") + 
  #with_blur(geom_rug(alpha=.7,aes(col=rowname),lwd=1,
  #                   length = unit(0.05, "npc")),sigma=1) + 
  geom_xsidedensity(data=pdist,fill="#a41ae4", alpha=.4,col=NA)+
  geom_ysidedensity(data=pdist,fill="#a41ae4", alpha=.4, col=NA)+
  theme_ggside_void()
```


:::



<div class="divider div-transparent div-dot"></div>

# Partial pooling

As the multilevel model treats our clusters as a random distribution of deviations around some fixed center, we can think of that fixed center as the 'average cluster'. It's tempting to think that we could get the fixed intercept $\gamma_{00}$ by calculating a simple linear model for each school and taking the average of all the intercepts. However, the multilevel model is much more clever than that. 

The amount by which each cluster contributes to the fixed estimate depends on:    

a) how much between-cluster variation there is relative to within-cluster variation
b) the number of observations in the cluster

This is a really useful feature, because it means that a) the model is more skeptical of clusters with few datapoints than of those with many datapoints, and b) this skepticism is weaker when clusters are in general more distinct from one another than when they are quite similar.  

Another way of thinking about this is by looking at the model predicted lines for each cluster, which are _also_ adjusted in the same way. In @fig-ppool, the blue lines show a simple linear model fitted to the data from each school (no pooling), and the orange lines show our predictions from the model with random intercepts and slopes for each school (partial pooling). 

Note two useful features:  

1. For "Hypothetical School X", which has far fewer datapoints, the multilevel model line is 'shrunk' back towards the average school line. This is good because we intuitively don't want to give as much weight to that school as to the others.
2. It is possible for the multilevel model to estimate a line for "Hypothetical School Y" _even though it only has one datapoint_. This is because these predicted lines "borrow strength" from the other schools.  


```{r}
#| echo: false
#| label: fig-ppool
#| fig-cap: "A set of 6 schools. The blue lines show simple regression models fitted to each schools' data separately (no pooling). The orange lines show the predictions from the multilevel model in which both intercepts and slopes of motiv vary by school (partial pooling)"
set.seed(123)
# sort(unique(schoolmot$schoolid))[c(1:4)]
bind_rows(
  schoolmot,
  tibble(
    schoolid = "Hypothetical School X",
    motiv = c(-1,0.1,1.4)+5,
    grade = 10*motiv + rnorm(3,0,10)
  )
) |> bind_rows(x=_, 
               tibble(schoolid="Hypothetical School Y",motiv = -2+5, grade = 65)
               ) -> tdf 

rsmod2 = lmer(grade~motiv+(1+motiv|schoolid),tdf,
              control=lmerControl(optimizer="bobyqa"))
femod2 = lm(grade~motiv*schoolid,tdf)

feplot = expand_grid(
  schoolid = c(as.character(sort(unique(schoolmot$schoolid))[c(1,4,5,9)]),
               "Hypothetical School X"),
  motiv = seq(0,10,.1)
) %>% mutate(.fitted = predict(femod2, newdata = .)) 


rsplot = 
  as.data.frame(coef(rsmod2)$schoolid) |> 
  rownames_to_column(var="schoolid") |>
  filter(schoolid %in% sort(unique(schoolmot$schoolid))[c(1,4,5,9)] | 
           grepl("Hypothetical", schoolid)) |>
  mutate(data = map2(`(Intercept)`,motiv, ~tibble(x = 0:10, .fitted = ..1 + ..2*(0:10)))) |> 
  unnest(data)

tdf |> 
  filter(schoolid %in% sort(unique(schoolmot$schoolid))[c(1,4,5,9)] | 
           grepl("Hypothetical", schoolid)) |>
  ggplot(aes(x=motiv,y=grade))+
  geom_point()+
  facet_wrap(~schoolid) +
  geom_line(data=feplot,
            aes(y=.fitted),col="blue",lwd=1)+
  geom_line(data=rsplot,
            aes(x=x,y=.fitted),col="darkorange3",lwd=1)+
  ylim(0,100)
```


::: {.callout-tip collapse="true"}
#### A (not very good) analogy

The no-pooling approach (i.e. something like `lm(grade~motiv*schoolid)`, or fitting a simple `lm()` separately to each school) is like the libertarian ideology (valuing autonomy and personal freedom). Each school gets the freedom to define its own line without interference from others.  

The partial-pooling approach (the multilevel model) is more akin to social democracy, where there is a recognition of the value of personal freedoms and diverse perspectives, but this is *within* the framework of a broader societal structure. 

:::


::: {.callout-caution collapse="true"}
#### optional: how does it work?  

The amount to which a cluster contributes to a fixed estimate (and the amount by which any predictions for that cluster are shrunk towards the average) is proportional to:^[this exact formula applies to the model with random intercepts, but the logic scales up when random slopes are added]

$$
\begin{align}
&\frac{\sigma^2_{b} }{\sigma^2_b + \frac{\sigma^2_e }{n_i}} \\
\qquad \\
\text{Where:} \\
& \sigma^2_b = \text{variance between clusters} \\
& \sigma^2_e = \text{variance within clusters} \\
& n_i = \text{number of observations within cluster }i \\
\end{align}
$$

This means that there is less contribution from (and more shrinkage of estimates for) clusters when:

- smaller $n_j$ (we have less information about a cluster)
- when within-cluster variance is large relative to between-cluster variance (clustering is not very informative)

:::

<div class="divider div-transparent div-dot"></div>


# Fitting Multilevel Models in R

While there is a big conceptual shift from the single level regression model to the multilevel model, the shift in R code is considerably less.  

We're going to use the `lme4` package, and specifically the functions `lmer()` and `glmer()`. "(g)lmer" here stands for "(generalised) linear mixed effects regression", and the two functions are designed to be logical extensions of `lm()` and `glm()`.  

```{r}
#| echo: false
#| label: fig-lmercode
#| out-width: "100%"
#| fig-cap: "Syntax of the lmer() function from the lme4 package. For now, focus on the formula section, and how this extends from the lm() function."
knitr::include_graphics("images/lmercode.png")
```

We write the first bit of our **formula** just the same as our old friend the normal linear model `y ~ 1 + x1 + x2 + ...`, where `y` is the name of our outcome variable, `1` is the intercept (which we don't have to explicitly state as it will be included anyway) and `x1`, `x2` etc are the names of our explanatory variables (our predictors).  

With `lmer()`, we have the addition of __random effect terms__, specified in parenthesis with the `|` operator (the vertical line | is often found to the left of the z key on QWERTY keyboards).  
We use the `|` operator to separate the parameters (intercept, slope etc.) on the left-hand side, from the grouping variable(s) on the right-hand side, by which we would like to model these parameters as varying.  

For instance, the two models we have been looking at can be fitted with:  

```{r}
library(lme4)
schoolmot <- read_csv("https://uoepsy.github.io/data/schoolmot.csv")

# a model with random intercepts by school
# (estimate how schools vary in their intercept)
smod1 <- lmer(grade ~ 1 + motiv + (1 | schoolid), 
              data = schoolmot)

# a model with random intercepts and random slopes by school
# (estimate how schools vary in their intercept, and in their slope of motiv)
smod2 <- lmer(grade ~ 1 + motiv + (1 + motiv | schoolid), 
              data = schoolmot)
```


Much like the simple `lm()` models, we can get a nice summary output: 
```{r}
summary(smod2)
```

The output contains two major components - the "fixed effects" and the "random effects". The fixed effects part contains the estimated intercept and slope(s) for the average school. The random effects part contains the estimated variance (and standard deviation^[remember, variance = standard deviation squared]) of school deviations around those fixed estimates.  

So from our ouput we can build up a picture in our heads - we know from the fixed effects that in the average school, children with zero motivation have an estimated grade of `r round(fixef(smod2)[1])`, and for every 1 more motivated a child is, their grades are estimated to increase by `r round(fixef(smod2)[2],2)`.  

The random effects part tells us that we would expect schools to vary in their intercepts with a standard deviation of 12.6, and in their slopes with a standard deviation of 2.1.  

If we recall our rough heuristic about normal distributions - that 95% of the distribution falls within 2 standard deviations, then we can start to build up a picture - we would expect most schools to have intercepts about 25 either side of the fixed intercept, and we would expect most schools to have slopes that are about 4 either side of the fixed slope (so most slopes will be between 0.5 and 8.5 - i.e. most will be positive).  

So what we're getting back to is something a bit like @fig-rslope that we saw earlier - the model provides a description of the population of schools that we have sampled from. To illustrate this more, we could imagine simulating (from our model) 1000 new schools, and plotting their lines, and we would get something like @fig-sim.  

```{r}
#| echo: false
#| label: fig-sim
#| fig-cap: "Model estimated fixed effects, with 1000 simulated hypothetical school lines"
plotlines = MASS::mvrnorm(1000, mu=fixef(smod2),Sigma=VarCorr(smod2)[[1]]) |>
  as.data.frame()

ggplot(schoolmot, aes(x=motiv,y=grade))+
  geom_point(alpha=0)+
  geom_abline(data=plotlines, aes(intercept=`(Intercept)`, slope=motiv),alpha=.05) + 
  geom_vline(xintercept=0,lty="dashed")+
  scale_x_continuous(limits=c(-1,12),breaks=0:10)+
  geom_abline(intercept=fixef(smod2)[1],slope=fixef(smod2)[2], lwd=1, col="#a41ae4") +
  geom_point(x=0,y=fixef(smod2)[1],size=3,col="#a41ae4")+
  annotate("text",x=-.1,y=fixef(smod2)[1],
           label="29.23",size=5,
           hjust=-.2,vjust=1.3,col="#a41ae4",parse=TRUE) +
  geom_segment(x=0,xend=1,
               y=(fixef(smod2) %*% c(1,0))[1],
               yend=(fixef(smod2) %*% c(1,0))[1]) +
  geom_segment(x=1,xend=2,
               y=(fixef(smod2) %*% c(1,1))[1],
               yend=(fixef(smod2) %*% c(1,1))[1]) +
  geom_segment(x=2,xend=3,
               y=(fixef(smod2) %*% c(1,2))[1],
               yend=(fixef(smod2) %*% c(1,2))[1]) + 
  geom_segment(x=3,xend=4,
               y=(fixef(smod2) %*% c(1,3))[1],
               yend=(fixef(smod2) %*% c(1,3))[1]) + 
  geom_segment(x=1,xend=1,
               y=(fixef(smod2) %*% c(1,0))[1],
               yend=(fixef(smod2) %*% c(1,1))[1],col="#a41ae4",lwd=1) +
  geom_segment(x=2,xend=2,
               y=(fixef(smod2) %*% c(1,1))[1],
               yend=(fixef(smod2) %*% c(1,2))[1],col="#a41ae4",lwd=1) +
  geom_segment(x=3,xend=3,
               y=(fixef(smod2) %*% c(1,2))[1],
               yend=(fixef(smod2) %*% c(1,3))[1],col="#a41ae4",lwd=1) +
  geom_segment(x=4,xend=4,
               y=(fixef(smod2) %*% c(1,3))[1],
               yend=(fixef(smod2) %*% c(1,4))[1],col="#a41ae4",lwd=1) +
  annotate("text",x=2.9,y=33,hjust=0,
           label="4.48",size=5,
           col="#a41ae4")+
  geom_segment(x=2,xend=2.7,
               y=36,yend=33,
               col="#a41ae4")
```



::: {.callout-tip collapse="true"}
#### mapping summary output to parts of the equation

```{r}
#| echo: false
#| out-width: "100%"
knitr::include_graphics("images/lmeroutput.png")
```

:::

## Extracting model parameters

Alongside `summary()`, there are some useful functions in R that allow us to extract the parameters estimated by the model: 

:::rtip
__fixed effects__  

The fixed effects represent the estimated average relationship within the entire sample of clusters.

```{r}
fixef(smod2)
```

:::


:::rtip
__random effect variances__  

The random effect variances represent the estimated spread with which clusters vary around the fixed effects

```{r}
VarCorr(smod2)
```

:::

## Making model predictions  

While they are not computed directly in the estimation of the model, the cluster-specific deviations from fixed effects can be extracted from our models   

:::rtip
__random effects__  

Often referred to as the "random effects", the deviations for each cluster from the fixed effects can be obtained using `ranef()`.  
Note that each row is a cluster (a school, in this example), and the columns show the distance from the fixed effects. We can see that "Anderson High School" has an estimated intercept that is 7.07 _higher_ than average, and an estimate slope of motivation that is 0.47 _lower_ than average.  

```{r}
#| eval: false
ranef(smod2)
```
```
$schoolid
                                        (Intercept)       motiv
Anderson High School                     7.07164826 -0.46505592
Ardnamurchan High School                -7.26417838  0.70012536
Balwearie High School                  -20.53626558  2.31397177
Beeslack Community High School          18.63574795 -1.45057126
...                                     ...          ...
```

We can also visualise all these using a handy function. This sort of visualisation is great for checking for peculiar clusters.  
```{r}
dotplot.ranef.mer(ranef(smod2))
```

:::

:::rtip
__cluster coefficients__  

Rather than looking at _deviations_ from fixed effects, we can calculate the intercept and slope for each cluster.  
For example, if we are estimating that "Anderson High School" has an intercept that is 7.07 higher than average, and the average is 29.23, then we know that this has an intercept of 29.23 + 7.07 = 36.3.  

We can get these out using `coef()`
```{r}
#| eval: false
coef(smod2)
```
```
$schoolid
                                    (Intercept)  motiv
Anderson High School                36.304968    4.010661
Ardnamurchan High School            21.969141    5.175842
Balwearie High School                8.697054    6.789689
Beeslack Community High School      47.869068    3.025146
...                                 ...          ...
```
:::sticky
<center>
fixef() + ranef() = coef()
</center>
:::

:::


## A more complex model

The models fitted in the reading thus far are fairly simple in that they only really have one predictor (a measure of a child's education motivation, `motiv`), and our observations (children) happen to be clustered into groups (schools). 

However, the multilevel model can also allow us to study questions that we might have about features of those groups (i.e., things about the schools) and how those relate to observation-level variables (things about the children).  

For instance, we might have questions that take the form:  

- "does [Level-2 variable] predict [Level-1 outcome]?"  
- "does [Level-2 variable] influence the relationship between [Level-1 predictor] and [Level-1 outcome]?  

_(in our example, Level-1 = children, Level-2 = Schools)._  

Consider, for example, if we want to investigate whether the relationship between children's motivation levels and their grades is different depending upon the source of school funding (private vs state).  

Addressing such questions requires a different fixed effect structure in order to allow us to test the relevant estimate of interest. Specifically here we need the interaction between `motiv` and `funding` (private vs state).    

Note that this interaction is 'cross-level'! It allows us to ask whether something about children (the `grade~motiv` relationship) depends upon something about the school they're in (funding type).  

```{r}
smod3 <- lmer(grade ~ motiv * funding + (1 + motiv | schoolid), 
              data = schoolmot)
```

Note, we _cannot_ include `funding` in the random effects part of our model, because "the effect of funding on school grades" is something we assess by comparing _between_ schools. We cannot think of that effect varying by-school because every school is _either_ "private" _or_ "state" funded. We never observe "Ardnamurchan High School" as anything other than "state" funded, so "the effect on grades of being state/private funded" does not exist for Ardnamurchan High School (and hence it is illogical to try and say that this effect varies between schools).  

Our additions to the fixed effects part here simply add in a couple of fixed terms to our model (the `funding` coefficient and the `motiv:funding` interaction coefficient). This means that in terms of our model structure, it is simply moving from the single line we had in @fig-rslopes2, to having two lines (one for "private" schools and one for "state" schools). The random effects are, as before, the variance in deviations of individual schools around these fixed estimates.  


::: {.callout-tip collapse="true"}
#### Model equation

This model is not too much of an extension on our previous equation, but when we move to models with more than 2 levels (e.g., children in schools in districts), these equations can become very cumbersome. 

Additionally, as you become more practiced at fitting multilevel models, you may well begin to think of these models in terms of the `lmer()` syntax in R, rather than in terms of the mathematical expressions. 

This is absolutely fine, and you should feel free to ignore these equations if they are of no help to your understanding!  

Because the `funding` variable is something we measure at Level 2 (schools), in most notations it gets placed in the level 2 equations:  

$$
\begin{align}
\text{For Child }j\text{ in School }i& \\
\text{Level 1 (child):}& \\
\text{grade}_{ij} &= b_{0i} + b_{1i} \cdot \text{motiv}_{ij} + \epsilon_{ij} \\
\text{Level 2 (school):}& \\
b_{0i} &= \gamma_{00} + \zeta_{0i} + \gamma_{01} \cdot \text{Funding}_i\\
b_{1i} &= \gamma_{10} + \zeta_{1i} + \gamma_{11} \cdot \text{Funding}_i\\
\end{align}
$$

It is sometimes easier to think of this in the "mixed effects notation" we saw above, where we substitute the level 2 equations into the level 1 equation, and rearrange to get:  
$$
\begin{align}
&\text{For Child }j\text{ in School }i \\
&\text{grade}_{ij} = (\gamma_{00} + \zeta_{0i}) + \gamma_{01} \cdot \text{Funding}_i + (\gamma_{10} + \zeta_{1i})\cdot \text{motiv}_{ij} + \gamma_{11} \cdot \text{Funding}_i \cdot \text{motiv}_{ij} + \epsilon_{ij} \\
\end{align}
$$
  
::: {.callout-caution collapse="true"}
#### optional: an attempted visual explanation

@fig-crosslev1 shows an attempted visual intuition of how the different parts of the model work:  

```{r}
#| echo: false
#| label: fig-crosslev1
#| fig-cap: "visual explanation of a model with a cross-level interaction"
pschools = c("Kilsyth Academy","St Andrew's Academy","Calderglen High School","St Ambrose High School", "Beeslack Community High School","The Mary Erskine School","Tarbert Academy","Stewarton Academy","St Columba's High School","Castlebrae Community High School","Penicuik High School")

plotlabs = schoolmot |> count(schoolid,funding) |> select(-n) |>
  mutate(motiv=10,x=10)
plotlabs$y = predict(smod3, newdata=plotlabs)

plotlines = as.data.frame(coef(smod3)$schoolid) |> 
  rownames_to_column() |>
  mutate(g = 1:n(),
         funding = ifelse(rowname%in%pschools,"private","state"),
         fundingstate = ifelse(funding=="state",fundingstate,0),
         `motiv:fundingstate` = ifelse(funding=="state",`motiv:fundingstate`,0),
         data = pmap(list(`(Intercept)`,motiv,fundingstate,`motiv:fundingstate`), 
                     ~tibble(x = 0:10, .fitted = ..1 + ..2*(0:10)+..3+(..4)*(0:10)))
  ) |> unnest(data) |>
  select(rowname,g,funding,x,.fitted)

pf <- 
  ggplot(schoolmot, aes(x=motiv,y=grade))+
    geom_point(alpha=.1,aes(col=schoolid)) +
    guides(col="none")+
    geom_vline(xintercept=0,lty="dashed")+
    scale_x_continuous(limits=c(-1,12),breaks=0:10) +
  with_blur(geom_line(data = plotlines, aes(x=x,y=.fitted,group=g,col=funding),alpha=.4),sigma=2) +
  geom_text(data=plotlabs,
            aes(x=x,y=y,label=schoolid,col=funding),
            hjust=0,alpha=.3)+
  geom_abline(intercept=fixef(smod3)[1],slope=fixef(smod3)[2], lwd=1,col="#00a8cc") + 
  geom_abline(intercept=sum(fixef(smod3)[c(1,3)]),slope=sum(fixef(smod3)[c(2,4)]), 
              lwd=1,col="#a41ae4")+
  geom_point(x=0,y=fixef(smod3)[1],size=3,col="#00a8cc")+
 annotate("text",x=-.1,y=fixef(smod3)[1],
         label=expression(gamma["00"]),size=5,
         hjust=-.25,vjust=-.5,col="#00a8cc") +
 geom_segment(x=1,xend=2,
              y=(fixef(smod3)[1:2]%*%c(1,1))[[1]],
              yend=(fixef(smod3)[1:2]%*%c(1,1))[[1]])+
  geom_segment(x=2,xend=2,
              y=(fixef(smod3)[1:2]%*%c(1,1))[[1]],
              yend=(fixef(smod3)[1:2]%*%c(1,2))[[1]],
              col="#00a8cc",lwd=1)+
  geom_segment(x=1,xend=2,
              y=(fixef(smod3)%*%c(1,1,1,1))[[1]],
              yend=(fixef(smod3)%*%c(1,1,1,1))[[1]])+
  geom_segment(x=2,xend=2,
              y=(fixef(smod3)%*%c(1,1,1,1))[[1]],
              yend=(fixef(smod3)%*%c(1,2,1,2))[[1]],
              col="#a41ae4",lwd=1)+
  geom_segment(x=2,xend=2,
              y=(fixef(smod3)%*%c(1,1,1,1))[[1]],
              yend=(fixef(smod3)%*%c(1,2,1,1))[[1]],
              col="#00a8cc",lwd=1)+
  geom_segment(x=1,xend=2,
              y=(fixef(smod3)%*%c(1,1,1,1))[[1]],
              yend=(fixef(smod3)%*%c(1,2,1,1))[[1]],
              col="#00a8cc") +
  geom_segment(x=0.1,xend=0.1,
              y=(fixef(smod3)%*%c(1,0,0,0))[[1]],
              yend=(fixef(smod3)%*%c(1,0,1,0))[[1]],
              col="green4",lwd=1) +
  annotate("text",x=0.1,y=33,
            label=expression(gamma["01"]),size=5,
            hjust=-.3,col="green4") +
  
  annotate("text",x=2,y=(fixef(smod3)%*%c(1,1,0,0))[[1]],
            label=expression(gamma["10"]),size=5,
            hjust=-.2,col="#00a8cc") +
  annotate("text",x=2,y=(fixef(smod3)%*%c(1.1,1,1,1))[[1]],
            label=expression(gamma["11"]),size=5,
            hjust=-.2,col="#a41ae4") +
 #  
 # geom_segment(x=-.2,xend=-.2,y=fixef(smod3)[1],
 #                yend=fixef(smod3)[1]+sqrt(VarCorr(smod3)[[1]][1]),
 #                col="darkorange3",lwd=1) +
 # annotate("text",x=-.2,y=45,
 #            label=expression(sigma["0"]),size=5,
 #            hjust=1.2,col="darkorange3") +
 # geom_segment(x=-.2,xend=-.2,y=sum(fixef(smod3)[c(1,3)]),
 #               yend=sum(fixef(smod3)[c(1,3)])+sqrt(VarCorr(smod3)[[1]][1]),
 #               col="darkorange3",lwd=1) +
 # annotate("text",x=-.2,y=27,
 #           label=expression(sigma["0"]),size=5,
 #           hjust=1.2,col="darkorange3")+
  NULL

pi <- as.data.frame(ranef(smod3)$schoolid) |>
  rownames_to_column() |>
  mutate(funding = ifelse(rowname%in%pschools,"private","state")) |>
  ggplot(aes(x=`(Intercept)`))+
  geom_area(stat = "function", fun = dnorm,args=list(mean=0,sd=sqrt(VarCorr(smod3)[[1]][1,1])),fill="#a41ae4",xlim=c(-30,30),alpha=.3)+
  geom_rug(alpha=.7,aes(col=funding),lwd=1,
                     length = unit(0.05, "npc")) +
  scale_color_manual(values=c("#00a8cc","#a41ae4"))+
  geom_segment(x=0,xend=sqrt(VarCorr(smod3)[[1]][1,1]),
               y=0.005, yend=0.005,
               col="darkorange3",lwd=1)+
  annotate("text",
           y=0.01,x=sqrt(VarCorr(smod3)[[1]][1,1])/2,
           label=expression(sigma["0"]),
           col="darkorange3",size=5)+
  guides(col="none")+
  scale_y_continuous(NULL,breaks=NULL)+
  labs(title="intercept deviations",x=expression(zeta["0i"]))

ps <- as.data.frame(ranef(smod3)$schoolid) |>
  rownames_to_column() |>
  mutate(funding = ifelse(rowname%in%pschools,"private","state")) |>
  ggplot(aes(x=motiv))+
  geom_area(stat = "function", fun = dnorm,args=list(mean=0,sd=sqrt(VarCorr(smod3)[[1]][2,2])),fill="#a41ae4",xlim=c(-6,6),alpha=.3)+
  geom_rug(alpha=.7,aes(col=funding),lwd=1,
                     length = unit(0.05, "npc")) +
  geom_segment(x=0,xend=sqrt(VarCorr(smod3)[[1]][2,2]),
               y=0.03, yend=0.03,
               col="darkorange3",lwd=1)+
  annotate("text",
           y=0.06,x=sqrt(VarCorr(smod3)[[1]][2,2])/2,
           label=expression(sigma["1"]),
           col="darkorange3",size=5)+
  guides(col="none")+
  scale_color_manual(values=c("#00a8cc","#a41ae4"))+
  scale_y_continuous(NULL,breaks=NULL)+
  labs(title="slope deviations",x=expression(zeta["1i"]))

(pf + (pi / ps)) + plot_layout(widths=c(2,1))
```


:::

:::




::::panelset
:::panel
#### model summary

```{r}
summary(smod3)
```

:::
:::panel
#### plot  

For plotting the fixed effect estimates (which are often the bit we're most interested in) from multilevel models, we can't rely on using `predict()`, `fitted()` or `augment()`, as these return to us the cluster-specific predicted values.  

Instead, we need to use tools like the __effects__ package that we saw at the end of the USMR course, that takes a fixed effect and averages over the other terms in the model:  

```{r}
library(effects)
effect(term="motiv*funding",mod=smod3,xlevels=20) |>
  as.data.frame() |>
  ggplot(aes(x=motiv,y=fit,col=funding,fill=funding))+
  geom_line()+
  geom_ribbon(aes(ymin=lower,ymax=upper),alpha=.3)
```

:::
::::


<div class="divider div-transparent div-dot"></div>

# Model Estimation

With single level regression models fitted with `lm()`, our estimated coefficients could actually be obtained using some matrix algebra.   Fitting multilevel models is a bit more complicated, and so we have to instead rely on an iterative procedure known as "maximum likelihood estimation" ("ML" or "MLE").  

We actually saw this previously when fitting logistic regressions. The process is iterative in that it involves testing the fit of a set of candidate parameters (i.e. giving some initial values for our coefficients) and working out what direction we need to change them in order to get a better fit. We then change them accordingly, evalute the fit, change them, evaluate fit, ... and so on until we reach a point where we don't think we can get any better.  

In maximum likelihood estimation, the "fit" of the model is assessed through the _likelihood_ (the probability of seeing our data, given some hypothesis, see [here](lvp.html){target="_blank"} for an explanation). 

If we were estimating just one single parameter (e.g. a mean), then we can imagine the process of maximum likelihood estimation in a one-dimensional world - simply finding the top of the curve (@fig-mle, LH panel).  

However, our typical models estimate a whole bunch of parameters, and with lots of parameters being estimated and all interacting to influence the likelihood, our nice curved line becomes a complex surface (@fig-mle RH panel shows it in 3D). What MLE does is try to find the maximum (the top the mountain), but avoid local maxima (false summits) and impossible values (e.g., variances $\leq 0$), without getting stuck (in plateaus). 
```{r}
#| label: fig-mle
#| echo: false
#| fig-cap: "maximum likelihood estimation in one dimension (LEFT), and a 3D visual of a multi-dimensional likelihood surface (RIGHT)"
knitr::include_graphics("images/mle.png")
```

We can choose whether to estimate our model parameters with ML (maximum likelihood) or REML (restricted maximum likelihood) with the `REML` argument of `lmer()`:  

<br>
<div style="margin-left:50px;">
lmer(*formula*,<br>
&nbsp; &nbsp; &nbsp; &nbsp; data = *dataframe*, <br>
&nbsp; &nbsp; &nbsp; &nbsp; REML = **_logical_**, <br>
&nbsp; &nbsp; &nbsp; &nbsp; control = lmerControl(*options*) <br>
&nbsp; &nbsp; &nbsp; &nbsp; )</div>    
<br>

:::sticky
__TL;DR__  

`lmer()` models are by default fitted with REML, which tends to be better for small samples.    

::: {.callout-caution collapse="true"}
#### optional: why REML?

REML overcomes a problem for multilevel models fitted with standard MLE, which is that at each iteration of the maximum likelihood, the random effect variances are estimated _after_ the fixed effects (because they are the variances of clusters around the fixed effects). This means that we are essentially treating the fixed effects as a known constant when estimating the random effect variance. The downside of this is that it biases our variance estimates to be smaller than they should be^[it's a bit like n-1 being in the denominator of the formula for standard deviation], especially if $n_\textrm{clusters} - n_\textrm{level 2 predictors} - 1 < 50$. This leads to the standard errors of the fixed effects being too small, thereby inflating our type 1 error rate (i.e. greater chance of incorrectly rejecting our null hypothesis).

REML avoids this by first partialling out the fixed effects (i.e. removing all of the association, so that the fixed effects are 0 _by definition_), then using maximum likelihood to iteratively estimate the random effect variances. At the end, it then uses generalised least squares to estimate the fixed effects given the known random effect structure. Because this separates the estimation of fixed and random parts of the model, it results in unbiased estimates of the variance components.   

:::

:::


## convergence warnings & singular fits 

There are different algorithms that we can use to actually undertake the iterative estimation procedure, which we can apply by using different 'optimisers'. 

<br>
<div style="margin-left:50px;">
lmer(*formula*,<br>
&nbsp; &nbsp; &nbsp; &nbsp; data = *dataframe*, <br>
&nbsp; &nbsp; &nbsp; &nbsp; REML = *logical*, <br>
&nbsp; &nbsp; &nbsp; &nbsp; control = lmerControl(**_options_**) <br>
&nbsp; &nbsp; &nbsp; &nbsp; )</div>    
<br>

Technical problems to do with **model convergence** and **'singular fit'** come into play when the optimiser we are using either can't find a suitable maximum, or gets stuck in a plateau, or gets stuck trying to move towards a number that we know isn't possible.  

For large datasets and/or complex models (lots of random-effects terms), it is quite common to get a convergence warning when trying to fit a model, and in the coming weeks you will see plenty of warnings such as:  

- A typical convergence warning:  
<p style="color:red">warning(s): Model failed to converge with max|grad| = 0.0071877 (tol = 0.002, component 1)</p>

- A singular fit:  
<p style="color:red">boundary (singular) fit: see ?isSingular</p>


:::sticky
__Do not trust the results of a model that does not converge__
:::


There are lots of different ways to [deal with these](https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html) (to try to rule out hypotheses about what is causing them), but for the time being, if `lmer()` gives you convergence errors or singular fits, you could try changing the optimizer. Bobyqa is a good one: add `control = lmerControl(optimizer = "bobyqa")` when you run your model.  

```{r eval=F}
lmer(y ~ 1 + x1 + ... + (1 + .... | g), data = df, 
     control = lmerControl(optimizer = "bobyqa"))
```



