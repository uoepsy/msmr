{
  "hash": "ba40fcca8c63a51191405928b6215563",
  "result": {
    "markdown": "---\ntitle: \"Likelihood vs Probability\"\nparams: \n    SHOW_SOLS: TRUE\n    TOGGLE: TRUE\n---\n\n\n\n\n\nUpon hearing the terms \"probability\" and \"likelihood\", people will often tend to interpret them as synonymous. In statistics, however, the distinction between these two concepts is very important (and often misunderstood).  \n\n:::statbox\nIn the statistical framework we have been learning, \"probability\" refers to the chance of observing possible results *if* some certain state of the world were true^[This is the typical frequentist stats view. There are other ways to do statistics (not covered in this course) - e.g., in Bayesian statistics, probability relates to the reasonable expectation (or \"plausibility\") of a belief]\n\nLikelihood refers to the probability of seeing our data, given some hypothesis.  \n\n:::\n\n\n## Setup\n\nLet's consider a coin flip. For a fair coin, the chance of getting a heads/tails for any given flip is 0.5.  \n\nWe can simulate the number of \"heads\" in a single fair coin flip with the following code (because it is a single flip, it's just going to return 0 or 1):\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrbinom(n = 1, size = 1, prob = 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1\n```\n:::\n:::\n\nWe can simulate the number of \"heads\" in 8 fair coin flips with the following code: \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrbinom(n = 1, size = 8, prob = 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3\n```\n:::\n:::\n\nAs the coin is fair, what number of heads would we expect to see out of 8 coin flips? Answer: 4! \nDoing another 8 flips:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrbinom(n = 1, size = 8, prob = 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2\n```\n:::\n:::\n\nand another 8:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrbinom(n = 1, size = 8, prob = 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5\n```\n:::\n:::\n\nWe see that they tend to be around our intuition expected number of 4 heads. We can change `n = 1` to ask `rbinom()` to not just do 1 set of 8 coin flips, but to do 1000 sets of 8 flips:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntable(rbinom(n = 1000, size = 8, prob = 0.5))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  0   1   2   3   4   5   6   7   8 \n  3  35 109 215 270 226 109  31   2 \n```\n:::\n:::\n\n\n## Probability\n\nSo what is the **probability** of observing $k$ heads in $n$ flips of a fair coin?  \n\nAs coin flips are independent, we can calculate probability using the product rule ($P(AB) = P(A)\\cdot P(B)$ where $A$ and $B$ are independent).   \nSo the probability of observing 2 heads in 2 flips is $0.5 \\cdot 0.5 = 0.25$  \n\nWe can get to this probability using `dbinom()`:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndbinom(2, size=2, prob=0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.25\n```\n:::\n:::\n\n\nIn **8** flips, those two heads could occur in various ways:\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div id=\"cwfpegchcn\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#cwfpegchcn table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#cwfpegchcn thead, #cwfpegchcn tbody, #cwfpegchcn tfoot, #cwfpegchcn tr, #cwfpegchcn td, #cwfpegchcn th {\n  border-style: none;\n}\n\n#cwfpegchcn p {\n  margin: 0;\n  padding: 0;\n}\n\n#cwfpegchcn .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#cwfpegchcn .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#cwfpegchcn .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#cwfpegchcn .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#cwfpegchcn .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#cwfpegchcn .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#cwfpegchcn .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#cwfpegchcn .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#cwfpegchcn .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#cwfpegchcn .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#cwfpegchcn .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#cwfpegchcn .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#cwfpegchcn .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#cwfpegchcn .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#cwfpegchcn .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#cwfpegchcn .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#cwfpegchcn .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#cwfpegchcn .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#cwfpegchcn .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#cwfpegchcn .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#cwfpegchcn .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#cwfpegchcn .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#cwfpegchcn .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#cwfpegchcn .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#cwfpegchcn .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#cwfpegchcn .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#cwfpegchcn .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#cwfpegchcn .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#cwfpegchcn .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#cwfpegchcn .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#cwfpegchcn .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#cwfpegchcn .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#cwfpegchcn .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#cwfpegchcn .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#cwfpegchcn .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#cwfpegchcn .gt_left {\n  text-align: left;\n}\n\n#cwfpegchcn .gt_center {\n  text-align: center;\n}\n\n#cwfpegchcn .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#cwfpegchcn .gt_font_normal {\n  font-weight: normal;\n}\n\n#cwfpegchcn .gt_font_bold {\n  font-weight: bold;\n}\n\n#cwfpegchcn .gt_font_italic {\n  font-style: italic;\n}\n\n#cwfpegchcn .gt_super {\n  font-size: 65%;\n}\n\n#cwfpegchcn .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#cwfpegchcn .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#cwfpegchcn .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#cwfpegchcn .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#cwfpegchcn .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#cwfpegchcn .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#cwfpegchcn .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#cwfpegchcn .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#cwfpegchcn div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {\n  height: 0px !important;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Ways to get 2 heads in 8 flips\">Ways to get 2 heads in 8 flips</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"Ways to get 2 heads in 8 flips\" class=\"gt_row gt_left\">TTTTTHHT</td></tr>\n    <tr><td headers=\"Ways to get 2 heads in 8 flips\" class=\"gt_row gt_left\">TTTTTHTH</td></tr>\n    <tr><td headers=\"Ways to get 2 heads in 8 flips\" class=\"gt_row gt_left\">HHTTTTTT</td></tr>\n    <tr><td headers=\"Ways to get 2 heads in 8 flips\" class=\"gt_row gt_left\">TTTHTHTT</td></tr>\n    <tr><td headers=\"Ways to get 2 heads in 8 flips\" class=\"gt_row gt_left\">TTTHTTTH</td></tr>\n    <tr><td headers=\"Ways to get 2 heads in 8 flips\" class=\"gt_row gt_left\">THTTTTTH</td></tr>\n    <tr><td headers=\"Ways to get 2 heads in 8 flips\" class=\"gt_row gt_left\">THTHTTTT</td></tr>\n    <tr><td headers=\"Ways to get 2 heads in 8 flips\" class=\"gt_row gt_left\">THTTTTHT</td></tr>\n    <tr><td headers=\"Ways to get 2 heads in 8 flips\" class=\"gt_row gt_left\">...</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\nAs it happens, there are 28 different ways this could happen.^[If you really want to see them all, try running `combn(8, 2)` in your console.]  \n\nThe probability of getting 2 heads in 8 flips of a fair coin is, therefore:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n28 * (0.5^8)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.109375\n```\n:::\n:::\n\nOr, using `dbinom()`\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndbinom(2, size = 8, prob = 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.109375\n```\n:::\n:::\n\n\n:::imp\nThe important thing here is that when we are computing the probability, two things are fixed: \n\n - the number of coin flips (8)\n - the value(s) that govern the coin's behaviour (0.5 chance of landing on heads for _any given flip_)\n \nWe can then can compute the probabilities for observing various numbers of heads:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndbinom(0:8, 8, prob = 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.00390625 0.03125000 0.10937500 0.21875000 0.27343750 0.21875000 0.10937500\n[8] 0.03125000 0.00390625\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lvp_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=80%}\n:::\n:::\n\nNote that the probability of observing 10 heads in 8 coin flips is 0, as we would hope! \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndbinom(10, 8, prob = 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n:::\n\n## Likelihood \n\nSo how does **likelihood** differ?  \n\nFor likelihood, we are interested in *hypotheses* about or *models* of our coin. Do we think it is a fair coin (for which the probability of heads is 0.5?). Do we think it is biased to land on heads 60% of the time? or 30% of the time? All of these are different 'models'.  \n\nTo consider these hypotheses, we need to observe some data -  we need to have a given number of flips, and the resulting number of heads.  \n\nWhereas when discussing probability, we varied the number of heads, and fixed the parameter that designates the true chance of landing on heads for any given flip, for the likelihood we are fixing the number of heads observed, and can make statements about different possible parameters that might govern the coin's behaviour. \n\nFor example, let's suppose we __did__ observe 2 heads in 8 flips, what is the probability of seeing this data given various parameters?  \n\nHere, our parameter (the probability that we think the coin lands on heads) can take any real number between from 0 to 1, but let's do it for a selection:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npossible_parameters = seq(from = 0, to = 1, by = 0.05)\ndbinom(2, 8, possible_parameters)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 0.000000e+00 5.145643e-02 1.488035e-01 2.376042e-01 2.936013e-01\n [6] 3.114624e-01 2.964755e-01 2.586868e-01 2.090189e-01 1.569492e-01\n[11] 1.093750e-01 7.033289e-02 4.128768e-02 2.174668e-02 1.000188e-02\n[16] 3.845215e-03 1.146880e-03 2.304323e-04 2.268000e-05 3.948437e-07\n[21] 0.000000e+00\n```\n:::\n:::\n\n\nSo what we are doing here is considering the possible parameters that govern our coin. Given that we observed 2 heads in 8 coin flips, it seems very unlikely that the coin weighted such that it lands on heads 80% of the time (e.g., the parameter of 0.8 is not likely). The idea that the coin is fair (0.5 probability) is more likely. The most likely parameter is 0.25 (because $\\frac{2}{8}=0.25$).  \nYou can visualise this below:  \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lvp_files/figure-html/unnamed-chunk-14-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n## A slightly more formal approach\n\nLet $d$ be our data (our _observed_ outcome), and let $\\theta$ be the parameters that govern the data generating process.  \n\nWhen talking about \"probability\" we are talking about $P(d | \\theta)$ for a given value of $\\theta$.  \nE.g. above we were talking about $P(\\text{2 heads in 8 flips}\\vert \\text{fair coin})$.  \n\nIn reality, we don't actually know what $\\theta$ is, but we do observe some data $d$.  \nGiven that we know that _if we have a specific value for $\\theta$_, then $P(d \\vert \\theta)$ will give us the probability of observing $d$, we can ask \"what value of $\\theta)$ will maximise the probability of observing $d$?\".  \nThis will sometimes get written as $\\mathcal{L}(\\theta \\vert d)$ as the \"likelihood function\" of our unknown parameters $\\theta$, conditioned upon our observed data $d$.  \n\n",
    "supporting": [
      "lvp_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}