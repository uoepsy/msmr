{
  "hash": "cd06628dff6580a0c9463199d42427b2",
  "result": {
    "markdown": "---\ntitle: \"1B: Linear Mixed Models/Multi-level Models\"\nparams: \n    SHOW_SOLS: FALSE\n    TOGGLE: TRUE\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n:::{.callout-caution collapse=\"true\"}\n## A Note on terminology\n\nThe methods we're going to start to look at are known by lots of different names (see @fig-wordcloud). The core idea is that **model parameters vary at more than one level.**. \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![size weighted by hits on google scholar search (sept 2020)](01b_lmm_files/figure-html/fig-wordcloud-1.png){#fig-wordcloud fig-align='center' width=80%}\n:::\n:::\n\n\n:::\n\n\n# LMM\n\nIn the simple linear regression model was written as $\\color{red}{y} = \\color{blue}{b_0 + b_1x_1 \\ + \\ ... \\ + \\ b_px_p} \\color{black}{\\ + \\ \\varepsilon}$, the estimated coefficients $\\color{blue}{b_0}$, $\\color{blue}{b_1}$ etc., are estimated as a fixed value.  \n\nIn the example where we model School children's grades as a function of their motivation score, we can fit a simple regression model, and the estimated parameters are two values that define the intercept and the slope of the line in @fig-schoolplot1.  \n \n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Grade predicted by motivation. The simple linear regression model defines the height and slope of the black line.](01b_lmm_files/figure-html/fig-schoolplot1-1.png){#fig-schoolplot1 fig-align='center' width=80%}\n:::\n:::\n\nThese two values are fixed. It does not matter what school a child is from, if they score 0 on the motivation scale, then our model predicts that they will get a grade of 40.3 (the intercept). \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nschoolmot <- read_csv(\"data/schoolmot.csv\")\nsrmod <- lm(grade ~ motiv, data = schoolmot)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n...\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  40.2776     1.8270  22.046  < 2e-16 ***\nmotiv         1.9551     0.3422   5.714  1.5e-08 ***\n---\n```\n:::\n:::\n\n\n\n\n\nthe linear mixed model (LMM) \n\nfits a distribution of intercepts.\na center ( a single value and a spread)\n\nso for a given school, the intercept is b0 + z0i  \na fixed number plus some random deviation\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\nintercepts vary\nslopes vary\n\nno pooling vs partial pooling: \n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\nhow is it different to fixed eff?\n\"partial pooling\" (link back to above)\nshrinkage\n- socialist vs liberal analogy?  \n\nhow/why does it do this?\nby modelling a distribution of lines  \n\n\n$$\n\\begin{align}\\\\\n& \\color{red}{y} = \\color{blue}{b_0 + b_1x_1 \\ + \\ ... \\ + \\ b_px_p} \\color{black}{+ \\varepsilon}\\\\ \n& \\text{Where:} \\\\\n& \\epsilon \\sim N(0, \\sigma) \\text{ independently}\n\\end{align}\n$$\n\n# fitting LMM in R\n\nlme4\nlmer\n\n# model parameters\n\n_what_ are the model parameters? \ni.e. variance components. \n\neq with model params coloured\n$$\n\n$$\n\n\nwe _can_ get out estimates of the specific group-lines if we want, but really the model is estimating the variances. \n\n# terminology: fixed effects, random effects, variance components\n\nwe often use \"random effects\" to just mean the distribution of random deviations. i.e. \n\nsometimes you might hear \n\"random effect of group\"\n\"random effect for group\"\n\"random effect [of x] by group\"\n\ngenerally, people are referring to the `(1 + ... | cluster)` bit. \n\ngraphic on how to read it.\n\nintercept >> 1\nslope of x >> x\n| >> varies by\nthese groups >> cluster\n\na common stumbling block. \n\"effect of x varies by cluster\" is not the same as \"x varies by cluster\".  \n\n\n\n\n\n# estimation\n\n## ML and REML\n\nMLE explainer\n\n- problem for lmm\nest fix > est varcorr > est fix > est varcorr\nest of varcorr assumes fixed effects are known. \nthis biases var ests to be slightly smaller  \na bit like n-1 in formula for sd\n\nREML\n- OLS to partial out fixef > \n  est varcorr > est varcorr > est varcorr > \n  use GLS to est fixef\n- in the estimation of varcorr, the fixed effects are 0 _by definition_\n  \n\n\n\n\n\n\n\n\n\n## fitting issues\n\nconvergence warnings, singular fits \n\n\n\n\n\n\n",
    "supporting": [
      "01b_lmm_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/panelset-0.2.6/panelset.css\" rel=\"stylesheet\" />\r\n<script src=\"site_libs/panelset-0.2.6/panelset.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}