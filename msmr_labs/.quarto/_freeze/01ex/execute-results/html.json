{
  "hash": "4b2b887f34272107271a6854e9fa22c2",
  "result": {
    "markdown": "---\ntitle: \"Week 1 Exercises: Intro to MLM\"\nparams: \n    SHOW_SOLS: TRUE\n    TOGGLE: TRUE\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n\n\n\n::: {.callout-note collapse=\"true\"}\n#### New Packages!\n\nThese are the main packages we're going to use in this block. It might make sense to install them now *if you do not have them already*\n\n+ __tidyverse__ : for organising data  \n+ __lme4__ : for fitting generalised linear mixed effects models\n+ __broom.mixed__ : tidying methods for mixed models\n+ __effects__ : for tabulating and graphing effects in linear models\n+ __lmerTest__: for quick p-values from mixed models\n+ __parameters__: various inferential methods for mixed models\n\n:::\n\n# A Toy Example  \n\n\n\n\n\n\nFor our first foray into the multilevel model, we're going to start with little toy example, and we're just going to ask you to plot the predictions from a) a simple linear model, b) a model with a random intercept, and c) a model with random intercepts and slopes.  \n\nThis is to build the understanding of the structure of multilevel models. When it comes to actually building models for research purposes, it is not necessary to slowly build up the complexity in this way.  \n\n:::frame\n__Data: New Toys!__  \n  \nRecall the example from last semesters' USMR course, where the lectures explored linear regression with a toy dataset of how practice influences the reading age of toy characters (see [USMR Week 7 Lecture](https://uoepsy.github.io/usmr/2324/lectures/lecture06.html#/learning-to-read-1){target=\"_blank\"}). We're going to now broaden our scope to the investigation of how practice affects reading age for **all** toys (not just Martin's Playmobil characters).  \n\nYou can find a dataset at [https://uoepsy.github.io/data/toy2.csv](https://uoepsy.github.io/data/toy2.csv){target=\"_blank\"} containing information on 129 different toy characters that come from a selection of different families/types of toy. You can see the variables in the table below^[Image sources:<br>http://tophatsasquatch.com/2012-tmnt-classics-action-figures/<br>https://www.dezeen.com/2016/02/01/barbie-dolls-fashionista-collection-mattel-new-body-types/<br>https://www.wish.com/product/5da9bc544ab36314cfa7f70c<br>https://www.worldwideshoppingmall.co.uk/toys/jumbo-farm-animals.asp<br>https://www.overstock.com/Sports-Toys/NJ-Croce-Scooby-Doo-5pc.-Bendable-Figure-Set-with-Scooby-Doo-Shaggy-Daphne-Velma-and-Fred/28534567/product.html<br>https://tvtropes.org/pmwiki/pmwiki.php/Toys/Furby<br>https://www.fun.com/toy-story-4-figure-4-pack.html<br>https://www.johnlewis.com/lego-minifigures-71027-series-20-pack/p5079461].  \n<br>  \n\n:::: {.columns}\n::: {.column width=\"45%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/toys.png){fig-align='center' width=300px}\n:::\n:::\n\n:::\n::: {.column width=\"10%\"}\n:::\n::: {.column width=\"45%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div id=\"tmxpldqhmo\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#tmxpldqhmo table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#tmxpldqhmo thead, #tmxpldqhmo tbody, #tmxpldqhmo tfoot, #tmxpldqhmo tr, #tmxpldqhmo td, #tmxpldqhmo th {\n  border-style: none;\n}\n\n#tmxpldqhmo p {\n  margin: 0;\n  padding: 0;\n}\n\n#tmxpldqhmo .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#tmxpldqhmo .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#tmxpldqhmo .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#tmxpldqhmo .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#tmxpldqhmo .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#tmxpldqhmo .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#tmxpldqhmo .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#tmxpldqhmo .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#tmxpldqhmo .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#tmxpldqhmo .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#tmxpldqhmo .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#tmxpldqhmo .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#tmxpldqhmo .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#tmxpldqhmo .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#tmxpldqhmo .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#tmxpldqhmo .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#tmxpldqhmo .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#tmxpldqhmo .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#tmxpldqhmo .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#tmxpldqhmo .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#tmxpldqhmo .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#tmxpldqhmo .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#tmxpldqhmo .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#tmxpldqhmo .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#tmxpldqhmo .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#tmxpldqhmo .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#tmxpldqhmo .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#tmxpldqhmo .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#tmxpldqhmo .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#tmxpldqhmo .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#tmxpldqhmo .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#tmxpldqhmo .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#tmxpldqhmo .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#tmxpldqhmo .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#tmxpldqhmo .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#tmxpldqhmo .gt_left {\n  text-align: left;\n}\n\n#tmxpldqhmo .gt_center {\n  text-align: center;\n}\n\n#tmxpldqhmo .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#tmxpldqhmo .gt_font_normal {\n  font-weight: normal;\n}\n\n#tmxpldqhmo .gt_font_bold {\n  font-weight: bold;\n}\n\n#tmxpldqhmo .gt_font_italic {\n  font-style: italic;\n}\n\n#tmxpldqhmo .gt_super {\n  font-size: 65%;\n}\n\n#tmxpldqhmo .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#tmxpldqhmo .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#tmxpldqhmo .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#tmxpldqhmo .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#tmxpldqhmo .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#tmxpldqhmo .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#tmxpldqhmo .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"variable\">variable</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"description\">description</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">toy_type</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Type of Toy</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">year</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Year Released</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">toy</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Character</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">hrs_week</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Hours of practice per week</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">R_AGE</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Reading Age</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n:::\n::::\n\n:::\n\n\n\n<div class='question-begin'>Question 1</div><div class='question-body'>\n\n\nRead in the data and plot the relationship between hours-per-week practice (`hrs_week`) and reading age (`R_AGE`).  \nFacet the plot by the type of toy.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n\"facet\" is the key word here! See [1A #visualisations](01a_clustered.html#visualisations){target=\"_blank\"}\n\n:::\n\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-1' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-1', 'sol-start-1')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-1\" style=\"display: none;\">\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ntoy2 <- read_csv(\"https://uoepsy.github.io/data/toy2.csv\")\n\nhead(toy2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 5\n  toy_type  year toy    hrs_week R_AGE\n  <chr>    <dbl> <chr>     <dbl> <dbl>\n1 Barbie    1959 Summer     4.04     8\n2 Barbie    1959 Nikki      2.36     6\n3 Barbie    1959 Barbie     4.02     8\n4 Barbie    1959 Midge      4.97     8\n5 Barbie    1959 Teresa     3.37     6\n6 Barbie    1959 Ken        4.56     8\n```\n:::\n\n```{.r .cell-code}\nggplot(toy2,aes(x=hrs_week,y=R_AGE))+\n  geom_point()+\n  facet_wrap(~toy_type)\n```\n\n::: {.cell-output-display}\n![](01ex_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 2</div><div class='question-body'>\n\n\nBelow is the code to fit a simple linear model and produce some diagnostic plots.  \nAfter running the code, do you think that we have violated any assumptions?  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod1 <- lm(R_AGE ~ hrs_week, data = toy2)\nplot(mod1)\n```\n:::\n\n\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-2' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-2', 'sol-start-2')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-2\" style=\"display: none;\">\n\n\nWe have violated an assumption here, and we don't need to look at the plots to realise it! As it happens, the plots don't actually look _terrible_ (the scale-location plot is a bit meh, but other than that things look okay).  \n\nThe assumption we have violated is that of **independence**. This is something we know through our understanding of the sampling procedure that has led to this data. We have got a random sample of different types of toys (e.g. power-rangers, toy-story, furbies etc), and within those types, we have a random sample of characters.  \n\nBut it is entirely likely that the type of toy is going to influence their reading age (i.e. farm animals might read worse than playmobil, etc).  \n\nSo this is something we can't really \"see\" in the data - we have to *think*. What do we know about the data generating process? (i.e. the process that led to this data)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod1 <- lm(R_AGE ~ hrs_week, data = toy2)\nplot(mod1)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](01ex_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 3</div><div class='question-body'>\n\n\nThere are lots of ways in R to get predicted values for a linear model (e.g. we saw `augment()` a lot in USMR). \n\nThe simplest way is to use functions like `predict()` or `fitted()` (they do the same thing), which gives us a vector of predicted values, which we can append to our dataframe (provided we don't have missing data): \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata$predictedvalues <- predict(model)\n```\n:::\n\n\nAdd the predictions from the linear model in the previous question to the facetted plot that you created in the earlier question. How well does the model fit each type of toy?  \n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-3' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-3', 'sol-start-3')\">  1 - add predictions to data</button></div><div class=\"solution-body\" id = \"sol-body-3\" style=\"display: none;\">\n\n\nThis only works because we don't have missing data (and so the length of `predict(mod1)` is the same as `nrow(toy2)`, and the predictions are in the correct order)  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# add predictions to data:\ntoy2$pred <- predict(mod1)\n```\n:::\n\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-4' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-4', 'sol-start-4')\">  2 - add predictions to the plot</button></div><div class=\"solution-body\" id = \"sol-body-4\" style=\"display: none;\">\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# plot both predictions and observations:\ntoy2 |>\n  ggplot(aes(x=hrs_week))+\n  geom_point(aes(y=R_AGE)) + # observations\n  geom_line(aes(y=pred)) + # predictions\n  facet_wrap(~toy_type)\n```\n\n::: {.cell-output-display}\n![](01ex_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n\n<div class='question-begin'>Question 4</div><div class='question-body'>\n\n\nLoad the __lme4__ package, and fit a model with random intercepts for each toy type.  \n\nUsing either `predict()` again, or this time you can use `augment()` from the __broom.mixed__ package, plot the predicted values and the observations.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nYou can see a model with a random intercept fitted in [1B# fitting-multilevel-models-in-r](01b_lmm.html#fitting-multilevel-models-in-r){target=\"_blank\"}.  \n\n:::\n\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-5' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-5', 'sol-start-5')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-5\" style=\"display: none;\">\n\n\n\nHere's our model, with a random intercept by toy-type:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(lme4)\nlibrary(broom.mixed)\n\nmod2 <- lmer(R_AGE ~ 1 + hrs_week + (1 | toy_type), data = toy2)\n```\n:::\n\nWe can use `augment()` from the __broom.mixed__ package, and which gives us the variables in the model along with things like fitted values (in the `.fitted` column)\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\naugment(mod2)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 129 × 14\n  R_AGE hrs_week toy_type .fitted  .resid  .hat  .cooksd .fixed   .mu .offset\n  <dbl>    <dbl> <fct>      <dbl>   <dbl> <dbl>    <dbl>  <dbl> <dbl>   <dbl>\n1     8     4.04 Barbie      7.43  0.574  0.158 0.0144     7.14  7.43       0\n2     6     2.36 Barbie      6.23 -0.229  0.183 0.00282    5.94  6.23       0\n3     8     4.02 Barbie      7.41  0.587  0.158 0.0151     7.12  7.41       0\n4     8     4.97 Barbie      8.09 -0.0855 0.170 0.000354   7.80  8.09       0\n5     6     3.37 Barbie      6.95 -0.950  0.161 0.0404     6.66  6.95       0\n# ℹ 124 more rows\n# ℹ 4 more variables: .sqrtXwt <dbl>, .sqrtrwt <dbl>, .weights <dbl>,\n#   .wtres <dbl>\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\naugment(mod2) |>\n  ggplot(aes(x=hrs_week))+\n  geom_point(aes(y=R_AGE)) + # observations\n  geom_line(aes(y=.fitted)) + # predictions\n  facet_wrap(~toy_type)\n```\n\n::: {.cell-output-display}\n![](01ex_files/figure-html/unnamed-chunk-15-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\nNote that the model predictions are now a lot better than they were for the single level linear model. The line has moved up for the \"Scooby Doos\", and down for the \"Farm Animals\", etc. But the lines are all still the same slope. The slope is \"fixed\".  \n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n\n<div class='question-begin'>Question 5</div><div class='question-body'>\n\n\nNow fit a model with random intercepts *and* slopes for each toy type. \n\nAs before, plot the predicted values of this model alongside the observations\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-6' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-6', 'sol-start-6')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-6\" style=\"display: none;\">\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod3 <- lmer(R_AGE ~ 1 + hrs_week + (1 + hrs_week| toy_type), \n             data = toy2)\n\naugment(mod3) |>\n  ggplot(aes(x=hrs_week))+\n  geom_point(aes(y=R_AGE)) + # observations\n  geom_line(aes(y=.fitted)) + # predictions\n  facet_wrap(~toy_type)\n```\n\n::: {.cell-output-display}\n![](01ex_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\nThis looks even better - the lines are at good heights and good angles for each type of toy. Why? Because we have modelled the intercept (line height) and slope of `hrs_week` (line angle) as varying across types of toy!  \n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n\n<div class='question-begin'>Question 6</div><div class='question-body'>\n\n\nFinally, add a `geom_smooth` to the plot from the previous question (making sure that this is has `y=R_AGE`).  \nThis will add a separate linear model `lm()` line for each of the facets in the plot.  \n\nWhat differences (look closely!) do you notice between the predictions from the model with random intercepts and slopes, and the simple geom_smooths? \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nYou could try changing `col`, `lty`, and `lwd` to make things easier to see.  \n\nWhat we're doing here is showing to ourselves 'partial pooling' in action ([1B #partial-pooling](01b_lmm.html#partial-pooling){target=\"_blank\"}).  \n\n:::\n\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-7' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-7', 'sol-start-7')\">  1 - adding geom_smooths to the plot</button></div><div class=\"solution-body\" id = \"sol-body-7\" style=\"display: none;\">\n\n\nhere's the model we are using:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod3 <- lmer(R_AGE ~ 1 + hrs_week + (1 + hrs_week| toy_type), \n             data = toy2)\n```\n:::\n\n\nand here is our plot:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\naugment(mod3) |>\n  ggplot(aes(x=hrs_week))+\n  geom_point(aes(y=R_AGE)) + # observations\n  geom_line(aes(y=.fitted)) + # predictions\n  geom_smooth(aes(y=R_AGE), method=lm, se=F) + # simple smooths\n  facet_wrap(~toy_type)\n```\n\n::: {.cell-output-display}\n![](01ex_files/figure-html/unnamed-chunk-18-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-8' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-8', 'sol-start-8')\">  2 - why?</button></div><div class=\"solution-body\" id = \"sol-body-8\" style=\"display: none;\">\n\n\nI've made it a bit clearer here by changing up the colours and  linewidths (`lwd`), and subsetting to just a select few of the toy types:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\naugment(mod3) |>\n  filter(toy_type %in% c(\"Farm Animals\",\"Scooby Doo\",\"Sock Puppets\",\"Polly Pocket\")) |>\n  ggplot(aes(x=hrs_week))+\n  geom_point(aes(y=R_AGE), alpha=.2) + # observations\n  geom_line(aes(y=.fitted), col=\"orange\", lwd=1) + # predictions\n  geom_smooth(aes(y=R_AGE), method=lm, se=F, lty=\"dashed\") + # simple smooths\n  facet_wrap(~toy_type)\n```\n\n::: {.cell-output-display}\n![](01ex_files/figure-html/unnamed-chunk-19-1.png){fig-align='center' width=80%}\n:::\n:::\n\nFor most of the toy types things look pretty similar. However, for \"Sock Puppets\" (only has 3 data points) the model predicted slope is shrunk back towards the average. \nIt is also possible to see this in the \"Farm Animals\" and \"Scooby Doo\" - the shrinkage is more noticeable on these because they are further away from the average. \n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n\n<div class='question-begin'>Question 7</div><div class='question-body'>\n\n\nHere is the model with the random intercepts (but not random slopes) that we fitted in an earlier question.  \n\nBelow is the code that produces a plot of the fitted values: \n\n::: {.callout-note collapse=\"true\"}\n#### A. Model Equation\n\n$$\n\\begin{align}\n\\text{For Toy }j\\text{ of Type }i & \\\\\n\\text{Level 1 (Toy):}& \\\\\n\\text{R\\_AGE}_{ij} &= b_{0i} + b_1 \\cdot \\text{hrs\\_week}_{ij} + \\epsilon_{ij} \\\\\n\\text{Level 2 (Type):}& \\\\\nb_{0i} &= \\gamma_{00} + \\zeta_{0i} \\\\\n\\text{Where:}& \\\\\n\\zeta_{0i} &\\sim N(0,\\sigma_{0}) \\\\\n\\varepsilon &\\sim N(0,\\sigma_{e}) \\\\\n\\end{align}\n\n$$  \n  \n  \n:::\n::: {.callout-note collapse=\"true\"}\n#### B. Model output\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod2 <- lmer(R_AGE ~ 1 + hrs_week + (1 | toy_type), \n             data = toy2)\nsummary(mod2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: R_AGE ~ 1 + hrs_week + (1 | toy_type)\n   Data: toy2\n\nREML criterion at convergence: 544.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.8809 -0.4687  0.0541  0.5579  3.3220 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n toy_type (Intercept) 7.278    2.698   \n Residual             2.550    1.597   \nNumber of obs: 129, groups:  toy_type, 20\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)   4.2594     0.9157   4.652\nhrs_week      0.7118     0.1651   4.312\n\nCorrelation of Fixed Effects:\n         (Intr)\nhrs_week -0.736\n```\n:::\n:::\n\n\n:::\n::: {.callout-note collapse=\"true\"}\n#### C. Plot of fitted values\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\naugment(mod2) |>\n  ggplot(aes(x=hrs_week, col=toy_type))+\n  geom_point(aes(y=R_AGE),alpha=.3) + # observations\n  geom_line(aes(y=.fitted)) + # predictions \n  geom_abline(intercept = fixef(mod2)[1], \n              slope = fixef(mod2)[2], lwd=1) +  # fixed effect line\n  guides(col=\"none\") + # remove legend\n  xlim(0,7) # extent to x=0\n```\n\n::: {.cell-output-display}\n![](01ex_files/figure-html/unnamed-chunk-21-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n:::\n\nMatch the parameters from the model equation, as well as coefficients from model output, to the corresponding points on the plot of fitted values.  \n\n:::: {.columns}\n::: {.column width=\"20%\"}\n__Model Equation__  \n\n+ **A1:** $\\sigma_{0}$   \n+ **A2:** $\\sigma_{\\varepsilon}$  \n+ **A3:** $\\gamma_{00}$  \n+ **A4:** $b_{1}$  \n\n:::\n::: {.column width=\"20%\"}\n__Model Output__  \n\n+ **B1:** 0.7118  \n+ **B2:** 2.698  \n+ **B3:** 1.597  \n+ **B4:** 4.2594  \n\n:::\n::: {.column width=\"60%\"}\n__Plot of fitted values__  \n\n+ **C1:** the standard deviation of the distances from all the individual toy types lines to the black line  \n+ **C2:** where the black line cuts the y axis  \n+ **C3:** the slope of the black line  \n+ **C4:** the standard deviation of the distances from all the individual observations to the line for the toy type to which it belongs.  \n\n\n\n\n:::\n\n::::\n\n\n\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-9' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-9', 'sol-start-9')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-9\" style=\"display: none;\">\n\n\n\n- A1 = B2 = C1\n- A2 = B3 = C4\n- A3 = B4 = C2\n- A4 = B1 = C3\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n\n<br>\n<div class=\"divider div-transparent div-dot\"></div>\n\n\n# Audio Interference in Executive Functioning\n\n\n\n\n\n:::frame\n__Data: Audio interference in executive functioning__  \n\nThis data is from a simulated study that aims to investigate the following research question: \n\n> How do different types of audio interfere with executive functioning, and does this interference differ depending upon whether or not noise-cancelling headphones are used? \n\n30 healthy volunteers each completed the Symbol Digit Modalities Test (SDMT) - a commonly used test to assess processing speed and motor speed - a total of 15 times. During the tests, participants listened to either no audio (5 tests), white noise (5 tests) or classical music (5 tests). Half the participants listened via active-noise-cancelling headphones, and the other half listened via speakers in the room. Unfortunately, lots of the tests were not administered correctly, and so not every participant has the full 15 trials worth of data.  \n\nThe data is available at [https://uoepsy.github.io/data/efsdmt.csv](https://uoepsy.github.io/data/efsdmt.csv).  \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div id=\"fptnpbqagc\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#fptnpbqagc table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#fptnpbqagc thead, #fptnpbqagc tbody, #fptnpbqagc tfoot, #fptnpbqagc tr, #fptnpbqagc td, #fptnpbqagc th {\n  border-style: none;\n}\n\n#fptnpbqagc p {\n  margin: 0;\n  padding: 0;\n}\n\n#fptnpbqagc .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#fptnpbqagc .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#fptnpbqagc .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#fptnpbqagc .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#fptnpbqagc .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#fptnpbqagc .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#fptnpbqagc .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#fptnpbqagc .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#fptnpbqagc .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#fptnpbqagc .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#fptnpbqagc .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#fptnpbqagc .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#fptnpbqagc .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#fptnpbqagc .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#fptnpbqagc .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#fptnpbqagc .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#fptnpbqagc .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#fptnpbqagc .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#fptnpbqagc .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#fptnpbqagc .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#fptnpbqagc .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#fptnpbqagc .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#fptnpbqagc .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#fptnpbqagc .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#fptnpbqagc .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#fptnpbqagc .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#fptnpbqagc .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#fptnpbqagc .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#fptnpbqagc .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#fptnpbqagc .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#fptnpbqagc .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#fptnpbqagc .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#fptnpbqagc .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#fptnpbqagc .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#fptnpbqagc .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#fptnpbqagc .gt_left {\n  text-align: left;\n}\n\n#fptnpbqagc .gt_center {\n  text-align: center;\n}\n\n#fptnpbqagc .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#fptnpbqagc .gt_font_normal {\n  font-weight: normal;\n}\n\n#fptnpbqagc .gt_font_bold {\n  font-weight: bold;\n}\n\n#fptnpbqagc .gt_font_italic {\n  font-style: italic;\n}\n\n#fptnpbqagc .gt_super {\n  font-size: 65%;\n}\n\n#fptnpbqagc .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#fptnpbqagc .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#fptnpbqagc .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#fptnpbqagc .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#fptnpbqagc .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#fptnpbqagc .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#fptnpbqagc .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"variable\">variable</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"description\">description</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">PID</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Participant ID</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">audio</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Audio heard during the test ('no_audio', 'white_noise','music')</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">headphones</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Whether the participant listened via speakers in the room or via noise cancelling headphones</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">SDMT</td>\n<td headers=\"description\" class=\"gt_row gt_left\">Symbol Digit Modalities Test (SDMT) score</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n\n:::\n\n\n\n<div class='question-begin'>Question 8</div><div class='question-body'>\n\n\nHow many participants are there in the data?   \nHow many have complete data (15 trials)?  \nWhat is the average number of trials that participants completed? What is the minimum?   \nDoes every participant have _some_ data for each type of audio?  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nFunctions like `table()` and `count()` will likely be useful here. \n:::\n\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-10' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-10', 'sol-start-10')\">  1 - read in the data </button></div><div class=\"solution-body\" id = \"sol-body-10\" style=\"display: none;\">\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nefdat <- read_csv(\"https://uoepsy.github.io/data/efsdmt.csv\")\nhead(efdat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 4\n  PID    audio       headphones      SDMT\n  <chr>  <chr>       <chr>          <dbl>\n1 PPT_15 no_audio    speakers          37\n2 PPT_22 no_audio    anc_headphones    55\n3 PPT_21 no_audio    anc_headphones    40\n4 PPT_20 no_audio    anc_headphones    36\n5 PPT_20 no_audio    anc_headphones    30\n6 PPT_05 white_noise speakers          30\n```\n:::\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-11' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-11', 'sol-start-11')\">  2 - how many ppts?</button></div><div class=\"solution-body\" id = \"sol-body-11\" style=\"display: none;\">\n\n\nFor a quick \"how many?\", functions like `n_distinct()` can be handy:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nn_distinct(efdat$PID)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 30\n```\n:::\n:::\n\n\nWhich is essentially the same as asking: \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nunique(efdat$PID) |> length()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 30\n```\n:::\n:::\n\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-12' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-12', 'sol-start-12')\">  3 - how many observations per ppt?</button></div><div class=\"solution-body\" id = \"sol-body-12\" style=\"display: none;\">\n\n\nHere are the counts of trials for each participant. \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nefdat |> \n  count(PID)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 30 × 2\n  PID        n\n  <chr>  <int>\n1 PPT_01    13\n2 PPT_02    12\n3 PPT_03    10\n4 PPT_04    10\n5 PPT_05    10\n# ℹ 25 more rows\n```\n:::\n:::\n\n\nWe can pass that to something like `summary()` to get a quick descriptive of the `n` column, and so we can see that no participant completed all 15 trials (max is 14). Everyone completed at least 10, and the median was 12. \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nefdat |> \n  count(PID) |>\n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     PID                  n     \n Length:30          Min.   :10  \n Class :character   1st Qu.:11  \n Mode  :character   Median :12  \n                    Mean   :12  \n                    3rd Qu.:13  \n                    Max.   :14  \n```\n:::\n:::\n\n\nWe could also do this easily with things like:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntable(efdat$PID) |> median()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 12\n```\n:::\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-13' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-13', 'sol-start-13')\">  4 - how many observations for each audio type per ppt?</button></div><div class=\"solution-body\" id = \"sol-body-13\" style=\"display: none;\">\n\n\nFor this kind of thing I would typically default to using `table()` for smaller datasets, to see how many datapoints are in each combination of `PID` and `audio`:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntable(efdat$PID, efdat$audio)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        \n         music no_audio white_noise\n  PPT_01     4        5           4\n  PPT_02     5        4           3\n  PPT_03     3        2           5\n  PPT_04     3        4           3\n  PPT_05     5        2           3\n  PPT_06     4        4           5\n  PPT_07     4        3           4\n  PPT_08     4        4           5\n  PPT_09     5        4           5\n  PPT_10     4        5           4\n  PPT_11     4        4           4\n  PPT_12     4        5           5\n  PPT_13     4        4           3\n  PPT_14     3        5           4\n  PPT_15     4        5           4\n  PPT_16     4        4           3\n  PPT_17     5        4           5\n  PPT_18     5        3           3\n  PPT_19     3        5           3\n  PPT_20     4        4           5\n  PPT_21     3        5           4\n  PPT_22     4        4           3\n  PPT_23     3        3           4\n  PPT_24     4        5           5\n  PPT_25     4        4           5\n  PPT_26     5        4           5\n  PPT_27     5        2           4\n  PPT_28     4        4           4\n  PPT_29     4        4           4\n  PPT_30     2        5           3\n```\n:::\n:::\n\n\nFrom the above, we can see that everyone has data from $\\geq 2$ trials for a given audio type.  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntable(efdat$PID, efdat$audio) |> min()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2\n```\n:::\n:::\n\n\n\n::: {.callout-tip collapse=\"true\"}\n#### a tidyverse way:\n\nWhen tables get too big, we can do the same thing with `count()`, but we need to make sure that we are working with factors, in order to summarise all possible combinations of groups (even empty ones)\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nefdat |> \n  mutate(PID = factor(PID),\n         audio = factor(audio)) |>\n  # the .drop=FALSE means \"keep empty groups\"\n  count(PID,audio,.drop=FALSE) |> \n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      PID             audio          n    \n PPT_01 : 3   music      :30   Min.   :2  \n PPT_02 : 3   no_audio   :30   1st Qu.:4  \n PPT_03 : 3   white_noise:30   Median :4  \n PPT_04 : 3                    Mean   :4  \n PPT_05 : 3                    3rd Qu.:5  \n PPT_06 : 3                    Max.   :5  \n (Other):72                               \n```\n:::\n:::\n\n\nThere are plenty of other ways (e.g., you could use combinations of `group_by()`, `summarise()`), so just pick one that makes sense to you.  \n\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n\n<div class='question-begin'>Question 9</div><div class='question-body'>\n\n\nConsider the following questions about the study:  \n  \n- What is our outcome of interest?  \n- What variables are we seeking to investigate in terms of their impact on the outcome?    \n- What are the units of observations?  \n- Are the observations clustered/grouped? In what way?  \n- What varies *within* these clusters?  \n- What varies *between* these clusters?  \n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-14' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-14', 'sol-start-14')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-14\" style=\"display: none;\">\n\n\n\n- What is our outcome of interest?  \n    + __SDMT scores__  \n- What variables are we seeking to investigate in terms of their impact on the outcome?  \n    + __audio type__ and the interaction __audio type $\\times$ wearing headphones__\n- What are the units of observations?  \n    + __individual trials__  \n- What are the groups/clusters?  \n    + __participants__  \n- What varies *within* these clusters?  \n    + __the type of audio__    \n- What varies *between* these clusters?  \n    + __whether they listen via headphones or speakers__  \n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 10</div><div class='question-body'>\n\n\nCalculate the ICC, using the `ICCbare()` function from the **ICC** package.  \n\nHow much of the variation in SDMT scores is attributable to participant level differences?  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nSee [1A #icc](01a_clustered.html#icc---quantifying-clustering-in-an-outcome-variable){target=\"_blank\"}, or look up the help documentation for `?ICCbare()`.  \n\n:::\n\n  \n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-15' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-15', 'sol-start-15')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-15\" style=\"display: none;\">\n\n\n44% of the variance in SDMT scores is attributable to participant level differences.  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(ICC)\nICCbare(x = PID, y = SDMT, data = efdat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.4363587\n```\n:::\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 11</div><div class='question-body'>\n\n\nThe multilevel model that has only an intercept (and the grouping structure) specified is sometimes referred to as the \"null model\" (or \"intercept only model\").  \nBecause there are no predictors in the fixed effects there is just a single value (the intercept). All of the variance in the outcome gets modelled in the random effects part, and is partitioned into either 'variance between groups' or 'residual variance'. This means we can just use those estimates to calculate the ICC.  \n\nFor our executive functioning study, fit the null model use the output to calculate the ICC.  \nCompare it to the answer from the previous question (it should be pretty close!)\n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/nullmod.png){fig-align='center' width=80%}\n:::\n:::\n\n\nThe formula for the ICC is:  \n$$\nICC = \\frac{\\sigma^2_{b}}{\\sigma^2_{b} + \\sigma^2_e} = \\frac{\\text{between-group variance}}{\\text{between-group variance}+\\text{within-group variance}}\n$$\n\n\n:::\n\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-16' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-16', 'sol-start-16')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-16\" style=\"display: none;\">\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnullmod <- lmer(SDMT ~ 1 + (1 | PID), data = efdat)\nsummary(nullmod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: SDMT ~ 1 + (1 | PID)\n   Data: efdat\n\nREML criterion at convergence: 2664.6\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.58680 -0.68262  0.03241  0.65701  2.26736 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n PID      (Intercept) 62.02    7.875   \n Residual             79.82    8.934   \nNumber of obs: 360, groups:  PID, 30\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)   34.789      1.514   22.98\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n$\\frac{62.02}{62.02+79.82} = 0.44$, or 44% of the variance in SDMT scores is explained by participant differences.  \n\nThis matches (closely enough) with the `ICCbare()` function from the previous question! \n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 12</div><div class='question-body'>\n\n\nMake factors and set the reference levels of the `audio` and `headphones` variables to \"no audio\" and \"speakers\" respectively.    \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nCan't remember about setting factors and reference levels? Check back to USMR materials!  \n\n:::\n\n\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-17' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-17', 'sol-start-17')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-17\" style=\"display: none;\">\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nefdat <- efdat %>%\n  mutate(\n    audio = fct_relevel(factor(audio), \"no_audio\"),\n    headphones = fct_relevel(factor(headphones), \"speakers\")\n  )\n```\n:::\n\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n\n<div class='question-begin'>Question 13</div><div class='question-body'>\n\n\nFit a multilevel model to address the aims of the study (copied below)\n\n> How do different types of audio interfere with executive functioning, and does this interference differ depending upon whether or not noise-cancelling headphones are used? \n \nSpecifying the model may feel like a lot, but try splitting it into three parts:  \n\n$$\n\\text{lmer(}\\overbrace{\\text{outcome }\\sim\\text{ fixed effects}}^1\\, + \\, (1 + \\underbrace{\\text{slopes}}_3\\, |\\, \\overbrace{\\text{grouping structure}}^2 )\n$$\n\n\n1. Just like the `lm()`s we have used in USMR, think about what we want to _test_. This should provide the outcome and the structure of our fixed effects.  \n2. Think about how the observations are clustered/grouped. This should tell us how to specify the grouping structure in the random effects.  \n3. Think about which slopes (i.e. which terms in our fixed effects) could feasibly vary between the clusters. This provides you with what to put in as random slopes.  \n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-18' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-18', 'sol-start-18')\">  1 - fixed effects</button></div><div class=\"solution-body\" id = \"sol-body-18\" style=\"display: none;\">\n\n\n\nThe question  \n&nbsp;&nbsp;&nbsp; \"*How do different types of audio interfere with executive functioning*\"   means we are interested in the effects of audio type (`audio`) on executive functioning (`SDMT` scores), so we will want:\n\n```\nlmer(SDMT ~ audio ...\n```\n\nHowever, the research aim also asks    \n&nbsp;&nbsp;&nbsp; \"*... and does this interference differ depending upon whether or not noise-cancelling headphones are used?*\"  \nwhich suggests that we are interested in the interaction `SDMT ~ audio * headphones`  \n\n```\nlmer(SDMT ~ audio * headphones + ...   \n```\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-19' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-19', 'sol-start-19')\">  2 - hierarchical data structure</button></div><div class=\"solution-body\" id = \"sol-body-19\" style=\"display: none;\">\n\n\n\nThere are lots of ways that our data is grouped.  \nWe have:  \n\n- 3 different groups of audio type (no_audio, white_noise, music)\n- 2 groups of listening condition (speakers, anc_headphones)\n- 30 groups of participants (\"PPT_01\", \"PPT_02\", \"PPT_03\", ...) \n\nThe effects of audio type and headphones are both things we actually want to _test_ - these variables are in our fixed effects. The levels of audio and headphones are not just a random sample from a wider population of levels - they're a specific set of things we want to compare SDMT scores between.  \n\nCompare this with the participants - we don't care about if there is a difference in SDMT scores between e.g., \"PPT_03\" and \"PPT_28\". The participants themselves are just a sample of people that we have taken from a wider population. This makes thinking of \"by-participant random effects\" a sensible approach - we model differences between participants as a normal distribution of deviations around some average:    \n\n```\nlmer(SDMT ~ audio * headphones + (1 + ... | PID)  \n```\n\nThe minimum that we can include is the random intercept. What `(1|PID)` specifies is that \"participants vary in their SDMT scores\". This makes sense - we would expect some participants to have higher executive functioning (and so will tend to score high on the SDMT), and others to have lower functioning (and so tend to score lower).  \n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-20' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-20', 'sol-start-20')\">  3 - random slopes</button></div><div class=\"solution-body\" id = \"sol-body-20\" style=\"display: none;\">\n\n\n\nWe can also include a random by-participant effect of `audio`.  \n`audio|PID` specifies that the effect of audio type on SDMT varies by participant. This seems feasible - music might be very distracting (and interfere a lot with the test) for some participants, but have a negligible effect for others.  \n\n```\nlmer(SDMT ~ audio * headphones + \n              (1 + audio | PID), data = efdat)\n```\n\n\n::: {.callout-tip collapse=\"true\"}\n#### Why can't we have `(headphones|PID)`?  \n\nWhy can we fit `(1 + audio | PID)` but not `(1 + headphones | PID)`, or both `(1 + audio + headphones | PID)` or `(1 + audio * headphones | PID)`?  \n\nRemember that `y ~ ... + (x | g)` is saying \"the slope of y~x varies by g\".  \nSuch a sentence only makes sense if each \"the slope of y~x\" is defined for every (or most) groups.  \n\nFor the `headphones` predictor, every participant is _either_ in the \"speakers\" condition _or_ the \"anc_headphones\" condition.  \nThis means that \"the effect of headphones on SDMT\" _doesn't exist_ for any single participant! This means it makes no sense to try and think of the effect as 'varying by participant'.  \n\nCompare this to the `audio` predictor, for the effect _does_ exist for a single given participant, therefore it is possible to think of it as being different for different participants (e.g. PPT_30's performance improves with white noise, but PPT_16's performance does not).  \n\nThe plots below may help to cement this idea:  \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](01ex_files/figure-html/unnamed-chunk-39-1.png){fig-align='center' width=80%}\n:::\n\n::: {.cell-output-display}\n![](01ex_files/figure-html/unnamed-chunk-39-2.png){fig-align='center' width=80%}\n:::\n:::\n\n\n:::\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n\n\n<div class='question-begin'>Question 14</div><div class='question-body'>\n\n\nWe now have a model, but we don't have any p-values or confidence intervals or anything - i.e. we have no inferential criteria on which to draw conclusions. There are a whole load of different methods available for drawing inferences from multilevel models, which means it can be a bit of a never-ending rabbit hole. For now, we'll just use the 'quick and easy' approach provided by the **lmerTest** package seen in the lectures.  \n\nUsing the **lmerTest** package, re-fit your model, and you should now get some p-values! \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nIf you use `library(lmerTest)` to load the package, then *every single* model you fit will show p-values calculated with the Satterthwaite method.  \nPersonally, I would rather this is not the case, so I often opt to fit specific models with these p-values without ever loading the package:  \n`modp <- lmerTest::lmer(y ~ 1 + x + ....`  \n\n:::\n\n::: {.callout-caution collapse=\"true\"}\n#### optional: a model comparison\n\nIf we want to go down the model comparison route, we just need to isolate the relevant part(s) of the model that we are interested in.  \n\nRemember, as we saw in USMR, model comparison is sometimes a useful way of testing a _set_ of coefficients. For instance, in this example the interaction involves estimating _two_ terms: \n`audiomusic:headphonesanc_headphones` and `audiowhite_noise:headphonesanc_headphones`.  \n\nTo test the interaction as a whole, we can create a model without the interaction, and then compare it. The `SATmodcomp()` function from the __pbkrtest__ package provides a way of conducting an F test with the same Satterthwaite method of approximating the degrees of freedom:  \n  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsdmt_mod <- lmer(SDMT ~ audio * headphones + \n              (1 + audio | PID), data = efdat)\nsdmt_res <- lmer(SDMT ~ audio + headphones + \n                   (1 + audio | PID), data = efdat)\nlibrary(pbkrtest)\nSATmodcomp(largeModel = sdmt_mod, smallModel = sdmt_res)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nlarge : SDMT ~ audio * headphones + (1 + audio | PID)\nsmall (restriction matrix) : \n                             \n 0 0 0 0 0.8936904 -0.4486841\n 0 0 0 0 0.4486841  0.8936904\n     statistic    ndf    ddf   p.value    \n[1,]    11.051  2.000 26.909 0.0003136 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n:::\n\n\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-21' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-21', 'sol-start-21')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-21\" style=\"display: none;\">\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsdmt_mod <- lmerTest::lmer(SDMT ~ audio * headphones + \n              (1 + audio | PID), data = efdat)\n\nsummary(sdmt_mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: SDMT ~ audio * headphones + (1 + audio | PID)\n   Data: efdat\n\nREML criterion at convergence: 2376.2\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.34520 -0.62861  0.05762  0.60807  2.21250 \n\nRandom effects:\n Groups   Name             Variance Std.Dev. Corr       \n PID      (Intercept)      51.17    7.153               \n          audiomusic       13.69    3.700     0.03      \n          audiowhite_noise 15.22    3.901    -0.25 -0.16\n Residual                  31.49    5.612               \nNumber of obs: 360, groups:  PID, 30\n\nFixed effects:\n                                          Estimate Std. Error       df t value\n(Intercept)                               33.25799    1.98897 28.22064  16.721\naudiomusic                                -8.01731    1.41149 27.58766  -5.680\naudiowhite_noise                          -0.03044    1.44502 26.32588  -0.021\nheadphonesanc_headphones                   6.85313    2.81170 28.19226   2.437\naudiomusic:headphonesanc_headphones       -3.58748    2.00129 27.94011  -1.793\naudiowhite_noise:headphonesanc_headphones  8.02458    2.04498 26.46166   3.924\n                                          Pr(>|t|)    \n(Intercept)                               3.54e-16 ***\naudiomusic                                4.58e-06 ***\naudiowhite_noise                          0.983354    \nheadphonesanc_headphones                  0.021355 *  \naudiomusic:headphonesanc_headphones       0.083875 .  \naudiowhite_noise:headphonesanc_headphones 0.000556 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) audmsc adwht_ hdphn_ adms:_\naudiomusic  -0.174                            \naudiowht_ns -0.352  0.192                     \nhdphnsnc_hd -0.707  0.123  0.249              \nadmsc:hdph_  0.123 -0.705 -0.135 -0.173       \nadwht_ns:h_  0.249 -0.136 -0.707 -0.351  0.191\n```\n:::\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n\n<div class='question-begin'>Question 15</div><div class='question-body'>\n\n\n\nWe've already seen in the example with the toys (above) that we can visualise the fitted values (model predictions) using things like `augment()` from the __broom.mixed__ package. But these were plotting all the cluster-specific values (i.e. our random effects), and what we are really interested in are the estimates of (and uncertainty around) our fixed effects.  \n\nUsing tools like the __effects__ package can provide us with the values of the outcome across levels of a specific fixed predictor (holding other predictors at their mean).   \n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-22' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-22', 'sol-start-22')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-22\" style=\"display: none;\">\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(effects)\neffect(term = \"audio*headphones\", mod = sdmt_mod) |>\n  as.data.frame() |>\n  ggplot(aes(x=audio,y=fit,\n             ymin=lower,ymax=upper,\n             col=headphones))+\n  geom_pointrange(size=1,lwd=1)\n```\n\n::: {.cell-output-display}\n![](01ex_files/figure-html/unnamed-chunk-42-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n\n<div class='question-begin'>Question 16</div><div class='question-body'>\n\n\nNow we have some p-values and a plot, try to create a short write-up of the analysis and results.   \n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-23' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-23', 'sol-start-23')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-23\" style=\"display: none;\">\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n:::int\nSDMT scores were modelled using linear mixed effects regression, with fixed effects of audio-type (no audio/white noise/music, treatment coded with no audio as the reference level), audio delivery (speakers/ANC-headphones, treatment coded with speakers as the reference level) and their interaction. Participant-level random intercepts and random slopes of audio-type were also included. The model was fitted using the **lme4** package in R, and estimated with restricted estimation maximum likelihood (REML). Denominator degrees of freedom for all tests were approximated using the Satterthwaite method.  \n\nInclusion of the interaction between headphones and audio-type was found to improve model fit ($F(2, 26.9) = 11.05, p < .001$), suggesting that the interference of different types of audio on executive functioning is dependent upon whether the audio is presented through ANC-headphones or through speakers.  \nParticipants not wearing headphones and presented with no audio scored on average 33.26 on the SDMT. Listening to music via speakers was associated with lower scores ($b = -8.02, t(27.59)=-5.68, p <0.001$) compared to no audio. White noise played via speakers was not associated with a difference in performance on the SDMT compared to no audio.  \n\nWithout any audio playing, wearing ANC-headphones was associated with higher SDMT scores compared to no headphones ($b = 6.85, t(28.19)=2.44, p =0.021$). This difference between headphones and speakers was also evident when listening to white-noise ($b = 8.02, t(26.46)=3.92, p <0.001$). The apparent detrimental influence of music was not found to differ depending on whether headphones were worn ($b = -3.59, p =0.084$). \n\nThese results suggest that while music appears to interfere with executive functioning (resulting in lower SDMT scores) regardless of whether it is heard through headphones or speakers, listening to white noise may actually improve executive functioning, but only when presented via headphones. Furthermore, there appears to be benefits for executive functioning from wearing ANC-headphones even when not-listening to audio, perhaps due to the noise cancellation. The pattern of findings are displayed in @fig-efplot.  \n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Interaction between the type (no audio/white noise/music) and the delivery (speakers/ANC headphones) on executive functioning task (SDMT)](01ex_files/figure-html/fig-efplot-1.png){#fig-efplot fig-align='center' width=80%}\n:::\n:::\n\n:::\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [
      "01ex_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/panelset-0.2.6/panelset.css\" rel=\"stylesheet\" />\r\n<script src=\"site_libs/panelset-0.2.6/panelset.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}