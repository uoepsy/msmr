{
  "hash": "c8ae0640d9e3dc69afad077897f9fa0d",
  "result": {
    "markdown": "---\ntitle: \"Week 8 Exercises: CFA\"\nparams: \n    SHOW_SOLS: TRUE\n    TOGGLE: TRUE\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n:::frame\n__New packages__  \n\nMake sure you have these packages installed:  \n\n+ lavaan\n+ semPlot\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n#### the language of diagrams\n\nIt is common to think about confirmatory factor models (and structural equation models, which we will go on to learn about) in terms of the connections between variables when drawn on a whiteboard (*and* those that are left undrawn). By representing a theoretical model as paths to and from different variables, we open up a whole new way of thinking about how we model the world around us. These _\"path diagrams\"_ have different shapes and symbols to denote the covariances, regressions, observed variables and latent variables.  \n\n- **Observed variables** are represented by squares or rectangles. These are the named variables of interest which exist in our dataset - i.e. the ones which we have measured directly. \n- **Latent variables** are represented as ovals/ellipses or circles. These are unobserved variables that we can only reason about and have not (or cannot) directly measured.  \n- **Covariances** are represented by double-headed arrows. In many diagrams these are curved.  \n- **Regressions** are shown by single headed arrows (e.g., an arrow from $x$ to $y$ for the path $y \\sim x$). **Factor loadings** are also regression paths - specifying a factor structure is simply to say that some measured variables $y_1\\,,\\, ...\\, ,\\, y_k$ are each regressed onto some unmeasured factor(s). The formula $y_1 = \\lambda_1 \\cdot F + u_1$ looks an awful lot like $y = b \\cdot x + \\epsilon$, we just do not observe $F$!.  \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Path/SEM diagrams contain various shapes and symbols to represent different types of variable and the relationships between them.](images/semdiag.png){#fig-diagsem fig-align='center' width=80%}\n:::\n:::\n\n\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n#### PCA as a diagram\n\n__Used for:__  \nReducing from a lot of correlated variables down to a smaller set of orthogonal (uncorrelated) components that capture a substantial amount of the variance. The components we get out are a bit like \"composites\" - they are a weighted sum of the original variables, and can be useful in subsequent analyses. For instance, if you have 20 predictors in a linear regression model that are highly correlated with one another (remember multicollinearity?), you might be able to instead use a small number of orthogonal components! \n\n__As a diagram__  \nNote that the idea of a 'composite' requires us to use a special shape (the hexagon), but many people would just use a square.\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/diag_pca.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n::: {.callout-caution collapse=\"true\"}\n#### optional: PCA in full\n\nPrincipal components sequentially capture the orthogonal (i.e., perpendicular) dimensions of the dataset with the most variance. The data reduction comes when we retain fewer components than we have dimensions in our original data. So if we were being pedantic, the diagram for PCA would look something like the diagram below. If the idea of 'dimensions' of a dataset is still a bit confusing, you can see a fun 3-dimensional explanation here: [PCA in 3D](00_pca.html){target=\"_blank\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/diag_pca2.png){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n\n:::\n::: {.callout-note collapse=\"true\"}\n#### EFA as a diagram\n\n__Used for:__  \nEFA is generally used with the aim of understanding the underlying constructs or latent variables that may be driving observed patterns of responses or behaviors. Often used in construction of questionnaires, scale development, and in the initial stages of developing theoretical frameworks.  \n\n__As a diagram__  \nExploratory Factor Analysis as a diagram has arrows going from the factors to the observed variables. Unlike PCA, we also have 'uniqueness' factors for each variable, representing the various stray causes that are specific to each variable. Sometimes, these uniqueness are represented by an arrow only, but they are technically themselves latent variables, and so can be drawn as circles. \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/diag_efa1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nWhen we apply a rotation to an EFA, we make it so that some loadings are smaller and some are higher - essentially creating a 'simple structure' (where each variable loads strongly on only one factor and weakly on all other factors). This structure simplifies the interpretation of factors, making them more distinct and easily understandable. With oblique rotations, we also allow factors to be correlated, as indicated by the double headed arrow between them in the diagram below\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/diag_efa2.png){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n::: {.callout-note collapse=\"true\"}\n#### CFA as a diagram\n\n__Used for:__  \nCFA is a method that allows us to assess the validity of a hypothesized factor structure (or to compare competing hypothesized structures). Typically factor structures fitted are ones that have been proposed based on theory or on previous research. \n\n__As a diagram__  \nThe diagram for a Confirmatory Factor Analysis model looks very similar to that of an exploratory factor analysis, but we now have the explicit absence of some arrows - i.e. a variable loads on to a specific factor (or factor**s** - we can have a variable that loads on multiple), and **not** on others.  \n\nNote that this is a change from the 'exploratory' nature of EFA, to a situation in which we are explicitly imposing a theoretical model on the data.  \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/diag_cfa.png){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n\n\n# Conduct Problems \n\n:::frame\n__Data: conduct_problems_2.csv__  \n\nLast week we conducted an exploratory factor analysis of a dataset to try and identify an optimal factor structure for a new measure of conduct (i.e., antisocial behavioural) problems. \n\nThis week, we'll conduct some confirmatory factor analyses (CFA) of the same inventory to assess the extent to which this 2-factor structure fits an independent sample. To do this, we have administered our measure to a new sample of n=600 adolescents. \n\nWe have re-ordered the questionnaire items to be grouped into the two types of behaviours:\n\n::::{.columns}\n:::{.column width=\"47.5%\"}\n__Non-Aggressive Behaviours__  \n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> item </th>\n   <th style=\"text-align:left;\"> behaviour </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> item 1 </td>\n   <td style=\"text-align:left;\"> Stealing </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> item 2 </td>\n   <td style=\"text-align:left;\"> Lying </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> item 3 </td>\n   <td style=\"text-align:left;\"> Skipping school </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> item 4 </td>\n   <td style=\"text-align:left;\"> Vandalism </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> item 5 </td>\n   <td style=\"text-align:left;\"> Breaking curfew </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n:::\n:::{.column width=\"5%\"}\n:::\n:::{.column width=\"47.5%\"}\n__Aggressive Behaviours__  \n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> item </th>\n   <th style=\"text-align:left;\"> behaviour </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> item 6 </td>\n   <td style=\"text-align:left;\"> Threatening others </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> item 7 </td>\n   <td style=\"text-align:left;\"> Bullying </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> item 8 </td>\n   <td style=\"text-align:left;\"> Spreading malicious rumours </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> item 9 </td>\n   <td style=\"text-align:left;\"> Using a weapon </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> item 10 </td>\n   <td style=\"text-align:left;\"> Fighting </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n:::\n::::\n\nThe data are available as a **.csv** at [https://uoepsy.github.io/data/conduct_problems_2.csv](https://uoepsy.github.io/data/conduct_problems_2.csv) \n\n:::\n\n\n\n\n<div class='question-begin'>Question 1</div><div class='question-body'>\n\n\nRead in the data. Take a look at the correlation matrix.  \n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-1' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-1', 'sol-start-1')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-1\" style=\"display: none;\">\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ncp2 <- read_csv(\"https://uoepsy.github.io/data/conduct_problems_2.csv\")\n\ncor(cp2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           item1     item2      item3     item4     item5      item6     item7\nitem1  1.0000000 0.5254249 0.43498606 0.4831121 0.5644047 0.13450795 0.2806369\nitem2  0.5254249 1.0000000 0.50099054 0.5119842 0.6740107 0.15239358 0.3031997\nitem3  0.4349861 0.5009905 1.00000000 0.4897339 0.5990709 0.09463966 0.2557407\nitem4  0.4831121 0.5119842 0.48973386 1.0000000 0.6199783 0.14847703 0.2492471\nitem5  0.5644047 0.6740107 0.59907089 0.6199783 1.0000000 0.11353641 0.3112458\nitem6  0.1345080 0.1523936 0.09463966 0.1484770 0.1135364 1.00000000 0.5461757\nitem7  0.2806369 0.3031997 0.25574075 0.2492471 0.3112458 0.54617567 1.0000000\nitem8  0.2576481 0.2748175 0.19355398 0.2553712 0.2463290 0.59441335 0.8009591\nitem9  0.2444337 0.2759875 0.20798523 0.2260156 0.2333758 0.36915878 0.5988582\nitem10 0.1783069 0.1618631 0.12924914 0.1433759 0.1394748 0.46316014 0.5316143\n           item8     item9    item10\nitem1  0.2576481 0.2444337 0.1783069\nitem2  0.2748175 0.2759875 0.1618631\nitem3  0.1935540 0.2079852 0.1292491\nitem4  0.2553712 0.2260156 0.1433759\nitem5  0.2463290 0.2333758 0.1394748\nitem6  0.5944133 0.3691588 0.4631601\nitem7  0.8009591 0.5988582 0.5316143\nitem8  1.0000000 0.6169829 0.5557168\nitem9  0.6169829 1.0000000 0.3613253\nitem10 0.5557168 0.3613253 1.0000000\n```\n:::\n:::\n\n\nJust from the visual, it looks like the same factor structure is present in this sample.  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(ggcorrplot)\nggcorrplot(cor(cp2))\n```\n\n::: {.cell-output-display}\n![](08ex_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 2</div><div class='question-body'>\n\n\nFit the proposed 2 factor model in __lavaan__.  \n\n\n::: {.callout-note collapse=\"true\"}\n#### The lavaan package\n\nFor the remaining weeks of the course, we're going to rely heavily on the **lavaan** (**La**tent **Va**riable **An**alysis) package. \nThis is the main package in R for fitting structural equation models, and there is a huge scope of what we can do with it.  \n\n__Operators in lavaan__  \n  \nThe first thing to get to grips with is the various new operators which __lavaan__ allows us to use.   \n\nOur standard multiple regression formula in R was specified as \n\n```\ny ~ x1 + x2 + x3 + ...\n```\n\nIn lavaan, we continue to fit regressions using the `~` symbol, but we can also specify the construction of latent variables using `=~` and residual variances & covariances using `~~`.  \n\n|  Formula type|  Operator|  Mnemonic|\n|--:|--:|--:|\n|  latent variable definition|  `=~`|  \"is measured by\"|\n|  regression|  `~`|  \"is regressed on\"|\n|  (residual) (co)variance |  `~~`|  \"is correlated with\"|\n|  intercept |  `~1`|  \"has an intercept\"|\n|  defined parameters | `:=` | \"is defined as\" |\n\n(from https://lavaan.ugent.be/tutorial/syntax1.html) \n\n__Fitting models with lavaan__\n\nIn practice, fitting models in lavaan tends to be a little different from things like `lm()` and `(g)lmer()`. Instead of including the model formula *inside* the fit function (e.g., `lm(y ~ x1 + x2, data = df)`), we tend to do it in a step-by-step process. This is because as our models become more complex, our formulas can pretty long!   \n\nIn lavaan, it is typical to write the model as a character string (e.g. `model <- \"y ~ x1 + x2\"`) and then we pass that formula along with the data to the relevant __lavaan__ function such as `cfa()` or `sem()`, giving it the formula and the data: `cfa(model, data = mydata)`.  \n\n1. Specify the model:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmymodel <- \"\n  factor1 =~ item1 + item2 + .....\n  factor2 =~ item6 + ...... \n  ...\n  ..\n\"\n```\n:::\n\n2. Estimate the model (other fitting functions include `sem()`, `growth()` and `lavaan()`):\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmyfittedmodel <- cfa(mymodel, data = mydata)\n```\n:::\n\n3. Examine the fitted model: \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(myfittedmodel)\n```\n:::\n\n\nThe output of the `summary()` will show you each estimated parameter in your model. It groups these according to whether they are loadings onto latent variables, covariances, regressions, variances etc.  \n:::\n  \n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-2' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-2', 'sol-start-2')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-2\" style=\"display: none;\">\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(lavaan)\ncpmod <- \"\n  # the non-aggressive problems factor\n  nonagg =~ item1 + item2 + item3 + item4 + item5\n\n  # the aggressive problems factor\n  agg =~ item6 + item7 + item8 + item9 + item10\n\n  # covariance between the two factors\n  # (this is included by default in cfa)\n  agg ~~ nonagg\n\"\n\ncpmod.est <- cfa(cpmod, data = cp2)\n\nsummary(cpmod.est)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nlavaan 0.6.17 ended normally after 27 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        21\n\n  Number of observations                           600\n\nModel Test User Model:\n                                                      \n  Test statistic                                65.765\n  Degrees of freedom                                34\n  P-value (Chi-square)                           0.001\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  nonagg =~                                           \n    item1             1.000                           \n    item2             1.217    0.076   15.965    0.000\n    item3             1.012    0.070   14.424    0.000\n    item4             1.146    0.077   14.967    0.000\n    item5             1.360    0.078   17.412    0.000\n  agg =~                                              \n    item6             1.000                           \n    item7             1.419    0.082   17.331    0.000\n    item8             1.437    0.081   17.662    0.000\n    item9             1.093    0.077   14.125    0.000\n    item10            0.950    0.073   13.073    0.000\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  nonagg ~~                                           \n    agg               0.156    0.023    6.856    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .item1             0.574    0.037   15.398    0.000\n   .item2             0.477    0.035   13.778    0.000\n   .item3             0.551    0.036   15.262    0.000\n   .item4             0.597    0.040   14.867    0.000\n   .item5             0.264    0.028    9.537    0.000\n   .item6             0.561    0.035   16.193    0.000\n   .item7             0.228    0.021   10.767    0.000\n   .item8             0.153    0.019    8.122    0.000\n   .item9             0.566    0.035   15.978    0.000\n   .item10            0.587    0.036   16.351    0.000\n    nonagg            0.453    0.052    8.701    0.000\n    agg               0.381    0.045    8.396    0.000\n```\n:::\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 3</div><div class='question-body'>\n\n\nLatent variable models like CFA come with a whole bucket load of 'fit indices' as metrics of how well our model is reflecting the observed data.  \n\nWe can get out these indices by either asking for the most common fit indices to be printed inside all of our summary output:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(myfittedmodel, fit.measures = TRUE)\n```\n:::\n\nOr by asking for _all_ available indices with:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfitmeasures(myfittedmodel)\n# to get just a select few, we can index the desired ones:\nfitmeasures(myfittedmodel)[c(\"rmsea\",\"srmr\",\"tli\",\"cfi\")]\n```\n:::\n\n\nExamine the fit of the 2-factor model of conduct problems to this new sample of 600 adolescents.  \n\n\n::: {.callout-note collapse=\"true\"}\n#### \"Model Fit\" \n\nYou'll have heard the term \"model fit\" many times when learning about statistics. However, the exact meaning of the phrase is different for different modelling frameworks.\n\nWe can think more generally as \"model fit\" as asking \"how well does our model reproduce the characteristics of the data that we observed?\". In things like multiple regression, this has been tied to the question of \"how much variance can we explain in outcome $y$ with our set of predictors?\"^[or in logistic regression, \"what is the likelihood of observing the outcome $y$ given our model parameters?\"].  \n\nFor methods like CFA, path analysis and SEM, we are working with models that run on covariances matrices, so \"model fit\" becomes \"how well can our model reproduce our observed covariance matrix?\".   \n\n:::\n\n::: {.callout-note collapse=\"true\"}\n#### Degrees of Freedom\n\nIn regression, we could only talk about model fit if we had more than 2 datapoints. This is because there is only one possible line that we can fit between 2 datapoints, and this line explains _all_ of the variance in the outcome variable (it uses up all our 2 degrees of freedom to estimate 1) the intercept and 2) the slope).   \n\nThe logic is the same for model fit in terms of CFA and SEM - we need more degrees of freedom than we have parameters that are estimated. \n\nThe difference is that it is all in terms of our covariance matrix, rather than individual observations. The idea is that we need to be estimating fewer paths (e.g. parameters) than there are variances/covariances in our covariance matrix. This is because if we just fit paths between all our variables, then our model would be able to reproduce the data perfectly (just like a regression with 2 datapoints has an $R^2$ of 1).  \n\n\nThe degrees of freedom for methods like CFA, Path and SEM, that are fitted to the covariance matrix of our data, correspond to the number of *knowns* (observed covariances/variances from our sample) minus the number of *unknowns* (parameters to be estimated by the model). \n\n- **degrees of freedom = number of knowns - number of unknowns**  \n  - number of knowns: how many variances/covariances in our data?  \n  The number of knowns in a covariance matrix of $k$ observed variables is equal to $\\frac{k \\cdot (k+1)}{2}$.  \n  - number of unknowns: how many parameters is our model estimating?  \n  We can reduce the number of unknowns (thereby getting back a degree of freedom) by fixing parameters to be specific values. *By removing a path altogether, we are fixing it to be zero.*  \n\nA model is only able to be estimated if it has at least 0 degrees of freedom (if there are as many knowns as unknowns). A model with 0 degrees of freedom is termed **just-identified**. An **under-identified** model is one with $<0$ degrees of freedom, and an **over-identified** one has $>0$ degrees of freedom.  \n\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n#### Fit Indices\n\nThere are _loads_ of different metrics that people use to examine model fit for CFA and SEM, and there's lots of debate over the various merits and disadvantages as well as the proposed cut-offs to be used with each method.  \n\nThe most fundamental test of model fit is a $\\chi^2$ test, which reflects the discrepancy between our observed covariance matrix and the *model-implied* covariance matrix. If we denote the population covariance matrix as $\\Sigma$ and the model-implied covariance matrix as $\\Sigma(\\Theta)$, then we can think of the null hypothesis here as $H_0: \\Sigma - \\Sigma(\\Theta) = 0$. In this way our null hypothesis is that our theoretical model is correct (and can therefore perfectly reproduce the covariance matrix), therefore a significant result indicates _poor_ fit. It is very sensitive to departures from normality, as well as sample size (for models with $n>400$, the $\\chi^2$ is almost always significant), and can often lead to rejecting otherwise adequate models.  \n\nAlongside this, the main four fit indices that are commonly used are known as RMSEA, SRMR, CFI and TLI. Smaller values of RMSEA and SRMR mean better fit while larger values of CFI and TLI mean better fit.  \n\n**Convention:** if $\\textrm{RMSEA} < .05$, $\\textrm{SRMR} < .05$, $\\textrm{TLI} > .95$ and $\\textrm{CFI} > .95$ then the model fits well.  \n\n::: {.callout-caution collapse=\"true\"}\n#### optional: absolute fit indices\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/fitmeas_abs.PNG){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n::: {.callout-caution collapse=\"true\"}\n#### optional: incremental fit indices\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/fitmeas_inc.PNG){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n\n\n\n\n:::\n\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-3' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-3', 'sol-start-3')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-3\" style=\"display: none;\">\n\n\n\nOur model fits well by all metrics!  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfitmeasures(cpmod.est)[c(\"srmr\",\"rmsea\",\"cfi\",\"tli\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      srmr      rmsea        cfi        tli \n0.03454489 0.03945991 0.98862263 0.98494172 \n```\n:::\n:::\n\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n\n<div class='question-begin'>Question 4</div><div class='question-body'>\n\n\nTake a look at the loadings of our variables on to the latent factors (these are in the `estimate` column under \"Latent Variables\" in the `summary()`).  \n\nIn EFA, our factor loadings were always <1, because they were _standardised_ loadings (where the factor and item were both standardised to have a variance of 1). Because a latent variable is unobserved, it's actually up to us how we define its scale! \nIn CFA, the default is to make it have the same scale as its first item, which is why the first loading for each factor is exactly 1, and has no standard error associated with it - it's _fixed_, rather than estimated.  \n\n\n::: {.callout-note collapse=\"true\"}\n#### Latent Variable Scaling\n\nin @fig-df1, we can see a the model of a latent factor loading on to 4 items. The number of paths to be estimated here is greater than the number of known covariances. However, we can get around this by *fixing certain parameters to be specific values*. In @fig-df2, the latent factor variance is set at 1, and the residual factor loadings are also set to 1.  \nThis has the additional benefit of making our latent factor have some defining features. Because we don't actually measure the latent variable (it is a hypothetical construct), it doesn't really have any intrinsic 'scale'. When we fix the variance to be 1, we are providing some property (its variance) we create a reference from which the other paths to/from the variable are in relation to. A common alternative is to fix the factor loading of the first item to be 1 (see @fig-df3).\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![A four item factor structure. There are 10 knowns, but 13 parameters](images/cfa_df1.png){#fig-df1 fig-align='center' width=80%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![A four item factor structure. By fixing 5 of these parameters to be equal to 1, we gain back degrees of freedom and make our model identifiable](images/cfa_df2.png){#fig-df2 fig-align='center' width=80%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![A four item factor structure. The 'marker method' fixes the first factor loading to be 1, leaving the factor variance free to be estimated.](images/cfa_df3.png){#fig-df3 fig-align='center' width=80%}\n:::\n:::\n\n\n:::\n\n\n\n\n\nFit the model again, (assign it a new name so we can compare), but this time use:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncfa(model_syntax, data = ..., std.lv = TRUE)\n```\n:::\n\n\nDo the fit measures such as TLI, CFI, RMSEA, SRMR etc., change at all? \nDo the loadings change at all? Can you see a link between these loadings and those from the previously fitted model?  \n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-4' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-4', 'sol-start-4')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-4\" style=\"display: none;\">\n\n\n\nHere's our original model:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncpmod.est <- cfa(cpmod, data = cp2)\n```\n:::\n\nHere's our model with `std.lv=TRUE`:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncpmod.est2 <- cfa(cpmod, data = cp2, std.lv=TRUE)\n```\n:::\n\n\nThe fit is identical! This is much like how `lm(y~x)` and `lm(scale(y)~scale(x))` are one and the same model - the difference only comes in the estimates being transformed to be in different scales.  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfitmeasures(cpmod.est)[c(\"srmr\",\"rmsea\",\"tli\",\"cfi\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      srmr      rmsea        tli        cfi \n0.03454489 0.03945991 0.98494172 0.98862263 \n```\n:::\n\n```{.r .cell-code}\nfitmeasures(cpmod.est2)[c(\"srmr\",\"rmsea\",\"tli\",\"cfi\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      srmr      rmsea        tli        cfi \n0.03454489 0.03945991 0.98494172 0.98862263 \n```\n:::\n:::\n\n\nThe loadings from the model with `std.lv=TRUE` are all <1. \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(cpmod.est2)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n...\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  nonagg =~                                           \n    item1             0.673    0.039   17.402    0.000\n    item2             0.819    0.039   21.024    0.000\n    item3             0.681    0.038   17.816    0.000\n    item4             0.771    0.041   18.876    0.000\n    item5             0.915    0.036   25.425    0.000\n  agg =~                                              \n    item6             0.618    0.037   16.793    0.000\n    item7             0.877    0.033   26.319    0.000\n    item8             0.887    0.032   28.087    0.000\n    item9             0.675    0.038   17.875    0.000\n    item10            0.587    0.037   15.872    0.000\n\n...\n```\n:::\n:::\n\n\nTaking just the first factor, note that the first loading is 0.673. _Relative to this loading_, the other loadings of 0.819, 0.681, 0.771, 0.915, are all bigger. How much bigger?  \nIf we divide each one by that first loading, we get their size relative to that loading - these are the same as our unstandardised loadings!  \n\n$\\frac{0.819}{0.673}=1.217$  \n$\\frac{0.681}{0.673}=1.012$  \n$\\frac{0.771}{0.673}=1.146$  \n$\\frac{0.915}{0.673}=1.360$  \n\n\nNote also that we now have _fixed_ values for the variances of the latent factors, which previously were being estimated for us.\n\nIn the second model, with `std.lv=TRUE`: \n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n...\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n    nonagg            1.000                           \n    agg               1.000                           \n...\n```\n:::\n:::\n\n\nAnd in the first: \n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n...\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n    nonagg            0.453    0.052    8.701    0.000\n    agg               0.381    0.045    8.396    0.000\n...\n```\n:::\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question Optional 5</div><div class='question-body'>\n\n\nWe don't actually even have to re-fit the model in order to get out standardised estimates.  \n\nTry doing:  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmod.est <- cfa(model_syntax, data = ...)\nsummary(mod.est, std=TRUE)\n```\n:::\n\n\nYou'll get some extra columns - can you figure out what they are?  \n\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-5' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-5', 'sol-start-5')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-5\" style=\"display: none;\">\n\n\n\nBack to our original model fit:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncpmod.est <- cfa(cpmod, data = cp2)\n```\n:::\n\n\nWe get out an extra couple of columns here. \nOne of which we have already seen - the `Std.lv` column contains the same numbers from the previous question. The numbers in the `Std.all` column are similar, but not quite the same.  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(mod.est, std=TRUE)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n...\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  nonagg =~                                                             \n    item1             1.000                               0.673    0.664\n    item2             1.217    0.076   15.965    0.000    0.819    0.765\n    item3             1.012    0.070   14.424    0.000    0.681    0.676\n    item4             1.146    0.077   14.967    0.000    0.771    0.706\n    item5             1.360    0.078   17.412    0.000    0.915    0.872\n  agg =~                                                                \n    item6             1.000                               0.618    0.636\n    item7             1.419    0.082   17.331    0.000    0.877    0.878\n    item8             1.437    0.081   17.662    0.000    0.887    0.915\n    item9             1.093    0.077   14.125    0.000    0.675    0.668\n    item10            0.950    0.073   13.073    0.000    0.587    0.608\n\n...\n```\n:::\n:::\n\n\nThe `Std.lv` column represents when the latent variables are scaled to have a variance of 1, but the measured variables variances are not.  \nThe `Std.all` column represents when *both* latent variables *and* measured variable are scaled to have variances of 1.  \n\nThis means that if we _first_ standardised all our observed variables manually, and _then_ fitted our model to that data, then the `Std.lv` and `Std.all` columns would be identical.  \n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 6</div><div class='question-body'>\n\n\nMake a diagram of your model, using the standardised factor loadings as labels.  \n\n\n::: {.callout-note collapse=\"true\"}\n#### The semPlot package\n\nFor more complex models with latent variables, we will almost always have to make diagrams manually, either in generic presentation software such as powerpoint or google slides, or in specific software such as [semdiag](https://semdiag.psychstat.org/){target=\"_blank\"}.  \n\nR has a couple of packages which work well enough for some of the more common model structures such as CFA.  \n\nThe `semPaths()` function from __semPlot__ package can take a fitted lavaan model and create a nice diagram. \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(semPlot)\nsemPaths(myfittedmodel, \n        what = ?, # line thickness & color by... \n        whatLabels = ?, # label lines as... \n        rotation = ? # rotations, +1 = 90degrees\n        )\n```\n:::\n\n\n\n::: {.callout-tip collapse=\"true\"}\n#### optional: handy functionality! \n\nOccasionally we might want to draw models before we even get the data. __lavaan__ has some useful functionality where you can give it a model formula and ask it to \"lavaanify\" it into a model object that just hasn't yet been fitted to anything. \n\nFor instance, by setting up a pretend model and \"lavaanify-ing\" it, we can then make a diagram!  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npretend_model <- \"\nbiscuits =~ digestive + oreo + custard_cream + bourbon + crackers\ncrisps =~ salt_vinegar + cheese_onion + prawn_cocktail + crackers\n\"\nlavaanify(pretend_model) |>\n  semPaths()\n```\n\n::: {.cell-output-display}\n![](08ex_files/figure-html/unnamed-chunk-37-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n:::\n\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-6' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-6', 'sol-start-6')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-6\" style=\"display: none;\">\n\n\nYou can rotate this however you like. Convention is typically to have it downwards but I like it left to right (not sure why!)\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(semPlot)\nsemPaths(cpmod.est, \n        whatLabels = \"std\", \n        rotation = 2)\n```\n\n::: {.cell-output-display}\n![](08ex_files/figure-html/unnamed-chunk-38-1.png){fig-align='center' width=80%}\n:::\n:::\n\nThe lines from `agg =~ item6` and `nonagg =~ item1` are dotted to indicate that the model was initially fitted with the loading fixed to 1. \nBecause we're showing standardised loadings, we could just use the model when fitted with `std.lv=TRUE` just to stop these dotted lines from appearing: \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(semPlot)\nsemPaths(cpmod.est2, \n        whatLabels = \"std\", \n        rotation = 2)\n```\n\n::: {.cell-output-display}\n![](08ex_files/figure-html/unnamed-chunk-39-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n\n<div class='question-begin'>Question 7</div><div class='question-body'>\n\n\nMake a bullet point list of everything you have done so far, and the resulting conclusions.  \nThen, if you feel like it, turn the bulleted list into written paragraphs, and you'll have a write-up of your analyses!  \n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-7' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-7', 'sol-start-7')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-7\" style=\"display: none;\">\n\n\n\n\nA two-factor model was tested. Items 1-5 loaded on a 'non-aggressive conduct problems' factor and items 6-10 loaded on an 'aggression' factor and these factors were allowed to correlate. Scaling and identification were achieved by fixing the loading of item 1 on the non-aggressive conduct problems factor and item 6 on the aggression factor to 1. The model was estimated using maximum likelihood estimation. The model fit well with CFI=.99, TLI=0.99,  RMSEA=.04, and SRMR=.04 (Hu & Bentler, 1999).  All loadings were statistically significant and >|.3| on the standardised scale. Overall, therefore, a two-factor oblique model was supported for the conduct problems items. The correlation between the factors was $r=.38\\,\\, (p<.001)$.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n|parameter      |   est| std.est|    se|z      |pvalue  |\n|:--------------|-----:|-------:|-----:|:------|:-------|\n|nonagg=~item1  | 1.000|   0.664| 0.000|       |        |\n|nonagg=~item2  | 1.217|   0.765| 0.076|15.965 |< 0.001 |\n|nonagg=~item3  | 1.012|   0.676| 0.070|14.424 |< 0.001 |\n|nonagg=~item4  | 1.146|   0.706| 0.077|14.967 |< 0.001 |\n|nonagg=~item5  | 1.360|   0.872| 0.078|17.412 |< 0.001 |\n|agg=~item6     | 1.000|   0.636| 0.000|       |        |\n|agg=~item7     | 1.419|   0.878| 0.082|17.331 |< 0.001 |\n|agg=~item8     | 1.437|   0.915| 0.081|17.662 |< 0.001 |\n|agg=~item9     | 1.093|   0.668| 0.077|14.125 |< 0.001 |\n|agg=~item10    | 0.950|   0.608| 0.073|13.073 |< 0.001 |\n|nonagg~~agg    | 0.156|   0.375| 0.023|6.856  |< 0.001 |\n|item1~~item1   | 0.574|   0.559| 0.037|15.398 |< 0.001 |\n|item2~~item2   | 0.477|   0.416| 0.035|13.778 |< 0.001 |\n|item3~~item3   | 0.551|   0.543| 0.036|15.262 |< 0.001 |\n|item4~~item4   | 0.597|   0.501| 0.040|14.867 |< 0.001 |\n|item5~~item5   | 0.264|   0.239| 0.028|9.537  |< 0.001 |\n|item6~~item6   | 0.561|   0.595| 0.035|16.193 |< 0.001 |\n|item7~~item7   | 0.228|   0.229| 0.021|10.767 |< 0.001 |\n|item8~~item8   | 0.153|   0.162| 0.019|8.122  |< 0.001 |\n|item9~~item9   | 0.566|   0.554| 0.035|15.978 |< 0.001 |\n|item10~~item10 | 0.587|   0.630| 0.036|16.351 |< 0.001 |\n|nonagg~~nonagg | 0.453|   1.000| 0.052|8.701  |< 0.001 |\n|agg~~agg       | 0.381|   1.000| 0.045|8.396  |< 0.001 |\n:::\n:::\n\n\n<!-- Modification indices and expected parameter changes were inspected but no modifications were made because no expected parameter changes were judged large enough to merit the inclusion of additional parameters given that there was little theoretical rationale for their inclusion. -->\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n<br>  \n\n# \"DOOM\" Scrolling \n\n\n:::frame\n__Dataset: doom.csv__  \n\nThe \"Domains of Online Obsession Measure\" (DOOM) is a fictitious scale that aims to assess the sub types of addictions to online content. It was developed to measure 2 separate domains of online obsession: items 1 to 9 are representative of the \"emotional\" relationships people have with their internet usage (i.e. how it makes them feel), and items 10 to 15 reflect \"practical\" relationship (i.e., how it connects or interferes with their day-to-day life). Each item is measured on a 7-point likert scale from \"strongly disagree\" to \"strongly agree\".  \n\nWe administered this scale to 476 participants in order to assess the validity of the 2 domain structure of the online obsession measure that we obtained during scale development.  \n\nThe data are available at [https://uoepsy.github.io/data/doom.csv](https://uoepsy.github.io/data/doom.csv){target=\"_blank\"}, and the table below shows the individual item wordings.  \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div id=\"mzoorxmypf\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#mzoorxmypf table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#mzoorxmypf thead, #mzoorxmypf tbody, #mzoorxmypf tfoot, #mzoorxmypf tr, #mzoorxmypf td, #mzoorxmypf th {\n  border-style: none;\n}\n\n#mzoorxmypf p {\n  margin: 0;\n  padding: 0;\n}\n\n#mzoorxmypf .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#mzoorxmypf .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#mzoorxmypf .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#mzoorxmypf .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#mzoorxmypf .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#mzoorxmypf .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#mzoorxmypf .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#mzoorxmypf .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#mzoorxmypf .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#mzoorxmypf .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#mzoorxmypf .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#mzoorxmypf .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#mzoorxmypf .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#mzoorxmypf .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#mzoorxmypf .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#mzoorxmypf .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#mzoorxmypf .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#mzoorxmypf .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#mzoorxmypf .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#mzoorxmypf .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#mzoorxmypf .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#mzoorxmypf .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#mzoorxmypf .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#mzoorxmypf .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#mzoorxmypf .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#mzoorxmypf .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#mzoorxmypf .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#mzoorxmypf .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#mzoorxmypf .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#mzoorxmypf .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#mzoorxmypf .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#mzoorxmypf .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#mzoorxmypf .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#mzoorxmypf .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#mzoorxmypf .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#mzoorxmypf .gt_left {\n  text-align: left;\n}\n\n#mzoorxmypf .gt_center {\n  text-align: center;\n}\n\n#mzoorxmypf .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#mzoorxmypf .gt_font_normal {\n  font-weight: normal;\n}\n\n#mzoorxmypf .gt_font_bold {\n  font-weight: bold;\n}\n\n#mzoorxmypf .gt_font_italic {\n  font-style: italic;\n}\n\n#mzoorxmypf .gt_super {\n  font-size: 65%;\n}\n\n#mzoorxmypf .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#mzoorxmypf .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#mzoorxmypf .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#mzoorxmypf .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#mzoorxmypf .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#mzoorxmypf .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#mzoorxmypf .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"variable\">variable</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"question\">question</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">item_1</td>\n<td headers=\"question\" class=\"gt_row gt_left\">i just can't stop watching videos of animals</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">item_2</td>\n<td headers=\"question\" class=\"gt_row gt_left\">i spend hours scrolling through tutorials but never actually attempt any projects.</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">item_3</td>\n<td headers=\"question\" class=\"gt_row gt_left\">cats are my main source of entertainment.</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">item_4</td>\n<td headers=\"question\" class=\"gt_row gt_left\">life without the internet would be boring, empty, and joyless</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">item_5</td>\n<td headers=\"question\" class=\"gt_row gt_left\">i try to hide how long ive been online</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">item_6</td>\n<td headers=\"question\" class=\"gt_row gt_left\">i avoid thinking about things by scrolling on the internet</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">item_7</td>\n<td headers=\"question\" class=\"gt_row gt_left\">everything i see online is either sad or terrifying</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">item_8</td>\n<td headers=\"question\" class=\"gt_row gt_left\">all the negative stuff online makes me feel better about my own life</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">item_9</td>\n<td headers=\"question\" class=\"gt_row gt_left\">i feel better the more 'likes' i receive</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">item_10</td>\n<td headers=\"question\" class=\"gt_row gt_left\">most of my time online is spent communicating with others</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">item_11</td>\n<td headers=\"question\" class=\"gt_row gt_left\">my work suffers because of the amount of time i spend online</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">item_12</td>\n<td headers=\"question\" class=\"gt_row gt_left\">i spend a lot of time online for work</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">item_13</td>\n<td headers=\"question\" class=\"gt_row gt_left\">i check my emails very regularly</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">item_14</td>\n<td headers=\"question\" class=\"gt_row gt_left\">others in my life complain about the amount of time i spend online</td></tr>\n    <tr><td headers=\"variable\" class=\"gt_row gt_left\">item_15</td>\n<td headers=\"question\" class=\"gt_row gt_left\">i neglect household chores to spend more time online</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n\n:::\n\n\n\n<div class='question-begin'>Question 8</div><div class='question-body'>\n\n\nAssess whether the 2 domain model of online obsession provides a good fit to the validation sample of 476 participants.   \n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-8' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-8', 'sol-start-8')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-8\" style=\"display: none;\">\n\n\n\nFrom the visual of the correlation matrix, you can see the vague outline of two groups of items correlations. Note there's a little overlap.. \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndoom <- read_csv(\"https://uoepsy.github.io/data/doom.csv\")\nggcorrplot(cor(doom))\n```\n\n::: {.cell-output-display}\n![](08ex_files/figure-html/unnamed-chunk-42-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\nfirst we write our model: \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmoddoom <- \"\n# emotional domain\nemot =~ item_1 + item_2 + item_3 + item_4 + item_5 + item_6 + item_7 + item_8 + item_9\n# practical domain\npract =~ item_10 + item_11 + item_13 + item_14 + item_15\n# correlated domains (will be estimated by default)\nemot ~~ pract\n\"\n```\n:::\n\nThen we fit it to the data:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmoddoom.est <- cfa(moddoom, data = doom)\n```\n:::\n\nThen we inspect that fitted model object.   \nI'm just going to extract the fit indices here first.  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfitmeasures(moddoom.est)[c(\"rmsea\",\"srmr\",\"cfi\",\"tli\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     rmsea       srmr        cfi        tli \n0.07331272 0.06227484 0.84791972 0.81790388 \n```\n:::\n:::\n\nUh-oh.. they don't look great. \n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n\n\n<div class='question-begin'>Question 9</div><div class='question-body'>\n\n\nAre there any areas of local misfit (certain parameters that are not in the model (and are therefore fixed to zero) but that could improve model fit _if they were_ estimated?).  \n\n::: {.callout-note collapse=\"true\"}\n#### modification indices\n\nWhen a factor structure does not fit well, we can either start over and go back to doing EFA, deciding on an appropriate factor structure, on whether we should drop certain items, etc. The downside of this is that we essentially result in _another_ version of the scale, and before we know it, we have 10 versions of the same measure floating around, in a perpetual state of scale-development. \nAlternatively, we can see if it is possible to minimally adjust our model based on areas of local misfit in order to see if our global fit improves. Note that this would still be in a sense _exploratory,_ and we should be very clear when writing up about the process that we undertook. We should also avoid just shoving any parameter in that might make it fit better - we should let common sense and theoretical knowledge support any adjustments we make.  \n\nThe `modindices()` function takes a fitted model object from __lavaan__ and provides a table of all the possible additional parameters we _could_ estimate.  \n\nThe output is a table, which we can ask to be sorted according to the `mi` column using `sort = TRUE`.  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodindices(myfittedmodel, sort = TRUE)\n```\n:::\n\n```\n      lhs op    rhs     mi    epc sepc.lv sepc.all sepc.nox\n72  item6 ~~ item10 10.747  0.082   0.082    0.144    0.144\n25 fact1  =~  item7  8.106  0.119   0.080    0.080    0.080\n65  item5 ~~  item7  6.720  0.039   0.039    0.160    0.160\n71  item6 ~~  item9  6.675 -0.065  -0.065   -0.115   -0.115\n.   ...   .   ...    ...    ...     ...      ...      ...\n```\n\nThe columns show:  \n\n| `lhs`,`op`,`rhs`  | `mi`  | `epc` | `sepc.lv`, `sepc.all`,`sepc.nox`    |\n| --------------------- | ----------------------- | --------------------- | --------------------- |\n| these three columns show the specific parameter, in lavaan syntax. So `fact1 =~ item7` is for the possible inclusion of `item7` being loaded on to the latent variable `fact1`. `item6 ~~ item10` is for the inclusion of a covariance between `item6` and `item10`, and so on. | \"modification index\" = the change in the model $\\chi^2$ value _were we to include this parameter in the model_ | \"expected parameter change\" = the estimated value that the parameter _would take were it included in the model_ | these provide the `epc` values but scaled to when a) the latent variables are standardised, b) all variables are standardised, and c) all except exogenous observed variables are standardised (not relevant for CFA) |\n\n\nOften, the `sepc.all`is a useful column to look at, because it shows the proposed parameter estimate in a standardised metric. i.e. if the `op` is `~~`, then the `sepc.all` value is a correlation, and so we can consider anything <.2/.3ish to be quite small. If `op` is `=~`, then the `sepc.all` value is a standardised factor loading, so values >.3 or >.4 are worth thinking about, and so on. \n:::\n\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-9' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-9', 'sol-start-9')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-9\" style=\"display: none;\">\n\n\n\nI'm printing out just the `head()`, so that I can look at the few parameters with the greatest modification indices.  \nThe top three parameters jump out immediately to me.  \n`item_1` and `item_3` have a suggested correlation of c0.5, as do `item_7` and `item_8`. In addition, it's suggested that including a loading (estimated to be about 0.6) from `item_10` to the `emot` factor would improve the model fit.\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodindices(moddoom.est, sort=TRUE) |>\n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        lhs op     rhs     mi    epc sepc.lv sepc.all sepc.nox\n47   item_1 ~~  item_3 88.700  0.560   0.560    0.459    0.459\n32     emot =~ item_10 74.374  1.690   0.817    0.640    0.640\n109  item_7 ~~  item_8 61.930  0.370   0.370    0.432    0.432\n34     emot =~ item_13 14.824 -0.655  -0.317   -0.275   -0.275\n122  item_9 ~~ item_10 12.634  0.145   0.145    0.217    0.217\n135 item_13 ~~ item_15  8.956  0.178   0.178    0.171    0.171\n```\n:::\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n\n<div class='question-begin'>Question 10</div><div class='question-body'>\n\n\n__Beware:__ there's a slightly blurred line here that we're about to step over, and move from confirmatory back to 'exploratory'.  \n\nLook carefully at the item wordings,do any of the suggested modifications make theoretical sense? Add them to the model and re-fit it. Does this new model fit well?  \n\n::: {.callout-caution collapse=\"true\"}\n#### model modifications are exploratory!!\n\nIt's likely you will have to make a couple of modifications in order to obtain a model that fits well to this data.  \n\n__BUT...__ we could simply keep adding suggested parameters to our model and we will eventually end up with a perfectly fitting model.  \n\nIt's very important to think critically here about _why_ such modifications may be necessary. \n\n- The initial model may have failed to capture the complexity of the underlying relationships among variables. For instance, suggested residual covariances, representing unexplained covariation among observed variables, may indicate misspecification in the initial model. \n- The structure of the construct is genuinely different in your population from the initial one in which the scale is developed (this could be a research question in and of itself - i.e. does the structure of \"anxiety\" differ as people age, or differ between cultures?)\n\nModifications to a CFA model should be made judiciously, with careful consideration of theory as well as quantitative metrics. The goal is to develop a model that accurately represents the underlying structure of the data while maintaining theoretical coherence and generalizability.  \n\n:::\n\nIn this case, the likely reason for the poor fit of the \"DOOM\" scale, is that the person who made the items (ahem, me) doesn't really know anything about the construct they are talking about, and didn't put much care into constructing the items!  \n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-10' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-10', 'sol-start-10')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-10\" style=\"display: none;\">\n\n\n\nThere are three main proposed adjustments from our initial model:  \n\n1. `item_1 ~~ item_3`. These questions are both about animals. It would make sense that these are related over and above the underlying \"emotional internet usage\" factor. \n2. `item_7 ~~ item_8`. These are both about viewing negative content online, so it makes sense here that they would be related beyond the 'emotional' factor. \n\n3. `emot =~ item_10`. This item is about communicating with others. It currently loads highly on the `pract` factor too. It maybe makes sense here that \"communicating with others\" will capture both a practical element of internet useage _and_ an emotional one. \n\n\nPutting them all in at once could be a mistake - if we added in `emot =~ item_10`, then we change slightly the underlying construct of the `emot` factor, meaning it might make other suggested modifications (`item_7 ~~ item_8`) less important. It's a bit like [Whac-A-Mole](https://en.wikipedia.org/wiki/Whac-A-Mole){target=\"_blank\"} - you make one modification and then a whole new area of misfits appears!  \n\nLet's adjust our model:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmoddoom2 <- \"\n# emotional domain\nemot =~ item_1 + item_2 + item_3 + item_4 + item_5 + item_6 + item_7 + item_8 + item_9 + item_10\n# practical domain\npract =~ item_10 + item_11 + item_13 + item_14 + item_15\n# correlated domains (will be estimated by default)\nemot ~~ pract\n\"\n```\n:::\n\nThen fit it to the data:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmoddoom2.est <- cfa(moddoom2, data = doom)\n\nfitmeasures(moddoom2.est)[c(\"rmsea\",\"srmr\",\"cfi\",\"tli\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     rmsea       srmr        cfi        tli \n0.06013775 0.05147585 0.89901514 0.87747171 \n```\n:::\n:::\n\n\nThe fit is still not great, and the same suggested correlations are present in modification indices:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodindices(moddoom2.est, sort=TRUE) |>\n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       lhs op     rhs     mi    epc sepc.lv sepc.all sepc.nox\n47  item_1 ~~  item_3 87.679  0.553   0.553    0.455    0.455\n109 item_7 ~~  item_8 61.827  0.365   0.365    0.421    0.421\n43   pract =~  item_7  7.117 -0.300  -0.178   -0.159   -0.159\n48  item_1 ~~  item_4  6.264 -0.139  -0.139   -0.128   -0.128\n117 item_8 ~~ item_10  6.072 -0.110  -0.110   -0.151   -0.151\n44   pract =~  item_8  5.065 -0.244  -0.145   -0.130   -0.130\n```\n:::\n:::\n\n\nLet's go ahead and put the covariance between `item_1` and `item_3` in. I personally went for this first because they seem more similar to me than `item_7` and `item_8` do. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmoddoom3 <- \"\n# emotional domain\nemot =~ item_1 + item_2 + item_3 + item_4 + item_5 + item_6 + item_7 + item_8 + item_9 + item_10\n# practical domain\npract =~ item_10 + item_11 + item_13 + item_14 + item_15\n# correlated domains (will be estimated by default)\nemot ~~ pract\nitem_1 ~~ item_3\n\"\n\nmoddoom3.est <- cfa(moddoom3, data = doom)\n\nfitmeasures(moddoom3.est)[c(\"rmsea\",\"srmr\",\"cfi\",\"tli\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     rmsea       srmr        cfi        tli \n0.03282045 0.03830848 0.97032291 0.96350520 \n```\n:::\n:::\n\n\nWhoop! It fits well! It may well be that if we inspect modification indices again, we still see that `item_1 ~~ item_3` would improve our model fit. The thing to remember however, is that we could simply keep adding parameters until we run out of degrees of freedom, and our model would \"fit better\". But such a model would not be useful. It would not generalise well, becaue it runs the risk of being overfitted to the nuances of this specific sample.\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n<br>\n\n# Optional Extra Exercises for the Enthusiastic\n\n:::frame\n__Dataset: radakovic_das.csv__  \n\nApathy is lack of motivation towards goal-directed behaviours. It is pervasive in a majority of psychiatric and neurological diseases, and impacts everyday life. Traditionally, apathy has been measured as a one-dimensional construct but is in fact composed of different types of demotivation.\n\nDimensional Apathy Scale (DAS)\nThe Dimensional Apathy Scale (DAS) is a multidimensional assessment for demotivation, in which 3 subtypes of apathy are assessed:  \n\n- **Executive:** lack of motivation for planning, attention or organisation\n- **Emotional:** lack of emotional motivation (indifference, affective or emotional neutrality, flatness or blunting)\n- **Initiation:** lack of motivation for self-generation of thoughts and/or actions\n\nThe DAS measures these subtypes of apathy and allows for quick and easy assessment, through self-assessment, observations by informants/carers or administration by researchers or healthcare professionals.  \n\nYou can find data for the DAS when administered to 250 healthy adults at [https://uoepsy.github.io/data/radakovic_das.csv](https://uoepsy.github.io/data/radakovic_das.csv){target=\"_blank\"}, and information on the items is below.  \n\n::: {.callout-note collapse=\"true\"}\n#### DAS Dictionary\n\nAll items are measured on a 6-point Likert scale of Always (0), Almost Always (1), Often (2), Occasionally (3), Hardly Ever (4), and Never (5). Certain items (indicated in the table below with a `-` direction) are reverse scored to ensure that higher scores indicate greater levels of apathy. \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div id=\"puzkanvvnn\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#puzkanvvnn table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#puzkanvvnn thead, #puzkanvvnn tbody, #puzkanvvnn tfoot, #puzkanvvnn tr, #puzkanvvnn td, #puzkanvvnn th {\n  border-style: none;\n}\n\n#puzkanvvnn p {\n  margin: 0;\n  padding: 0;\n}\n\n#puzkanvvnn .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#puzkanvvnn .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#puzkanvvnn .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#puzkanvvnn .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#puzkanvvnn .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#puzkanvvnn .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#puzkanvvnn .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#puzkanvvnn .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#puzkanvvnn .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#puzkanvvnn .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#puzkanvvnn .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#puzkanvvnn .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#puzkanvvnn .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#puzkanvvnn .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#puzkanvvnn .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#puzkanvvnn .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#puzkanvvnn .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#puzkanvvnn .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#puzkanvvnn .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#puzkanvvnn .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#puzkanvvnn .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#puzkanvvnn .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#puzkanvvnn .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#puzkanvvnn .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#puzkanvvnn .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#puzkanvvnn .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#puzkanvvnn .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#puzkanvvnn .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#puzkanvvnn .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#puzkanvvnn .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#puzkanvvnn .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#puzkanvvnn .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#puzkanvvnn .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#puzkanvvnn .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#puzkanvvnn .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#puzkanvvnn .gt_left {\n  text-align: left;\n}\n\n#puzkanvvnn .gt_center {\n  text-align: center;\n}\n\n#puzkanvvnn .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#puzkanvvnn .gt_font_normal {\n  font-weight: normal;\n}\n\n#puzkanvvnn .gt_font_bold {\n  font-weight: bold;\n}\n\n#puzkanvvnn .gt_font_italic {\n  font-style: italic;\n}\n\n#puzkanvvnn .gt_super {\n  font-size: 65%;\n}\n\n#puzkanvvnn .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#puzkanvvnn .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#puzkanvvnn .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#puzkanvvnn .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#puzkanvvnn .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#puzkanvvnn .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#puzkanvvnn .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"item\">item</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"direction\">direction</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"dimension\">dimension</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"question\">question</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">1</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">+</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Executive</td>\n<td headers=\"question\" class=\"gt_row gt_left\">I need a bit of encouragement to get things started</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">2</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">-</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Initiation</td>\n<td headers=\"question\" class=\"gt_row gt_left\">I contact my friends</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">3</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">-</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Emotional</td>\n<td headers=\"question\" class=\"gt_row gt_left\">I express my emotions</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">4</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">-</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Initiation</td>\n<td headers=\"question\" class=\"gt_row gt_left\">I think of new things to do during the day</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">5</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">-</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Emotional</td>\n<td headers=\"question\" class=\"gt_row gt_left\">I am concerned about how my family feel</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">6</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">+</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Executive</td>\n<td headers=\"question\" class=\"gt_row gt_left\">I find myself staring in to space</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">7</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">-</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Emotional</td>\n<td headers=\"question\" class=\"gt_row gt_left\">Before I do something I think about how others would feel about it</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">8</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">-</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Initiation</td>\n<td headers=\"question\" class=\"gt_row gt_left\">I plan my days activities in advance</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">9</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">-</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Emotional</td>\n<td headers=\"question\" class=\"gt_row gt_left\">When I receive bad news I feel bad about it</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">10</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">-</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Executive</td>\n<td headers=\"question\" class=\"gt_row gt_left\">I am unable to focus on a task until it is finished</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">11</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">+</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Executive</td>\n<td headers=\"question\" class=\"gt_row gt_left\">I lack motivation</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">12</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">+</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Emotional</td>\n<td headers=\"question\" class=\"gt_row gt_left\">I struggle to empathise with other people</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">13</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">-</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Initiation</td>\n<td headers=\"question\" class=\"gt_row gt_left\">I set goals for myself</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">14</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">-</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Initiation</td>\n<td headers=\"question\" class=\"gt_row gt_left\">I try new things</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">15</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">+</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Emotional</td>\n<td headers=\"question\" class=\"gt_row gt_left\">I am unconcerned about how others feel about my behaviour</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">16</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">-</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Initiation</td>\n<td headers=\"question\" class=\"gt_row gt_left\">I act on things I have thought about during the day</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">17</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">+</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Executive</td>\n<td headers=\"question\" class=\"gt_row gt_left\">When doing a demanding task, I have difficulty working out what I have to do</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">18</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">-</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Initiation</td>\n<td headers=\"question\" class=\"gt_row gt_left\">I keep myself busy</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">19</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">+</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Executive</td>\n<td headers=\"question\" class=\"gt_row gt_left\">I get easily confused when doing several things at once</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">20</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">-</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Emotional</td>\n<td headers=\"question\" class=\"gt_row gt_left\">I become emotional easily when watching something happy or sad on TV</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">21</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">+</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Executive</td>\n<td headers=\"question\" class=\"gt_row gt_left\">I find it difficult to keep my mind on things</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">22</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">-</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Initiation</td>\n<td headers=\"question\" class=\"gt_row gt_left\">I am spontaneous</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">23</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">+</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Executive</td>\n<td headers=\"question\" class=\"gt_row gt_left\">I am easily distracted</td></tr>\n    <tr><td headers=\"item\" class=\"gt_row gt_right\">24</td>\n<td headers=\"direction\" class=\"gt_row gt_right\">+</td>\n<td headers=\"dimension\" class=\"gt_row gt_left\">Emotional</td>\n<td headers=\"question\" class=\"gt_row gt_left\">I feel indifferent to what is going on around me</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n\n:::\n\n:::\n\n\n\n<div class='question-begin'>Question 11</div><div class='question-body'>\n\n\nRead in the data. \nIt will need a little bit of tidying before we can get to fitting a CFA.  \nIf you haven't already, check out the page on [Data Wrangling for Surveys & Questionnaires](00_surveywrangle.html){target=\"_blank\"}.  \n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-11' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-11', 'sol-start-11')\">  1 - Read and check</button></div><div class=\"solution-body\" id = \"sol-body-11\" style=\"display: none;\">\n\n\n\nFirst let's just read in the dataset:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrdas <- read_csv(\"https://uoepsy.github.io/data/radakovic_das.csv\")\nhead(rdas)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6  24\n  I need a bit of encouragement  `I contact my friends` I express my emotion\n  <chr>                            <chr>                  <chr>                 \n1 Often                            Almost Always          Almost Always         \n2 Almost Always                    Hardly Ever            Occasionally          \n3 Often                            Occasionally           Occasionally          \n4 Hardly Ever                      Occasionally           Almost Always         \n5 Occasionally                     Hardly Ever            Occasionally          \n6 Occasionally                     Occasionally           Almost Always         \n#  abbreviated names: `I need a bit of encouragement to get things started`,\n#   `I express my emotions`\n#  21 more variables: `I think of new things to do during the day` <chr>,\n#   `I am concerned about how my family feel` <chr>,\n#   `I find myself staring in to space` <chr>,\n#   `Before I do something I think about how others would feel about it` <chr>,\n#   `I plan my days activities in advance` <chr>, \n```\n:::\n:::\n\n\nThe names we're getting are useful in that they show the items, but they're horrible to have to use in R, so we will ideally replace them with easy to use names. \nNote also that the data is being read in as the actual response option - e.g., \"Almost Always\" - and we want to treat these as a numeric scale. So those will have to change too.  \n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-12' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-12', 'sol-start-12')\">  2 - Renaming variables</button></div><div class=\"solution-body\" id = \"sol-body-12\" style=\"display: none;\">\n\n\n\nI like to make a \"data dictionary\" whenever I get data like this. While I want to rename the variables to make it easier for me to use, I also want to keep track of what the questions were.  \nHere I make a \"tibble\" (the function `data.frame()` would work too, tibble is just tidyverse version). I indicate what I am going to rename things as (\"q1\",\"q2\", ..., \"q24\"), and then I have the current names of the variables\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrdas_dict <- tibble(\n  variable = paste0(\"q\",1:24),\n  item = names(rdas)\n)\n```\n:::\n\n\nDoing this is really useful because I can't keep track in my head of what \"q5\" was.  \nIf I want to know, then I can just do: \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrdas_dict[5,]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1  2\n  variable item                                   \n  <chr>    <chr>                                  \n1 q5       I am concerned about how my family feel\n```\n:::\n:::\n\n\nNow let's actually change the names in our data to what we said we would:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnames(rdas) <- paste0(\"q\", 1:24)\n```\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-13' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-13', 'sol-start-13')\">  3 - Recoding responses</button></div><div class=\"solution-body\" id = \"sol-body-13\" style=\"display: none;\">\n\n\n\nOkay, so we have all our data in words, not numbers. Views on how to treat Likert data are mixed, but it's very common to treat it as continuous in Psychology.  \n\nLet's check the response values we have. Just in question 1 for now:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nunique(rdas$q1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Often\"         \"Almost Always\" \"Hardly Ever\"   \"Occasionally\" \n[5] \"Always\"        NA              \"Never\"        \n```\n:::\n:::\n\n\nA little trick that we can use to find the unique values in an entire dataset is to quickly convert the dataframe into one big long vector. Technically, a dataframe is a \"list of vectors\", and the function `unlist()` will remove this structure.  \nSo we can find all the unique values in all the questions with:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nunique(unlist(rdas))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Often\"         \"Almost Always\" \"Hardly Ever\"   \"Occasionally\" \n[5] \"Always\"        NA              \"Never\"         \"[NO ENTRY]\"   \n```\n:::\n:::\n\n\nPerfect. So we know we have uniformity of spelling. It happens less often these days as questionnaire software is improving, but you might occasionally encounter typos in _some_ of the questions, or things with and without capital letters (R is a bit thick, and doesn't recognise that \"Often\" and \"often\" are the same thing).  \nNote that we have the 6 responses that we would expect given the description of the scale, but we also have some `NA` values, and some `[NO ENTRY]` values. Not sure how those got there.  \nWe want to turn each \"Always\" in to 0, each \"Almost Always\" in to 1, \"Often\" in to 2, and so on. If we simply leave out the \"[NO ENTRY]\", then this will be turned into a missing value `NA`, which is handy.  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrdas <- rdas |> \n  mutate(across(q1:q24, ~case_match(.,\n    \"Always\" ~ 0,\n    \"Almost Always\" ~ 1,\n    \"Often\" ~ 2,\n    \"Occasionally\" ~ 3,\n    \"Hardly Ever\" ~ 4,\n    \"Never\" ~ 5\n  )))\nhead(rdas)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6  24\n     q1    q2    q3    q4    q5    q6    q7    q8    q9   q10   q11   q12   q13\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1     2     1     1     4     1     3     1     4     2     2     3     2     3\n2     1     4     3     4    NA     0    NA     2    NA     2     1     2     3\n3     2     3     3     4     3     3     2     2     4     1     3     2     3\n4     4     3     1     3     1    NA     2     2    NA     2     3     4     2\n5     3     4     3     5     2     2     2     3     3     2     2     2     1\n6     3     3     1     0     1     2     1     1     0     2     1     4     3\n#  11 more variables: q14 <dbl>, q15 <dbl>, q16 <dbl>, q17 <dbl>, q18 <dbl>,\n#   q19 <dbl>, q20 <dbl>, q21 <dbl>, q22 <dbl>, q23 <dbl>, q24 <dbl>\n```\n:::\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-14' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-14', 'sol-start-14')\">  4 - Removing missingness</button></div><div class=\"solution-body\" id = \"sol-body-14\" style=\"display: none;\">\n\n\n\nWe haven't learned about more sophisticated methods of handling missing data, so for now we will just remove any rows in which there is missingness - i.e., we'll do \"listwise deletion\":  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncompl_rdas <- na.omit(rdas)\n```\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n\n<div class='question-begin'>Question 12</div><div class='question-body'>\n\n\nHow well does the 3-dimensional model of apathy fit to this dataset?  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nYou'll have to use the data dictionary to figure out which items are associated with with dimensions.  \n\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-15' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-15', 'sol-start-15')\">  Solution </button></div><div class=\"solution-body\" id = \"sol-body-15\" style=\"display: none;\">\n\n\nHere is the model structure, according to the list of items in the dictionary.  \nI'm calling my factors \"Em\", \"Ex\", and \"BCI\" for \"emotional\", \"executive\" and \"behavioural/cognitive initiation\" respectively. The factor correlations will be estimated by default, but I like to write things explicitly. \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndasmod = \"\nEm =~ q1 + q6 + q10 + q11 + q17 + q19 + q23\nEx =~ q3 + q5 + q7 + q9 + q12 + q15 + q20 + q24\nBCI =~ q2 + q4 + q8 + q13 + q14 + q16 + q18 + q22\nEm ~~ Ex\nEm ~~ BCI\nEx ~~ BCI\n\"\n```\n:::\n\n\nLet's fit the model!  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndasmod.est = cfa(dasmod, compl_rdas)\n```\n:::\n\n\nAnd examine the global fit: \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfitmeasures(dasmod.est)[c(\"srmr\",\"rmsea\",\"tli\",\"cfi\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      srmr      rmsea        tli        cfi \n0.05484788 0.02614997 0.95698828 0.96140846 \n```\n:::\n:::\n\n\nAll looks pretty good! Cut-offs for SRMR tend to vary, with some using <0.08, or <0.09, and some being stricter with <0.05. Remember, these criteria are somewhat arbitrary.  \n\nModification indices suggest a whole bunch of items that could have some associations beyond that modelled in the factors, but these are all weak correlations at around 0.2.  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodindices(dasmod.est, sort=TRUE) |> head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    lhs op rhs     mi    epc sepc.lv sepc.all sepc.nox\n126  q6 ~~  q3 15.790 -0.221  -0.221   -0.284   -0.284\n108  q1 ~~  q9 11.413  0.169   0.169    0.264    0.264\n206 q19 ~~ q20 10.884 -0.167  -0.167   -0.257   -0.257\n331  q4 ~~  q8  7.552  0.201   0.201    0.208    0.208\n99   q1 ~~  q6  7.310  0.150   0.150    0.224    0.224\n101  q1 ~~ q11  6.183 -0.149  -0.149   -0.236   -0.236\n```\n:::\n:::\n\n\nThese are the top 3 being suggested. I can't see any obvious link between any of these that would make me think they are related beyond their measuring of 'apathy'.  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrdas_dict[c(3,6),]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2  2\n  variable item                             \n  <chr>    <chr>                            \n1 q3       I express my emotions            \n2 q6       I find myself staring in to space\n```\n:::\n\n```{.r .cell-code}\nrdas_dict[c(1,9),]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2  2\n  variable item                                               \n  <chr>    <chr>                                              \n1 q1       I need a bit of encouragement to get things started\n2 q9       When I receive bad news I feel bad about it        \n```\n:::\n\n```{.r .cell-code}\nrdas_dict[c(19,20),]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2  2\n  variable item                                                                \n  <chr>    <chr>                                                               \n1 q19      I get easily confused when doing several things at once             \n2 q20      I become emotional easily when watching something happy or sad on TV\n```\n:::\n:::\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n\n<div class='question-begin'>Question 13</div><div class='question-body'>\n\n\nMuch like for EFA, we can estimate individuals' scores on the latent factors. In lavaan, the function `lavPredict()` will get us some estimates.  \n\nHowever, for a clinician administering the DAS to a patient, this option is not available. Instead, it is common that scores on the individual items associated with a given factor are used to create a sum score or a mean score which can be used in a practical setting (e.g., scores above a given threshold might indicate cause for concern).  \n\nCalculate sum scores for each of the dimensions of apathy. \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nYou'll need to reverse some items first! See [Data Wrangling for Surveys #reverse-coding](00_surveywrangle.html#reverse-coding){target=\"_blank\"}.  \n\n:::\n\n\n\n</div><p class=\"question-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-16' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-16', 'sol-start-16')\">  1 - Reversing items</button></div><div class=\"solution-body\" id = \"sol-body-16\" style=\"display: none;\">\n\n\n\nAccording to the table of items, the ones which need to be reverse scored are:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nreversed <- c(2,3,4,5,7,8,9,10,13,14,16,18,20,22)\n```\n:::\n\n\nFor these items, we want 5s to become 0s, 4s become 1s, and so on.. \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncompl_rdas[, reversed] <- apply(\n  compl_rdas[, reversed], MARGIN = 2, function(x) 5-x)\n```\n:::\n\n\n__Note:__ The above code works nicely because our dataset is currently ordered such that the first column is item 1, 2nd column is item 2, and so on. This means we can use _numbers_ to index the appropriate variables, rather than _names_. It would need adjusting if, for instance, our first column contained \"participant ID\", and our items only began later.  \n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n<div class=\"solution-begin\"><button id='sol-start-17' class=\"jk-circle-right solution-icon clickable\" onclick=\"toggle_visibility('sol-body-17', 'sol-start-17')\">  2 - Sum Scoring</button></div><div class=\"solution-body\" id = \"sol-body-17\" style=\"display: none;\">\n\n\n\nHere are the sets of items associated with each dimension: \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nExitems <- c(1,6,10,11,17,19,21,23)\nEmitems <- c(3,5,7,9,12,15,20,24)\nBCIitems <- c(2,4,8,13,14,16,18,22)\n```\n:::\n\n\nAgain, because the item numbers correspond to the column positions in our data, we can just do rowSums indexing on those column numbers to get our scores:  \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncompl_rdas$ExSCORE <- rowSums(compl_rdas[,Exitems])\ncompl_rdas$EmSCORE <- rowSums(compl_rdas[,Emitems])\ncompl_rdas$BCIScore <- rowSums(compl_rdas[,BCIitems])\n```\n:::\n\n\n\n\n\n</div><p class=\"solution-end\"></p>\n\n\n\n\n::: {.callout-caution collapse=\"true\"}\n#### optional: what is a sum score but a constrained factor model?  \n\nComputing sum scores can feel like a 'model free' calculation, but actually it **does** pre-suppose a factor structure, and a much more constrained one than those we have been estimating. For a full explanation of this, see [\"Thinking twice about sum scores\", McNeish & Wolf 2020](https://doi.org/10.3758/s13428-020-01398-0){target=\"_blank\"}. \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/diag_sumscore.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n:::\n\n\n\n\n",
    "supporting": [
      "08ex_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/panelset-0.2.6/panelset.css\" rel=\"stylesheet\" />\r\n<script src=\"site_libs/panelset-0.2.6/panelset.js\"></script>\r\n<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\r\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}