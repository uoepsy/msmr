{"title":"Week 2 Exercises: Logistic and Longitudinal","markdown":{"yaml":{"title":"Week 2 Exercises: Logistic and Longitudinal","params":{"SHOW_SOLS":false,"TOGGLE":true},"editor_options":{"chunk_output_type":"console"}},"headingText":"ss = round(runif(1,1e3,1e6))","containsRefs":false,"markdown":"\n\n```{r}\n#| label: setup\n#| include: false\nsource('assets/setup.R')\nlibrary(xaringanExtra)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(ggdist)\nxaringanExtra::use_panelset()\nqcounter <- function(){\n  if(!exists(\"qcounter_i\")){\n    qcounter_i <<- 1\n  }else{\n    qcounter_i <<- qcounter_i + 1\n  }\n  qcounter_i\n}\n```\n\n```{r}\n#| echo: false\nss = 230168\nset.seed(ss)\nn_groups = 168\nnpgroup = round(runif(368,2,8))\ng = unlist(sapply(1:n_groups, function(x) rep(x,npgroup[x])))\nN = length(g)\nx = round(runif(N,1,10))\nb = sample(letters[1:4],n_groups,T,prob=c(.3,.2,.3,.2))\nb = b[g]\nres = MASS::mvrnorm(n=n_groups,\n                    mu=c(0,0),\n                    Sigma=diag(c(3,2))%*%matrix(c(1,.4,.4,1),nrow=2)%*%diag(c(3,2)))\nre0 = res[,1]\nre  = re0[g]\nrex = res[,2]\nre_x  = rex[g]\nlp = (0 + re) + (1.1 + re_x)*scale(x,center=F)[,1] + \n  1.4*(b==\"c\") +1.8*(b==\"a\") +    \n  .8*(b==\"c\")*scale(x,center=F)[,1]+\n  -1.1*(b==\"d\")*scale(x,center=F)[,1]\ny = lp + rnorm(N,0,1)\ndf = data.frame(x = x,g=g, b=b,y=round(scale(y)[,1],1))\n\nmnames = unique(randomNames::randomNames(1e5,which=\"first\"))\n\ndf = df |>\n  transmute(\n    ape = mnames[g],\n    age = x,\n    species = as.character(factor(b, levels=letters[1:4],labels=c(\"gorilla\",\"bonobo\",\"chimp\",\"orangutan\"))),\n    dominance = y\n  )\n# \n# m1=lmer(dominance ~ age + (1+age|ape),df)\n# m2=lmer(dominance ~ age + species + (1+age|ape),df)\n# m3=lmer(dominance ~ age * species + (1+age|ape),df)\n# any(!is.null(c(m1@optinfo$conv$lme4$messages,\n#                m2@optinfo$conv$lme4$messages,\n#                m3@optinfo$conv$lme4$messages)))\n# library(lme4)\n# df$age=df$age-1\n# m1=lmer(dominance ~ age + (1+age|ape),df)\n# m2=lmer(dominance ~ age + species + (1+age|ape),df)\n# m3=lmer(dominance ~ age * species + (1+age|ape),df)\n# any(!is.null(c(m1@optinfo$conv$lme4$messages,\n#                m2@optinfo$conv$lme4$messages,\n#                m3@optinfo$conv$lme4$messages)))\n# anova(m1,m2,m3)\n# plot(effects::effect(\"age*species\",m3))\n# summary(m3)\n\ndf$dominance[sample(1:nrow(df),2)] <- c(19.4,-21.2)\n\nspl = df |> count(ape,species) |>\n  mutate(\n    sp2 = case_when(\n      species==\"chimp\" ~ sample(c(\"chimp\",\"chimpanzee\"),n(),T),\n      TRUE ~ species\n    )\n  )\ndf = left_join(df,spl)\ndf[df$ape==\"Paige\",\"sp2\"] = \"gorrila\"\ndf$age[sample(1:nrow(df),3)] <- -99\ndf = df |> transmute(\n  ape, species=sp2, age, dominance\n)\n\n# df |> count(ape,species) |> select(-n) |>\n#   write_csv(file=\"../../data/msmr_apespecies.csv\")\n# df |> select(ape, age, dominance) |>\n#   write_csv(file=\"../../data/msmr_apeage.csv\")\n\n\n\n\n# library(lme4)\n# m1=lmer(dominance ~ age + (1+age|ape),df)\n# m2=lmer(dominance ~ age + species + (1+age|ape),df)\n# m3=lmer(dominance ~ age * species + (1+age|ape),df)\n# any(!is.null(c(m1@optinfo$conv$lme4$messages,\n#                m2@optinfo$conv$lme4$messages,\n#                m3@optinfo$conv$lme4$messages)))\n# anova(m1,m2,m3)\n# plot(effects::effect(\"age*species\",m3))\n# summary(m3)\n# emmeans::emtrends(m3,var=\"x\") |> summary(infer=c(TRUE))\n```\n\n\n# Great Apes!  \n\n:::frame\n__Data: msmr_apespecies.csv__ & __msmr_apeage.csv__  \n\nWe have data from a large sample of great apes who have been studied between the ages of 1 to 10 years old (i.e. during adolescence). Our data includes 4 species of great apes: Chimpanzees, Bonobos, Gorillas and Orangutans. Each ape has been assessed on a primate dominance scale at various ages. Data collection was not very rigorous, so apes do not have consistent assessment schedules (i.e., one may have been assessed at ages 1, 3 and 6, whereas another at ages 2 and 8).  \n\nThe researchers are interested in examining how the adolescent development of dominance in great apes differs between species.  \n\nData on the dominance scores of the apes are available at [https://uoepsy.github.io/data/msmr_apeage.csv](https://uoepsy.github.io/data/msmr_apeage.csv){target=\"_blank\"} and the information about which species each ape is are in [https://uoepsy.github.io/data/msmr_apespecies.csv](https://uoepsy.github.io/data/msmr_apespecies.csv){target=\"_blank\"}.  \n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n```{r}\n#| echo: false\n#| label: tbl-spec1\n#| tbl-cap: \"Data Dictionary: msmr_apespecies.csv\"  \nape_species <- read_csv(\"../../data/msmr_apespecies.csv\")\ntibble(\n  variable = names(ape_species),\n  description = c(\"Ape Name\",\"Species (Bonobo, Chimpanzee, Gorilla, Orangutan)\")\n) |> gt::gt()\n```\n:::\n::: {.column width=\"10%\"}\n\n:::\n::: {.column width=\"45%\"}\n```{r}\n#| echo: false\n#| label: tbl-spec2\n#| tbl-cap: \"Data Dictionary: msmr_apeage.csv\"  \nape_age <- read_csv(\"../../data/msmr_apeage.csv\")\ntibble(\n  variable = names(ape_age),\n  description = c(\"Ape Name\",\"Age at assessment (years)\",\"Dominance (Z-scored)\")\n) |> gt::gt()\n```\n\n:::\n::::\n\n:::\n\n\n\n\n`r qbegin(qcounter())`\nRead in the data and check over it. Do any relevant cleaning/wrangling that might be necessary.   \n\n`r qend()`\n`r solbegin(label=\"1 - reading and joining\", slabel=F,show=T, toggle=params$TOGGLE)`\nWe'll read in both datasets, and then join them together. \n```{r}\nlibrary(tidyverse)\nlibrary(lme4)\nape_species <- read_csv(\"https://uoepsy.github.io/data/msmr_apespecies.csv\")\nape_age <- read_csv(\"https://uoepsy.github.io/data/msmr_apeage.csv\")\n```\nSometimes is handy to check that all our participants are in both datasets:\n```{r}\n# are all the apes in ape_age also in ape_species?\nall(ape_age$ape %in% ape_species$ape)\n# and vice versa?\nall(ape_species$ape %in% ape_age$ape)\n```\n\n\n::: {.callout-warning collapse=\"true\"}\n#### optional - working with sets!\n\nI often default to using `%in%` and asking several questions to carefully make sure I know what's going on - i.e. \"is all of A `%in%` B? and is all of B `%in%` A, ... etc.\"  \nThere is actually a neat way to ask these questions both at once using some handy functions (that I often forget about) to perform operations on \"sets\" (i.e. collections of things). These include:\n\n- `union(x,y)` - return everything that is in set x or in set y (or both)\n- `intersect(x,y)` - return everything that is in both x and y\n- `setdiff(x,y)` - return everything in x that is not in y (*not there's asymmetry here!*)\n- `setequal(x,y)` - are sets x and y equal?\n\nSo we can use these to ask if, e.g., the two sets of apes in each dataset are equal:\n```{r}\nsetequal(ape_species$ape,ape_age$ape)\n```\n\nIf you want a fun^[really!?!?] challenge, there are lots of other (less concise ways) that we can ask the same thing. Try and come up with a few different ways.  \nE.g.: \"is there anything in the union of the two sets that is not in the intersection of the two sets?\"\n```{r}\nsetdiff(union(ape_species$ape,ape_age$ape), \n        intersect(ape_species$ape,ape_age$ape))\n```\n\n:::\n\nOkay, both datasets contain data for the same set of apes.  \nLet's join them:  \n```{r}\napedat <- full_join(ape_age, ape_species)\nhead(apedat)\n```\n`r solend()`\n`r solbegin(label=\"2 - identifying issues\", slabel=F,show=T, toggle=params$TOGGLE)`\n\nFirst off, we can see that we've got some weird typos. Some apes have been identified as \"gorrila\" but it is actually spelled \"gorilla\".  \nAlso, we've got people using two alternatives for the chimps: \"chimp\" and \"chimpanzee\". We'll need to combine those.  \n```{r}\ntable(apedat$species)\n```\n\n\nAge looks like it has some weird values (possibly \"-99\"?), and there are possibly a few outliers in the dominance variable. Given that dominance is standardised, it is _extremely_ unlikely that we would see values around 20.. They're not \"impossible\", but they're so incredibly unlikely that I'd be more comfortable assuming they are typos: \n```{r echo=c(2,3)}\npar(mfrow=c(2,1))\nhist(apedat$age, breaks=20)\nhist(apedat$dominance, breaks=20)\npar(mfrow=c(1,1))\n```\n\nJust to see what the most extreme values of dominance are:  \n```{r}\n# show the biggest 5 absolute values in dominance variable\nsort(abs(apedat$dominance), decreasing = TRUE)[1:5]\n```\n\n`r solend()`\n`r solbegin(label=\"3 - cleaning up\", slabel=F,show=T, toggle=params$TOGGLE)`\n\n\n```{r}\n\napedat <- apedat |> \n  mutate(\n    # fix species typos\n    species = case_when(\n      species %in% c(\"chimp\",\"chimpanzee\") ~ \"chimp\",\n      species %in% c(\"gorilla\",\"gorrila\") ~ \"gorilla\",\n      TRUE ~ species\n    )\n  ) |>\n    filter(\n      # get rid of ages -99\n      age > 0, \n      # keep when dominance is between -5 and 5 \n      # (5 here is a slightly arbitrary choice, but you can see from\n      # our checks that this will only exclude the two extreme datapoints\n      # that are 21.2 and 19.4\n      (dominance < 5 & dominance > -5) \n    )\n\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nHow is this data structure \"hierarchical\" (or \"clustered\")? How many levels do we have, and what are the observational units at each level?  \n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nWe have a random sample of $\\underbrace{\\text{timepoints}}_{\\text{level 1}}$ from a random sample of $\\underbrace{\\text{apes}}_{\\text{level 2}}$.  \n\n\n`r solend()`\n\n`r qbegin(qcounter())`\nFor how many apes do we have data? How many of each species?  \nHow many datapoints does each ape have?  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nWe've seen this last week too - counting the different levels in our data. See [Chapter 4: logisticMLM - #getting-to-know-my-monkeys](https://uoepsy.github.io/lmm/04_log.html#getting-to-know-my-monkeys){target=\"_blank\"} for an example (also about monkeys!)  \n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nWe have `r length(unique(apedat$ape))` apes in our dataset:  \n```{r}\nlength(unique(apedat$ape))\n```\n\nHere's how many of each species:  \n```{r}\napedat |> \n  group_by(species) |>\n  summarise(\n   n_apes = n_distinct(ape) \n  )\n```\n\nLet's create a table of how many observations for each ape, and then we can create a table _from_ that table, to show how many apes have 2 datapoints, how many have 3, 4, and so on:  \n```{r}\ntable(apedat$ape) |>\n  table() |>\n  barplot()\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nMake a plot to show how dominance changes for each ape as they get older.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nIn [Chapter 5: Longitudinal MLM - #exploring-the-data](https://uoepsy.github.io/lmm/05_long.html#exploring-the-data){target=\"_blank\"} we made a facet for each cluster (each participant). That was fine because we had only 20 people. In this dataset we have 168! That's too many to facet. We could try using `group` aesthetic instead, to plot multiple lines on the same plot, or we could just plot a sample of our apes. This is all just an initial look at the data, after all. \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nHere's a line for each ape, and a facet for each species:  \n```{r}\nggplot(apedat, aes(x = age, y = dominance, col = species))+\n  geom_line(aes(group = ape)) + \n  facet_wrap(~species) + \n  guides(col=\"none\")\n```\n\nIt's kind of hard to see the trend for each ape, so let's also make a separate little linear model for each ape:  \n\n```{r}\nggplot(apedat, aes(x = age, y = dominance, col = species))+\n  geom_smooth(aes(group = ape), method=lm, se=FALSE) + \n  facet_wrap(~species) + \n  guides(col=\"none\")\n```\n\nAlternatively, let's take a sample of apes, and plot the same stuff but facetted:\n```{r}\napedat |>\n  # choose the rows where ape ID is one of a random sample of 16 ape IDs\n  filter(ape %in% sample(unique(apedat$ape), 16) ) |>\n  ggplot(aes(x = age, y = dominance, col = species))+\n  geom_point() +\n  geom_smooth(method=lm, se=FALSE)+\n  facet_wrap(~ape)\n```\n\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nRecenter the `age` variable so that \"0\" becomes a 1-year old, which is the youngest age that we've got data on for any of our species.   \n\nThen fit a model that estimates the differences between primate species in how dominance changes over time.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nthink slowly about \"differences between primate species in how dominance changes over time\".  \n\n- \"how dominance changes over time\" -- sounds like `dominance ~ time`\n- so differences between primate species in this would require the interaction `dominance ~ time * species`\n- we have a random sample of apes, and for each of these we have multiple observations. We can model these as by-ape random effects - `+ (...... | ape)`\n\n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\napedat$age = apedat$age-1 \n\nm.full <- lmer(dominance ~ 1 + age * species + (1 + age | ape), data = apedat)\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\n__*Do*__ primate species differ in the growth of dominance?  \nPerform an appropriate test/comparison.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThis is asking about the `age*species` interaction, which in our model is represented by 3 parameters. To assess the overall question, it might make more sense to do a model comparison.  \n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nm.int <- lmer(dominance ~ 1 + age + species + (1 + age | ape), data = apedat)\n\nanova(m.int, m.full)\n```\n\n\n```{r}\n#| echo: false\nres = anova(m.int, m.full)\n\n```\n\n:::int\n\nSpecies differ in how dominance changes over adolescence ($\\chi^2(`r res[2,7]`) = `r round(res[2,6],2)`, p = `r format.pval(res[2,8],eps=.001,digits=1)`$).  \n\n:::\n\n\n`r solend()`\n\n`r qbegin(qcounter())`\nPlot the average model predicted values for each age.  \n\nBefore you plot.. do you expect to see straight lines? (remember, not every ape is measured at age 2, or age 3, etc).  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThis is like taking `predict()` from the model, and then then grouping by `age`, and calculating the mean of those predictions. However, we can do this more easily using `augment()` and then some fancy `stat_summary()` in ggplot (see [the lecture](https://uoepsy.github.io/msmr/2425/lectures/msmr_lec02-2_LinearLDA.html#17){target=\"_blank\"}).  \n\n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nAveraging fitted values would give us straight lines _if_ every ape had data at all ages, but in our study we have some apes with only 2 data points, and each ape has different set of ages (e.g., one ape might be measured at age 3, 6, and 10, another ape might be at ages 2 and 16).  \n\n```{r}\nlibrary(broom.mixed)\n\naugment(m.full) |>\nggplot(aes(age,dominance, color=species)) +\n  # the point ranges are our observations\n  stat_summary(fun.data=mean_se, geom=\"pointrange\") + \n  # the lines are our average predictions  \n  stat_summary(aes(y=.fitted, linetype=species), fun=mean, geom=\"line\")\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nPlot the model based fixed effects:  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\neffects::effect(\"age*species\", m.full, xlevels=10) |>\n  as.data.frame() |>\n  ggplot(aes(x=age+1,y=fit,col=species))+\n  geom_line(lwd=1)+\n  geom_ribbon(aes(ymin=lower,ymax=upper,fill=species),col=NA,alpha=.3) +  \n  scale_color_manual(values=c(\"grey30\",\"black\",\"grey50\",\"darkorange\")) +\n  scale_fill_manual(values=c(\"grey30\",\"black\",\"grey50\",\"darkorange\")) +\n  facet_wrap(~species) + \n  guides(col=\"none\",fill=\"none\") +\n  labs(x=\"Age (years)\")\n  \n```\n\n\n`r solend()`\n\n`r qbegin(qcounter())`\nIdentify what each of the fixed effects from the model represents (you might also want to get some p-values or confidence intervals).  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nEach of the estimates should correspond to part of our plot from the previous question.  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nLet's get some confidence intervals:  \n```{r}\nconfint(m.full, method=\"profile\",\n        parm = \"beta_\")\n```\n\n\n```{r}\n#| echo: false\ncis = confint(m.full, method=\"profile\",\n        parm = \"beta_\")\nsign = ifelse(cis[,1]>0|cis[,2]<0,1,0)\n\ntidy(m.full) |>\n  filter(effect==\"fixed\") |>\n  transmute(term, est=round(estimate,2),\n            CI = paste0(\"[\",round(cis[,1],2),\", \",round(cis[,2],2),\"]\")) |>\n  mutate(\n    CI = ifelse(sign,paste0(CI,\"*\"),CI)\n  ) |> \n  mutate(\n    interpretation = c(\n      \"estimated dominance of 1 year old bonobos (at left hand side of plot, bonobo line is lower than 0)\",\n      \"estimated change in dominance score for every year older a bonobo gets (slope of bonobo line)\",\n      \"estimated difference in dominance scores at age 1 between bonobos and chimps (at left hand side of plot, chimp line is higher than bonobo line)\",\n      \"estimated difference in dominance scores at age 1 between bonobos and gorillas (at left hand side of plot, gorilla line is higher than bonobo line)\",\n      \"no significant difference in dominance scores at age 1 between bonobos and orangutans (at the left hand side of our plot, orangutan line is similar height to bonobo line)\",\n      \"no significant difference between chimps and bonobos in the change in dominance for every year older (slope of chimp line is similar to slope of bonobo line)\",\n      \"no significant difference between gorillas and bonobos in the change in dominance for every year older (slope of gorilla line is similar to slope of bonobo line)\",\n      \"estimated difference between orangutans and bonobos in the change in dominance for every year older (slope of orangutan line is less steep than slope of bonobo line)\"\n    )\n  ) |> gt::gt()\n```\n\n\n`r solend()`\n\n<br>\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Trolley problems\n\n\n```{r}\n#| echo: false\nss = 173223\n#while(TRUE){\n#  ss = round(runif(1,1e3,1e6))\n  set.seed(ss)\n  n_groups = 120\n  npgroup = rep(12,n_groups)\n  g = unlist(lapply(1:n_groups, function(x) rep(x,npgroup[x])))\n  N = length(g)\n  b = round(runif(n_groups,18,45))\n  b = b[g]\n  x = rep(rep(1:3,e=4),n_groups)\n  x2 = rep(rep(letters[4:5],6),n_groups)\n  res = MASS::mvrnorm(n=n_groups,\n                      mu=c(0,0,0),\n                      Sigma=diag(c(4,2,2)) %*% \n                        matrix(c(1,.4,.3,.4,1,.4,.3,.4,1),nrow=3) %*% \n                        diag(c(4,2,2)))\n  re0 = res[,1]\n  re  = re0[g]\n  rex = res[,2]\n  re_x  = rex[g]\n  rex2 = res[,3]\n  re_x2  = rex2[g]\n  lp = (0 + re) + (.1*b) + \n    (-2 + re_x)*x + (2 + re_x2)*(x2==\"e\") +\n    (2*(x-2)*(x2==\"e\"))\n  y = lp + rnorm(N,0,1)\n  y_bin = rbinom(N,1, plogis(.75+scale(lp)))\n  df = data.frame(x=x,x2=x2,g=g, b=b,y=y,y_bin=y_bin)\n  mnames = unique(randomNames::randomNames(1e5,which=\"first\"))\n  df = df |> transmute(\n    frame = factor(x, levels=c(\"1\",\"2\",\"3\"),\n                   labels=c(\"positive\",\"neutral\",\"negative\")),\n    lives = factor(x2, levels=c(\"d\",\"e\"),labels=c(\"5lives\",\"15lives\")),\n    age = b,\n    PID = paste0(\"PPT_\",g),\n    lever = y_bin\n  )\n#   m = glmer(lever ~ scale(age) + frame*lives +\n#               (1+frame+lives|PID),data=df,family=binomial,\n#             control=glmerControl(optimizer = \"bobyqa\"))\n#   if(is.null(m@optinfo$conv$lme4$messages)){break}\n#   m = glmer(lever ~ scale(age) + frame*lives +\n#               (1+lives|PID),data=df,family=binomial,\n#             control=glmerControl(optimizer = \"bobyqa\"))\n#   if(is.null(m@optinfo$conv$lme4$messages)){break}\n# }\n# sjPlot::plot_model(m,type=\"int\")\n# summary(m)\ntrolley <- df |> select(PID,frame,lives,lever)\n# write_csv(trolley, file=\"../../data/msmr_trolley.csv\")\n```\n\n:::frame\n__Data: msmr_trolley.csv__  \n\nThe \"Trolley Problem\" is a thought experiment in moral philosophy that asks you to decide whether or not to pull a lever to divert a trolley. Pulling the lever changes the trolley direction from hitting 5 people to a track on which it will hit one person.  \n\n```{r}\n#| echo: false\nknitr::include_graphics(\"images/trolley.png\")\n```\n\nPrevious research has found that the \"framing\" of the problem will influence the decisions people make: \n\n```{r}\n#| echo: false\ntribble(\n  ~`positive frame`,~`neutral frame`,~`negative frame`,\n  \"5 people will be saved if you pull the lever; one person on another track will be saved if you do not pull the lever. All your actions are legal and understandable. Will you pull the lever?\",\"5 people will be saved if you pull the lever, but another person will die. One people will be saved if you do not pull the lever, but 5 people will die. All your actions are legal and understandable. Will you pull the lever?\",\n  \"One person will die if you pull the lever. 5 people will die if you do not pull the lever. All your actions are legal and understandable. Will you pull the lever?\"\n) |> gt::gt()\n```\n\nWe conducted a study to investigate **whether the framing effects on moral judgements depends upon the stakes (i.e. the number of lives saved)**.  \n\n`r n_distinct(trolley$PID)` participants were recruited, and each gave answers to 12 versions of the thought experiment. For each participant, four versions followed each of the positive/neutral/negative framings described above, and for each framing, 2 would save 5 people and 2 would save 15 people.  \n\nThe data are available at [https://uoepsy.github.io/data/msmr_trolley.csv](https://uoepsy.github.io/data/msmr_trolley.csv){target=\"_blank\"}.  \n\n```{r}\n#| echo: false\n#| label: tbl-trolley\n#| tbl-cap: \"Data Dictionary: trolley.csv\"\ntibble(\n  variable = names(trolley),\n  description = c(\n    \"Participant ID\",\n    \"framing of the thought experiment (positive/neutral/negative\",\n    \"lives at stake in the thought experiment (5 or 15)\",\n    \"Whether or not the participant chose to pull the lever (1 = yes, 0 = no)\")\n) |> gt::gt()\n```\n\n\n\n:::\n\n`r qbegin(qcounter())`\nRead in the data and check over how many people we have, and whether we have complete data for each participant.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nI would maybe try `data |> group_by(participant) |> summarise()`, and then use the `n_distinct()` function to count how many \"things\" each person sees (e.g., [Chapter 4: Logistic MLM #example](https://uoepsy.github.io/lmm/04_log.html#example){target=\"_blank\"}). \n\n:::\n\n\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n\n```{r}\ntrolley <- read_csv(\"https://uoepsy.github.io/data/msmr_trolley.csv\")\nhead(trolley)\n```\n\nHow many participants?\n```{r}\nlength(unique(trolley$PID))\n```\n\nHow many trials for each participant in each condition.  \nWe can, for each participant, count how many trials they have in total, how many \"frames\" they see, how many \"lives\" they see, and how many \"frame x lives\" combinations they see:  \n```{r}\ntrolley |>\n  group_by(PID) |>\n  summarise(\n    n_trials = n(),\n    n_frame = n_distinct(frame),\n    n_lives = n_distinct(lives),\n    n_combn = n_distinct(frame,lives)\n  )\n```\n\nIf everybody gets the same here (as we can see they do below), then everyone has complete data!  \n\n```{r}\ntrolley |>\n  group_by(PID) |>\n  summarise(\n    n_trials = n(),\n    n_frame = n_distinct(frame),\n    n_lives = n_distinct(lives),\n    n_combn = n_distinct(frame,lives)\n  ) |>\n  summary()\n```\n\n\n`r solend()`\n\n`r qbegin(qcounter())`\nConstruct an appropriate plot to summarise the data in a suitable way to illustrate the research question.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nSomething making use of `stat_summary()` to give proportions, a bit like the plot in [Chapter 4: Logistic MLM - #getting-to-know-my-monkeys](https://uoepsy.github.io/lmm/04_log.html#getting-to-know-my-monkeys){target=\"_blank\"}?  \n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nHere is a plot of proportions of trials in which the lever was pulled, split by how the problem was framed, and the number of lives saved:  \n```{r}\nggplot(trolley, aes(x=frame, y=lever, col=lives)) +\n  stat_summary(geom=\"pointrange\", size=1, \n               position=position_dodge(width=.2)) \n  \n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nFit a model to assess the research aims.  \nDon't worry if it gives you an error/warning, we'll deal with that in a second.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- Remember, a good way to start is to split this up into 3 parts: 1) the outcome and fixed effects, 2) the grouping structure, and 3) the random slopes.  \n- If we have an interaction `y ~ 1 + x1*x2 + (1 .... | groups)`, and both predictors `x1` and `x2` vary within groups (i.e., each group has various values of the predictor), then because we can put random slopes of these variables --- `(1 + x1 + x2 | groups)` --- we can almost always also put the interaction in and have `(1 + x1 * x2 | groups)`  \n- fitting (or attempting to fit!) `glmer` models might take time!  \n\n\n:::\n\n`r qend()`\n`r solbegin(label=\"1 - fixed\", slabel=F,show=T, toggle=params$TOGGLE)`\n\nThe researchers are *\"interested in whether the framing effects on moral judgements depends upon the stakes (i.e. the number of lives saved)\"*.  \n\n\"the framing effect on moral judgements\" here is operationalised as  \n```{r}\n#| eval: false\nlever ~ frame\n```\nand the wording \"depends upon the stakes\" means that we want to know if that effect of frame \"is different for\" the situations when lives = 5, vs lives = 15 - i.e. we need the interaction!  \n```{r}\n#| eval: false\nlever ~ frame * lives\n```\n\nThe outcome here is lever pulled (yes v no), so it's a binary variable!  \n\n```{r}\n#| eval: false\nglmer(lever ~ frame * lives + ....\n      ....,  \n      data = trolley, family = binomial)\n```\n\n`r solend()`\n`r solbegin(label=\"2 - grouping\", slabel=F,show=T, toggle=params$TOGGLE)`\n\nWe know that we have multiple observations for each participant, and those participants are just a random sample (it's not something we're interested in testing, we would like to model participant differences as random variation).  \n```{r}\n#| eval: false\nglmer(lever ~ frame * lives + ....\n      (1 + .... | PID),  \n      data = trolley, family = binomial)\n```\n\n\n`r solend()`\n`r solbegin(label=\"3 - random\", slabel=F,show=T, toggle=params$TOGGLE)`\n\nFinally, what effects _could_ theoretically vary between our participants?  \nEvery participant saw everything (i.e. both `frame` and `lives` are \"within participant\" variables). \n\nIn theory, all of these are possible given our design:  \n\n- the effect of frame on probability of pulling the lever could vary between participants\n- the effect of number of lives on probability of pulling the lever could vary between participants\n- the amount by which number of lives influences the effect of frame on pulling the lever could vary between participants\n\nSo we could theoretically try and fit this model:  \n```{r}\n#| eval: false\nmod1 <- glmer(lever ~ frame * lives + \n      (1 + frame * lives | PID),  \n      data = trolley, family = binomial)\n```\n<p style=\"color:red;\">\nWarning messages:<br>\n1: In (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int(Inf,  :\n  failure to converge in 10000 evaluations<br>\n2: In optwrap(optimizer, devfun, start, rho\\$lower, control = control,  :\n  convergence code 4 from Nelder_Mead: failure to converge in 10000 evaluations<br>\n3: In checkConv(attr(opt, \"derivs\"), opt\\$par, ctrl = control\\$checkConv,  :\n  Model failed to converge with max|grad| = 0.0795145 (tol = 0.002, component 1)\n</p>\n`r solend()`\n\n`r qbegin(qcounter())`\nThis is probably the first time we've had to deal with a model not converging.  \n\nSometimes changing the optimizer can help, but ideally we wouldn't want to just shop around until we find one that doesn't tell us about an error! More often than not, the model we are trying to fit is just too complex for our sample. Often, the groups in our sample just don't vary enough for us to estimate a random slope (this doesn't mean there is no variance in the real world, we might simply not have enough groups to see it).  \n\nThe aim here is to simplify our random effect structure in order to obtain a converging model, but be careful not to over simplify.  \n\nThere are no hard-and-fast rules on how to simplify, but the guiding principles might be thought of as: \n\n1. we are **only** simplifying the random effects part, and **not** the fixed effects\n2. remove one thing at a time!  \n3. consider removing \"more complex\" parts first (interactions, slopes of categorical predictors)\n3. sometimes, the estimated variances in the non-converging model can guide us by indicating the parts of the structure for which there is not enough variability in the data (essentially, look for the tiny variances!).  \n\n\nTry it now. What model do you end up with? (You might not end up with the same model as each other, which is fine. These methods don't have \"cookbook recipes\"!)\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nYou could think of the interaction as the 'most complex' part of our random effects, so you might want to remove that first.  \n\n:::\n\n\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n\nWe'll remove the interaction first. But this model still does not converge:  \n```{r}\nmod2 <- glmer(lever ~ frame * lives + \n      (1 + frame + lives | PID),  \n      data = trolley, family = binomial)\n```\n<p style=\"color:red;\">\nWarning message:<br>\nIn checkConv(attr(opt, \"derivs\"), opt\\$par, ctrl = control\\$checkConv,  :\n  Model failed to converge with max|grad| = 0.00734804 (tol = 0.002, component 1)\n</p>\n\nWe have a choice here - do we remove `frame|PID` or `lives|PID`?  \nOne practical point is that each participant has only 4 observations for each `frame` type, but they have 6 observations for each `lives` type, which might make it easier to fit.  \n\nAnother argument is that when doing this experiment, the `lives` manipulation is perhaps more *salient* than the specific wording. I could imagine, taking this study as a participant, that I might sort of skim read each version and not fully attend to the framing, but notice quite clearly the number of lives at stake. So it's possible that this effect may be bigger (and therefore more variable between people) than the effect of framing.  \n```{r}\nmod3 <- glmer(lever ~ frame * lives + \n      (1 + lives | PID),  \n      data = trolley, family = binomial)\n```\nHooray! it converges!  \n\n`r solend()`\n\n`r qbegin(qcounter())`\nWe're now going to plot the predicted probabilities from your model for each combination of `frame` and `lives`.  \n\nBefore you actually do this, ask yourself what pattern you expect to see (based on your fixed effects)? Then plot it and see if you were right!  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nlibrary(effects)\neffect(\"frame*lives\", mod3) |>\n  as.data.frame() |>\n  ggplot(aes(x = frame, y = fit, col = lives)) +\n  geom_pointrange(aes(ymin=lower,ymax=upper),\n                  position=position_dodge(width=.2),\n                  size=1)+\n  labs(y=\"probability of pulling the lever\")\n```\n\n\n`r solend()`\n\n<!-- `r qbegin(qcounter())` -->\n<!-- Compute odds ratios and create some confidence intervals, then interpret them.   -->\n\n\n<!-- ::: {.callout-tip collapse=\"true\"} -->\n<!-- #### Hints -->\n\n<!-- Odds ratios are confusing, so take the lead from your plot about what goes up/down etc.   -->\n<!-- The default of profile likelihood confidence intervals might take a while to compute, so you could choose the Wald method instead (see [2B #interpretation](02b_loglong.html#interpretation){target=\"_blank\"}).   -->\n\n<!-- ::: -->\n\n\n<!-- `r qend()` -->\n<!-- `r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)` -->\n\n<!-- ```{r} -->\n<!-- cbind( -->\n<!--   fixef(mod3), # the fixed effects -->\n<!--   confint(mod3, method=\"Wald\", parm=\"beta_\") # Wald CIs for fixed effects -->\n<!-- ) |> -->\n<!--   exp() -->\n<!-- ``` -->\n\n<!-- ```{r} -->\n<!-- #| echo: false -->\n<!-- cbind( -->\n<!--   fixef(mod3), # the fixed effects -->\n<!--   confint(mod3, method=\"Wald\", parm=\"beta_\") # Wald CIs for fixed effects -->\n<!-- ) |> -->\n<!--   exp() |> as.data.frame() |> -->\n<!--   rownames_to_column() |> -->\n<!--   transmute( -->\n<!--     term = rowname, OR=round(V1,2), -->\n<!--     CI = paste0(\"[\", -->\n<!--                 round(`2.5 %`,2),\", \", -->\n<!--                 round(`97.5 %`,2),\"]\" -->\n<!--     ), -->\n<!--     interpretation = c( -->\n<!--       \"Odds of pulling the lever when in a positive framed problem with the potential of saving 5 lives\", -->\n<!--       paste0(\"With 5 lives at stake, a neutral framing is associated with \",round(exp(fixef(mod3))[2],2),\" times the odds of pulling the lever in comparison to a positive framing\"), -->\n<!--       paste0(\"With 5 lives at stake, a negative framing is associated with \",round(exp(fixef(mod3))[3],2),\" times the odds of pulling the lever in comparison to a positive framing\"), -->\n<!--       \"In a positive framing, the number of lives at stake is not associated with a change in the odds of pulling the lever\", -->\n<!--       paste0(\"In the neutral framing, the 15 vs 5 lives The neutral vs positive framing difference is increase  \",round(exp(fixef(mod3))[2],2),\" times the odds of pulling the lever in comparison to a positive framing\"), -->\n<!--     ) -->\n<!--   )  -->\n<!-- ``` -->\n\n<!-- `r solend()` -->\n\n\n<br>\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n\n# Optional extra: Novel Word Learning\n\n\n:::frame\n__Data: nwl.Rdata__ \n\n```{r}\nload(url(\"https://uoepsy.github.io/msmr/data/nwl.RData\"))\n```\n\nIn the `nwl` data set (accessed using the code above), participants with aphasia are separated into two groups based on the general location of their brain lesion: anterior vs. posterior. There is data on the numbers of correct and incorrect responses participants gave in each of a series of experimental blocks. There were 7 learning blocks, immediately followed by a test. Finally, participants also completed a follow-up test.\n<br>\nData were also collect from healthy controls. \n<br>\n@fig-nwl shows the differences between lesion location groups in the average proportion of correct responses at each point in time (i.e., each block, test, and follow-up)\n\n```{r}\n#| label: fig-nwl\n#| echo: false\n#| fig.cap: \"Differences between groups in the average proportion of correct responses at each block\"\nload(url(\"https://uoepsy.github.io/msmr/data/nwl.RData\"))\nggplot(filter(nwl, !is.na(lesion_location)), aes(block, PropCorrect, \n                                            color=lesion_location, \n                                            shape=lesion_location)) +\n  #geom_line(aes(group=ID),alpha=.2) + \n  stat_summary(fun.data=mean_se, geom=\"pointrange\") + \n  stat_summary(data=filter(nwl, !is.na(lesion_location), block <= 7), \n                           fun=mean, geom=\"line\") + \n  geom_hline(yintercept=0.5, linetype=\"dashed\") + \n  geom_vline(xintercept=c(7.5, 8.5), linetype=\"dashed\") + \n  scale_x_continuous(breaks=1:9, labels=c(1:7, \"Test\", \"Follow-Up\")) + \n  theme_bw(base_size=10) + \n  labs(x=\"Block\", y=\"Proportion Correct\", shape=\"Lesion\\nLocation\", color=\"Lesion\\nLocation\")\n```\n\n\n```{r}\n#| echo: false\ndata.frame(\n  variable = names(nwl),\n  description = c(\"Whether participant is a stroke patient ('patient') or a healthy control ('control')\", \"Location of brain lesion: anterior vs posterior\",\"Experimental block (1-9). Blocks 1-7 were learning blocks, immediately followed by a test in block 8. Block 9 was a follow-up test at a later point\",\"Proportion of 30 responses in a given block that the participant got correct\",\"Number of responses (out of 30) in a given block that the participant got correct\",\"Number of responses (out of 30) in a given block that the participant got incorrect\",\"Participant Identifier\",\"Experimental phase, corresponding to experimental block(s): 'Learning', 'Immediate','Follow-up'\")\n) |> gt::gt()\n```\n\n\n:::\n\n\n`r qbegin(qcounter())`\nLoad the data. Take a look around. Any missing values? Can you think of why?  \n`r qend()`\n\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n\n```{r}\nload(url(\"https://uoepsy.github.io/msmr/data/nwl.RData\"))\nsummary(nwl)\n```\n\nThe only missing vales are in the lesion location, and it's probably because the healthy controls don't have any lesions. There may also be a few patients for which the lesion_location is missing, but this should be comparatively fewer values compared to controls.\n\nThe following command creates a two-way frequency table showing the number of controls or patients by lesion location, confirming that controls only have missing values (NAs) and only 9 patients have missing values:\n\n```{r}\ntable(nwl$group, nwl$lesion_location, useNA = \"ifany\")\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nOur broader research aim today is to compare the two lesion location groups (those with anterior vs. posterior lesions) with respect to their accuracy of responses over the course of the study.  \n\n- What is the outcome variable? \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThink carefully: there might be several variables which either fully or partly express the information we are considering the \"outcome\" here. \nWe saw this back in [USMR](https://uoepsy.github.io/usmr/2425/labs/10a_glm.html#fitting-glm-in-r){target=\"_blank\"} with the `glm()`!  \n\n:::\n\n\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\nThe outcome here is (in words) the proportion of correct answers or, equivalently, the probability of answering correctly. A proportion/probability can only vary between 0 and 1 and, as such, we cannot use traditional linear regression or we could end up with predictions outside of the [0, 1] range.\n\nAs said, the outcome is the proportion of correct answers in each block. This makes it tempting to look at the variable called `PropCorrect`, but this is encoded as a proportion. We have learned to use logistic models, but these require either:\n\n- a binary outcome variable, where the values are 0s or 1s\n- a binomial outcome variable, where the values are aggregated counts of 1s and 0s \n\n__Binary data__. In the case below you would use the specification `correct ~ ...`:\n\n```{r echo=FALSE}\ntibble(participant = c(1,1,1),\n       question=c(1,2,3),\n       correct=c(1,0,1)) %>%\n    rbind(rep(\"...\",3)) %>%\n    gt::gt()\n```\n\n__Binomial data__. You would use the specification `cbind(NumCorrect, NumError) ~ ...`:  \n\n\n```{r echo=FALSE}\ntibble(participant = c(1,2,3),\n       NumCorrect=c(2,1,3),\n       NumError=c(1,2,0)) %>% \n    rbind(rep(\"...\",3)) %>% \n    gt::gt()\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\n> **Research Question 1:**  \n> Is the learning rate (training blocks) different between the two lesion location groups?\n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- Do we want `cbind(successes, failures)`?\n\n- Ensure you are running models on only the data we are actually interested in. \n\n    + Are the healthy controls included in the research question under investigation?\n    + Are the testing blocks included in the research question, or only the learning blocks?\n\n- We could use model comparison via likelihood ratio tests (using `anova(model1, model2, model3, ...)`. For this question, we could compare:\n\n    + A model with just the change over the sequence of blocks\n    + A model with the change over the sequence of blocks *and* an overall difference between groups\n    + A model with groups differing with respect to their change over the sequence of blocks\n\n- What about the random effects part?  \n    \n    1. What are our observations grouped by? \n    2. What variables can vary within these groups? \n    3. What do you want your model to allow to vary within these groups?\n\n:::\n\n`r qend()`\n`r solbegin(label=\"1 - answers to the hints\", slabel=F,show=T, toggle=params$TOGGLE)`\n\n- Do we want `cbind(successes, failures)`?\n\n    + Yes, we don't a binary variable with correct/incorrect questions but the binomial variables NumCorrect and NumError representing, respectively, the aggregated count (out of 30) of correct and incorrect questions. As such, we will need the following: `cbind(NumCorrect, NumError)`\n\n- Ensure you are running models on only the data we are actually interested in. \n\n    + The healthy controls are not included in the research question under investigation, so we will exclude them.\n    + We are only interested in the learning blocks, and we will exclude the testing blocks (block > 7) \n    + You might want to store this data in a separate object, but in the code for the solution we will just use `filter()` *inside* the `glmer()`.   \n  \n- A model with just the change over the sequence of blocks:\n    - **outcome ~ block**\n- A model with the change over the sequence of blocks *and* an overall difference between groups:\n    - **outcome ~ block + lesion_location**\n- A model with groups differing with respect to their change *over the sequence of blocks:\n    - **outcome ~ block * lesion_location**\n    \n- What are our observations grouped by? \n    - repeated measures by-participant. i.e., the `ID` variable\n- What variables can vary within these groups? \n    - `Block` and `Phase`. Be careful though - you can create the `Phase` variable out of the `Block` variable, so really this is just one piece of information, encoded differently in two variables. \n    - The other variables (`lesion_location` and `group`) do **not** vary for each ID. Lesions don't suddenly change where they are located, nor do participants swap between being a patient vs a control (we don't need the group variable anyway as we are excluding the controls).  \nWhat do you want your model to allow to vary within these groups?\n    - Do you think the change over the course of the blocks is **the same** for everybody? Or do you think it varies? Is this variation important to think about in terms of your research question?   \n    \n`r solend()`\n`r solbegin(label=\"2 - modelling\", slabel=F,show=T, toggle=params$TOGGLE)`\n\n```{r}\nm.base <- glmer(cbind(NumCorrect, NumError) ~ block + (1 + block | ID), \n                data = filter(nwl, block < 8, !is.na(lesion_location)),\n                family=binomial)\n\nm.loc0 <- glmer(cbind(NumCorrect, NumError) ~ block + lesion_location + (1 + block | ID), \n                data=filter(nwl, block < 8, !is.na(lesion_location)),\n                family=binomial)\n\nm.loc1 <- glmer(cbind(NumCorrect, NumError) ~ block * lesion_location + (1 + block | ID), \n                data=filter(nwl, block < 8, !is.na(lesion_location)),\n                family=binomial)\n\n\nanova(m.base, m.loc0, m.loc1, test=\"Chisq\")\n```\n:::int\nNo significant difference in learning rate between groups ($\\chi^2(1)=2.2, p = 0.138$).\n:::\n\n`r solend()`\n\n`r qbegin(qcounter())`\n> **Research Question 2**  \n> In the testing phase, does performance on the immediate test differ between lesion location groups, and does the retention from immediate to follow-up test differ between the two lesion location groups?\n\nLet's try a different approach to this. Instead of fitting various models and comparing them via likelihood ratio tests, just fit the one model which could answer both parts of the question above.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- This might required a bit more data-wrangling beforehand. Think about the order of your factor levels (alphabetically speaking, \"Follow-up\" comes before \"Immediate\")!\n\n:::\n\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n```{r}\nnwl_test <- filter(nwl, block > 7, !is.na(lesion_location)) |>\n    mutate(\n        Phase = factor(Phase), \n        Phase = fct_relevel(Phase, \"Immediate\")\n    )\n\nm.recall.loc <- glmer(cbind(NumCorrect, NumError) ~ Phase * lesion_location + (1 | ID), \n                      nwl_test, family=\"binomial\")\n\nsummary(m.recall.loc)\n```\n\n\n__Note 1__: \n\nIn the above, we have made sure to select the patients by specifying `!is.na(lesion_location)`, meaning that we want those rows where the lesion location is not missing. As a reminder `!` is the negation function (not). As we saw in the earlier question, this excludes the 126 healthy controls, as well as the 9 patients for which we have missing values (NAs).\n\n__Note 2__:  \n\nWe didn't specify `(Phase | ID)` as the random effect because each participant only has 2 data points for Phase, and there is only one line that fits two data points. In other words, there is only one possible way to fit those two data points. As such, as each group of 2 points will have a perfect line fit, and the residuals $\\varepsilon_{ij}$ will all be 0. As a consequence of this, the residuals will have no variability as they are all 0, so $\\sigma_{\\epsilon}$ is 0 which in turn leads to problem with estimating the model coefficients.\n\n```{r}\nsubset(nwl_test, ID == 'patient15')\n```\n\nIf you try using `(Phase | ID)` as random effect, you will see the following message:\n\n`boundary (singular) fit: see help('isSingular')`\n\n`r solend()`\n\n`r qbegin(qcounter())`\n\n1. In `family = binomial(link='logit')`. What function is used to relate the linear predictors in the model to the expected value of the response variable?  \n2. How do we convert this into something more interpretable?  \n\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n \n1. The link function is the `logit`, or log-odds (other link functions are available).\n\n2. To convert log-odds to odds, we can use `exp()`, to get odds and odds ratios.  \n\n`r solend()`\n\n`r qbegin(qcounter())`\nMake sure you pay attention to trying to interpret each fixed effect from your models.  \nThese can be difficult, especially when it's logistic, and especially when there are interactions.  \n\n- What is the increase in the odds of answering correctly in the immediate test if you were to have a posterior legion instead of an anterior legion?  \n\n<!-- `r optbegin(\"Optional help: Our Solution to A4\", olabel=F, toggle=params$TOGGLE)` -->\n<!-- ```{r eval=F} -->\n<!-- nwl_test <- filter(nwl, block > 7, !is.na(lesion_location)) %>% -->\n<!--   mutate( -->\n<!--     Phase = fct_relevel(factor(Phase),\"Immediate\") -->\n<!--   ) -->\n\n<!-- m.recall.loc <- glmer(cbind(NumCorrect, NumError) ~ Phase * lesion_location + (Phase | ID),  -->\n<!--                   nwl_test, family=\"binomial\") -->\n<!-- ``` -->\n<!-- `r optend()` -->\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nexp(fixef(m.recall.loc))\n```\n\n\n* `(Intercept)` ==> Anterior lesion group performance in immediate test. This is the odds of them answering correctly in the immediate test. \n* `PhaseFollow-up`  ==> Change in performance (for someone with an anterior lesion) from immediate to follow-up test. \n* `lesion_locationposterior` ==> Change in performance in immediate test were a patient to have a posterior lesion instead of an anterior lesion. \n* `PhaseFollow-up:lesion_locationposterior` ==> How change in performance from immediate to follow-up test would differ were a patient to have a posterior lesion instead of an anterior lesion.  \n\n```{r}\nexp(fixef(m.recall.loc))[3]\n```\n\n:::int\nHaving a posterior lesions is associated with `r round(exp(fixef(m.recall.loc))[3],2)` times the odds of answering correctly in the immediate test compared to having an anterior lesion.  \n:::\n\n`r solend()`\n\n`r qbegin(qcounter())`\nRecreate the visualisation in @fig-nwl2.  \n\n```{r}\n#| label: fig-nwl2\n#| echo: false\n#| fig-cap: \"Differences between groups in the average proportion of correct responses at each block\"\nload(url(\"https://uoepsy.github.io/msmr/data/nwl.RData\"))\nggplot(filter(nwl, !is.na(lesion_location)), aes(block, PropCorrect, \n                                                 color=lesion_location, \n                                                 shape=lesion_location)) +\n    #geom_line(aes(group=ID),alpha=.2) + \n    stat_summary(fun.data=mean_se, geom=\"pointrange\") + \n    stat_summary(data=filter(nwl, !is.na(lesion_location), block <= 7), \n                 fun=mean, geom=\"line\") + \n    geom_hline(yintercept=0.5, linetype=\"dashed\") + \n    geom_vline(xintercept=c(7.5, 8.5), linetype=\"dashed\") + \n    scale_x_continuous(breaks=1:9, \n                       labels=c(1:7, \"Test\", \"Follow-Up\")) + \n    theme_bw(base_size=10) + \n    labs(x=\"Block\", y=\"Proportion Correct\", \n         shape=\"Lesion\\nLocation\", color=\"Lesion\\nLocation\")\n```\n\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n```{r}\nggplot(filter(nwl, !is.na(lesion_location)), aes(block, PropCorrect, \n                                                 color=lesion_location, \n                                                 shape=lesion_location)) +\n    #geom_line(aes(group=ID),alpha=.2) + \n    stat_summary(fun.data=mean_se, geom=\"pointrange\") + \n    stat_summary(data=filter(nwl, !is.na(lesion_location), block <= 7), \n                 fun=mean, geom=\"line\") + \n    geom_hline(yintercept=0.5, linetype=\"dashed\") + \n    geom_vline(xintercept=c(7.5, 8.5), linetype=\"dashed\") + \n    scale_x_continuous(breaks=1:9, \n                       labels=c(1:7, \"Test\", \"Follow-Up\")) + \n    theme_bw(base_size=10) + \n    labs(x=\"Block\", y=\"Proportion Correct\", \n         shape=\"Lesion\\nLocation\", color=\"Lesion\\nLocation\")\n```\n`r solend()`\n\n\n<!-- `r qbegin(qcounter())` -->\n<!-- This code is that we used to answer the question above, only we have edited it to change lesion location to be fitted with \"sum contrasts\".   -->\n\n<!-- ```{r echo=TRUE} -->\n<!-- nwl_test <- filter(nwl, block > 7, !is.na(lesion_location)) %>% -->\n<!--     mutate( -->\n<!--         Phase = factor(Phase), -->\n<!--         Phase = fct_relevel(Phase, \"Immediate\") -->\n<!--     ) -->\n\n<!-- m.recall.loc.effcoding <-  -->\n<!--     glmer(cbind(NumCorrect, NumError) ~ Phase * lesion_location + (1 | ID),  -->\n<!--           contrasts = list(lesion_location = \"contr.sum\"), -->\n<!--           data = nwl_test, family=\"binomial\") -->\n<!-- ``` -->\n\n\n<!-- The interpretation of this is going to get pretty tricky - we have a logistic regression, and we have different coding scheme for our categorical predictor, and we have an interaction.. &#x1f92f;   -->\n\n<!-- Can you work out the interpretation of the fixed effects estimates?   -->\n\n<!-- `r qend()` -->\n<!-- `r solbegin(show=TRUE, toggle=params$TOGGLE)` -->\n\n<!-- * `(Intercept)` ==> Overall performance in immediate test. This is the overall log-odds of answering correctly in the immediate test.  -->\n<!-- * `PhaseFollow-up`  ==> Average change in performance from immediate to follow-up test.  -->\n<!-- * `lesion_location1` ==> Anterior lesion group performance in immediate test relative to *overall average* performance in immediate test -->\n<!-- * `PhaseFollow-up:lesion_location1` ==> Change in performance from immediate to follow-up test, anterior lesion group relative to overall average -->\n\n\n<!-- **???**   -->\n<!-- How do we know that `lesion_location1` is the *anterior* and not the *posterior* lesion group?  -->\n<!-- We need to check the what the contrasts look like:   -->\n<!-- ```{r} -->\n<!-- contrasts(nwl_test$lesion_location) <- \"contr.sum\" -->\n<!-- contrasts(nwl_test$lesion_location) -->\n<!-- ``` -->\n<!-- Because there are only two levels to this variable, the estimate will simply flip sign (positive/negative) depending on which way the contrast is leveled.   -->\n\n\n<!-- ::: {.callout-note collapse=\"true\"} -->\n<!-- #### I liked my coefficients being named properly? -->\n\n<!-- ```{r} -->\n<!-- colnames(contrasts(nwl_test$lesion_location)) <- \"PeppaPig\" -->\n\n<!-- contrasts(nwl_test$lesion_location) -->\n\n<!-- modeltest <-  -->\n<!--     glmer(cbind(NumCorrect, NumError) ~ Phase * lesion_location + (1 | ID), -->\n<!--           nwl_test, family=\"binomial\") -->\n<!-- summary(modeltest)$coefficients -->\n<!-- ``` -->\n\n<!-- ::: -->\n\n<!-- `r solend()` -->\n\n\n","srcMarkdownNoYaml":"\n\n```{r}\n#| label: setup\n#| include: false\nsource('assets/setup.R')\nlibrary(xaringanExtra)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(ggdist)\nxaringanExtra::use_panelset()\nqcounter <- function(){\n  if(!exists(\"qcounter_i\")){\n    qcounter_i <<- 1\n  }else{\n    qcounter_i <<- qcounter_i + 1\n  }\n  qcounter_i\n}\n```\n\n```{r}\n#| echo: false\nss = 230168\n# ss = round(runif(1,1e3,1e6))\nset.seed(ss)\nn_groups = 168\nnpgroup = round(runif(368,2,8))\ng = unlist(sapply(1:n_groups, function(x) rep(x,npgroup[x])))\nN = length(g)\nx = round(runif(N,1,10))\nb = sample(letters[1:4],n_groups,T,prob=c(.3,.2,.3,.2))\nb = b[g]\nres = MASS::mvrnorm(n=n_groups,\n                    mu=c(0,0),\n                    Sigma=diag(c(3,2))%*%matrix(c(1,.4,.4,1),nrow=2)%*%diag(c(3,2)))\nre0 = res[,1]\nre  = re0[g]\nrex = res[,2]\nre_x  = rex[g]\nlp = (0 + re) + (1.1 + re_x)*scale(x,center=F)[,1] + \n  1.4*(b==\"c\") +1.8*(b==\"a\") +    \n  .8*(b==\"c\")*scale(x,center=F)[,1]+\n  -1.1*(b==\"d\")*scale(x,center=F)[,1]\ny = lp + rnorm(N,0,1)\ndf = data.frame(x = x,g=g, b=b,y=round(scale(y)[,1],1))\n\nmnames = unique(randomNames::randomNames(1e5,which=\"first\"))\n\ndf = df |>\n  transmute(\n    ape = mnames[g],\n    age = x,\n    species = as.character(factor(b, levels=letters[1:4],labels=c(\"gorilla\",\"bonobo\",\"chimp\",\"orangutan\"))),\n    dominance = y\n  )\n# \n# m1=lmer(dominance ~ age + (1+age|ape),df)\n# m2=lmer(dominance ~ age + species + (1+age|ape),df)\n# m3=lmer(dominance ~ age * species + (1+age|ape),df)\n# any(!is.null(c(m1@optinfo$conv$lme4$messages,\n#                m2@optinfo$conv$lme4$messages,\n#                m3@optinfo$conv$lme4$messages)))\n# library(lme4)\n# df$age=df$age-1\n# m1=lmer(dominance ~ age + (1+age|ape),df)\n# m2=lmer(dominance ~ age + species + (1+age|ape),df)\n# m3=lmer(dominance ~ age * species + (1+age|ape),df)\n# any(!is.null(c(m1@optinfo$conv$lme4$messages,\n#                m2@optinfo$conv$lme4$messages,\n#                m3@optinfo$conv$lme4$messages)))\n# anova(m1,m2,m3)\n# plot(effects::effect(\"age*species\",m3))\n# summary(m3)\n\ndf$dominance[sample(1:nrow(df),2)] <- c(19.4,-21.2)\n\nspl = df |> count(ape,species) |>\n  mutate(\n    sp2 = case_when(\n      species==\"chimp\" ~ sample(c(\"chimp\",\"chimpanzee\"),n(),T),\n      TRUE ~ species\n    )\n  )\ndf = left_join(df,spl)\ndf[df$ape==\"Paige\",\"sp2\"] = \"gorrila\"\ndf$age[sample(1:nrow(df),3)] <- -99\ndf = df |> transmute(\n  ape, species=sp2, age, dominance\n)\n\n# df |> count(ape,species) |> select(-n) |>\n#   write_csv(file=\"../../data/msmr_apespecies.csv\")\n# df |> select(ape, age, dominance) |>\n#   write_csv(file=\"../../data/msmr_apeage.csv\")\n\n\n\n\n# library(lme4)\n# m1=lmer(dominance ~ age + (1+age|ape),df)\n# m2=lmer(dominance ~ age + species + (1+age|ape),df)\n# m3=lmer(dominance ~ age * species + (1+age|ape),df)\n# any(!is.null(c(m1@optinfo$conv$lme4$messages,\n#                m2@optinfo$conv$lme4$messages,\n#                m3@optinfo$conv$lme4$messages)))\n# anova(m1,m2,m3)\n# plot(effects::effect(\"age*species\",m3))\n# summary(m3)\n# emmeans::emtrends(m3,var=\"x\") |> summary(infer=c(TRUE))\n```\n\n\n# Great Apes!  \n\n:::frame\n__Data: msmr_apespecies.csv__ & __msmr_apeage.csv__  \n\nWe have data from a large sample of great apes who have been studied between the ages of 1 to 10 years old (i.e. during adolescence). Our data includes 4 species of great apes: Chimpanzees, Bonobos, Gorillas and Orangutans. Each ape has been assessed on a primate dominance scale at various ages. Data collection was not very rigorous, so apes do not have consistent assessment schedules (i.e., one may have been assessed at ages 1, 3 and 6, whereas another at ages 2 and 8).  \n\nThe researchers are interested in examining how the adolescent development of dominance in great apes differs between species.  \n\nData on the dominance scores of the apes are available at [https://uoepsy.github.io/data/msmr_apeage.csv](https://uoepsy.github.io/data/msmr_apeage.csv){target=\"_blank\"} and the information about which species each ape is are in [https://uoepsy.github.io/data/msmr_apespecies.csv](https://uoepsy.github.io/data/msmr_apespecies.csv){target=\"_blank\"}.  \n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n```{r}\n#| echo: false\n#| label: tbl-spec1\n#| tbl-cap: \"Data Dictionary: msmr_apespecies.csv\"  \nape_species <- read_csv(\"../../data/msmr_apespecies.csv\")\ntibble(\n  variable = names(ape_species),\n  description = c(\"Ape Name\",\"Species (Bonobo, Chimpanzee, Gorilla, Orangutan)\")\n) |> gt::gt()\n```\n:::\n::: {.column width=\"10%\"}\n\n:::\n::: {.column width=\"45%\"}\n```{r}\n#| echo: false\n#| label: tbl-spec2\n#| tbl-cap: \"Data Dictionary: msmr_apeage.csv\"  \nape_age <- read_csv(\"../../data/msmr_apeage.csv\")\ntibble(\n  variable = names(ape_age),\n  description = c(\"Ape Name\",\"Age at assessment (years)\",\"Dominance (Z-scored)\")\n) |> gt::gt()\n```\n\n:::\n::::\n\n:::\n\n\n\n\n`r qbegin(qcounter())`\nRead in the data and check over it. Do any relevant cleaning/wrangling that might be necessary.   \n\n`r qend()`\n`r solbegin(label=\"1 - reading and joining\", slabel=F,show=T, toggle=params$TOGGLE)`\nWe'll read in both datasets, and then join them together. \n```{r}\nlibrary(tidyverse)\nlibrary(lme4)\nape_species <- read_csv(\"https://uoepsy.github.io/data/msmr_apespecies.csv\")\nape_age <- read_csv(\"https://uoepsy.github.io/data/msmr_apeage.csv\")\n```\nSometimes is handy to check that all our participants are in both datasets:\n```{r}\n# are all the apes in ape_age also in ape_species?\nall(ape_age$ape %in% ape_species$ape)\n# and vice versa?\nall(ape_species$ape %in% ape_age$ape)\n```\n\n\n::: {.callout-warning collapse=\"true\"}\n#### optional - working with sets!\n\nI often default to using `%in%` and asking several questions to carefully make sure I know what's going on - i.e. \"is all of A `%in%` B? and is all of B `%in%` A, ... etc.\"  \nThere is actually a neat way to ask these questions both at once using some handy functions (that I often forget about) to perform operations on \"sets\" (i.e. collections of things). These include:\n\n- `union(x,y)` - return everything that is in set x or in set y (or both)\n- `intersect(x,y)` - return everything that is in both x and y\n- `setdiff(x,y)` - return everything in x that is not in y (*not there's asymmetry here!*)\n- `setequal(x,y)` - are sets x and y equal?\n\nSo we can use these to ask if, e.g., the two sets of apes in each dataset are equal:\n```{r}\nsetequal(ape_species$ape,ape_age$ape)\n```\n\nIf you want a fun^[really!?!?] challenge, there are lots of other (less concise ways) that we can ask the same thing. Try and come up with a few different ways.  \nE.g.: \"is there anything in the union of the two sets that is not in the intersection of the two sets?\"\n```{r}\nsetdiff(union(ape_species$ape,ape_age$ape), \n        intersect(ape_species$ape,ape_age$ape))\n```\n\n:::\n\nOkay, both datasets contain data for the same set of apes.  \nLet's join them:  \n```{r}\napedat <- full_join(ape_age, ape_species)\nhead(apedat)\n```\n`r solend()`\n`r solbegin(label=\"2 - identifying issues\", slabel=F,show=T, toggle=params$TOGGLE)`\n\nFirst off, we can see that we've got some weird typos. Some apes have been identified as \"gorrila\" but it is actually spelled \"gorilla\".  \nAlso, we've got people using two alternatives for the chimps: \"chimp\" and \"chimpanzee\". We'll need to combine those.  \n```{r}\ntable(apedat$species)\n```\n\n\nAge looks like it has some weird values (possibly \"-99\"?), and there are possibly a few outliers in the dominance variable. Given that dominance is standardised, it is _extremely_ unlikely that we would see values around 20.. They're not \"impossible\", but they're so incredibly unlikely that I'd be more comfortable assuming they are typos: \n```{r echo=c(2,3)}\npar(mfrow=c(2,1))\nhist(apedat$age, breaks=20)\nhist(apedat$dominance, breaks=20)\npar(mfrow=c(1,1))\n```\n\nJust to see what the most extreme values of dominance are:  \n```{r}\n# show the biggest 5 absolute values in dominance variable\nsort(abs(apedat$dominance), decreasing = TRUE)[1:5]\n```\n\n`r solend()`\n`r solbegin(label=\"3 - cleaning up\", slabel=F,show=T, toggle=params$TOGGLE)`\n\n\n```{r}\n\napedat <- apedat |> \n  mutate(\n    # fix species typos\n    species = case_when(\n      species %in% c(\"chimp\",\"chimpanzee\") ~ \"chimp\",\n      species %in% c(\"gorilla\",\"gorrila\") ~ \"gorilla\",\n      TRUE ~ species\n    )\n  ) |>\n    filter(\n      # get rid of ages -99\n      age > 0, \n      # keep when dominance is between -5 and 5 \n      # (5 here is a slightly arbitrary choice, but you can see from\n      # our checks that this will only exclude the two extreme datapoints\n      # that are 21.2 and 19.4\n      (dominance < 5 & dominance > -5) \n    )\n\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nHow is this data structure \"hierarchical\" (or \"clustered\")? How many levels do we have, and what are the observational units at each level?  \n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nWe have a random sample of $\\underbrace{\\text{timepoints}}_{\\text{level 1}}$ from a random sample of $\\underbrace{\\text{apes}}_{\\text{level 2}}$.  \n\n\n`r solend()`\n\n`r qbegin(qcounter())`\nFor how many apes do we have data? How many of each species?  \nHow many datapoints does each ape have?  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nWe've seen this last week too - counting the different levels in our data. See [Chapter 4: logisticMLM - #getting-to-know-my-monkeys](https://uoepsy.github.io/lmm/04_log.html#getting-to-know-my-monkeys){target=\"_blank\"} for an example (also about monkeys!)  \n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nWe have `r length(unique(apedat$ape))` apes in our dataset:  \n```{r}\nlength(unique(apedat$ape))\n```\n\nHere's how many of each species:  \n```{r}\napedat |> \n  group_by(species) |>\n  summarise(\n   n_apes = n_distinct(ape) \n  )\n```\n\nLet's create a table of how many observations for each ape, and then we can create a table _from_ that table, to show how many apes have 2 datapoints, how many have 3, 4, and so on:  \n```{r}\ntable(apedat$ape) |>\n  table() |>\n  barplot()\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nMake a plot to show how dominance changes for each ape as they get older.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nIn [Chapter 5: Longitudinal MLM - #exploring-the-data](https://uoepsy.github.io/lmm/05_long.html#exploring-the-data){target=\"_blank\"} we made a facet for each cluster (each participant). That was fine because we had only 20 people. In this dataset we have 168! That's too many to facet. We could try using `group` aesthetic instead, to plot multiple lines on the same plot, or we could just plot a sample of our apes. This is all just an initial look at the data, after all. \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nHere's a line for each ape, and a facet for each species:  \n```{r}\nggplot(apedat, aes(x = age, y = dominance, col = species))+\n  geom_line(aes(group = ape)) + \n  facet_wrap(~species) + \n  guides(col=\"none\")\n```\n\nIt's kind of hard to see the trend for each ape, so let's also make a separate little linear model for each ape:  \n\n```{r}\nggplot(apedat, aes(x = age, y = dominance, col = species))+\n  geom_smooth(aes(group = ape), method=lm, se=FALSE) + \n  facet_wrap(~species) + \n  guides(col=\"none\")\n```\n\nAlternatively, let's take a sample of apes, and plot the same stuff but facetted:\n```{r}\napedat |>\n  # choose the rows where ape ID is one of a random sample of 16 ape IDs\n  filter(ape %in% sample(unique(apedat$ape), 16) ) |>\n  ggplot(aes(x = age, y = dominance, col = species))+\n  geom_point() +\n  geom_smooth(method=lm, se=FALSE)+\n  facet_wrap(~ape)\n```\n\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nRecenter the `age` variable so that \"0\" becomes a 1-year old, which is the youngest age that we've got data on for any of our species.   \n\nThen fit a model that estimates the differences between primate species in how dominance changes over time.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nthink slowly about \"differences between primate species in how dominance changes over time\".  \n\n- \"how dominance changes over time\" -- sounds like `dominance ~ time`\n- so differences between primate species in this would require the interaction `dominance ~ time * species`\n- we have a random sample of apes, and for each of these we have multiple observations. We can model these as by-ape random effects - `+ (...... | ape)`\n\n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\napedat$age = apedat$age-1 \n\nm.full <- lmer(dominance ~ 1 + age * species + (1 + age | ape), data = apedat)\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\n__*Do*__ primate species differ in the growth of dominance?  \nPerform an appropriate test/comparison.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThis is asking about the `age*species` interaction, which in our model is represented by 3 parameters. To assess the overall question, it might make more sense to do a model comparison.  \n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nm.int <- lmer(dominance ~ 1 + age + species + (1 + age | ape), data = apedat)\n\nanova(m.int, m.full)\n```\n\n\n```{r}\n#| echo: false\nres = anova(m.int, m.full)\n\n```\n\n:::int\n\nSpecies differ in how dominance changes over adolescence ($\\chi^2(`r res[2,7]`) = `r round(res[2,6],2)`, p = `r format.pval(res[2,8],eps=.001,digits=1)`$).  \n\n:::\n\n\n`r solend()`\n\n`r qbegin(qcounter())`\nPlot the average model predicted values for each age.  \n\nBefore you plot.. do you expect to see straight lines? (remember, not every ape is measured at age 2, or age 3, etc).  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThis is like taking `predict()` from the model, and then then grouping by `age`, and calculating the mean of those predictions. However, we can do this more easily using `augment()` and then some fancy `stat_summary()` in ggplot (see [the lecture](https://uoepsy.github.io/msmr/2425/lectures/msmr_lec02-2_LinearLDA.html#17){target=\"_blank\"}).  \n\n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nAveraging fitted values would give us straight lines _if_ every ape had data at all ages, but in our study we have some apes with only 2 data points, and each ape has different set of ages (e.g., one ape might be measured at age 3, 6, and 10, another ape might be at ages 2 and 16).  \n\n```{r}\nlibrary(broom.mixed)\n\naugment(m.full) |>\nggplot(aes(age,dominance, color=species)) +\n  # the point ranges are our observations\n  stat_summary(fun.data=mean_se, geom=\"pointrange\") + \n  # the lines are our average predictions  \n  stat_summary(aes(y=.fitted, linetype=species), fun=mean, geom=\"line\")\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nPlot the model based fixed effects:  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\neffects::effect(\"age*species\", m.full, xlevels=10) |>\n  as.data.frame() |>\n  ggplot(aes(x=age+1,y=fit,col=species))+\n  geom_line(lwd=1)+\n  geom_ribbon(aes(ymin=lower,ymax=upper,fill=species),col=NA,alpha=.3) +  \n  scale_color_manual(values=c(\"grey30\",\"black\",\"grey50\",\"darkorange\")) +\n  scale_fill_manual(values=c(\"grey30\",\"black\",\"grey50\",\"darkorange\")) +\n  facet_wrap(~species) + \n  guides(col=\"none\",fill=\"none\") +\n  labs(x=\"Age (years)\")\n  \n```\n\n\n`r solend()`\n\n`r qbegin(qcounter())`\nIdentify what each of the fixed effects from the model represents (you might also want to get some p-values or confidence intervals).  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nEach of the estimates should correspond to part of our plot from the previous question.  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nLet's get some confidence intervals:  \n```{r}\nconfint(m.full, method=\"profile\",\n        parm = \"beta_\")\n```\n\n\n```{r}\n#| echo: false\ncis = confint(m.full, method=\"profile\",\n        parm = \"beta_\")\nsign = ifelse(cis[,1]>0|cis[,2]<0,1,0)\n\ntidy(m.full) |>\n  filter(effect==\"fixed\") |>\n  transmute(term, est=round(estimate,2),\n            CI = paste0(\"[\",round(cis[,1],2),\", \",round(cis[,2],2),\"]\")) |>\n  mutate(\n    CI = ifelse(sign,paste0(CI,\"*\"),CI)\n  ) |> \n  mutate(\n    interpretation = c(\n      \"estimated dominance of 1 year old bonobos (at left hand side of plot, bonobo line is lower than 0)\",\n      \"estimated change in dominance score for every year older a bonobo gets (slope of bonobo line)\",\n      \"estimated difference in dominance scores at age 1 between bonobos and chimps (at left hand side of plot, chimp line is higher than bonobo line)\",\n      \"estimated difference in dominance scores at age 1 between bonobos and gorillas (at left hand side of plot, gorilla line is higher than bonobo line)\",\n      \"no significant difference in dominance scores at age 1 between bonobos and orangutans (at the left hand side of our plot, orangutan line is similar height to bonobo line)\",\n      \"no significant difference between chimps and bonobos in the change in dominance for every year older (slope of chimp line is similar to slope of bonobo line)\",\n      \"no significant difference between gorillas and bonobos in the change in dominance for every year older (slope of gorilla line is similar to slope of bonobo line)\",\n      \"estimated difference between orangutans and bonobos in the change in dominance for every year older (slope of orangutan line is less steep than slope of bonobo line)\"\n    )\n  ) |> gt::gt()\n```\n\n\n`r solend()`\n\n<br>\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Trolley problems\n\n\n```{r}\n#| echo: false\nss = 173223\n#while(TRUE){\n#  ss = round(runif(1,1e3,1e6))\n  set.seed(ss)\n  n_groups = 120\n  npgroup = rep(12,n_groups)\n  g = unlist(lapply(1:n_groups, function(x) rep(x,npgroup[x])))\n  N = length(g)\n  b = round(runif(n_groups,18,45))\n  b = b[g]\n  x = rep(rep(1:3,e=4),n_groups)\n  x2 = rep(rep(letters[4:5],6),n_groups)\n  res = MASS::mvrnorm(n=n_groups,\n                      mu=c(0,0,0),\n                      Sigma=diag(c(4,2,2)) %*% \n                        matrix(c(1,.4,.3,.4,1,.4,.3,.4,1),nrow=3) %*% \n                        diag(c(4,2,2)))\n  re0 = res[,1]\n  re  = re0[g]\n  rex = res[,2]\n  re_x  = rex[g]\n  rex2 = res[,3]\n  re_x2  = rex2[g]\n  lp = (0 + re) + (.1*b) + \n    (-2 + re_x)*x + (2 + re_x2)*(x2==\"e\") +\n    (2*(x-2)*(x2==\"e\"))\n  y = lp + rnorm(N,0,1)\n  y_bin = rbinom(N,1, plogis(.75+scale(lp)))\n  df = data.frame(x=x,x2=x2,g=g, b=b,y=y,y_bin=y_bin)\n  mnames = unique(randomNames::randomNames(1e5,which=\"first\"))\n  df = df |> transmute(\n    frame = factor(x, levels=c(\"1\",\"2\",\"3\"),\n                   labels=c(\"positive\",\"neutral\",\"negative\")),\n    lives = factor(x2, levels=c(\"d\",\"e\"),labels=c(\"5lives\",\"15lives\")),\n    age = b,\n    PID = paste0(\"PPT_\",g),\n    lever = y_bin\n  )\n#   m = glmer(lever ~ scale(age) + frame*lives +\n#               (1+frame+lives|PID),data=df,family=binomial,\n#             control=glmerControl(optimizer = \"bobyqa\"))\n#   if(is.null(m@optinfo$conv$lme4$messages)){break}\n#   m = glmer(lever ~ scale(age) + frame*lives +\n#               (1+lives|PID),data=df,family=binomial,\n#             control=glmerControl(optimizer = \"bobyqa\"))\n#   if(is.null(m@optinfo$conv$lme4$messages)){break}\n# }\n# sjPlot::plot_model(m,type=\"int\")\n# summary(m)\ntrolley <- df |> select(PID,frame,lives,lever)\n# write_csv(trolley, file=\"../../data/msmr_trolley.csv\")\n```\n\n:::frame\n__Data: msmr_trolley.csv__  \n\nThe \"Trolley Problem\" is a thought experiment in moral philosophy that asks you to decide whether or not to pull a lever to divert a trolley. Pulling the lever changes the trolley direction from hitting 5 people to a track on which it will hit one person.  \n\n```{r}\n#| echo: false\nknitr::include_graphics(\"images/trolley.png\")\n```\n\nPrevious research has found that the \"framing\" of the problem will influence the decisions people make: \n\n```{r}\n#| echo: false\ntribble(\n  ~`positive frame`,~`neutral frame`,~`negative frame`,\n  \"5 people will be saved if you pull the lever; one person on another track will be saved if you do not pull the lever. All your actions are legal and understandable. Will you pull the lever?\",\"5 people will be saved if you pull the lever, but another person will die. One people will be saved if you do not pull the lever, but 5 people will die. All your actions are legal and understandable. Will you pull the lever?\",\n  \"One person will die if you pull the lever. 5 people will die if you do not pull the lever. All your actions are legal and understandable. Will you pull the lever?\"\n) |> gt::gt()\n```\n\nWe conducted a study to investigate **whether the framing effects on moral judgements depends upon the stakes (i.e. the number of lives saved)**.  \n\n`r n_distinct(trolley$PID)` participants were recruited, and each gave answers to 12 versions of the thought experiment. For each participant, four versions followed each of the positive/neutral/negative framings described above, and for each framing, 2 would save 5 people and 2 would save 15 people.  \n\nThe data are available at [https://uoepsy.github.io/data/msmr_trolley.csv](https://uoepsy.github.io/data/msmr_trolley.csv){target=\"_blank\"}.  \n\n```{r}\n#| echo: false\n#| label: tbl-trolley\n#| tbl-cap: \"Data Dictionary: trolley.csv\"\ntibble(\n  variable = names(trolley),\n  description = c(\n    \"Participant ID\",\n    \"framing of the thought experiment (positive/neutral/negative\",\n    \"lives at stake in the thought experiment (5 or 15)\",\n    \"Whether or not the participant chose to pull the lever (1 = yes, 0 = no)\")\n) |> gt::gt()\n```\n\n\n\n:::\n\n`r qbegin(qcounter())`\nRead in the data and check over how many people we have, and whether we have complete data for each participant.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nI would maybe try `data |> group_by(participant) |> summarise()`, and then use the `n_distinct()` function to count how many \"things\" each person sees (e.g., [Chapter 4: Logistic MLM #example](https://uoepsy.github.io/lmm/04_log.html#example){target=\"_blank\"}). \n\n:::\n\n\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n\n```{r}\ntrolley <- read_csv(\"https://uoepsy.github.io/data/msmr_trolley.csv\")\nhead(trolley)\n```\n\nHow many participants?\n```{r}\nlength(unique(trolley$PID))\n```\n\nHow many trials for each participant in each condition.  \nWe can, for each participant, count how many trials they have in total, how many \"frames\" they see, how many \"lives\" they see, and how many \"frame x lives\" combinations they see:  \n```{r}\ntrolley |>\n  group_by(PID) |>\n  summarise(\n    n_trials = n(),\n    n_frame = n_distinct(frame),\n    n_lives = n_distinct(lives),\n    n_combn = n_distinct(frame,lives)\n  )\n```\n\nIf everybody gets the same here (as we can see they do below), then everyone has complete data!  \n\n```{r}\ntrolley |>\n  group_by(PID) |>\n  summarise(\n    n_trials = n(),\n    n_frame = n_distinct(frame),\n    n_lives = n_distinct(lives),\n    n_combn = n_distinct(frame,lives)\n  ) |>\n  summary()\n```\n\n\n`r solend()`\n\n`r qbegin(qcounter())`\nConstruct an appropriate plot to summarise the data in a suitable way to illustrate the research question.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nSomething making use of `stat_summary()` to give proportions, a bit like the plot in [Chapter 4: Logistic MLM - #getting-to-know-my-monkeys](https://uoepsy.github.io/lmm/04_log.html#getting-to-know-my-monkeys){target=\"_blank\"}?  \n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nHere is a plot of proportions of trials in which the lever was pulled, split by how the problem was framed, and the number of lives saved:  \n```{r}\nggplot(trolley, aes(x=frame, y=lever, col=lives)) +\n  stat_summary(geom=\"pointrange\", size=1, \n               position=position_dodge(width=.2)) \n  \n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nFit a model to assess the research aims.  \nDon't worry if it gives you an error/warning, we'll deal with that in a second.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- Remember, a good way to start is to split this up into 3 parts: 1) the outcome and fixed effects, 2) the grouping structure, and 3) the random slopes.  \n- If we have an interaction `y ~ 1 + x1*x2 + (1 .... | groups)`, and both predictors `x1` and `x2` vary within groups (i.e., each group has various values of the predictor), then because we can put random slopes of these variables --- `(1 + x1 + x2 | groups)` --- we can almost always also put the interaction in and have `(1 + x1 * x2 | groups)`  \n- fitting (or attempting to fit!) `glmer` models might take time!  \n\n\n:::\n\n`r qend()`\n`r solbegin(label=\"1 - fixed\", slabel=F,show=T, toggle=params$TOGGLE)`\n\nThe researchers are *\"interested in whether the framing effects on moral judgements depends upon the stakes (i.e. the number of lives saved)\"*.  \n\n\"the framing effect on moral judgements\" here is operationalised as  \n```{r}\n#| eval: false\nlever ~ frame\n```\nand the wording \"depends upon the stakes\" means that we want to know if that effect of frame \"is different for\" the situations when lives = 5, vs lives = 15 - i.e. we need the interaction!  \n```{r}\n#| eval: false\nlever ~ frame * lives\n```\n\nThe outcome here is lever pulled (yes v no), so it's a binary variable!  \n\n```{r}\n#| eval: false\nglmer(lever ~ frame * lives + ....\n      ....,  \n      data = trolley, family = binomial)\n```\n\n`r solend()`\n`r solbegin(label=\"2 - grouping\", slabel=F,show=T, toggle=params$TOGGLE)`\n\nWe know that we have multiple observations for each participant, and those participants are just a random sample (it's not something we're interested in testing, we would like to model participant differences as random variation).  \n```{r}\n#| eval: false\nglmer(lever ~ frame * lives + ....\n      (1 + .... | PID),  \n      data = trolley, family = binomial)\n```\n\n\n`r solend()`\n`r solbegin(label=\"3 - random\", slabel=F,show=T, toggle=params$TOGGLE)`\n\nFinally, what effects _could_ theoretically vary between our participants?  \nEvery participant saw everything (i.e. both `frame` and `lives` are \"within participant\" variables). \n\nIn theory, all of these are possible given our design:  \n\n- the effect of frame on probability of pulling the lever could vary between participants\n- the effect of number of lives on probability of pulling the lever could vary between participants\n- the amount by which number of lives influences the effect of frame on pulling the lever could vary between participants\n\nSo we could theoretically try and fit this model:  \n```{r}\n#| eval: false\nmod1 <- glmer(lever ~ frame * lives + \n      (1 + frame * lives | PID),  \n      data = trolley, family = binomial)\n```\n<p style=\"color:red;\">\nWarning messages:<br>\n1: In (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int(Inf,  :\n  failure to converge in 10000 evaluations<br>\n2: In optwrap(optimizer, devfun, start, rho\\$lower, control = control,  :\n  convergence code 4 from Nelder_Mead: failure to converge in 10000 evaluations<br>\n3: In checkConv(attr(opt, \"derivs\"), opt\\$par, ctrl = control\\$checkConv,  :\n  Model failed to converge with max|grad| = 0.0795145 (tol = 0.002, component 1)\n</p>\n`r solend()`\n\n`r qbegin(qcounter())`\nThis is probably the first time we've had to deal with a model not converging.  \n\nSometimes changing the optimizer can help, but ideally we wouldn't want to just shop around until we find one that doesn't tell us about an error! More often than not, the model we are trying to fit is just too complex for our sample. Often, the groups in our sample just don't vary enough for us to estimate a random slope (this doesn't mean there is no variance in the real world, we might simply not have enough groups to see it).  \n\nThe aim here is to simplify our random effect structure in order to obtain a converging model, but be careful not to over simplify.  \n\nThere are no hard-and-fast rules on how to simplify, but the guiding principles might be thought of as: \n\n1. we are **only** simplifying the random effects part, and **not** the fixed effects\n2. remove one thing at a time!  \n3. consider removing \"more complex\" parts first (interactions, slopes of categorical predictors)\n3. sometimes, the estimated variances in the non-converging model can guide us by indicating the parts of the structure for which there is not enough variability in the data (essentially, look for the tiny variances!).  \n\n\nTry it now. What model do you end up with? (You might not end up with the same model as each other, which is fine. These methods don't have \"cookbook recipes\"!)\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nYou could think of the interaction as the 'most complex' part of our random effects, so you might want to remove that first.  \n\n:::\n\n\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n\nWe'll remove the interaction first. But this model still does not converge:  \n```{r}\nmod2 <- glmer(lever ~ frame * lives + \n      (1 + frame + lives | PID),  \n      data = trolley, family = binomial)\n```\n<p style=\"color:red;\">\nWarning message:<br>\nIn checkConv(attr(opt, \"derivs\"), opt\\$par, ctrl = control\\$checkConv,  :\n  Model failed to converge with max|grad| = 0.00734804 (tol = 0.002, component 1)\n</p>\n\nWe have a choice here - do we remove `frame|PID` or `lives|PID`?  \nOne practical point is that each participant has only 4 observations for each `frame` type, but they have 6 observations for each `lives` type, which might make it easier to fit.  \n\nAnother argument is that when doing this experiment, the `lives` manipulation is perhaps more *salient* than the specific wording. I could imagine, taking this study as a participant, that I might sort of skim read each version and not fully attend to the framing, but notice quite clearly the number of lives at stake. So it's possible that this effect may be bigger (and therefore more variable between people) than the effect of framing.  \n```{r}\nmod3 <- glmer(lever ~ frame * lives + \n      (1 + lives | PID),  \n      data = trolley, family = binomial)\n```\nHooray! it converges!  \n\n`r solend()`\n\n`r qbegin(qcounter())`\nWe're now going to plot the predicted probabilities from your model for each combination of `frame` and `lives`.  \n\nBefore you actually do this, ask yourself what pattern you expect to see (based on your fixed effects)? Then plot it and see if you were right!  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nlibrary(effects)\neffect(\"frame*lives\", mod3) |>\n  as.data.frame() |>\n  ggplot(aes(x = frame, y = fit, col = lives)) +\n  geom_pointrange(aes(ymin=lower,ymax=upper),\n                  position=position_dodge(width=.2),\n                  size=1)+\n  labs(y=\"probability of pulling the lever\")\n```\n\n\n`r solend()`\n\n<!-- `r qbegin(qcounter())` -->\n<!-- Compute odds ratios and create some confidence intervals, then interpret them.   -->\n\n\n<!-- ::: {.callout-tip collapse=\"true\"} -->\n<!-- #### Hints -->\n\n<!-- Odds ratios are confusing, so take the lead from your plot about what goes up/down etc.   -->\n<!-- The default of profile likelihood confidence intervals might take a while to compute, so you could choose the Wald method instead (see [2B #interpretation](02b_loglong.html#interpretation){target=\"_blank\"}).   -->\n\n<!-- ::: -->\n\n\n<!-- `r qend()` -->\n<!-- `r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)` -->\n\n<!-- ```{r} -->\n<!-- cbind( -->\n<!--   fixef(mod3), # the fixed effects -->\n<!--   confint(mod3, method=\"Wald\", parm=\"beta_\") # Wald CIs for fixed effects -->\n<!-- ) |> -->\n<!--   exp() -->\n<!-- ``` -->\n\n<!-- ```{r} -->\n<!-- #| echo: false -->\n<!-- cbind( -->\n<!--   fixef(mod3), # the fixed effects -->\n<!--   confint(mod3, method=\"Wald\", parm=\"beta_\") # Wald CIs for fixed effects -->\n<!-- ) |> -->\n<!--   exp() |> as.data.frame() |> -->\n<!--   rownames_to_column() |> -->\n<!--   transmute( -->\n<!--     term = rowname, OR=round(V1,2), -->\n<!--     CI = paste0(\"[\", -->\n<!--                 round(`2.5 %`,2),\", \", -->\n<!--                 round(`97.5 %`,2),\"]\" -->\n<!--     ), -->\n<!--     interpretation = c( -->\n<!--       \"Odds of pulling the lever when in a positive framed problem with the potential of saving 5 lives\", -->\n<!--       paste0(\"With 5 lives at stake, a neutral framing is associated with \",round(exp(fixef(mod3))[2],2),\" times the odds of pulling the lever in comparison to a positive framing\"), -->\n<!--       paste0(\"With 5 lives at stake, a negative framing is associated with \",round(exp(fixef(mod3))[3],2),\" times the odds of pulling the lever in comparison to a positive framing\"), -->\n<!--       \"In a positive framing, the number of lives at stake is not associated with a change in the odds of pulling the lever\", -->\n<!--       paste0(\"In the neutral framing, the 15 vs 5 lives The neutral vs positive framing difference is increase  \",round(exp(fixef(mod3))[2],2),\" times the odds of pulling the lever in comparison to a positive framing\"), -->\n<!--     ) -->\n<!--   )  -->\n<!-- ``` -->\n\n<!-- `r solend()` -->\n\n\n<br>\n\n<div class=\"divider div-transparent div-dot\"></div>\n\n\n# Optional extra: Novel Word Learning\n\n\n:::frame\n__Data: nwl.Rdata__ \n\n```{r}\nload(url(\"https://uoepsy.github.io/msmr/data/nwl.RData\"))\n```\n\nIn the `nwl` data set (accessed using the code above), participants with aphasia are separated into two groups based on the general location of their brain lesion: anterior vs. posterior. There is data on the numbers of correct and incorrect responses participants gave in each of a series of experimental blocks. There were 7 learning blocks, immediately followed by a test. Finally, participants also completed a follow-up test.\n<br>\nData were also collect from healthy controls. \n<br>\n@fig-nwl shows the differences between lesion location groups in the average proportion of correct responses at each point in time (i.e., each block, test, and follow-up)\n\n```{r}\n#| label: fig-nwl\n#| echo: false\n#| fig.cap: \"Differences between groups in the average proportion of correct responses at each block\"\nload(url(\"https://uoepsy.github.io/msmr/data/nwl.RData\"))\nggplot(filter(nwl, !is.na(lesion_location)), aes(block, PropCorrect, \n                                            color=lesion_location, \n                                            shape=lesion_location)) +\n  #geom_line(aes(group=ID),alpha=.2) + \n  stat_summary(fun.data=mean_se, geom=\"pointrange\") + \n  stat_summary(data=filter(nwl, !is.na(lesion_location), block <= 7), \n                           fun=mean, geom=\"line\") + \n  geom_hline(yintercept=0.5, linetype=\"dashed\") + \n  geom_vline(xintercept=c(7.5, 8.5), linetype=\"dashed\") + \n  scale_x_continuous(breaks=1:9, labels=c(1:7, \"Test\", \"Follow-Up\")) + \n  theme_bw(base_size=10) + \n  labs(x=\"Block\", y=\"Proportion Correct\", shape=\"Lesion\\nLocation\", color=\"Lesion\\nLocation\")\n```\n\n\n```{r}\n#| echo: false\ndata.frame(\n  variable = names(nwl),\n  description = c(\"Whether participant is a stroke patient ('patient') or a healthy control ('control')\", \"Location of brain lesion: anterior vs posterior\",\"Experimental block (1-9). Blocks 1-7 were learning blocks, immediately followed by a test in block 8. Block 9 was a follow-up test at a later point\",\"Proportion of 30 responses in a given block that the participant got correct\",\"Number of responses (out of 30) in a given block that the participant got correct\",\"Number of responses (out of 30) in a given block that the participant got incorrect\",\"Participant Identifier\",\"Experimental phase, corresponding to experimental block(s): 'Learning', 'Immediate','Follow-up'\")\n) |> gt::gt()\n```\n\n\n:::\n\n\n`r qbegin(qcounter())`\nLoad the data. Take a look around. Any missing values? Can you think of why?  \n`r qend()`\n\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n\n```{r}\nload(url(\"https://uoepsy.github.io/msmr/data/nwl.RData\"))\nsummary(nwl)\n```\n\nThe only missing vales are in the lesion location, and it's probably because the healthy controls don't have any lesions. There may also be a few patients for which the lesion_location is missing, but this should be comparatively fewer values compared to controls.\n\nThe following command creates a two-way frequency table showing the number of controls or patients by lesion location, confirming that controls only have missing values (NAs) and only 9 patients have missing values:\n\n```{r}\ntable(nwl$group, nwl$lesion_location, useNA = \"ifany\")\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nOur broader research aim today is to compare the two lesion location groups (those with anterior vs. posterior lesions) with respect to their accuracy of responses over the course of the study.  \n\n- What is the outcome variable? \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThink carefully: there might be several variables which either fully or partly express the information we are considering the \"outcome\" here. \nWe saw this back in [USMR](https://uoepsy.github.io/usmr/2425/labs/10a_glm.html#fitting-glm-in-r){target=\"_blank\"} with the `glm()`!  \n\n:::\n\n\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\nThe outcome here is (in words) the proportion of correct answers or, equivalently, the probability of answering correctly. A proportion/probability can only vary between 0 and 1 and, as such, we cannot use traditional linear regression or we could end up with predictions outside of the [0, 1] range.\n\nAs said, the outcome is the proportion of correct answers in each block. This makes it tempting to look at the variable called `PropCorrect`, but this is encoded as a proportion. We have learned to use logistic models, but these require either:\n\n- a binary outcome variable, where the values are 0s or 1s\n- a binomial outcome variable, where the values are aggregated counts of 1s and 0s \n\n__Binary data__. In the case below you would use the specification `correct ~ ...`:\n\n```{r echo=FALSE}\ntibble(participant = c(1,1,1),\n       question=c(1,2,3),\n       correct=c(1,0,1)) %>%\n    rbind(rep(\"...\",3)) %>%\n    gt::gt()\n```\n\n__Binomial data__. You would use the specification `cbind(NumCorrect, NumError) ~ ...`:  \n\n\n```{r echo=FALSE}\ntibble(participant = c(1,2,3),\n       NumCorrect=c(2,1,3),\n       NumError=c(1,2,0)) %>% \n    rbind(rep(\"...\",3)) %>% \n    gt::gt()\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\n> **Research Question 1:**  \n> Is the learning rate (training blocks) different between the two lesion location groups?\n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- Do we want `cbind(successes, failures)`?\n\n- Ensure you are running models on only the data we are actually interested in. \n\n    + Are the healthy controls included in the research question under investigation?\n    + Are the testing blocks included in the research question, or only the learning blocks?\n\n- We could use model comparison via likelihood ratio tests (using `anova(model1, model2, model3, ...)`. For this question, we could compare:\n\n    + A model with just the change over the sequence of blocks\n    + A model with the change over the sequence of blocks *and* an overall difference between groups\n    + A model with groups differing with respect to their change over the sequence of blocks\n\n- What about the random effects part?  \n    \n    1. What are our observations grouped by? \n    2. What variables can vary within these groups? \n    3. What do you want your model to allow to vary within these groups?\n\n:::\n\n`r qend()`\n`r solbegin(label=\"1 - answers to the hints\", slabel=F,show=T, toggle=params$TOGGLE)`\n\n- Do we want `cbind(successes, failures)`?\n\n    + Yes, we don't a binary variable with correct/incorrect questions but the binomial variables NumCorrect and NumError representing, respectively, the aggregated count (out of 30) of correct and incorrect questions. As such, we will need the following: `cbind(NumCorrect, NumError)`\n\n- Ensure you are running models on only the data we are actually interested in. \n\n    + The healthy controls are not included in the research question under investigation, so we will exclude them.\n    + We are only interested in the learning blocks, and we will exclude the testing blocks (block > 7) \n    + You might want to store this data in a separate object, but in the code for the solution we will just use `filter()` *inside* the `glmer()`.   \n  \n- A model with just the change over the sequence of blocks:\n    - **outcome ~ block**\n- A model with the change over the sequence of blocks *and* an overall difference between groups:\n    - **outcome ~ block + lesion_location**\n- A model with groups differing with respect to their change *over the sequence of blocks:\n    - **outcome ~ block * lesion_location**\n    \n- What are our observations grouped by? \n    - repeated measures by-participant. i.e., the `ID` variable\n- What variables can vary within these groups? \n    - `Block` and `Phase`. Be careful though - you can create the `Phase` variable out of the `Block` variable, so really this is just one piece of information, encoded differently in two variables. \n    - The other variables (`lesion_location` and `group`) do **not** vary for each ID. Lesions don't suddenly change where they are located, nor do participants swap between being a patient vs a control (we don't need the group variable anyway as we are excluding the controls).  \nWhat do you want your model to allow to vary within these groups?\n    - Do you think the change over the course of the blocks is **the same** for everybody? Or do you think it varies? Is this variation important to think about in terms of your research question?   \n    \n`r solend()`\n`r solbegin(label=\"2 - modelling\", slabel=F,show=T, toggle=params$TOGGLE)`\n\n```{r}\nm.base <- glmer(cbind(NumCorrect, NumError) ~ block + (1 + block | ID), \n                data = filter(nwl, block < 8, !is.na(lesion_location)),\n                family=binomial)\n\nm.loc0 <- glmer(cbind(NumCorrect, NumError) ~ block + lesion_location + (1 + block | ID), \n                data=filter(nwl, block < 8, !is.na(lesion_location)),\n                family=binomial)\n\nm.loc1 <- glmer(cbind(NumCorrect, NumError) ~ block * lesion_location + (1 + block | ID), \n                data=filter(nwl, block < 8, !is.na(lesion_location)),\n                family=binomial)\n\n\nanova(m.base, m.loc0, m.loc1, test=\"Chisq\")\n```\n:::int\nNo significant difference in learning rate between groups ($\\chi^2(1)=2.2, p = 0.138$).\n:::\n\n`r solend()`\n\n`r qbegin(qcounter())`\n> **Research Question 2**  \n> In the testing phase, does performance on the immediate test differ between lesion location groups, and does the retention from immediate to follow-up test differ between the two lesion location groups?\n\nLet's try a different approach to this. Instead of fitting various models and comparing them via likelihood ratio tests, just fit the one model which could answer both parts of the question above.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- This might required a bit more data-wrangling beforehand. Think about the order of your factor levels (alphabetically speaking, \"Follow-up\" comes before \"Immediate\")!\n\n:::\n\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n```{r}\nnwl_test <- filter(nwl, block > 7, !is.na(lesion_location)) |>\n    mutate(\n        Phase = factor(Phase), \n        Phase = fct_relevel(Phase, \"Immediate\")\n    )\n\nm.recall.loc <- glmer(cbind(NumCorrect, NumError) ~ Phase * lesion_location + (1 | ID), \n                      nwl_test, family=\"binomial\")\n\nsummary(m.recall.loc)\n```\n\n\n__Note 1__: \n\nIn the above, we have made sure to select the patients by specifying `!is.na(lesion_location)`, meaning that we want those rows where the lesion location is not missing. As a reminder `!` is the negation function (not). As we saw in the earlier question, this excludes the 126 healthy controls, as well as the 9 patients for which we have missing values (NAs).\n\n__Note 2__:  \n\nWe didn't specify `(Phase | ID)` as the random effect because each participant only has 2 data points for Phase, and there is only one line that fits two data points. In other words, there is only one possible way to fit those two data points. As such, as each group of 2 points will have a perfect line fit, and the residuals $\\varepsilon_{ij}$ will all be 0. As a consequence of this, the residuals will have no variability as they are all 0, so $\\sigma_{\\epsilon}$ is 0 which in turn leads to problem with estimating the model coefficients.\n\n```{r}\nsubset(nwl_test, ID == 'patient15')\n```\n\nIf you try using `(Phase | ID)` as random effect, you will see the following message:\n\n`boundary (singular) fit: see help('isSingular')`\n\n`r solend()`\n\n`r qbegin(qcounter())`\n\n1. In `family = binomial(link='logit')`. What function is used to relate the linear predictors in the model to the expected value of the response variable?  \n2. How do we convert this into something more interpretable?  \n\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n \n1. The link function is the `logit`, or log-odds (other link functions are available).\n\n2. To convert log-odds to odds, we can use `exp()`, to get odds and odds ratios.  \n\n`r solend()`\n\n`r qbegin(qcounter())`\nMake sure you pay attention to trying to interpret each fixed effect from your models.  \nThese can be difficult, especially when it's logistic, and especially when there are interactions.  \n\n- What is the increase in the odds of answering correctly in the immediate test if you were to have a posterior legion instead of an anterior legion?  \n\n<!-- `r optbegin(\"Optional help: Our Solution to A4\", olabel=F, toggle=params$TOGGLE)` -->\n<!-- ```{r eval=F} -->\n<!-- nwl_test <- filter(nwl, block > 7, !is.na(lesion_location)) %>% -->\n<!--   mutate( -->\n<!--     Phase = fct_relevel(factor(Phase),\"Immediate\") -->\n<!--   ) -->\n\n<!-- m.recall.loc <- glmer(cbind(NumCorrect, NumError) ~ Phase * lesion_location + (Phase | ID),  -->\n<!--                   nwl_test, family=\"binomial\") -->\n<!-- ``` -->\n<!-- `r optend()` -->\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nexp(fixef(m.recall.loc))\n```\n\n\n* `(Intercept)` ==> Anterior lesion group performance in immediate test. This is the odds of them answering correctly in the immediate test. \n* `PhaseFollow-up`  ==> Change in performance (for someone with an anterior lesion) from immediate to follow-up test. \n* `lesion_locationposterior` ==> Change in performance in immediate test were a patient to have a posterior lesion instead of an anterior lesion. \n* `PhaseFollow-up:lesion_locationposterior` ==> How change in performance from immediate to follow-up test would differ were a patient to have a posterior lesion instead of an anterior lesion.  \n\n```{r}\nexp(fixef(m.recall.loc))[3]\n```\n\n:::int\nHaving a posterior lesions is associated with `r round(exp(fixef(m.recall.loc))[3],2)` times the odds of answering correctly in the immediate test compared to having an anterior lesion.  \n:::\n\n`r solend()`\n\n`r qbegin(qcounter())`\nRecreate the visualisation in @fig-nwl2.  \n\n```{r}\n#| label: fig-nwl2\n#| echo: false\n#| fig-cap: \"Differences between groups in the average proportion of correct responses at each block\"\nload(url(\"https://uoepsy.github.io/msmr/data/nwl.RData\"))\nggplot(filter(nwl, !is.na(lesion_location)), aes(block, PropCorrect, \n                                                 color=lesion_location, \n                                                 shape=lesion_location)) +\n    #geom_line(aes(group=ID),alpha=.2) + \n    stat_summary(fun.data=mean_se, geom=\"pointrange\") + \n    stat_summary(data=filter(nwl, !is.na(lesion_location), block <= 7), \n                 fun=mean, geom=\"line\") + \n    geom_hline(yintercept=0.5, linetype=\"dashed\") + \n    geom_vline(xintercept=c(7.5, 8.5), linetype=\"dashed\") + \n    scale_x_continuous(breaks=1:9, \n                       labels=c(1:7, \"Test\", \"Follow-Up\")) + \n    theme_bw(base_size=10) + \n    labs(x=\"Block\", y=\"Proportion Correct\", \n         shape=\"Lesion\\nLocation\", color=\"Lesion\\nLocation\")\n```\n\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n```{r}\nggplot(filter(nwl, !is.na(lesion_location)), aes(block, PropCorrect, \n                                                 color=lesion_location, \n                                                 shape=lesion_location)) +\n    #geom_line(aes(group=ID),alpha=.2) + \n    stat_summary(fun.data=mean_se, geom=\"pointrange\") + \n    stat_summary(data=filter(nwl, !is.na(lesion_location), block <= 7), \n                 fun=mean, geom=\"line\") + \n    geom_hline(yintercept=0.5, linetype=\"dashed\") + \n    geom_vline(xintercept=c(7.5, 8.5), linetype=\"dashed\") + \n    scale_x_continuous(breaks=1:9, \n                       labels=c(1:7, \"Test\", \"Follow-Up\")) + \n    theme_bw(base_size=10) + \n    labs(x=\"Block\", y=\"Proportion Correct\", \n         shape=\"Lesion\\nLocation\", color=\"Lesion\\nLocation\")\n```\n`r solend()`\n\n\n<!-- `r qbegin(qcounter())` -->\n<!-- This code is that we used to answer the question above, only we have edited it to change lesion location to be fitted with \"sum contrasts\".   -->\n\n<!-- ```{r echo=TRUE} -->\n<!-- nwl_test <- filter(nwl, block > 7, !is.na(lesion_location)) %>% -->\n<!--     mutate( -->\n<!--         Phase = factor(Phase), -->\n<!--         Phase = fct_relevel(Phase, \"Immediate\") -->\n<!--     ) -->\n\n<!-- m.recall.loc.effcoding <-  -->\n<!--     glmer(cbind(NumCorrect, NumError) ~ Phase * lesion_location + (1 | ID),  -->\n<!--           contrasts = list(lesion_location = \"contr.sum\"), -->\n<!--           data = nwl_test, family=\"binomial\") -->\n<!-- ``` -->\n\n\n<!-- The interpretation of this is going to get pretty tricky - we have a logistic regression, and we have different coding scheme for our categorical predictor, and we have an interaction.. &#x1f92f;   -->\n\n<!-- Can you work out the interpretation of the fixed effects estimates?   -->\n\n<!-- `r qend()` -->\n<!-- `r solbegin(show=TRUE, toggle=params$TOGGLE)` -->\n\n<!-- * `(Intercept)` ==> Overall performance in immediate test. This is the overall log-odds of answering correctly in the immediate test.  -->\n<!-- * `PhaseFollow-up`  ==> Average change in performance from immediate to follow-up test.  -->\n<!-- * `lesion_location1` ==> Anterior lesion group performance in immediate test relative to *overall average* performance in immediate test -->\n<!-- * `PhaseFollow-up:lesion_location1` ==> Change in performance from immediate to follow-up test, anterior lesion group relative to overall average -->\n\n\n<!-- **???**   -->\n<!-- How do we know that `lesion_location1` is the *anterior* and not the *posterior* lesion group?  -->\n<!-- We need to check the what the contrasts look like:   -->\n<!-- ```{r} -->\n<!-- contrasts(nwl_test$lesion_location) <- \"contr.sum\" -->\n<!-- contrasts(nwl_test$lesion_location) -->\n<!-- ``` -->\n<!-- Because there are only two levels to this variable, the estimate will simply flip sign (positive/negative) depending on which way the contrast is leveled.   -->\n\n\n<!-- ::: {.callout-note collapse=\"true\"} -->\n<!-- #### I liked my coefficients being named properly? -->\n\n<!-- ```{r} -->\n<!-- colnames(contrasts(nwl_test$lesion_location)) <- \"PeppaPig\" -->\n\n<!-- contrasts(nwl_test$lesion_location) -->\n\n<!-- modeltest <-  -->\n<!--     glmer(cbind(NumCorrect, NumError) ~ Phase * lesion_location + (1 | ID), -->\n<!--           nwl_test, family=\"binomial\") -->\n<!-- summary(modeltest)$coefficients -->\n<!-- ``` -->\n\n<!-- ::: -->\n\n<!-- `r solend()` -->\n\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"include-in-header":["assets/toggling.html",{"text":"<link rel=\"stylesheet\" href=\"https://uoepsy.github.io/assets/css/ccfooter.css\" />\n"}],"number-sections":false,"output-file":"02ex.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.42","toc_float":true,"link-citations":true,"theme":["united","assets/style-labs.scss"],"title":"Week 2 Exercises: Logistic and Longitudinal","params":{"SHOW_SOLS":false,"TOGGLE":true},"editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}