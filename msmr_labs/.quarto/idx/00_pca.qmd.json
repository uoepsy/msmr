{"title":"PCA in 3D","markdown":{"yaml":{"title":"PCA in 3D","params":{"SHOW_SOLS":true,"TOGGLE":true}},"containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nsource('assets/setup.R')\nlibrary(rgl)\nlibrary(psych)\nset.seed(33)\nS = runif(3,.4,2)\nf = runif(3,.7,.99)\nR = f %*% t(f)\ndiag(R) = 1\nR[1,3] <- R[2,3] <- R[3,1] <- R[3,2] <- .1\nSigma = diag(S)%*%R%*%diag(S)\nMean <- rep(0,3)\nx <- MASS::mvrnorm(500, Mean, Sigma)\n\n```\n\nImagine we had 3 measured variables: y1, y2, and y3, as visualised in 3-dimensional space in @fig-scat  \n\n```{r}\n#| echo: false\n#| label: fig-scat\n#| fig-cap: \"3 measured variables\"\nplot3d(x, box = FALSE, xlab=\"y1\",ylab=\"y2\",zlab=\"y3\")\nrglwidget()\n```\n\nThe cloud of datapoints in @fig-scat has a shape - it is longer in one direction (sort of diagonally across y1 and y2), slightly shorter in another (across y3), and then quite narrow in another. You can imagine trying to characterise this shape as the ellipse in @fig-ellip\n\n\n```{r}\n#| echo: false\n#| label: fig-ellip\n#| fig-cap: \"An ellipsis capturing the cloud of datapoints\"\nplot3d(x, box = FALSE, xlab=\"y1\",ylab=\"y2\",zlab=\"y3\")\nplot3d(ellipse3d(Sigma, centre = Mean), col = \"#A41AE4\", alpha = 0.4, add = TRUE)\nrglwidget()\n```\n\nWhen faced with trying to characterise the shape of a 3-dimensional object, we might normally think about its length, width and depth. Imagine being given a ruler and being asked to give two numbers to provide a measurement of your smartphone. What do you pick? Chances are, you will measure its length and then its width. You're likely to ignore the depth because it is much less than the other two dimensions. This is what PCA is doing. \nIf we take three perpendicular dimensions, we can see that the shape in @fig-ellip is longer in one dimension, then slightly shorter in another, and very short in another. These dimensions (seen in @fig-pca3) are our principal components!  Our scree plot (indicating the amount of variance captured by each component) would look like @fig-scree - we can see that each dimension captures less and less of the variance.  \n\n```{r}\n#| label: fig-scree\n#| fig-cap: \"Scree plot for PCA of 3 uncorrelated variables\"\n#| column: margin\n#| echo: false\nscree(x,factor=FALSE)\n```\n\n```{r}\n#| echo: false\n#| label: fig-pca3\n#| fig-cap: \"Principal components are the axes\"\nplot3d(x, box = FALSE, xlab=\"y1\",ylab=\"y2\",zlab=\"y3\")\nplot3d(ellipse3d(Sigma, centre = Mean), col = \"#A41AE4\", alpha = 0.4, add = TRUE)\nplot3d(\n  abclines3d(0,0,0,a=principal(x,nfactors=3,rotate=\"none\")$loadings[,1]),\n  col=\"green\", lwd=2, add=TRUE)\nplot3d(\n  abclines3d(0,0,0,a=principal(x,nfactors=3,rotate=\"none\")$loadings[,2]),\n             col=\"red\",lwd=2, add=TRUE)\nplot3d(\n  abclines3d(0,0,0,a=principal(x,nfactors=3,rotate=\"none\")$loadings[,3]),\n           col=\"blue\", lwd=2, add=TRUE)\nrglwidget()\n\n```\n\nOur principal components capture sequentially the largest dimensions of the shape, which reflect where the most variance is. If there was no correlation between any of our observed variables (i.e. they're all unrelated), then we would have a shape that was basically a sphere, and the no single dimension would capture much more variance than any other. This would look something like @fig-pcano. Our scree plot would look like @fig-scree2 - we can see that each component captures a similar amount. \n\n```{r}\n#| label: fig-scree2\n#| fig-cap: \"Scree plot for PCA of 3 uncorrelated variables\"\n#| column: margin\n#| echo: false\nset.seed(33)\nS = runif(3,.4,2)\nf = runif(3,0,.1)\nR = f %*% t(f)\ndiag(R) = 1\nSigma2 = diag(S)%*%R%*%diag(S)\nMean2 <- rep(0,3)\nx2 <- MASS::mvrnorm(500, Mean2, Sigma2)\nscree(x2,factor=FALSE)\n```\n```{r}\n#| echo: false\n#| label: fig-pcano\n#| fig-cap: \"Principal components for 3 uncorrelated variables\"\nplot3d(x2, box = FALSE, xlab=\"y1\",ylab=\"y2\",zlab=\"y3\")\nplot3d( ellipse3d(Sigma2, centre = Mean2), col = \"#A41AE4\", alpha = 0.4, add = TRUE)\nplot3d(\n  abclines3d(0,0,0,a=principal(x2,nfactors=3,rotate=\"none\")$loadings[,1]),\n           col=\"green\", lwd=2, add=TRUE)\nplot3d(\n  abclines3d(0,0,0,a=principal(x2,nfactors=3,rotate=\"none\")$loadings[,2]),\n           col=\"red\",lwd=2, add=TRUE)\nplot3d(\n  abclines3d(0,0,0,a=principal(x2,nfactors=3,rotate=\"none\")$loadings[,3]),\n           col=\"blue\", lwd=2, add=TRUE)\nrglwidget()\n```\n\n\nThe \"loadings\" we get out of a PCA reflect the amount to which each variable changes across the component. Try rotating the plots in @fig-pca1 and @fig-pca2, which show the first principal component and second principal component respectively. \nYou will see that the first component (the black line) is much more closely linked to changes in y1 and y2 than it is to changes in y3. The second component is the opposite. This reflected in the relative weight of the loadings below! \n```{r}\n#| echo: false\nxx = as.data.frame(x)\nnames(x)<-c(\"y1\",\"y2\",\"y3\")\nprincipal(xx,nfactors=3,rotate=\"none\")$loadings\n```\n\n\n\n```{r}\n#| echo: false\n#| label: fig-pca1\n#| fig-cap: \"The first principal component\"\nplot3d(x, box = FALSE, xlab=\"y1\",ylab=\"y2\",zlab=\"y3\")\nplot3d(ellipse3d(Sigma, centre = Mean), col = \"#A41AE4\", alpha = 0.4, add = TRUE)\nplot3d(\n  abclines3d(0,0,0,a=principal(x,nfactors=3,rotate=\"none\")$loadings[,1]),\n  col=\"green\", lwd=2, add=TRUE)\nrglwidget()\n```\n\n```{r}\n#| echo: false\n#| label: fig-pca2\n#| fig-cap: \"The second principal component\"\nplot3d(x, box = FALSE, xlab=\"y1\",ylab=\"y2\",zlab=\"y3\")\nplot3d(ellipse3d(Sigma, centre = Mean), col = \"#A41AE4\", alpha = 0.4, add = TRUE)\nplot3d(\n  abclines3d(0,0,0,a=principal(x,nfactors=3,rotate=\"none\")$loadings[,2]),\n  col=\"green\", lwd=2, add=TRUE)\nrglwidget()\n```\n\n\n\n","srcMarkdownNoYaml":"\n\n```{r setup, include=FALSE}\nsource('assets/setup.R')\nlibrary(rgl)\nlibrary(psych)\nset.seed(33)\nS = runif(3,.4,2)\nf = runif(3,.7,.99)\nR = f %*% t(f)\ndiag(R) = 1\nR[1,3] <- R[2,3] <- R[3,1] <- R[3,2] <- .1\nSigma = diag(S)%*%R%*%diag(S)\nMean <- rep(0,3)\nx <- MASS::mvrnorm(500, Mean, Sigma)\n\n```\n\nImagine we had 3 measured variables: y1, y2, and y3, as visualised in 3-dimensional space in @fig-scat  \n\n```{r}\n#| echo: false\n#| label: fig-scat\n#| fig-cap: \"3 measured variables\"\nplot3d(x, box = FALSE, xlab=\"y1\",ylab=\"y2\",zlab=\"y3\")\nrglwidget()\n```\n\nThe cloud of datapoints in @fig-scat has a shape - it is longer in one direction (sort of diagonally across y1 and y2), slightly shorter in another (across y3), and then quite narrow in another. You can imagine trying to characterise this shape as the ellipse in @fig-ellip\n\n\n```{r}\n#| echo: false\n#| label: fig-ellip\n#| fig-cap: \"An ellipsis capturing the cloud of datapoints\"\nplot3d(x, box = FALSE, xlab=\"y1\",ylab=\"y2\",zlab=\"y3\")\nplot3d(ellipse3d(Sigma, centre = Mean), col = \"#A41AE4\", alpha = 0.4, add = TRUE)\nrglwidget()\n```\n\nWhen faced with trying to characterise the shape of a 3-dimensional object, we might normally think about its length, width and depth. Imagine being given a ruler and being asked to give two numbers to provide a measurement of your smartphone. What do you pick? Chances are, you will measure its length and then its width. You're likely to ignore the depth because it is much less than the other two dimensions. This is what PCA is doing. \nIf we take three perpendicular dimensions, we can see that the shape in @fig-ellip is longer in one dimension, then slightly shorter in another, and very short in another. These dimensions (seen in @fig-pca3) are our principal components!  Our scree plot (indicating the amount of variance captured by each component) would look like @fig-scree - we can see that each dimension captures less and less of the variance.  \n\n```{r}\n#| label: fig-scree\n#| fig-cap: \"Scree plot for PCA of 3 uncorrelated variables\"\n#| column: margin\n#| echo: false\nscree(x,factor=FALSE)\n```\n\n```{r}\n#| echo: false\n#| label: fig-pca3\n#| fig-cap: \"Principal components are the axes\"\nplot3d(x, box = FALSE, xlab=\"y1\",ylab=\"y2\",zlab=\"y3\")\nplot3d(ellipse3d(Sigma, centre = Mean), col = \"#A41AE4\", alpha = 0.4, add = TRUE)\nplot3d(\n  abclines3d(0,0,0,a=principal(x,nfactors=3,rotate=\"none\")$loadings[,1]),\n  col=\"green\", lwd=2, add=TRUE)\nplot3d(\n  abclines3d(0,0,0,a=principal(x,nfactors=3,rotate=\"none\")$loadings[,2]),\n             col=\"red\",lwd=2, add=TRUE)\nplot3d(\n  abclines3d(0,0,0,a=principal(x,nfactors=3,rotate=\"none\")$loadings[,3]),\n           col=\"blue\", lwd=2, add=TRUE)\nrglwidget()\n\n```\n\nOur principal components capture sequentially the largest dimensions of the shape, which reflect where the most variance is. If there was no correlation between any of our observed variables (i.e. they're all unrelated), then we would have a shape that was basically a sphere, and the no single dimension would capture much more variance than any other. This would look something like @fig-pcano. Our scree plot would look like @fig-scree2 - we can see that each component captures a similar amount. \n\n```{r}\n#| label: fig-scree2\n#| fig-cap: \"Scree plot for PCA of 3 uncorrelated variables\"\n#| column: margin\n#| echo: false\nset.seed(33)\nS = runif(3,.4,2)\nf = runif(3,0,.1)\nR = f %*% t(f)\ndiag(R) = 1\nSigma2 = diag(S)%*%R%*%diag(S)\nMean2 <- rep(0,3)\nx2 <- MASS::mvrnorm(500, Mean2, Sigma2)\nscree(x2,factor=FALSE)\n```\n```{r}\n#| echo: false\n#| label: fig-pcano\n#| fig-cap: \"Principal components for 3 uncorrelated variables\"\nplot3d(x2, box = FALSE, xlab=\"y1\",ylab=\"y2\",zlab=\"y3\")\nplot3d( ellipse3d(Sigma2, centre = Mean2), col = \"#A41AE4\", alpha = 0.4, add = TRUE)\nplot3d(\n  abclines3d(0,0,0,a=principal(x2,nfactors=3,rotate=\"none\")$loadings[,1]),\n           col=\"green\", lwd=2, add=TRUE)\nplot3d(\n  abclines3d(0,0,0,a=principal(x2,nfactors=3,rotate=\"none\")$loadings[,2]),\n           col=\"red\",lwd=2, add=TRUE)\nplot3d(\n  abclines3d(0,0,0,a=principal(x2,nfactors=3,rotate=\"none\")$loadings[,3]),\n           col=\"blue\", lwd=2, add=TRUE)\nrglwidget()\n```\n\n\nThe \"loadings\" we get out of a PCA reflect the amount to which each variable changes across the component. Try rotating the plots in @fig-pca1 and @fig-pca2, which show the first principal component and second principal component respectively. \nYou will see that the first component (the black line) is much more closely linked to changes in y1 and y2 than it is to changes in y3. The second component is the opposite. This reflected in the relative weight of the loadings below! \n```{r}\n#| echo: false\nxx = as.data.frame(x)\nnames(x)<-c(\"y1\",\"y2\",\"y3\")\nprincipal(xx,nfactors=3,rotate=\"none\")$loadings\n```\n\n\n\n```{r}\n#| echo: false\n#| label: fig-pca1\n#| fig-cap: \"The first principal component\"\nplot3d(x, box = FALSE, xlab=\"y1\",ylab=\"y2\",zlab=\"y3\")\nplot3d(ellipse3d(Sigma, centre = Mean), col = \"#A41AE4\", alpha = 0.4, add = TRUE)\nplot3d(\n  abclines3d(0,0,0,a=principal(x,nfactors=3,rotate=\"none\")$loadings[,1]),\n  col=\"green\", lwd=2, add=TRUE)\nrglwidget()\n```\n\n```{r}\n#| echo: false\n#| label: fig-pca2\n#| fig-cap: \"The second principal component\"\nplot3d(x, box = FALSE, xlab=\"y1\",ylab=\"y2\",zlab=\"y3\")\nplot3d(ellipse3d(Sigma, centre = Mean), col = \"#A41AE4\", alpha = 0.4, add = TRUE)\nplot3d(\n  abclines3d(0,0,0,a=principal(x,nfactors=3,rotate=\"none\")$loadings[,2]),\n  col=\"green\", lwd=2, add=TRUE)\nrglwidget()\n```\n\n\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"include-in-header":["assets/toggling.html",{"text":"<link rel=\"stylesheet\" href=\"https://uoepsy.github.io/assets/css/ccfooter.css\" />\n"}],"number-sections":false,"output-file":"00_pca.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","toc_float":true,"link-citations":true,"theme":["united","assets/style-labs.scss"],"title":"PCA in 3D","params":{"SHOW_SOLS":true,"TOGGLE":true}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}