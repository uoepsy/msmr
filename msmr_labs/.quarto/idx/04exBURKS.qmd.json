{"title":"Week 4 Exercises: Nested and Crossed","markdown":{"yaml":{"title":"Week 4 Exercises: Nested and Crossed","params":{"SHOW_SOLS":true,"TOGGLE":true},"editor_options":{"chunk_output_type":"console"}},"headingText":"Psychoeducation Treatment Effects","containsRefs":false,"markdown":"\n\n```{r}\n#| label: setup\n#| include: false\nsource('assets/setup.R')\nlibrary(xaringanExtra)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(ggdist)\nxaringanExtra::use_panelset()\nqcounter <- function(){\n  if(!exists(\"qcounter_i\")){\n    qcounter_i <<- 1\n  }else{\n    qcounter_i <<- qcounter_i + 1\n  }\n  qcounter_i\n}\nlibrary(lme4)\n```\n\n\n\n```{r}\n#| eval: false\n#| echo: false\nsimm2<-function(seed=NULL,b0=0,b1=1,b2=1,z0=1,z1=1,e=1){\n  if(!is.null(seed)){\n    set.seed(seed)\n  }\n  n_groups = round(runif(1,1,15))*2\n  npg = 5\n  g = rep(1:n_groups, e = 5)      # the group identifier\n  x = rep(0:4,n_groups)\n  b = rep(0:1,e=n_groups/2)\n  b = b[g]\n  re0 = rnorm(n_groups, sd = z0)  # random intercepts\n  re  = re0[g]\n  rex = rnorm(n_groups, sd = z1)  # random effects\n  re_x  = rex[g]\n  lp = (b0 + re) + (b1 + re_x)*x + b2*x*b \n  y = rnorm(length(g), mean = lp, sd = e) # create a continuous target variable\n  # y_bin = rbinom(N, size = 1, prob = plogis(lp)) # create a binary target variable\n  data.frame(x, b=factor(b), g=factor(g), y)\n}\neseed = round(runif(1,1e3,1e6))\nset.seed(645533)\nbig = tibble(\n    school = 1:30,\n    int = rnorm(30,20,1),\n    sl = rnorm(30,-.3,.5),\n    intr = rnorm(30,-1,.5),\n    z0 = runif(30,.5,1),\n    z1 = runif(30,.5,1),\n    e = runif(30,.5,1)\n  )\n  big = big |> mutate(\n    data = pmap(list(int,sl,intr,z0,z1,e), ~simm2(b0=..1,b1=..2,b2=..3,z0=..4,z1=..5,e=..6))\n  ) |> unnest(data)\n\n  # m = lmer(round(y)~x*b+(1+x*b|school)+(1+x|school:g),big)\n  # broom.mixed::augment(m) |>\n  #   ggplot(aes(x=x,y=.fitted,col=factor(b)))+\n  #   geom_point(aes(y=`round(y)`))+\n  #   geom_line(aes(group=interaction(school,g)))\n\ntnames = unique(replicate(100,paste0(sample(LETTERS,2),collapse=\"\")))\n  \nbig |> transmute(\n    therapist = tnames[school],\n    group = ifelse(b==0,\"Control\",\"Treatment\"),\n    patient = pmap_chr(list(therapist,group,g),~paste(..1,..2,..3,sep=\"_\")),\n    visit = x,\n    GAD = pmin(35,pmax(7,round(y)+5))\n  ) |> select(patient,visit,GAD) |>\n  pivot_wider(names_from=visit,values_from=GAD, names_prefix=\"visit_\") |>\n  write_csv(file=\"../../data/msmr_gadeduc.csv\")\n\n```\n\n\n\n:::frame\n__Data: gadeduc.csv__\n\n```{r}\n#| include: false\ngeduc = read_csv(\"https://uoepsy.github.io/data/msmr_gadeduc.csv\")\ngeduc1 = geduc |> \n  pivot_longer(2:last_col(), names_to=\"visit\",values_to=\"GAD\") |>\n  mutate(\n    visit = as.numeric(gsub(\"visit_\",\"\",visit))\n  ) |>\n  separate(patient, into=c(\"therapist\",\"group\",\"patient\"), sep=\"_\")\n# m = lmer(GAD~visit*group+(1+visit*group|therapist)+(1+visit|therapist:patient),geduc1)\n# summary(m)\ntn = geduc1 |> group_by(therapist) |> summarise(np = n_distinct(patient))\n```\n\nThis is synthetic data from a randomised controlled trial, in which `r nrow(tn)` therapists randomly assigned participants (each therapist saw between `r min(tn[,'np'])` and `r max(tn[,'np'])` patients) to a control or treatment group, and monitored the participants' scores over time on a measure of generalised anxiety disorder (GAD7 - a 7 item questionnaire with 5 point likert scales).  \nThe control group of participants received standard sessions offered by the therapists. \nFor the treatment group, 10 mins of each sessions was replaced with a specific psychoeducational component, and participants were given relevant tasks to complete between each session. All participants had monthly therapy sessions. Generalised Anxiety Disorder was assessed at baseline and then every visit over 4 months of sessions (5 assessments in total).  \n\nThe data are available at [https://uoepsy.github.io/data/msmr_gadeduc.csv](https://uoepsy.github.io/data/msmr_gadeduc.csv){target=\"_blank\"}\n\nYou can find a data dictionary below:\n```{r}\n#| echo: false\n#| label: tbl-msmr_gadeduc.csv\n#| tbl-cap: \"Data Dictionary: msmr_gadeduc.csv\"\ntibble(\n    variable = names(geduc),\n    description = c(\"A patient code in which the labels take the form <Therapist initials>_<group>_<patient number>.\",\"Score on the GAD7 at baseline\", \n                    \"GAD7 at 1 month assessment\",\n                    \"GAD7 at 2 month assessment\",\n                    \"GAD7 at 3 month assessment\",\n                    \"GAD7 at 4 month assessment\"\n                    )\n)  |>\n    kableExtra::kbl() |>\n    kableExtra::kable_styling(full_width = FALSE)\n```\n\n:::\n\n\n`r qbegin(qcounter())`\n\n- read in the data. uh-oh... this isn't data in the same shape as we've been giving you thus far.  \n- can you get it into a suitable format for modelling?  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- it's wide, and we want it long\n- once it's long. \"visit_0\", \"visit_1\",.. needs to become the numbers 0, 1, ...\n- one variable (`patient`) contains lots of information that we want to separate out.     \n`data |> separate(variable, into=c(\"thing1\",\"thing2\",\"thing3\",...), sep = \"separator\")`  \n\n\n:::\n\n\n`r qend()`\n`r solbegin(label=\"1 - reshaping\", slabel=F,show=T, toggle=params$TOGGLE)`\n```{r}\ngeduc = read_csv(\"../../data/msmr_gadeduc.csv\")\n\ngeduc |> \n  pivot_longer(2:last_col(), names_to=\"visit\",values_to=\"GAD\")\n```\n\n\n`r solend()`\n`r solbegin(label=\"2 - time is numeric\", slabel=F,show=T, toggle=params$TOGGLE)`\n```{r}\ngeduc |> \n  pivot_longer(2:last_col(), names_to=\"visit\",values_to=\"GAD\") |>\n  mutate(\n    visit = as.numeric(gsub(\"visit_\",\"\",visit))\n  ) \n```\n\n\n`r solend()`\n`r solbegin(label=\"3 - splitting up the patient variable\", slabel=F,show=T, toggle=params$TOGGLE)`\n```{r}\ngeduc_long <- geduc |> \n  pivot_longer(2:last_col(), names_to=\"visit\",values_to=\"GAD\") |>\n  mutate(\n    visit = as.numeric(gsub(\"visit_\",\"\",visit))\n  ) |>\n  separate(patient, into=c(\"therapist\",\"group\",\"patient\"), sep=\"_\")\n\ngeduc_long\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nVisualise the data. Does it look like the treatment had an effect?  \nDoes it look like it had an effect for every therapist?  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nggplot(geduc_long, aes(x = visit, y = GAD, col = group)) +\n  stat_summary(geom=\"pointrange\")\n```\n\n\n```{r}\nggplot(geduc_long, aes(x = visit, y = GAD, col = group)) +\n  stat_summary(geom=\"pointrange\") +\n  facet_wrap(~therapist)\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nfit a model to test if the psychoeducational treatment is associated with more improvement in anxiety over time.  \n`r qend()`\n`r solbegin(label=\"1 - fixed effects\", slabel=F,show=T, toggle=params$TOGGLE)`\n\n```{r}\n#| eval: false\nlmer(GAD ~ visit * group + ...\n       ...\n     data = geduc_long)\n```\n\n`r solend()`\n`r solbegin(label=\"2 - grouping structure\", slabel=F,show=T, toggle=params$TOGGLE)`\n\n```{r}\n#| eval: false\nlmer(GAD ~ visit * group + ...\n       ( ... | therapist) + \n       ( ... | therapist:patient),\n     data = geduc_long)\n```\n\n\n`r solend()`\n`r solbegin(label=\"3 - random effects\", slabel=F,show=T, toggle=params$TOGGLE)`\n\n```{r}\nmod1 <- lmer(GAD ~ visit*group + \n               (1+visit*group|therapist)+\n               (1+visit|therapist:patient),\n             geduc_long)\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nfor each of the models below, what is wrong or suboptimal about the random effect structure?  \n\n```{r}\n#| eval: false\nmodelA <- lmer(GAD ~ visit*group + \n               (1+visit*group|therapist)+\n               (1+visit|patient),\n             geduc_long)\n\nmodelB <- lmer(GAD ~ visit*group + \n               (1+visit*group|therapist/patient),\n             geduc_long)\n```\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n- patient doesn't capture the different patients _within_ therapists. so it actually fits crossed random effects and treats all data where `patient==1` as from the same group (even if this includes several different patients' worth of data from different therapists!)\n\n- using the `/` means we have the same random slopes fitted for therapists and for patients-within-therapists. but the effect of group can't vary by patient, so this doesn't work. hence why we need to split them up into `(...|therapist)+(...|therapist:patient)`.  \n\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nlet's suppose I don't want the psychoeducation treatment, I just want the standard therapy sessions that the 'Control' group received. Which therapist should I go to?  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\ndotplot.ranef.mer might help here\n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\nWG, EQ, or EI.. \n\nwhy? they all have the most negative slope of visit  \n\n```{r}\ndotplot.ranef.mer(ranef(mod1))$therapist\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nrecreate this plot.  \n\nThe faint lines represent the model estimated lines for each patient.  The points and ranges represent our fixed effect estimates and their uncertainty.  \n\n```{r} \n#| echo: false\neffplot <- effects::effect(\"visit*group\",mod1) |>\n  as.data.frame()\n\nbroom.mixed::augment(mod1) |> \n  mutate(\n    upatient = paste0(therapist,patient)\n  ) |>\n  ggplot(aes(x=visit,y=.fitted,col=group))+\n  stat_summary(geom=\"line\", aes(group=upatient,col=group), alpha=.1)+\n  geom_pointrange(data=effplot, aes(y=fit,ymin=lower,ymax=upper,col=group))+\n  labs(x=\"- Month -\",y=\"GAD7\")\n\n```\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\neffplot <- effects::effect(\"visit*group\",mod1) |>\n  as.data.frame()\n\nbroom.mixed::augment(mod1) |> \n  mutate(\n    upatient = paste0(therapist,patient)\n  ) |>\n  ggplot(aes(x=visit,y=.fitted,col=group))+\n  stat_summary(geom=\"line\", aes(group=upatient,col=group), alpha=.1)+\n  geom_pointrange(data=effplot, aes(y=fit,ymin=lower,ymax=upper,col=group))+\n  labs(x=\"- Month -\",y=\"GAD7\")\n```\n\n\n`r solend()`\n\n\n<br><br>\n\n# Test Enhanced Learning\n\n:::frame\n__Data: Test-enhanced learning__  \n\nAn experiment was run to conceptually replicate \"test-enhanced learning\" (Roediger & Karpicke, 2006): two groups of 25 participants were presented with material to learn. One group studied the material twice (`StudyStudy`), the other group studied the material once then did a test (`StudyTest`). Recall was tested immediately (one minute) after the learning session and one week later. The recall tests were composed of 175 items identified by a keyword (`Test_word`). \n\nThe critical (replication) prediction is that the `StudyStudy` group should perform somewhat better on the immediate recall test, but the `StudyTest` group will retain the material better and thus perform better on the 1-week follow-up test.\n\nThe following code loads the data into your R environment by creating a variable called `tel`:\n\n```{r}\n#| eval: false\nload(url(\"https://uoepsy.github.io/data/testenhancedlearning.RData\"))\n```\n\n```{r} \n#| echo: false\n#| label: tbl-teldict\n#| tbl-cap: \"Data Dictionary: testenhancedlearning.Rdata\"\nload(url(\"https://uoepsy.github.io/data/testenhancedlearning.RData\"))\ntibble(\n  variable=names(tel),\n  description=c(\"Unique Participant Identifier\", \"Group denoting whether the participant studied the material twice (StudyStudy), or studied it once then did a test (StudyTest)\",\"Time of recall test ('min' = Immediate, 'week' = One week later)\",\"Word being recalled (175 different test words)\",\"Whether or not the word was correctly recalled\",\"Time to recall word (milliseconds)\")\n) |>\n    kableExtra::kbl() |>\n    kableExtra::kable_styling(full_width = FALSE)\n```\n\n:::\n\n\n\n`r qbegin(qcounter())`\nLoad and plot the data. Does it look like the effect was replicated?  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nload(url(\"https://uoepsy.github.io/data/testenhancedlearning.RData\"))\n\nggplot(tel, aes(Delay, Correct, col=Group)) + \n  stat_summary(fun.data=mean_se, geom=\"pointrange\")+\n  theme_light()\n```\n\nThat looks like test-enhanced learning to me!  \n\n\n`r solend()`\n\n`r qbegin(qcounter())`\n\nTest the critical hypothesis using a mixed-effects model.  \n\nFit the maximal random effect structure supported by the experimental design. Simplify the random effect structure until you reach a model that converges.  \n\nSome of the models you attempt here might take time to fit. This is normal, and you can cancel the estimation at any time by pressing the escape key.  \nI suggest you write your initial model, set it running, and then look at the first solution to see if it converged for me. \nAssume that if it didn't work for me, it also won't work for you. In which case cancel it and write your next model (then look at the next solution as that model is fitting, and so on.. )  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nWhat we're aiming to do here is to follow [Barr et al.'s](https://doi.org/10.1016/j.jml.2012.11.001) advice of defining our maximal model and then removing only the terms to allow a non-singular fit.  \n\n+ What kind of model will you use? What is our outcome? is it binary, or continuous? \n+ We can expect variability across subjects (some people are better at learning than others) and across items (some of the recall items are harder than others). How should this be represented in the random effects?\n\n:::\n\n`r qend()` \n`r solbegin(label=\"1 - maximal model\", slabel=F,show=T, toggle=params$TOGGLE)`\n\n```{r}\n#| echo: false\n# save(mod1,mod2,mod3,mod4,file=\"data/telmodels.Rdata\")\nload(\"data/telmodels.Rdata\")\n```\n\n\nThis one took my computer about 6 minutes.  \n```{r}\n#| eval: false\nmod1 <- glmer(Correct ~ Delay*Group +\n             (1 + Delay | Subject_ID) +\n             (1 + Delay * Group | Test_word),\n             family=binomial, data=tel)\n```\n<p style=\"color:red;font-size:.8em\">\nWarning message:<br>\nIn checkConv(attr(opt, \"derivs\"), opt\\$par, ctrl = control\\$checkConv,  :<br>\n  Model failed to converge with max|grad| = 0.0184773 (tol = 0.002, component 1)\n</p>\n\n```{r}\nVarCorr(mod1)\n```\n\n`r solend()`\n`r solbegin(label=\"2 - Removing Group|Subject_ID\", slabel=F,show=T, toggle=params$TOGGLE)`\n\nlets remove the interaction in the by-word random effects.  \nThis one took about 5 minutes...\n```{r}\n#| eval: false\nmod2 <- glmer(Correct ~ Delay*Group +\n             (1 + Delay | Subject_ID) +\n             (1 + Delay + Group | Test_word),\n             family=binomial, data=tel)\n```\n<p style=\"color:red;font-size:.8em\">\nWarning message:<br>\nIn checkConv(attr(opt, \"derivs\"), opt\\$par, ctrl = control\\$checkConv,  :<br>\n  Model failed to converge with max|grad| = 0.00887744 (tol = 0.002, component 1)\n</p>\n\n```{r}\nVarCorr(mod2)\n```\n\n`r solend()`\n`r solbegin(label=\"3 - Removing Group|Test_word\", slabel=F,show=T, toggle=params$TOGGLE)`\n\nWe still have a singular fit here. Thinking about the study, if we are going to remove __one__ of the by-testword random effects (`Delay` or `Group`), which one do we consider to be more theoretically justified? Is the effect of Delay likely to vary by test-words? More so than the effect of group is likely to vary by test-words? Quite possibly - there's no obvious reason for _certain_ words to be more memorable for people in one group vs another. But there is reason for words to vary in the effect that delay of one week has - how familiar a word is will likely influence the amount to which a week's delay has on recall.   \n\nLet's remove the by-testword random effect of group. \n```{r}\n#| eval: false\nmod3 <- glmer(Correct ~ Delay*Group +\n             (1 + Delay | Subject_ID) +\n             (1 + Delay | Test_word),\n             family=binomial, data=tel)\n```\n\nThis one converges! But we still have a correlation of -1. Why did we not get a warning message?  \n```{r}\nVarCorr(mod3)\n```\n\n```{r}\nisSingular(mod3)\n```\n\n`r solend()`\n`r solbegin(label=\"4 - Removing Delay|Test_word\", slabel=F,show=T, toggle=params$TOGGLE)`\n\n```{r}\n#| eval: false\nmod4 <- glmer(Correct ~ Delay*Group +\n             (1 + Delay | Subject_ID) +\n             (1 | Test_word),\n             family=binomial, data=tel)\n```\n```{r}\nisSingular(mod4)\n```\n\n\n\n\n\n`r solend()`\n`r solbegin(label=\"5 - Comparisons\", slabel=F,show=T, toggle=params$TOGGLE)`\n\nHere are the fixed effects from each model: \n```{r}\n#| echo: false\nbind_rows(\n broom.mixed::tidy(mod1) |> filter(effect==\"fixed\") |> mutate(mod=\"mod1\"), \n broom.mixed::tidy(mod2) |> filter(effect==\"fixed\") |> mutate(mod=\"mod2\"), \n broom.mixed::tidy(mod3) |> filter(effect==\"fixed\") |> mutate(mod=\"mod3\"), \n broom.mixed::tidy(mod4) |> filter(effect==\"fixed\") |> mutate(mod=\"mod4\")\n) |> select(mod,term,estimate) |> pivot_wider(values_from=estimate,names_from=mod)\n```\n\nAnd here are the standard errors of fixed effects for each model:  \n```{r}\n#| echo: false\nbind_rows(\n broom.mixed::tidy(mod1) |> filter(effect==\"fixed\") |> mutate(mod=\"mod1\"), \n broom.mixed::tidy(mod2) |> filter(effect==\"fixed\") |> mutate(mod=\"mod2\"), \n broom.mixed::tidy(mod3) |> filter(effect==\"fixed\") |> mutate(mod=\"mod3\"), \n broom.mixed::tidy(mod4) |> filter(effect==\"fixed\") |> mutate(mod=\"mod4\")\n) |> select(mod,term,std.error) |> pivot_wider(values_from=std.error,names_from=mod)\n```\n\n\n`r solend()` \n\n\n\n`r qbegin(qcounter())`\nCreate a plot of the fixed effects.  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nlibrary(effects)\neffplot <- effect(\"Delay:Group\", mod4) |>\n  as.data.frame()\n\nggplot(effplot, aes(Delay, fit, color=Group)) + \n  geom_pointrange(aes(ymax=upper, ymin=lower), \n                  position=position_dodge(width = 0.2))+\n  theme_classic() # just for a change :)\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nWhat should we do with this information? How can we apply test-enhanced learning to learning R and statistics?\n`r qend()` \n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\nYou'll get the benefits of test-enhanced learning if you try yourself before looking at the solutions! If you don't test yourself, you're more likely to forget it in the long run. \n`r solend()` \n\n<br><br>\n\n# Vocab Development\n\n\n\n\n:::frame\n__Data: pvt_bilingual.csv__ \n\n```{r}\n#| echo: false\npvt <- read_csv(\"https://uoepsy.github.io/data/pvt_bilingual.csv\")\npvtsc = pvt |> count(school,child,isBilingual)\n```\n\n`r nrow(pvtsc)` children from `r length(unique(pvt$school))` schools were included in the study. Children were assessed on a yearly basis for 7 years throughout primary school on a measure of vocabulary administered in English, the Picture Vocab Test (PVT). `r sum(pvtsc$isBilingual==0)` were monolingual English speakers, and `r sum(pvtsc$isBilingual==1)` were bilingual (english + another language). \n\nPrevious research conducted on monolingual children has suggested that that scores on the PVT increase steadily up until the age of approximately 7 or 8 at which point they begin to plateau. The aim of the present study is to investigate differences in the development of vocabulary between monolingual and bilingual children.  \n\nThe data are available at [https://uoepsy.github.io/data/pvt_bilingual.csv](https://uoepsy.github.io/data/pvt_bilingual.csv).  \n\n```{r}\n#| echo: false\n#| label: tbl-pvtdict\n#| tbl-cap: \"Data Dictionary: pvt_bilingual.csv\"\ntibble(variable = names(pvt),\n       description = c(\n         \"Child's name\",\n         \"School Identifier\",\n         \"Binary variable indicating whether the child is monolingual (0) or bilingual (1)\",\n         \"Age (years)\",\n         \"Score on the Picture Vocab Test (PVT). Scores range 0 to 60\")\n) |>\n    kableExtra::kbl() |>\n    kableExtra::kable_styling(full_width = FALSE)\n```\n\n:::\n\n`r qbegin(qcounter())`\nLet's start by thinking about our clustering - we'd like to know how much of the variance in PVT scores is due to the clustering of data within children, who are themselves within schools. One easy way of assessing this is to fit an _intercept only_ model, which has the appropriate random effect structure.  \n\nUsing the model below, calculate the proportion of variance attributable to the clustering of data within children within schools.  \n\n```{r}\npvt_null <- lmer(PVT ~ 1 +  (1 | school/child), data = pvt)\n```\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\nthe random intercept variances are the building blocks here. There are no predictors in this model, so all the variance in the outcome gets attributed to either school-level nesting, child-level nesting, or else is lumped into the residual.   \n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\n# pvt <- read_csv(\"../../data/bntmono.csv\")\npvt_null <- lmer(PVT ~ 1 +  (1 | school/child), data = pvt)\nsummary(pvt_null)\n```\n\n```{r}\n#| echo: false\nvcres = VarCorr(pvt_null) |> as.data.frame()\nvcres = round(vcres$vcov,2)\n```\n\n\nAs we can see from `summary(bnt_null)`, the random intercept variances are `r vcres[1]` for child-level, `r vcres[2]` for school-level, and the residual variance is `r vcres[3]`.  \n\nSo child level differences account for $\\frac{`r vcres[1]`}{`r paste0(vcres,collapse=\" + \")`} = `r round(vcres[1]/sum(vcres),2)`$ of the variance in PVT scores, and child & school differences together account for $\\frac{`r paste0(vcres[1:2],collapse=\" + \")`}{`r paste0(vcres,collapse=\" + \")`} = `r round(sum(vcres[1:2])/sum(vcres),2)`$ of the variance.  \n\n\n`r solend()`\n\n`r qbegin(paste0(qcounter(), \" - Less Guided\"))`\nConduct an analysis to estimate the differences in trajectories of vocabulary development between children attending bilingual schools vs those attending monolingual schools.  \n\nWrite up your results.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- make things factors\n- always plot your data!\n- \n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nggplot(pvt, aes(x=age,y=PVT,col=factor(isBilingual)))+\n  stat_summary(geom=\"pointrange\")+\n  stat_summary(geom=\"line\")\n```\n\n\n\n```{r}\npvt <- pvt |> mutate(\n  poly1 = poly(age, 3)[,1],\n  poly2 = poly(age, 3)[,2],\n  poly3 = poly(age, 3)[,3],\n  isBilingual = factor(isBilingual)\n)\n```\n\n```{r}\n#| eval: false\nmod1 <- lmer(PVT ~ 1 + (poly1 + poly2 + poly3) * isBilingual + \n       (1 + (poly1 + poly2 + poly3)*isBilingual | school) + \n       (1 + (poly1 + poly2 + poly3) | school:child),\n     data = pvt)\n\nmod2 <- lmer(PVT ~ 1 + (poly1 + poly2 + poly3) * isBilingual + \n       (1 + isBilingual * (poly1 + poly2) + poly3 | school) +\n       (1 + (poly1 + poly2 + poly3) | school:child),\n     data = pvt)\n\nmod3 <- lmer(PVT ~ 1 + (poly1 + poly2 + poly3) * isBilingual + \n       (1 + isBilingual * (poly1 + poly2) | school) +\n       (1 + (poly1 + poly2 + poly3) | school:child),\n     data = pvt)\n\nmod4 <- lmer(PVT ~ 1 + (poly1 + poly2 + poly3) * isBilingual + \n       (1 + isBilingual * (poly1) + poly2 | school) +\n       (1 + (poly1 + poly2 + poly3) | school:child),\n     data = pvt)\n\nmod5 <- lmer(PVT ~ 1 + (poly1 + poly2 + poly3) * isBilingual + \n       (1 + isBilingual * (poly1) | school) +\n       (1 + (poly1 + poly2 + poly3) | school:child),\n     data = pvt)\n\nmod6 <- lmer(PVT ~ 1 + (poly1 + poly2 + poly3) * isBilingual + \n       (1 + isBilingual + poly1 | school) +\n       (1 + (poly1 + poly2 + poly3) | school:child),\n     data = pvt)\n```\n\n\n```{r}\nmod7 <- lmer(PVT ~ 1 + (poly1 + poly2 + poly3) * isBilingual + \n       (1 + poly1 | school) +\n       (1 + (poly1 + poly2 + poly3) | school:child),\n     data = pvt)\n```\n\n\n```{r}\nlibrary(broom.mixed)\naugment(mod7) |> \n  mutate(\n    poly1 = round(poly1, 3) # because of rounding errors make plot weird\n  ) |>\n  ggplot(aes(x=poly1,col=isBilingual))+\n  stat_summary(geom=\"pointrange\",aes(y=PVT))+\n  stat_summary(geom=\"line\", aes(y=.fitted))\n```\n\n\n\n\n\n`r solend()`\n\n\n\n\n\n\n","srcMarkdownNoYaml":"\n\n```{r}\n#| label: setup\n#| include: false\nsource('assets/setup.R')\nlibrary(xaringanExtra)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(ggdist)\nxaringanExtra::use_panelset()\nqcounter <- function(){\n  if(!exists(\"qcounter_i\")){\n    qcounter_i <<- 1\n  }else{\n    qcounter_i <<- qcounter_i + 1\n  }\n  qcounter_i\n}\nlibrary(lme4)\n```\n\n\n# Psychoeducation Treatment Effects\n\n```{r}\n#| eval: false\n#| echo: false\nsimm2<-function(seed=NULL,b0=0,b1=1,b2=1,z0=1,z1=1,e=1){\n  if(!is.null(seed)){\n    set.seed(seed)\n  }\n  n_groups = round(runif(1,1,15))*2\n  npg = 5\n  g = rep(1:n_groups, e = 5)      # the group identifier\n  x = rep(0:4,n_groups)\n  b = rep(0:1,e=n_groups/2)\n  b = b[g]\n  re0 = rnorm(n_groups, sd = z0)  # random intercepts\n  re  = re0[g]\n  rex = rnorm(n_groups, sd = z1)  # random effects\n  re_x  = rex[g]\n  lp = (b0 + re) + (b1 + re_x)*x + b2*x*b \n  y = rnorm(length(g), mean = lp, sd = e) # create a continuous target variable\n  # y_bin = rbinom(N, size = 1, prob = plogis(lp)) # create a binary target variable\n  data.frame(x, b=factor(b), g=factor(g), y)\n}\neseed = round(runif(1,1e3,1e6))\nset.seed(645533)\nbig = tibble(\n    school = 1:30,\n    int = rnorm(30,20,1),\n    sl = rnorm(30,-.3,.5),\n    intr = rnorm(30,-1,.5),\n    z0 = runif(30,.5,1),\n    z1 = runif(30,.5,1),\n    e = runif(30,.5,1)\n  )\n  big = big |> mutate(\n    data = pmap(list(int,sl,intr,z0,z1,e), ~simm2(b0=..1,b1=..2,b2=..3,z0=..4,z1=..5,e=..6))\n  ) |> unnest(data)\n\n  # m = lmer(round(y)~x*b+(1+x*b|school)+(1+x|school:g),big)\n  # broom.mixed::augment(m) |>\n  #   ggplot(aes(x=x,y=.fitted,col=factor(b)))+\n  #   geom_point(aes(y=`round(y)`))+\n  #   geom_line(aes(group=interaction(school,g)))\n\ntnames = unique(replicate(100,paste0(sample(LETTERS,2),collapse=\"\")))\n  \nbig |> transmute(\n    therapist = tnames[school],\n    group = ifelse(b==0,\"Control\",\"Treatment\"),\n    patient = pmap_chr(list(therapist,group,g),~paste(..1,..2,..3,sep=\"_\")),\n    visit = x,\n    GAD = pmin(35,pmax(7,round(y)+5))\n  ) |> select(patient,visit,GAD) |>\n  pivot_wider(names_from=visit,values_from=GAD, names_prefix=\"visit_\") |>\n  write_csv(file=\"../../data/msmr_gadeduc.csv\")\n\n```\n\n\n\n:::frame\n__Data: gadeduc.csv__\n\n```{r}\n#| include: false\ngeduc = read_csv(\"https://uoepsy.github.io/data/msmr_gadeduc.csv\")\ngeduc1 = geduc |> \n  pivot_longer(2:last_col(), names_to=\"visit\",values_to=\"GAD\") |>\n  mutate(\n    visit = as.numeric(gsub(\"visit_\",\"\",visit))\n  ) |>\n  separate(patient, into=c(\"therapist\",\"group\",\"patient\"), sep=\"_\")\n# m = lmer(GAD~visit*group+(1+visit*group|therapist)+(1+visit|therapist:patient),geduc1)\n# summary(m)\ntn = geduc1 |> group_by(therapist) |> summarise(np = n_distinct(patient))\n```\n\nThis is synthetic data from a randomised controlled trial, in which `r nrow(tn)` therapists randomly assigned participants (each therapist saw between `r min(tn[,'np'])` and `r max(tn[,'np'])` patients) to a control or treatment group, and monitored the participants' scores over time on a measure of generalised anxiety disorder (GAD7 - a 7 item questionnaire with 5 point likert scales).  \nThe control group of participants received standard sessions offered by the therapists. \nFor the treatment group, 10 mins of each sessions was replaced with a specific psychoeducational component, and participants were given relevant tasks to complete between each session. All participants had monthly therapy sessions. Generalised Anxiety Disorder was assessed at baseline and then every visit over 4 months of sessions (5 assessments in total).  \n\nThe data are available at [https://uoepsy.github.io/data/msmr_gadeduc.csv](https://uoepsy.github.io/data/msmr_gadeduc.csv){target=\"_blank\"}\n\nYou can find a data dictionary below:\n```{r}\n#| echo: false\n#| label: tbl-msmr_gadeduc.csv\n#| tbl-cap: \"Data Dictionary: msmr_gadeduc.csv\"\ntibble(\n    variable = names(geduc),\n    description = c(\"A patient code in which the labels take the form <Therapist initials>_<group>_<patient number>.\",\"Score on the GAD7 at baseline\", \n                    \"GAD7 at 1 month assessment\",\n                    \"GAD7 at 2 month assessment\",\n                    \"GAD7 at 3 month assessment\",\n                    \"GAD7 at 4 month assessment\"\n                    )\n)  |>\n    kableExtra::kbl() |>\n    kableExtra::kable_styling(full_width = FALSE)\n```\n\n:::\n\n\n`r qbegin(qcounter())`\n\n- read in the data. uh-oh... this isn't data in the same shape as we've been giving you thus far.  \n- can you get it into a suitable format for modelling?  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- it's wide, and we want it long\n- once it's long. \"visit_0\", \"visit_1\",.. needs to become the numbers 0, 1, ...\n- one variable (`patient`) contains lots of information that we want to separate out.     \n`data |> separate(variable, into=c(\"thing1\",\"thing2\",\"thing3\",...), sep = \"separator\")`  \n\n\n:::\n\n\n`r qend()`\n`r solbegin(label=\"1 - reshaping\", slabel=F,show=T, toggle=params$TOGGLE)`\n```{r}\ngeduc = read_csv(\"../../data/msmr_gadeduc.csv\")\n\ngeduc |> \n  pivot_longer(2:last_col(), names_to=\"visit\",values_to=\"GAD\")\n```\n\n\n`r solend()`\n`r solbegin(label=\"2 - time is numeric\", slabel=F,show=T, toggle=params$TOGGLE)`\n```{r}\ngeduc |> \n  pivot_longer(2:last_col(), names_to=\"visit\",values_to=\"GAD\") |>\n  mutate(\n    visit = as.numeric(gsub(\"visit_\",\"\",visit))\n  ) \n```\n\n\n`r solend()`\n`r solbegin(label=\"3 - splitting up the patient variable\", slabel=F,show=T, toggle=params$TOGGLE)`\n```{r}\ngeduc_long <- geduc |> \n  pivot_longer(2:last_col(), names_to=\"visit\",values_to=\"GAD\") |>\n  mutate(\n    visit = as.numeric(gsub(\"visit_\",\"\",visit))\n  ) |>\n  separate(patient, into=c(\"therapist\",\"group\",\"patient\"), sep=\"_\")\n\ngeduc_long\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nVisualise the data. Does it look like the treatment had an effect?  \nDoes it look like it had an effect for every therapist?  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nggplot(geduc_long, aes(x = visit, y = GAD, col = group)) +\n  stat_summary(geom=\"pointrange\")\n```\n\n\n```{r}\nggplot(geduc_long, aes(x = visit, y = GAD, col = group)) +\n  stat_summary(geom=\"pointrange\") +\n  facet_wrap(~therapist)\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nfit a model to test if the psychoeducational treatment is associated with more improvement in anxiety over time.  \n`r qend()`\n`r solbegin(label=\"1 - fixed effects\", slabel=F,show=T, toggle=params$TOGGLE)`\n\n```{r}\n#| eval: false\nlmer(GAD ~ visit * group + ...\n       ...\n     data = geduc_long)\n```\n\n`r solend()`\n`r solbegin(label=\"2 - grouping structure\", slabel=F,show=T, toggle=params$TOGGLE)`\n\n```{r}\n#| eval: false\nlmer(GAD ~ visit * group + ...\n       ( ... | therapist) + \n       ( ... | therapist:patient),\n     data = geduc_long)\n```\n\n\n`r solend()`\n`r solbegin(label=\"3 - random effects\", slabel=F,show=T, toggle=params$TOGGLE)`\n\n```{r}\nmod1 <- lmer(GAD ~ visit*group + \n               (1+visit*group|therapist)+\n               (1+visit|therapist:patient),\n             geduc_long)\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nfor each of the models below, what is wrong or suboptimal about the random effect structure?  \n\n```{r}\n#| eval: false\nmodelA <- lmer(GAD ~ visit*group + \n               (1+visit*group|therapist)+\n               (1+visit|patient),\n             geduc_long)\n\nmodelB <- lmer(GAD ~ visit*group + \n               (1+visit*group|therapist/patient),\n             geduc_long)\n```\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n- patient doesn't capture the different patients _within_ therapists. so it actually fits crossed random effects and treats all data where `patient==1` as from the same group (even if this includes several different patients' worth of data from different therapists!)\n\n- using the `/` means we have the same random slopes fitted for therapists and for patients-within-therapists. but the effect of group can't vary by patient, so this doesn't work. hence why we need to split them up into `(...|therapist)+(...|therapist:patient)`.  \n\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nlet's suppose I don't want the psychoeducation treatment, I just want the standard therapy sessions that the 'Control' group received. Which therapist should I go to?  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\ndotplot.ranef.mer might help here\n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\nWG, EQ, or EI.. \n\nwhy? they all have the most negative slope of visit  \n\n```{r}\ndotplot.ranef.mer(ranef(mod1))$therapist\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nrecreate this plot.  \n\nThe faint lines represent the model estimated lines for each patient.  The points and ranges represent our fixed effect estimates and their uncertainty.  \n\n```{r} \n#| echo: false\neffplot <- effects::effect(\"visit*group\",mod1) |>\n  as.data.frame()\n\nbroom.mixed::augment(mod1) |> \n  mutate(\n    upatient = paste0(therapist,patient)\n  ) |>\n  ggplot(aes(x=visit,y=.fitted,col=group))+\n  stat_summary(geom=\"line\", aes(group=upatient,col=group), alpha=.1)+\n  geom_pointrange(data=effplot, aes(y=fit,ymin=lower,ymax=upper,col=group))+\n  labs(x=\"- Month -\",y=\"GAD7\")\n\n```\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\neffplot <- effects::effect(\"visit*group\",mod1) |>\n  as.data.frame()\n\nbroom.mixed::augment(mod1) |> \n  mutate(\n    upatient = paste0(therapist,patient)\n  ) |>\n  ggplot(aes(x=visit,y=.fitted,col=group))+\n  stat_summary(geom=\"line\", aes(group=upatient,col=group), alpha=.1)+\n  geom_pointrange(data=effplot, aes(y=fit,ymin=lower,ymax=upper,col=group))+\n  labs(x=\"- Month -\",y=\"GAD7\")\n```\n\n\n`r solend()`\n\n\n<br><br>\n\n# Test Enhanced Learning\n\n:::frame\n__Data: Test-enhanced learning__  \n\nAn experiment was run to conceptually replicate \"test-enhanced learning\" (Roediger & Karpicke, 2006): two groups of 25 participants were presented with material to learn. One group studied the material twice (`StudyStudy`), the other group studied the material once then did a test (`StudyTest`). Recall was tested immediately (one minute) after the learning session and one week later. The recall tests were composed of 175 items identified by a keyword (`Test_word`). \n\nThe critical (replication) prediction is that the `StudyStudy` group should perform somewhat better on the immediate recall test, but the `StudyTest` group will retain the material better and thus perform better on the 1-week follow-up test.\n\nThe following code loads the data into your R environment by creating a variable called `tel`:\n\n```{r}\n#| eval: false\nload(url(\"https://uoepsy.github.io/data/testenhancedlearning.RData\"))\n```\n\n```{r} \n#| echo: false\n#| label: tbl-teldict\n#| tbl-cap: \"Data Dictionary: testenhancedlearning.Rdata\"\nload(url(\"https://uoepsy.github.io/data/testenhancedlearning.RData\"))\ntibble(\n  variable=names(tel),\n  description=c(\"Unique Participant Identifier\", \"Group denoting whether the participant studied the material twice (StudyStudy), or studied it once then did a test (StudyTest)\",\"Time of recall test ('min' = Immediate, 'week' = One week later)\",\"Word being recalled (175 different test words)\",\"Whether or not the word was correctly recalled\",\"Time to recall word (milliseconds)\")\n) |>\n    kableExtra::kbl() |>\n    kableExtra::kable_styling(full_width = FALSE)\n```\n\n:::\n\n\n\n`r qbegin(qcounter())`\nLoad and plot the data. Does it look like the effect was replicated?  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nload(url(\"https://uoepsy.github.io/data/testenhancedlearning.RData\"))\n\nggplot(tel, aes(Delay, Correct, col=Group)) + \n  stat_summary(fun.data=mean_se, geom=\"pointrange\")+\n  theme_light()\n```\n\nThat looks like test-enhanced learning to me!  \n\n\n`r solend()`\n\n`r qbegin(qcounter())`\n\nTest the critical hypothesis using a mixed-effects model.  \n\nFit the maximal random effect structure supported by the experimental design. Simplify the random effect structure until you reach a model that converges.  \n\nSome of the models you attempt here might take time to fit. This is normal, and you can cancel the estimation at any time by pressing the escape key.  \nI suggest you write your initial model, set it running, and then look at the first solution to see if it converged for me. \nAssume that if it didn't work for me, it also won't work for you. In which case cancel it and write your next model (then look at the next solution as that model is fitting, and so on.. )  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nWhat we're aiming to do here is to follow [Barr et al.'s](https://doi.org/10.1016/j.jml.2012.11.001) advice of defining our maximal model and then removing only the terms to allow a non-singular fit.  \n\n+ What kind of model will you use? What is our outcome? is it binary, or continuous? \n+ We can expect variability across subjects (some people are better at learning than others) and across items (some of the recall items are harder than others). How should this be represented in the random effects?\n\n:::\n\n`r qend()` \n`r solbegin(label=\"1 - maximal model\", slabel=F,show=T, toggle=params$TOGGLE)`\n\n```{r}\n#| echo: false\n# save(mod1,mod2,mod3,mod4,file=\"data/telmodels.Rdata\")\nload(\"data/telmodels.Rdata\")\n```\n\n\nThis one took my computer about 6 minutes.  \n```{r}\n#| eval: false\nmod1 <- glmer(Correct ~ Delay*Group +\n             (1 + Delay | Subject_ID) +\n             (1 + Delay * Group | Test_word),\n             family=binomial, data=tel)\n```\n<p style=\"color:red;font-size:.8em\">\nWarning message:<br>\nIn checkConv(attr(opt, \"derivs\"), opt\\$par, ctrl = control\\$checkConv,  :<br>\n  Model failed to converge with max|grad| = 0.0184773 (tol = 0.002, component 1)\n</p>\n\n```{r}\nVarCorr(mod1)\n```\n\n`r solend()`\n`r solbegin(label=\"2 - Removing Group|Subject_ID\", slabel=F,show=T, toggle=params$TOGGLE)`\n\nlets remove the interaction in the by-word random effects.  \nThis one took about 5 minutes...\n```{r}\n#| eval: false\nmod2 <- glmer(Correct ~ Delay*Group +\n             (1 + Delay | Subject_ID) +\n             (1 + Delay + Group | Test_word),\n             family=binomial, data=tel)\n```\n<p style=\"color:red;font-size:.8em\">\nWarning message:<br>\nIn checkConv(attr(opt, \"derivs\"), opt\\$par, ctrl = control\\$checkConv,  :<br>\n  Model failed to converge with max|grad| = 0.00887744 (tol = 0.002, component 1)\n</p>\n\n```{r}\nVarCorr(mod2)\n```\n\n`r solend()`\n`r solbegin(label=\"3 - Removing Group|Test_word\", slabel=F,show=T, toggle=params$TOGGLE)`\n\nWe still have a singular fit here. Thinking about the study, if we are going to remove __one__ of the by-testword random effects (`Delay` or `Group`), which one do we consider to be more theoretically justified? Is the effect of Delay likely to vary by test-words? More so than the effect of group is likely to vary by test-words? Quite possibly - there's no obvious reason for _certain_ words to be more memorable for people in one group vs another. But there is reason for words to vary in the effect that delay of one week has - how familiar a word is will likely influence the amount to which a week's delay has on recall.   \n\nLet's remove the by-testword random effect of group. \n```{r}\n#| eval: false\nmod3 <- glmer(Correct ~ Delay*Group +\n             (1 + Delay | Subject_ID) +\n             (1 + Delay | Test_word),\n             family=binomial, data=tel)\n```\n\nThis one converges! But we still have a correlation of -1. Why did we not get a warning message?  \n```{r}\nVarCorr(mod3)\n```\n\n```{r}\nisSingular(mod3)\n```\n\n`r solend()`\n`r solbegin(label=\"4 - Removing Delay|Test_word\", slabel=F,show=T, toggle=params$TOGGLE)`\n\n```{r}\n#| eval: false\nmod4 <- glmer(Correct ~ Delay*Group +\n             (1 + Delay | Subject_ID) +\n             (1 | Test_word),\n             family=binomial, data=tel)\n```\n```{r}\nisSingular(mod4)\n```\n\n\n\n\n\n`r solend()`\n`r solbegin(label=\"5 - Comparisons\", slabel=F,show=T, toggle=params$TOGGLE)`\n\nHere are the fixed effects from each model: \n```{r}\n#| echo: false\nbind_rows(\n broom.mixed::tidy(mod1) |> filter(effect==\"fixed\") |> mutate(mod=\"mod1\"), \n broom.mixed::tidy(mod2) |> filter(effect==\"fixed\") |> mutate(mod=\"mod2\"), \n broom.mixed::tidy(mod3) |> filter(effect==\"fixed\") |> mutate(mod=\"mod3\"), \n broom.mixed::tidy(mod4) |> filter(effect==\"fixed\") |> mutate(mod=\"mod4\")\n) |> select(mod,term,estimate) |> pivot_wider(values_from=estimate,names_from=mod)\n```\n\nAnd here are the standard errors of fixed effects for each model:  \n```{r}\n#| echo: false\nbind_rows(\n broom.mixed::tidy(mod1) |> filter(effect==\"fixed\") |> mutate(mod=\"mod1\"), \n broom.mixed::tidy(mod2) |> filter(effect==\"fixed\") |> mutate(mod=\"mod2\"), \n broom.mixed::tidy(mod3) |> filter(effect==\"fixed\") |> mutate(mod=\"mod3\"), \n broom.mixed::tidy(mod4) |> filter(effect==\"fixed\") |> mutate(mod=\"mod4\")\n) |> select(mod,term,std.error) |> pivot_wider(values_from=std.error,names_from=mod)\n```\n\n\n`r solend()` \n\n\n\n`r qbegin(qcounter())`\nCreate a plot of the fixed effects.  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nlibrary(effects)\neffplot <- effect(\"Delay:Group\", mod4) |>\n  as.data.frame()\n\nggplot(effplot, aes(Delay, fit, color=Group)) + \n  geom_pointrange(aes(ymax=upper, ymin=lower), \n                  position=position_dodge(width = 0.2))+\n  theme_classic() # just for a change :)\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nWhat should we do with this information? How can we apply test-enhanced learning to learning R and statistics?\n`r qend()` \n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\nYou'll get the benefits of test-enhanced learning if you try yourself before looking at the solutions! If you don't test yourself, you're more likely to forget it in the long run. \n`r solend()` \n\n<br><br>\n\n# Vocab Development\n\n\n\n\n:::frame\n__Data: pvt_bilingual.csv__ \n\n```{r}\n#| echo: false\npvt <- read_csv(\"https://uoepsy.github.io/data/pvt_bilingual.csv\")\npvtsc = pvt |> count(school,child,isBilingual)\n```\n\n`r nrow(pvtsc)` children from `r length(unique(pvt$school))` schools were included in the study. Children were assessed on a yearly basis for 7 years throughout primary school on a measure of vocabulary administered in English, the Picture Vocab Test (PVT). `r sum(pvtsc$isBilingual==0)` were monolingual English speakers, and `r sum(pvtsc$isBilingual==1)` were bilingual (english + another language). \n\nPrevious research conducted on monolingual children has suggested that that scores on the PVT increase steadily up until the age of approximately 7 or 8 at which point they begin to plateau. The aim of the present study is to investigate differences in the development of vocabulary between monolingual and bilingual children.  \n\nThe data are available at [https://uoepsy.github.io/data/pvt_bilingual.csv](https://uoepsy.github.io/data/pvt_bilingual.csv).  \n\n```{r}\n#| echo: false\n#| label: tbl-pvtdict\n#| tbl-cap: \"Data Dictionary: pvt_bilingual.csv\"\ntibble(variable = names(pvt),\n       description = c(\n         \"Child's name\",\n         \"School Identifier\",\n         \"Binary variable indicating whether the child is monolingual (0) or bilingual (1)\",\n         \"Age (years)\",\n         \"Score on the Picture Vocab Test (PVT). Scores range 0 to 60\")\n) |>\n    kableExtra::kbl() |>\n    kableExtra::kable_styling(full_width = FALSE)\n```\n\n:::\n\n`r qbegin(qcounter())`\nLet's start by thinking about our clustering - we'd like to know how much of the variance in PVT scores is due to the clustering of data within children, who are themselves within schools. One easy way of assessing this is to fit an _intercept only_ model, which has the appropriate random effect structure.  \n\nUsing the model below, calculate the proportion of variance attributable to the clustering of data within children within schools.  \n\n```{r}\npvt_null <- lmer(PVT ~ 1 +  (1 | school/child), data = pvt)\n```\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\nthe random intercept variances are the building blocks here. There are no predictors in this model, so all the variance in the outcome gets attributed to either school-level nesting, child-level nesting, or else is lumped into the residual.   \n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\n# pvt <- read_csv(\"../../data/bntmono.csv\")\npvt_null <- lmer(PVT ~ 1 +  (1 | school/child), data = pvt)\nsummary(pvt_null)\n```\n\n```{r}\n#| echo: false\nvcres = VarCorr(pvt_null) |> as.data.frame()\nvcres = round(vcres$vcov,2)\n```\n\n\nAs we can see from `summary(bnt_null)`, the random intercept variances are `r vcres[1]` for child-level, `r vcres[2]` for school-level, and the residual variance is `r vcres[3]`.  \n\nSo child level differences account for $\\frac{`r vcres[1]`}{`r paste0(vcres,collapse=\" + \")`} = `r round(vcres[1]/sum(vcres),2)`$ of the variance in PVT scores, and child & school differences together account for $\\frac{`r paste0(vcres[1:2],collapse=\" + \")`}{`r paste0(vcres,collapse=\" + \")`} = `r round(sum(vcres[1:2])/sum(vcres),2)`$ of the variance.  \n\n\n`r solend()`\n\n`r qbegin(paste0(qcounter(), \" - Less Guided\"))`\nConduct an analysis to estimate the differences in trajectories of vocabulary development between children attending bilingual schools vs those attending monolingual schools.  \n\nWrite up your results.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\n- make things factors\n- always plot your data!\n- \n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nggplot(pvt, aes(x=age,y=PVT,col=factor(isBilingual)))+\n  stat_summary(geom=\"pointrange\")+\n  stat_summary(geom=\"line\")\n```\n\n\n\n```{r}\npvt <- pvt |> mutate(\n  poly1 = poly(age, 3)[,1],\n  poly2 = poly(age, 3)[,2],\n  poly3 = poly(age, 3)[,3],\n  isBilingual = factor(isBilingual)\n)\n```\n\n```{r}\n#| eval: false\nmod1 <- lmer(PVT ~ 1 + (poly1 + poly2 + poly3) * isBilingual + \n       (1 + (poly1 + poly2 + poly3)*isBilingual | school) + \n       (1 + (poly1 + poly2 + poly3) | school:child),\n     data = pvt)\n\nmod2 <- lmer(PVT ~ 1 + (poly1 + poly2 + poly3) * isBilingual + \n       (1 + isBilingual * (poly1 + poly2) + poly3 | school) +\n       (1 + (poly1 + poly2 + poly3) | school:child),\n     data = pvt)\n\nmod3 <- lmer(PVT ~ 1 + (poly1 + poly2 + poly3) * isBilingual + \n       (1 + isBilingual * (poly1 + poly2) | school) +\n       (1 + (poly1 + poly2 + poly3) | school:child),\n     data = pvt)\n\nmod4 <- lmer(PVT ~ 1 + (poly1 + poly2 + poly3) * isBilingual + \n       (1 + isBilingual * (poly1) + poly2 | school) +\n       (1 + (poly1 + poly2 + poly3) | school:child),\n     data = pvt)\n\nmod5 <- lmer(PVT ~ 1 + (poly1 + poly2 + poly3) * isBilingual + \n       (1 + isBilingual * (poly1) | school) +\n       (1 + (poly1 + poly2 + poly3) | school:child),\n     data = pvt)\n\nmod6 <- lmer(PVT ~ 1 + (poly1 + poly2 + poly3) * isBilingual + \n       (1 + isBilingual + poly1 | school) +\n       (1 + (poly1 + poly2 + poly3) | school:child),\n     data = pvt)\n```\n\n\n```{r}\nmod7 <- lmer(PVT ~ 1 + (poly1 + poly2 + poly3) * isBilingual + \n       (1 + poly1 | school) +\n       (1 + (poly1 + poly2 + poly3) | school:child),\n     data = pvt)\n```\n\n\n```{r}\nlibrary(broom.mixed)\naugment(mod7) |> \n  mutate(\n    poly1 = round(poly1, 3) # because of rounding errors make plot weird\n  ) |>\n  ggplot(aes(x=poly1,col=isBilingual))+\n  stat_summary(geom=\"pointrange\",aes(y=PVT))+\n  stat_summary(geom=\"line\", aes(y=.fitted))\n```\n\n\n\n\n\n`r solend()`\n\n\n\n\n\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"include-in-header":["assets/toggling.html"],"number-sections":false,"output-file":"04exBURKS.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.340","toc_float":true,"link-citations":true,"theme":["united","assets/style-labs.scss"],"title":"Week 4 Exercises: Nested and Crossed","params":{"SHOW_SOLS":true,"TOGGLE":true},"editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}