{"title":"Week 1 Exercises: Intro to MLM","markdown":{"yaml":{"title":"Week 1 Exercises: Intro to MLM","params":{"SHOW_SOLS":true,"TOGGLE":true},"editor_options":{"chunk_output_type":"console"}},"headingText":"New Packages!","containsRefs":false,"markdown":"\n\n```{r}\n#| label: setup\n#| include: false\nsource('assets/setup.R')\nlibrary(xaringanExtra)\nlibrary(tidyverse)\nlibrary(lme4)\nlibrary(patchwork)\nlibrary(ggdist)\nxaringanExtra::use_panelset()\nqcounter <- function(){\n  if(!exists(\"qcounter_i\")){\n    qcounter_i <<- 1\n  }else{\n    qcounter_i <<- qcounter_i + 1\n  }\n  qcounter_i\n}\n```\n\n\n\n\n::: {.callout-note collapse=\"false\"}\n\nThese are the main packages we're going to use in this block. It might make sense to install them now *if you do not have them already*\n\n+ __tidyverse__ : for organising data  \n+ __lme4__ : for fitting generalised linear mixed effects models\n+ __broom.mixed__ : tidying methods for mixed models\n+ __effects__ : for tabulating and graphing effects in linear models\n+ __lmerTest__: for quick p-values from mixed models\n+ __parameters__: various inferential methods for mixed models\n\n:::\n\n\n# Getting to grips with MLM\n\n:::lo\nThese first set of exercises are not \"how to do analyses with multilevel models\" - they are designed to get you thinking, and help with an understanding of how these models work.  \n:::\n\n\n:::frame\n__Data: New Toys!__  \n  \nRecall the example from last semesters' USMR course, where the lectures explored linear regression with a toy dataset of how practice influences the reading age of toy characters (see [USMR Week 7 Lecture](https://uoepsy.github.io/usmr/2324/lectures/lecture06.html#/learning-to-read-1){target=\"_blank\"}). We're going to now broaden our scope to the investigation of how practice affects reading age for **all** toys (not just Martin's Playmobil characters).  \n\nYou can find a dataset at [https://uoepsy.github.io/data/toy2.csv](https://uoepsy.github.io/data/toy2.csv){target=\"_blank\"} containing information on 129 different toy characters that come from a selection of different families/types of toy. You can see the variables in the table below^[Image sources:<br>http://tophatsasquatch.com/2012-tmnt-classics-action-figures/<br>https://www.dezeen.com/2016/02/01/barbie-dolls-fashionista-collection-mattel-new-body-types/<br>https://www.wish.com/product/5da9bc544ab36314cfa7f70c<br>https://www.worldwideshoppingmall.co.uk/toys/jumbo-farm-animals.asp<br>https://www.overstock.com/Sports-Toys/NJ-Croce-Scooby-Doo-5pc.-Bendable-Figure-Set-with-Scooby-Doo-Shaggy-Daphne-Velma-and-Fred/28534567/product.html<br>https://tvtropes.org/pmwiki/pmwiki.php/Toys/Furby<br>https://www.fun.com/toy-story-4-figure-4-pack.html<br>https://www.johnlewis.com/lego-minifigures-71027-series-20-pack/p5079461].  \n<br>  \n\n:::: {.columns}\n::: {.column width=\"45%\"}\n```{r echo=FALSE, out.width=\"300px\",fig.align=\"center\"}\nknitr::include_graphics(\"images/toys.png\")\n```\n:::\n::: {.column width=\"10%\"}\n:::\n::: {.column width=\"45%\"}\n```{r echo=FALSE, message=FALSE,warning=FALSE}\ntoy2 <- read_csv(\"https://uoepsy.github.io/data/toy2.csv\")\nlibrary(gt)\ntibble(variable=names(toy2),\n       description=c(\"Type of Toy\",\"Year Released\",\"Character\",\"Hours of practice per week\",\"Reading Age\")\n) %>% gt()\n\n```\n:::\n::::\n\n:::\n\n\n`r qbegin(qcounter())`\nBelow is some code that fits a model of \"reading age\" (`R_AGE`) predicted by hours of practice (`hrs_week`). Line 2 then gets the 'fitted' values from the model and adds them as a new column to the dataset, called `pred_lm`. The fitted values are what the model predicts for every individual observation (every individual toy in our dataset).  \n\nLines 4-7 then plot the data, split up by each type of toy, and adds lines showing the model fitted values.  \n\nRun the code and check that you get a plot. What do you notice about the lines?  \n\n```{r}\n#| eval: false\n#| code-line-numbers: true\nlm_mod <- lm(R_AGE ~ hrs_week, data = toy2)\ntoy2$pred_lm <- predict(lm_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_lm), col = \"red\")\n```\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nWe should get something like this:  \n```{r}\nlm_mod <- lm(R_AGE ~ hrs_week, data = toy2)\ntoy2$pred_lm <- predict(lm_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_lm), col = \"red\")\n```\n\nNote that the lines are exactly the same for each type of toy. This makes total sense, because the model (which is where we've got the lines from) completely _ignores_ the `toy_type` variable!  \n\n`r solend()`\n\n`r qbegin(qcounter())`\n\nBelow are 3 more code chunks that all 1) fit a model, then 2) add the fitted values of that model to the plot.  \n\nThe first model is a 'no-pooling' approach, where we use tools learned in USMR and simply add in `toy_type` as a predictor in the model to estimate all the differences between types of toys.\n\nThe second and third are multilevel models. The second fits random intercepts by-toytype, and the third fits random intercepts and slopes of `hrs_week`  \n\nCopy each chunk and run through the code. Pay attention to how the lines differ.  \n\n```{r}\n#| eval: false\n#| code-fold: true\nfe_mod <- lm(R_AGE ~ toy_type + hrs_week, data = toy2)\ntoy2$pred_fe <- predict(fe_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_fe), col = \"blue\")\n```\n\n```{r}\n#| eval: false\n#| code-fold: true\nlibrary(lme4)\nri_mod <- lmer(R_AGE ~ hrs_week + (1 | toy_type), data = toy2)\ntoy2$pred_ri <- predict(ri_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_ri), col = \"green\")\n```\n\n```{r}\n#| eval: false\n#| code-fold: true\nrs_mod <- lmer(R_AGE ~ hrs_week + (1 + hrs_week | toy_type), data = toy2)\ntoy2$pred_rs <- predict(rs_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_rs), col = \"orange\")\n```\n\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n\nThe first model has an adjustment for each toy-type (we can see this in the coefficients if we want). What this means is that the line for each type of toy is shifted up or down. We can see that the lines are now shifted up for things like \"Scooby Doo\" and \"G.I.Joe\", and down for \"transformers\" and \"farm animals\":  \n```{r}\nfe_mod <- lm(R_AGE ~ toy_type + hrs_week, data = toy2)\ntoy2$pred_fe <- predict(fe_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_fe), col = \"blue\")\n```\n\n\nThis next one _looks_ very similar to the previous one, but it is conceptually doing something a bit different. Rather than separating out and estimating differences between all the toy-types, we are modelling _a distribution_ of deviations for each type from some average.  \n\n\n```{r}\nri_mod <- lmer(R_AGE ~ hrs_week + (1 | toy_type), data = toy2)\ntoy2$pred_ri <- predict(ri_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_ri), col = \"green\")\n```\n\nFinally, we can add in the random slopes of `hrs_week`. In this model, we are not only allowing toy-types to vary in their average reading age (i.e. shifting lines up and down), but we are also allowing them to vary in the association between hrs_week and reading age (letting the lines have different slopes). Some types of toy (Scooby Doo, Sock Puppets, Stretch Armstrong) have fairly positive slopes, and some have a flatter association (e.g, SuperZings etc).  \n\n```{r}\nrs_mod <- lmer(R_AGE ~ hrs_week + (1 + hrs_week | toy_type), data = toy2)\ntoy2$pred_rs <- predict(rs_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_rs), col = \"orange\")\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\n\nFrom the previous questions you should have a model called `ri_mod`.  \n\nBelow is a plot of the fitted values from that model. Rather than having a separate facet for each type of toy as we did above, I have put them all on one plot. The thick black line is the average intercept and slope of the toy-type lines. \n\nIdentify the parts of the plot that correspond to A1-4 in the summary output of the model below  \n\n::::{.columns}\n:::{.column width=\"50%\"}\n```{r}\n#| echo: false\n#| out-width: \"100%\"\nknitr::include_graphics(\"images/match_summ1.png\")\n```\n:::\n:::{.column width=\"50%\"}\n```{r}\n#| echo: false\n#| out-width: \"100%\"\nbroom.mixed::augment(ri_mod) |>\n  ggplot(aes(x=hrs_week, col=toy_type))+\n  geom_point(aes(y=R_AGE),alpha=.5) + # observations\n  geom_line(aes(y=.fitted)) + # predictions \n  geom_abline(intercept = fixef(ri_mod)[1], \n              slope = fixef(ri_mod)[2], lwd=1)  # fixed effect line\n```\n:::\n::::\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nChoose from these options:\n\n+ where the black line cuts the y axis (at x=0)  \n+ the slope of the black line  \n+ the standard deviation of the distances from all the individual datapoints (toys) to their respective toy-type lines  \n+ the standard deviation of the distances from all the toy-type lines to the black line  \n\n:::\n\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n::::{.columns}\n:::{.column width=\"50%\"}\n```{r}\n#| echo: false\n#| out-width: \"100%\"\nknitr::include_graphics(\"images/match_summ1.png\")\n```\n:::\n:::{.column width=\"50%\"}\n```{r}\n#| echo: false\n#| out-width: \"100%\"\nbroom.mixed::augment(ri_mod) |>\n  ggplot(aes(x=hrs_week, col=toy_type))+\n  geom_point(aes(y=R_AGE),alpha=.5) + # observations\n  geom_line(aes(y=.fitted)) + # predictions \n  geom_abline(intercept = fixef(ri_mod)[1], \n              slope = fixef(ri_mod)[2], lwd=1)  # fixed effect line\n```\n:::\n::::\n\n+ **A1** = the standard deviation of the distances from all the toy-type lines to the black line  \n+ **A2** = the standard deviation of the distances from all the individual datapoints (toys) to their respective toy-type lines  \n+ **A3** = where the black line cuts the y axis  \n+ **A4** = the slope of the black line  \n\n`r solend()`\n\n\n`r qbegin(\"Optional Extra\", qlabel=FALSE)`\n\nBelow is the model equation for the `ri_mod` model.  \n\nIdentify the part of the equation that represents each of A1-4.  \n\n::::{.columns}\n:::{.column width=\"50%\"}\n```{r}\n#| echo: false\n#| out-width: \"100%\"\nknitr::include_graphics(\"images/match_summ1.png\")\n```\n:::\n\n:::{.column width=\"50%\"}\n<div style=\"font-size: .7em\">\n\n\\begin{align}\n\\text{For Toy }j\\text{ of Type }i & \\\\\n\\text{Level 1 (Toy):}& \\\\\n\\text{R\\_AGE}_{ij} &= b_{0i} + b_1 \\cdot \\text{hrs\\_week}_{ij} + \\epsilon_{ij} \\\\\n\\text{Level 2 (Type):}& \\\\\nb_{0i} &= \\gamma_{00} + \\zeta_{0i} \\\\\n\\text{Where:}& \\\\\n\\zeta_{0i} &\\sim N(0,\\sigma_{0}) \\\\\n\\varepsilon &\\sim N(0,\\sigma_{e}) \\\\\n\\end{align}\n\n</div>\n\n:::\n::::\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nChoose from:\n\n+ $\\sigma_{\\varepsilon}$  \n+ $b_{1}$  \n+ $\\sigma_{0}$   \n+ $\\gamma_{00}$  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n+ **A1 =** $\\sigma_{0}$   \n+ **A2 =** $\\sigma_{\\varepsilon}$  \n+ **A3 =** $\\gamma_{00}$  \n+ **A4 =** $b_{1}$  \n\n\n`r solend()`\n\n<br>\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Audio Interference in Executive Functioning (Repeated Measures)\n\n:::lo\nThis next set are closer to conducting a real study. We have some data and a research question (below). The exercises will walk you through describing the data, then prompt you to think about how we might fit an appropriate model to address the research question, and finally task you with having a go at writing up what you've done.  \n:::\n\n\n```{r}\n#| include: false\nset.seed(5)\nn_groups = 30\nN = n_groups*3*5\ng = rep(1:n_groups, e = N/n_groups)\n\nw = rep(rep(letters[1:3],5),n_groups)\nw1 = model.matrix(lm(rnorm(N)~w))[,2]\nw2 = model.matrix(lm(rnorm(N)~w))[,3]\n\nb = rep(0:1, e = N/2)\n\nre0 = rnorm(n_groups, sd = 2)[g]\nre_w1  = rnorm(n_groups, sd = 1)[g]\nre_w2  = rnorm(n_groups, sd = 1)[g]\n\nlp = (0 + re0) + \n  (3)*b + \n  (0 + re_w1)*w1 +\n  (-2 + re_w2)*w2 + \n  (2)*b*w1 +\n  (-1)*b*w2\n  \ny = rnorm(N, mean = lp, sd = 1.5) # create a continuous target variable\n\ndf <- data.frame(w, g=factor(g),b, y)\nhead(df)\nwith(df,boxplot(y~interaction(w,b)))\n\nlibrary(tidyverse)\ndf %>% transmute(\n  PID = paste0(\"PPT_\",formatC(g,width=2,flag=0)),\n  audio = fct_recode(factor(w),\n                     no_audio = \"a\",\n                     white_noise = \"b\",\n                     music = \"c\"),\n  headphones = fct_recode(factor(b),\n                          speakers = \"0\",\n                          anc_headphones = \"1\"),\n  SDMT = pmax(0,round(35 + scale(y)[,1]*12))\n) %>% arrange(PID,audio,headphones) -> ef_music\n\nef_music <- ef_music %>% group_by(PID) %>%\n  mutate(trial_n = paste0(\"Trial_\",formatC(sample(1:15),width=2,flag=0))) %>%\n  arrange(PID,trial_n) %>% ungroup()\n\nefrep <- slice_sample(ef_music, prop = .8) %>% select(PID,trial_n,audio,headphones,SDMT)\n\n# write_csv(efrep |> select(-trial_n), file=\"../../data/efsdmt.csv\")\n```\n\n:::frame\n__Data: Audio interference in executive functioning__  \n\nThis data is from a simulated study that aims to investigate the following research question: \n\n> How do different types of audio interfere with executive functioning, and does this interference differ depending upon whether or not noise-cancelling headphones are used? \n\n`r length(unique(efrep$PID))` healthy volunteers each completed the Symbol Digit Modalities Test (SDMT) - a commonly used test to assess processing speed and motor speed - a total of 15 times. During the tests, participants listened to either no audio (5 tests), white noise (5 tests) or classical music (5 tests). Half the participants listened via active-noise-cancelling headphones, and the other half listened via speakers in the room. Unfortunately, lots of the tests were not administered correctly, and so not every participant has the full 15 trials worth of data.  \n\nThe data is available at [https://uoepsy.github.io/data/lmm_ef_sdmt.csv](https://uoepsy.github.io/data/lmm_ef_sdmt.csv).  \n\n```{r}\n#| echo: false\nefrep <- read_csv(\"https://uoepsy.github.io/data/lmm_ef_sdmt.csv\")\ntibble(variable=names(efrep),\n       description = c(\n         \"Participant ID\",\n         \"Audio heard during the test ('no_audio', 'white_noise','music')\",\n         \"Whether the participant listened via speakers (S) in the room or via noise cancelling headphones (H)\",\n         \"Symbol Digit Modalities Test (SDMT) score\")\n) %>% gt::gt()\n```\n\n:::\n\n`r qbegin(qcounter())`\nHow many participants are there in the data?   \nHow many have complete data (15 trials)?  \nWhat is the average number of trials that participants completed? What is the minimum?   \nDoes every participant have _some_ data for each type of audio?  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nFunctions like `table()` and `count()` will likely be useful here. \n:::\n\n\n`r qend()`\n`r solbegin(label=\"1 - read in the data \", slabel=F,show=T, toggle=params$TOGGLE)`\n```{r}\nefdat <- read_csv(\"https://uoepsy.github.io/data/lmm_ef_sdmt.csv\")\nhead(efdat)\n```\n`r solend()`\n`r solbegin(label=\"2 - how many ppts?\", slabel=F,show=T, toggle=params$TOGGLE)`\nFor a quick \"how many?\", functions like `n_distinct()` can be handy:  \n```{r}\nn_distinct(efdat$PID)\n```\n\nWhich is essentially the same as asking: \n```{r}\nunique(efdat$PID) |> length()\n```\n\n\n`r solend()`\n`r solbegin(label=\"3 - how many observations per ppt?\", slabel=F,show=T, toggle=params$TOGGLE)`\nHere are the counts of trials for each participant. \n```{r}\n#| eval: false\nefdat |> \n  count(PID)\n```\n```{r}\n#| echo: false\nefdat |> \n  count(PID) |>\n  print(n=5)\n```\n\nWe can pass that to something like `summary()` to get a quick descriptive of the `n` column, and so we can see that no participant completed all 15 trials (max is 14). Everyone completed at least 10, and the median was 12. \n```{r}\nefdat |> \n  count(PID) |>\n  summary()\n```\n\nWe could also do this easily with things like:\n```{r}\ntable(efdat$PID) |> median()\n```\n\n`r solend()`\n`r solbegin(label=\"4 - how many observations for each audio type per ppt?\", slabel=F,show=T, toggle=params$TOGGLE)`\nFor this kind of thing I would typically default to using `table()` for smaller datasets, to see how many datapoints are in each combination of `PID` and `audio`:  \n```{r}\ntable(efdat$PID, efdat$audio)\n```\n\nFrom the above, we can see that everyone has data from $\\geq 2$ trials for a given audio type.  \n\n```{r}\ntable(efdat$PID, efdat$audio) |> min()\n```\n\n\n::: {.callout-tip collapse=\"true\"}\n#### a tidyverse way:\n\nWhen tables get too big, we can do the same thing with `count()`, but we need to make sure that we are working with factors, in order to summarise all possible combinations of groups (even empty ones)\n```{r}\nefdat |> \n  mutate(PID = factor(PID),\n         audio = factor(audio)) |>\n  # the .drop=FALSE means \"keep empty groups\"\n  count(PID,audio,.drop=FALSE) |> \n  summary()\n```\n\nThere are plenty of other ways (e.g., you could use combinations of `group_by()`, `summarise()`), so just pick one that makes sense to you.  \n\n:::\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\n\n> How do different types of audio interfere with executive functioning, and does this interference differ depending upon whether or not noise-cancelling headphones are used? \n\nConsider the following questions about the study:  \n  \n- What is our outcome of interest?  \n- What variables are we seeking to investigate in terms of their impact on the outcome?    \n- What are the units of observations?  \n- Are the observations clustered/grouped? In what way?  \n- What varies *within* these clusters?  \n- What varies *between* these clusters?  \n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n- What is our outcome of interest?  \n    + __SDMT scores__  \n- What variables are we seeking to investigate in terms of their impact on the outcome?  \n    + __audio type__ and the interaction __audio type $\\times$ wearing headphones__\n- What are the units of observations?  \n    + __individual trials__  \n- What are the groups/clusters?  \n    + __participants__  \n- What varies *within* these clusters?  \n    + __the type of audio__    \n- What varies *between* these clusters?  \n    + __whether they listen via headphones or speakers__  \n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nMake factors and set the reference levels of the `audio` and `headphones` variables to \"no audio\" and \"speakers\" respectively.    \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nCan't remember about setting factors and reference levels? Check back to USMR!  \n\n:::\n\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nefdat <- efdat |>\n  mutate(\n    audio = fct_relevel(factor(audio), \"no_audio\"),\n    headphones = fct_relevel(factor(headphones), \"S\")\n  )\n```\n\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nFit a multilevel model to address the aims of the study (copied below)\n\n> How do different types of audio interfere with executive functioning, and does this interference differ depending upon whether or not noise-cancelling headphones are used? \n \nSpecifying the model may feel like a lot, but try splitting it into three parts:  \n\n$$\n\\text{lmer(}\\overbrace{\\text{outcome }\\sim\\text{ fixed effects}}^1\\, + \\, (1 + \\underbrace{\\text{slopes}}_3\\, |\\, \\overbrace{\\text{grouping structure}}^2 )\n$$\n\n\n1. Just like the `lm()`s we have used in the past, think about what we want to _test_. This should provide the outcome and the structure of our fixed effects.  \n2. Think about how the observations are clustered/grouped. This should tell us how to specify the grouping structure in the random effects.  \n3. Think about which slopes (i.e. which terms in our fixed effects) could feasibly vary between the clusters. This provides you with what to put in as random slopes.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nMake sure to read about multilevel modesl and how to fit them in [Chapter 2: MLM #multilevel-models-in-r](https://uoepsy.github.io/lmm/02_lmm.html#multilevel-models-in-r){target=\"_blank\"}.  \n\n:::\n\n\n\n`r qend()`\n`r solbegin(label=\"1 - fixed effects\", slabel=F,show=T, toggle=params$TOGGLE)`\n\nThe question  \n&nbsp;&nbsp;&nbsp; \"*How do different types of audio interfere with executive functioning*\"   means we are interested in the effects of audio type (`audio`) on executive functioning (`SDMT` scores), so we will want:\n\n```\nlmer(SDMT ~ audio ...\n```\n\nHowever, the research aim also asks    \n&nbsp;&nbsp;&nbsp; \"*... and does this interference differ depending upon whether or not noise-cancelling headphones are used?*\"  \nwhich suggests that we are interested in the interaction `SDMT ~ audio * headphones`  \n\n```\nlmer(SDMT ~ audio * headphones + ...   \n```\n\n`r solend()`\n`r solbegin(label=\"2 - hierarchical data structure\", slabel=F,show=T, toggle=params$TOGGLE)`\n\nThere are lots of ways that our data is grouped.  \nWe have:  \n\n- 3 different groups of audio type (`r paste(unique(efdat$audio),collapse=\", \")`)\n- 2 groups of listening condition (`r paste(unique(efdat$headphones),collapse=\", \")`)\n- 30 groups of participants (\"PPT_01\", \"PPT_02\", \"PPT_03\", ...) \n\nThe effects of audio type and headphones are both things we actually want to _test_ - these variables are in our fixed effects. The levels of audio and headphones are not just a random sample from a wider population of levels - they're a specific set of things we want to compare SDMT scores between.  \n\nCompare this with the participants - we don't care about if there is a difference in SDMT scores between e.g., \"PPT_03\" and \"PPT_28\". The participants themselves are just a sample of people that we have taken from a wider population. This makes thinking of \"by-participant random effects\" a sensible approach - we model differences between participants as a normal distribution of deviations around some average:    \n\n```\nlmer(SDMT ~ audio * headphones + (1 + ... | PID)  \n```\n\nThe minimum that we can include is the random intercept. What `(1|PID)` specifies is that \"participants vary in their SDMT scores\". This makes sense - we would expect some participants to have higher executive functioning (and so will tend to score high on the SDMT), and others to have lower functioning (and so tend to score lower).  \n\n\n`r solend()`\n`r solbegin(label=\"3 - random slopes\", slabel=F,show=T, toggle=params$TOGGLE)`\n\nWe can also include a random by-participant effect of `audio`.  \n`audio|PID` specifies that the effect of audio type on SDMT varies by participant. This seems feasible - music might be very distracting (and interfere a lot with the test) for some participants, but have a negligible effect for others.  \n\n```\nlmer(SDMT ~ audio * headphones + \n              (1 + audio | PID), data = efdat)\n```\n\n\n::: {.callout-tip collapse=\"true\"}\n#### Why can't we have `(headphones|PID)`?  \n\nWhy can we fit `(1 + audio | PID)` but not `(1 + headphones | PID)`, or both `(1 + audio + headphones | PID)` or `(1 + audio * headphones | PID)`?  \n\nRemember that `y ~ ... + (x | g)` is saying \"the slope of y~x varies by g\".  \nSuch a sentence only makes sense if each \"the slope of y~x\" is defined for every (or most) groups.  \n\nFor the `headphones` predictor, every participant is _either_ in the \"S\" (speakers) condition _or_ the \"H\" (headphones) condition.  \nThis means that \"the effect of headphones on SDMT\" _doesn't exist_ for any single participant! This means it makes no sense to try and think of the effect as 'varying by participant'.  \n\nCompare this to the `audio` predictor, for the effect _does_ exist for a single given participant, therefore it is possible to think of it as being different for different participants (e.g. PPT_30's performance improves with white noise, but PPT_16's performance does not).  \n\nThe plots below may help to cement this idea:  \n\n```{r}\n#| echo: false\nlibrary(lattice)\nbwplot(SDMT~headphones|PID, data = efdat, scales=list(x=list(rot=90)))\n\nbwplot(SDMT~audio|PID, data = efdat, scales=list(x=list(rot=90)))\n```\n\n:::\n\n`r solend()`\n\n\n\n`r qbegin(qcounter())`\nWe now have a model, but we don't have any p-values or confidence intervals or anything - i.e. we have no inferential criteria on which to draw conclusions. There are a whole load of different methods available for drawing inferences from multilevel models, which means it can be a bit of a never-ending rabbit hole. For now, we'll just use the 'quick and easy' approach provided by the **lmerTest** package seen in the lectures.  \n\nUsing the **lmerTest** package, re-fit your model, and you should now get some p-values! \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nIf you use `library(lmerTest)` to load the package, then *every single* model you fit will show p-values calculated with the Satterthwaite method.  \nPersonally, I would rather this is not the case, so I often opt to fit specific models with these p-values without ever loading the package:  \n`modp <- lmerTest::lmer(y ~ 1 + x + ....`  \n\n:::\n\n::: {.callout-caution collapse=\"true\"}\n#### optional: a model comparison\n\nIf we want to go down the model comparison route, we just need to isolate the relevant part(s) of the model that we are interested in.  \n\nRemember, model comparison is sometimes a useful way of testing a _set_ of coefficients. For instance, in this example the interaction involves estimating _two_ terms: \n`audiomusic:headphonesH` and `audiowhite_noise:headphonesH`.  \n\nTo test the interaction as a whole, we can create a model without the interaction, and then compare it. The `SATmodcomp()` function from the __pbkrtest__ package provides a way of conducting an F test with the same Satterthwaite method of approximating the degrees of freedom:  \n  \n```{r}\nsdmt_mod <- lmer(SDMT ~ audio * headphones + \n              (1 + audio | PID), data = efdat)\nsdmt_res <- lmer(SDMT ~ audio + headphones + \n                   (1 + audio | PID), data = efdat)\nlibrary(pbkrtest)\nSATmodcomp(largeModel = sdmt_mod, smallModel = sdmt_res)\n```\n\n:::\n\n\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nsdmt_mod <- lmerTest::lmer(SDMT ~ audio * headphones + \n              (1 + audio | PID), data = efdat)\n\nsummary(sdmt_mod)\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\n\nWe've already seen in the example with the with the different types of toys (above) that we can visualise the fitted values (model predictions). But these were plotting all the cluster-specific values, and what we are really interested in are the estimates of (and uncertainty around) our *fixed effects* (i.e. estimates for clusters *on average*)  \n\nUsing tools like the __effects__ package can provide us with the values of the outcome across levels of a specific fixed predictor (holding other predictors at their mean).   \n\nThis should get you started:  \n```{r}\n#| eval: false\nlibrary(effects)\neffect(term = \"audio*headphones\", mod = sdmt_mod) |>\n  as.data.frame()\n```\n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nYou can see the effects package in [Chapter 2: MLM #visualising-models](https://uoepsy.github.io/lmm/02_lmm.html#visualising-models){target=\"_blank\"}. The logic is just the same as it was for USMR, it's just that the estimated effects are from an `lmer()` instead of an `lm()`/`glm()`.  \n\n:::\n\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nlibrary(effects)\neffect(term = \"audio*headphones\", mod = sdmt_mod) |>\n  as.data.frame() |>\n  ggplot(aes(x=audio,y=fit,\n             ymin=lower,ymax=upper,\n             col=headphones))+\n  geom_pointrange(size=1,lwd=1)\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nNow we have some p-values and a plot, try to create a short write-up of the analysis and results.   \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThink about the principles that have guided you during write-ups thus far. \n\nThe aim in writing a statistical report should be that a reader is able to more or less replicate your analyses **without** referring to your analysis code. Furthermore, it should be able for a reader to understand and replicate your work _even if they use something other than R_. This requires detailing all of the steps you took in conducting the analysis, but without simply referring to R code.   \n\n\n- Provide a description of the sample that is used in the analysis, and any steps that you took to get this sample (i.e. data cleaning/removal)\n- Describe the model/test and how it addresses the research question. What is the structure of the model, and how did you get to this model? *(You don't need a fancy model equation, you can describe in words!)*. \n- Present (visually and numerically) the key results of the coefficient tests or model comparisons, and explain what these mean in the context of the research question (this could be things like practical significance of the effect size, and the group-level variability in the effects). \n\n\n:::\n\n\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n:::imp\nNot a perfect write-up (there's not really any such thing!).  \n:::\n\n\n```{r}\n#| echo: false\nres = as.data.frame(parameters::model_parameters(sdmt_mod, ci_method=\"s\"))\nres[,c(2,3,5,6,7,8)] <- apply(res[,c(2,3,5,6,7,8)], 2, function(x) round(x, 2))\nres[,9] <- format.pval(res[,9],eps=.001,digits=2)\nres[,9][!grepl(\"<\",res[,9])] <- paste0(\"=\",res[,9][!grepl(\"<\",res[,9])])\n\nres2 = as.data.frame(VarCorr(sdmt_mod)) |> mutate(sdcor = round(sdcor,2))\n```\n\n:::int\nSDMT scores were modelled using linear mixed effects regression, with fixed effects of audio-type (no audio/white noise/music, treatment coded with no audio as the reference level), audio delivery (speakers vs ANC-headphones, treatment coded with speakers as the reference level) and their interaction. Participant-level random intercepts and random slopes of audio-type were also included. The inclusion of the interaction term between audio-type and audio-delivery was used to address the question of whether the interference of different audio on executive function depends on whether it is heard via noise-cancelling headphones. A model comparison was conducted between the full model and a restricted model that was identical to the full model with the exception that the interaction term was excluded. Models were fitted using the **lme4** package in R, and estimated with restricted estimation maximum likelihood (REML). Denominator degrees of freedom for all comparisons and tests were approximated using the Satterthwaite method.  \n\nInclusion of the interaction between headphones and audio-type was found to improve model fit ($F(2, 26.9) = 11.05, p < .001$), suggesting that the interference of different types of audio on executive functioning is dependent upon whether the audio is presented through ANC-headphones or through speakers.  \n\nParticipants not wearing headphones and presented with no audio scored on average `r res[1,2]` on the SDMT. For participants without headphones, listening to music via speakers was associated with lower scores compared to no audio ($b = `r res[2,2]`, t(`r res[2,8]`)=`r res[2,7]`, p `r res[2,9]`$), but there was no significant difference between white noise and no audio.   \n\nWith no audio playing, wearing ANC-headphones was associated with higher SDMT scores compared to those wearing no headphones ($b = `r res[4,2]`, t(`r res[4,8]`)=`r res[4,7]`, p `r res[4,9]`$).\nThe apparent detrimental effect of music on SDMT scores was not significantly different in the headphones condition compared to the no-headphones condition ($b = `r res[5,2]`, t(`r res[5,8]`)=`r res[5,7]`, p `r res[5,9]`$). Compared to those listening through speakers, white noise was associated with a greater increase in scores over no audio, when listening via ANC-heaphones ($b = `r res[6,2]`, t(`r res[6,8]`)=`r res[6,7]`, p `r res[6,9]`$).  \n\nThere was considerable variability in baseline (i.e. no-audio) SDMT scores across participants (SD = `r res2[1,5]`), with participants showing similar variability in the effects of music (SD = `r res2[2,5]`) and of white-noise (SD = `r res2[3,5]`). A weak negative correlation (`r res2[5,5]`) between participant-level intercepts and effects of white-noise indicated that people who score higher in the no-audio condition tended to be more negatively effect by white-noise. A similar weak negative correlation (`r res2[6,5]`) between music and white-noise effects suggests participants who were more positively affected by one type of audio tended to be more negatively affected by the other.  \n\nThese results suggest that music appears to interfere with executive functioning (lower SDMT scores) compared to listening to no audio, and this is not dependent upon whether is heard through headphones or speakers. When listening via speakers, white noise was not associated with differences in executive functioning compared to no audio, but this was different for those listening via headphones, in which white noise saw a greater increase in performance. Furthermore, there appear to be benefits for executive functioning from wearing ANC-headphones even when not-listening to audio, perhaps due to the noise cancellation. The pattern of findings are displayed in @fig-efplot.  \n\n\n```{r}\n#| label: fig-efplot\n#| fig-cap: \"Interaction between the type (no audio/white noise/music) and the delivery (speakers/ANC headphones) on executive functioning task (SDMT)\"\n#| echo: false\nplotfit <- effect(term = \"audio*headphones\", mod = sdmt_mod) |>\n  as.data.frame()\n\nggplot(efdat, aes(x=audio,y=SDMT,col=headphones))+\n  geom_jitter(height=0,width=.2,alpha=.3) +\n  geom_pointrange(data = plotfit, \n                  aes(y=fit,ymin=lower,ymax=upper),\n                  size=1,lwd=1) \n```\n\n```{r}\n#| echo: false\nsjPlot::tab_model(sdmt_mod,df.method=\"satterthwaite\",\n                  show.ci=F,show.stat=T,show.df=T)\n```\n\n\n:::\n`r solend()`\n\n<br>\n<div class=\"divider div-transparent div-dot\"></div>\n","srcMarkdownNoYaml":"\n\n```{r}\n#| label: setup\n#| include: false\nsource('assets/setup.R')\nlibrary(xaringanExtra)\nlibrary(tidyverse)\nlibrary(lme4)\nlibrary(patchwork)\nlibrary(ggdist)\nxaringanExtra::use_panelset()\nqcounter <- function(){\n  if(!exists(\"qcounter_i\")){\n    qcounter_i <<- 1\n  }else{\n    qcounter_i <<- qcounter_i + 1\n  }\n  qcounter_i\n}\n```\n\n\n\n\n::: {.callout-note collapse=\"false\"}\n#### New Packages!\n\nThese are the main packages we're going to use in this block. It might make sense to install them now *if you do not have them already*\n\n+ __tidyverse__ : for organising data  \n+ __lme4__ : for fitting generalised linear mixed effects models\n+ __broom.mixed__ : tidying methods for mixed models\n+ __effects__ : for tabulating and graphing effects in linear models\n+ __lmerTest__: for quick p-values from mixed models\n+ __parameters__: various inferential methods for mixed models\n\n:::\n\n\n# Getting to grips with MLM\n\n:::lo\nThese first set of exercises are not \"how to do analyses with multilevel models\" - they are designed to get you thinking, and help with an understanding of how these models work.  \n:::\n\n\n:::frame\n__Data: New Toys!__  \n  \nRecall the example from last semesters' USMR course, where the lectures explored linear regression with a toy dataset of how practice influences the reading age of toy characters (see [USMR Week 7 Lecture](https://uoepsy.github.io/usmr/2324/lectures/lecture06.html#/learning-to-read-1){target=\"_blank\"}). We're going to now broaden our scope to the investigation of how practice affects reading age for **all** toys (not just Martin's Playmobil characters).  \n\nYou can find a dataset at [https://uoepsy.github.io/data/toy2.csv](https://uoepsy.github.io/data/toy2.csv){target=\"_blank\"} containing information on 129 different toy characters that come from a selection of different families/types of toy. You can see the variables in the table below^[Image sources:<br>http://tophatsasquatch.com/2012-tmnt-classics-action-figures/<br>https://www.dezeen.com/2016/02/01/barbie-dolls-fashionista-collection-mattel-new-body-types/<br>https://www.wish.com/product/5da9bc544ab36314cfa7f70c<br>https://www.worldwideshoppingmall.co.uk/toys/jumbo-farm-animals.asp<br>https://www.overstock.com/Sports-Toys/NJ-Croce-Scooby-Doo-5pc.-Bendable-Figure-Set-with-Scooby-Doo-Shaggy-Daphne-Velma-and-Fred/28534567/product.html<br>https://tvtropes.org/pmwiki/pmwiki.php/Toys/Furby<br>https://www.fun.com/toy-story-4-figure-4-pack.html<br>https://www.johnlewis.com/lego-minifigures-71027-series-20-pack/p5079461].  \n<br>  \n\n:::: {.columns}\n::: {.column width=\"45%\"}\n```{r echo=FALSE, out.width=\"300px\",fig.align=\"center\"}\nknitr::include_graphics(\"images/toys.png\")\n```\n:::\n::: {.column width=\"10%\"}\n:::\n::: {.column width=\"45%\"}\n```{r echo=FALSE, message=FALSE,warning=FALSE}\ntoy2 <- read_csv(\"https://uoepsy.github.io/data/toy2.csv\")\nlibrary(gt)\ntibble(variable=names(toy2),\n       description=c(\"Type of Toy\",\"Year Released\",\"Character\",\"Hours of practice per week\",\"Reading Age\")\n) %>% gt()\n\n```\n:::\n::::\n\n:::\n\n\n`r qbegin(qcounter())`\nBelow is some code that fits a model of \"reading age\" (`R_AGE`) predicted by hours of practice (`hrs_week`). Line 2 then gets the 'fitted' values from the model and adds them as a new column to the dataset, called `pred_lm`. The fitted values are what the model predicts for every individual observation (every individual toy in our dataset).  \n\nLines 4-7 then plot the data, split up by each type of toy, and adds lines showing the model fitted values.  \n\nRun the code and check that you get a plot. What do you notice about the lines?  \n\n```{r}\n#| eval: false\n#| code-line-numbers: true\nlm_mod <- lm(R_AGE ~ hrs_week, data = toy2)\ntoy2$pred_lm <- predict(lm_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_lm), col = \"red\")\n```\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nWe should get something like this:  \n```{r}\nlm_mod <- lm(R_AGE ~ hrs_week, data = toy2)\ntoy2$pred_lm <- predict(lm_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_lm), col = \"red\")\n```\n\nNote that the lines are exactly the same for each type of toy. This makes total sense, because the model (which is where we've got the lines from) completely _ignores_ the `toy_type` variable!  \n\n`r solend()`\n\n`r qbegin(qcounter())`\n\nBelow are 3 more code chunks that all 1) fit a model, then 2) add the fitted values of that model to the plot.  \n\nThe first model is a 'no-pooling' approach, where we use tools learned in USMR and simply add in `toy_type` as a predictor in the model to estimate all the differences between types of toys.\n\nThe second and third are multilevel models. The second fits random intercepts by-toytype, and the third fits random intercepts and slopes of `hrs_week`  \n\nCopy each chunk and run through the code. Pay attention to how the lines differ.  \n\n```{r}\n#| eval: false\n#| code-fold: true\nfe_mod <- lm(R_AGE ~ toy_type + hrs_week, data = toy2)\ntoy2$pred_fe <- predict(fe_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_fe), col = \"blue\")\n```\n\n```{r}\n#| eval: false\n#| code-fold: true\nlibrary(lme4)\nri_mod <- lmer(R_AGE ~ hrs_week + (1 | toy_type), data = toy2)\ntoy2$pred_ri <- predict(ri_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_ri), col = \"green\")\n```\n\n```{r}\n#| eval: false\n#| code-fold: true\nrs_mod <- lmer(R_AGE ~ hrs_week + (1 + hrs_week | toy_type), data = toy2)\ntoy2$pred_rs <- predict(rs_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_rs), col = \"orange\")\n```\n\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n\nThe first model has an adjustment for each toy-type (we can see this in the coefficients if we want). What this means is that the line for each type of toy is shifted up or down. We can see that the lines are now shifted up for things like \"Scooby Doo\" and \"G.I.Joe\", and down for \"transformers\" and \"farm animals\":  \n```{r}\nfe_mod <- lm(R_AGE ~ toy_type + hrs_week, data = toy2)\ntoy2$pred_fe <- predict(fe_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_fe), col = \"blue\")\n```\n\n\nThis next one _looks_ very similar to the previous one, but it is conceptually doing something a bit different. Rather than separating out and estimating differences between all the toy-types, we are modelling _a distribution_ of deviations for each type from some average.  \n\n\n```{r}\nri_mod <- lmer(R_AGE ~ hrs_week + (1 | toy_type), data = toy2)\ntoy2$pred_ri <- predict(ri_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_ri), col = \"green\")\n```\n\nFinally, we can add in the random slopes of `hrs_week`. In this model, we are not only allowing toy-types to vary in their average reading age (i.e. shifting lines up and down), but we are also allowing them to vary in the association between hrs_week and reading age (letting the lines have different slopes). Some types of toy (Scooby Doo, Sock Puppets, Stretch Armstrong) have fairly positive slopes, and some have a flatter association (e.g, SuperZings etc).  \n\n```{r}\nrs_mod <- lmer(R_AGE ~ hrs_week + (1 + hrs_week | toy_type), data = toy2)\ntoy2$pred_rs <- predict(rs_mod)\n\nggplot(toy2, aes(x = hrs_week)) + \n  geom_point(aes(y = R_AGE), size=1, alpha=.3) +\n  facet_wrap(~toy_type) +\n  geom_line(aes(y=pred_rs), col = \"orange\")\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\n\nFrom the previous questions you should have a model called `ri_mod`.  \n\nBelow is a plot of the fitted values from that model. Rather than having a separate facet for each type of toy as we did above, I have put them all on one plot. The thick black line is the average intercept and slope of the toy-type lines. \n\nIdentify the parts of the plot that correspond to A1-4 in the summary output of the model below  \n\n::::{.columns}\n:::{.column width=\"50%\"}\n```{r}\n#| echo: false\n#| out-width: \"100%\"\nknitr::include_graphics(\"images/match_summ1.png\")\n```\n:::\n:::{.column width=\"50%\"}\n```{r}\n#| echo: false\n#| out-width: \"100%\"\nbroom.mixed::augment(ri_mod) |>\n  ggplot(aes(x=hrs_week, col=toy_type))+\n  geom_point(aes(y=R_AGE),alpha=.5) + # observations\n  geom_line(aes(y=.fitted)) + # predictions \n  geom_abline(intercept = fixef(ri_mod)[1], \n              slope = fixef(ri_mod)[2], lwd=1)  # fixed effect line\n```\n:::\n::::\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nChoose from these options:\n\n+ where the black line cuts the y axis (at x=0)  \n+ the slope of the black line  \n+ the standard deviation of the distances from all the individual datapoints (toys) to their respective toy-type lines  \n+ the standard deviation of the distances from all the toy-type lines to the black line  \n\n:::\n\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n::::{.columns}\n:::{.column width=\"50%\"}\n```{r}\n#| echo: false\n#| out-width: \"100%\"\nknitr::include_graphics(\"images/match_summ1.png\")\n```\n:::\n:::{.column width=\"50%\"}\n```{r}\n#| echo: false\n#| out-width: \"100%\"\nbroom.mixed::augment(ri_mod) |>\n  ggplot(aes(x=hrs_week, col=toy_type))+\n  geom_point(aes(y=R_AGE),alpha=.5) + # observations\n  geom_line(aes(y=.fitted)) + # predictions \n  geom_abline(intercept = fixef(ri_mod)[1], \n              slope = fixef(ri_mod)[2], lwd=1)  # fixed effect line\n```\n:::\n::::\n\n+ **A1** = the standard deviation of the distances from all the toy-type lines to the black line  \n+ **A2** = the standard deviation of the distances from all the individual datapoints (toys) to their respective toy-type lines  \n+ **A3** = where the black line cuts the y axis  \n+ **A4** = the slope of the black line  \n\n`r solend()`\n\n\n`r qbegin(\"Optional Extra\", qlabel=FALSE)`\n\nBelow is the model equation for the `ri_mod` model.  \n\nIdentify the part of the equation that represents each of A1-4.  \n\n::::{.columns}\n:::{.column width=\"50%\"}\n```{r}\n#| echo: false\n#| out-width: \"100%\"\nknitr::include_graphics(\"images/match_summ1.png\")\n```\n:::\n\n:::{.column width=\"50%\"}\n<div style=\"font-size: .7em\">\n\n\\begin{align}\n\\text{For Toy }j\\text{ of Type }i & \\\\\n\\text{Level 1 (Toy):}& \\\\\n\\text{R\\_AGE}_{ij} &= b_{0i} + b_1 \\cdot \\text{hrs\\_week}_{ij} + \\epsilon_{ij} \\\\\n\\text{Level 2 (Type):}& \\\\\nb_{0i} &= \\gamma_{00} + \\zeta_{0i} \\\\\n\\text{Where:}& \\\\\n\\zeta_{0i} &\\sim N(0,\\sigma_{0}) \\\\\n\\varepsilon &\\sim N(0,\\sigma_{e}) \\\\\n\\end{align}\n\n</div>\n\n:::\n::::\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nChoose from:\n\n+ $\\sigma_{\\varepsilon}$  \n+ $b_{1}$  \n+ $\\sigma_{0}$   \n+ $\\gamma_{00}$  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n+ **A1 =** $\\sigma_{0}$   \n+ **A2 =** $\\sigma_{\\varepsilon}$  \n+ **A3 =** $\\gamma_{00}$  \n+ **A4 =** $b_{1}$  \n\n\n`r solend()`\n\n<br>\n<div class=\"divider div-transparent div-dot\"></div>\n\n# Audio Interference in Executive Functioning (Repeated Measures)\n\n:::lo\nThis next set are closer to conducting a real study. We have some data and a research question (below). The exercises will walk you through describing the data, then prompt you to think about how we might fit an appropriate model to address the research question, and finally task you with having a go at writing up what you've done.  \n:::\n\n\n```{r}\n#| include: false\nset.seed(5)\nn_groups = 30\nN = n_groups*3*5\ng = rep(1:n_groups, e = N/n_groups)\n\nw = rep(rep(letters[1:3],5),n_groups)\nw1 = model.matrix(lm(rnorm(N)~w))[,2]\nw2 = model.matrix(lm(rnorm(N)~w))[,3]\n\nb = rep(0:1, e = N/2)\n\nre0 = rnorm(n_groups, sd = 2)[g]\nre_w1  = rnorm(n_groups, sd = 1)[g]\nre_w2  = rnorm(n_groups, sd = 1)[g]\n\nlp = (0 + re0) + \n  (3)*b + \n  (0 + re_w1)*w1 +\n  (-2 + re_w2)*w2 + \n  (2)*b*w1 +\n  (-1)*b*w2\n  \ny = rnorm(N, mean = lp, sd = 1.5) # create a continuous target variable\n\ndf <- data.frame(w, g=factor(g),b, y)\nhead(df)\nwith(df,boxplot(y~interaction(w,b)))\n\nlibrary(tidyverse)\ndf %>% transmute(\n  PID = paste0(\"PPT_\",formatC(g,width=2,flag=0)),\n  audio = fct_recode(factor(w),\n                     no_audio = \"a\",\n                     white_noise = \"b\",\n                     music = \"c\"),\n  headphones = fct_recode(factor(b),\n                          speakers = \"0\",\n                          anc_headphones = \"1\"),\n  SDMT = pmax(0,round(35 + scale(y)[,1]*12))\n) %>% arrange(PID,audio,headphones) -> ef_music\n\nef_music <- ef_music %>% group_by(PID) %>%\n  mutate(trial_n = paste0(\"Trial_\",formatC(sample(1:15),width=2,flag=0))) %>%\n  arrange(PID,trial_n) %>% ungroup()\n\nefrep <- slice_sample(ef_music, prop = .8) %>% select(PID,trial_n,audio,headphones,SDMT)\n\n# write_csv(efrep |> select(-trial_n), file=\"../../data/efsdmt.csv\")\n```\n\n:::frame\n__Data: Audio interference in executive functioning__  \n\nThis data is from a simulated study that aims to investigate the following research question: \n\n> How do different types of audio interfere with executive functioning, and does this interference differ depending upon whether or not noise-cancelling headphones are used? \n\n`r length(unique(efrep$PID))` healthy volunteers each completed the Symbol Digit Modalities Test (SDMT) - a commonly used test to assess processing speed and motor speed - a total of 15 times. During the tests, participants listened to either no audio (5 tests), white noise (5 tests) or classical music (5 tests). Half the participants listened via active-noise-cancelling headphones, and the other half listened via speakers in the room. Unfortunately, lots of the tests were not administered correctly, and so not every participant has the full 15 trials worth of data.  \n\nThe data is available at [https://uoepsy.github.io/data/lmm_ef_sdmt.csv](https://uoepsy.github.io/data/lmm_ef_sdmt.csv).  \n\n```{r}\n#| echo: false\nefrep <- read_csv(\"https://uoepsy.github.io/data/lmm_ef_sdmt.csv\")\ntibble(variable=names(efrep),\n       description = c(\n         \"Participant ID\",\n         \"Audio heard during the test ('no_audio', 'white_noise','music')\",\n         \"Whether the participant listened via speakers (S) in the room or via noise cancelling headphones (H)\",\n         \"Symbol Digit Modalities Test (SDMT) score\")\n) %>% gt::gt()\n```\n\n:::\n\n`r qbegin(qcounter())`\nHow many participants are there in the data?   \nHow many have complete data (15 trials)?  \nWhat is the average number of trials that participants completed? What is the minimum?   \nDoes every participant have _some_ data for each type of audio?  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nFunctions like `table()` and `count()` will likely be useful here. \n:::\n\n\n`r qend()`\n`r solbegin(label=\"1 - read in the data \", slabel=F,show=T, toggle=params$TOGGLE)`\n```{r}\nefdat <- read_csv(\"https://uoepsy.github.io/data/lmm_ef_sdmt.csv\")\nhead(efdat)\n```\n`r solend()`\n`r solbegin(label=\"2 - how many ppts?\", slabel=F,show=T, toggle=params$TOGGLE)`\nFor a quick \"how many?\", functions like `n_distinct()` can be handy:  \n```{r}\nn_distinct(efdat$PID)\n```\n\nWhich is essentially the same as asking: \n```{r}\nunique(efdat$PID) |> length()\n```\n\n\n`r solend()`\n`r solbegin(label=\"3 - how many observations per ppt?\", slabel=F,show=T, toggle=params$TOGGLE)`\nHere are the counts of trials for each participant. \n```{r}\n#| eval: false\nefdat |> \n  count(PID)\n```\n```{r}\n#| echo: false\nefdat |> \n  count(PID) |>\n  print(n=5)\n```\n\nWe can pass that to something like `summary()` to get a quick descriptive of the `n` column, and so we can see that no participant completed all 15 trials (max is 14). Everyone completed at least 10, and the median was 12. \n```{r}\nefdat |> \n  count(PID) |>\n  summary()\n```\n\nWe could also do this easily with things like:\n```{r}\ntable(efdat$PID) |> median()\n```\n\n`r solend()`\n`r solbegin(label=\"4 - how many observations for each audio type per ppt?\", slabel=F,show=T, toggle=params$TOGGLE)`\nFor this kind of thing I would typically default to using `table()` for smaller datasets, to see how many datapoints are in each combination of `PID` and `audio`:  \n```{r}\ntable(efdat$PID, efdat$audio)\n```\n\nFrom the above, we can see that everyone has data from $\\geq 2$ trials for a given audio type.  \n\n```{r}\ntable(efdat$PID, efdat$audio) |> min()\n```\n\n\n::: {.callout-tip collapse=\"true\"}\n#### a tidyverse way:\n\nWhen tables get too big, we can do the same thing with `count()`, but we need to make sure that we are working with factors, in order to summarise all possible combinations of groups (even empty ones)\n```{r}\nefdat |> \n  mutate(PID = factor(PID),\n         audio = factor(audio)) |>\n  # the .drop=FALSE means \"keep empty groups\"\n  count(PID,audio,.drop=FALSE) |> \n  summary()\n```\n\nThere are plenty of other ways (e.g., you could use combinations of `group_by()`, `summarise()`), so just pick one that makes sense to you.  \n\n:::\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\n\n> How do different types of audio interfere with executive functioning, and does this interference differ depending upon whether or not noise-cancelling headphones are used? \n\nConsider the following questions about the study:  \n  \n- What is our outcome of interest?  \n- What variables are we seeking to investigate in terms of their impact on the outcome?    \n- What are the units of observations?  \n- Are the observations clustered/grouped? In what way?  \n- What varies *within* these clusters?  \n- What varies *between* these clusters?  \n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n- What is our outcome of interest?  \n    + __SDMT scores__  \n- What variables are we seeking to investigate in terms of their impact on the outcome?  \n    + __audio type__ and the interaction __audio type $\\times$ wearing headphones__\n- What are the units of observations?  \n    + __individual trials__  \n- What are the groups/clusters?  \n    + __participants__  \n- What varies *within* these clusters?  \n    + __the type of audio__    \n- What varies *between* these clusters?  \n    + __whether they listen via headphones or speakers__  \n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nMake factors and set the reference levels of the `audio` and `headphones` variables to \"no audio\" and \"speakers\" respectively.    \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nCan't remember about setting factors and reference levels? Check back to USMR!  \n\n:::\n\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nefdat <- efdat |>\n  mutate(\n    audio = fct_relevel(factor(audio), \"no_audio\"),\n    headphones = fct_relevel(factor(headphones), \"S\")\n  )\n```\n\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nFit a multilevel model to address the aims of the study (copied below)\n\n> How do different types of audio interfere with executive functioning, and does this interference differ depending upon whether or not noise-cancelling headphones are used? \n \nSpecifying the model may feel like a lot, but try splitting it into three parts:  \n\n$$\n\\text{lmer(}\\overbrace{\\text{outcome }\\sim\\text{ fixed effects}}^1\\, + \\, (1 + \\underbrace{\\text{slopes}}_3\\, |\\, \\overbrace{\\text{grouping structure}}^2 )\n$$\n\n\n1. Just like the `lm()`s we have used in the past, think about what we want to _test_. This should provide the outcome and the structure of our fixed effects.  \n2. Think about how the observations are clustered/grouped. This should tell us how to specify the grouping structure in the random effects.  \n3. Think about which slopes (i.e. which terms in our fixed effects) could feasibly vary between the clusters. This provides you with what to put in as random slopes.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nMake sure to read about multilevel modesl and how to fit them in [Chapter 2: MLM #multilevel-models-in-r](https://uoepsy.github.io/lmm/02_lmm.html#multilevel-models-in-r){target=\"_blank\"}.  \n\n:::\n\n\n\n`r qend()`\n`r solbegin(label=\"1 - fixed effects\", slabel=F,show=T, toggle=params$TOGGLE)`\n\nThe question  \n&nbsp;&nbsp;&nbsp; \"*How do different types of audio interfere with executive functioning*\"   means we are interested in the effects of audio type (`audio`) on executive functioning (`SDMT` scores), so we will want:\n\n```\nlmer(SDMT ~ audio ...\n```\n\nHowever, the research aim also asks    \n&nbsp;&nbsp;&nbsp; \"*... and does this interference differ depending upon whether or not noise-cancelling headphones are used?*\"  \nwhich suggests that we are interested in the interaction `SDMT ~ audio * headphones`  \n\n```\nlmer(SDMT ~ audio * headphones + ...   \n```\n\n`r solend()`\n`r solbegin(label=\"2 - hierarchical data structure\", slabel=F,show=T, toggle=params$TOGGLE)`\n\nThere are lots of ways that our data is grouped.  \nWe have:  \n\n- 3 different groups of audio type (`r paste(unique(efdat$audio),collapse=\", \")`)\n- 2 groups of listening condition (`r paste(unique(efdat$headphones),collapse=\", \")`)\n- 30 groups of participants (\"PPT_01\", \"PPT_02\", \"PPT_03\", ...) \n\nThe effects of audio type and headphones are both things we actually want to _test_ - these variables are in our fixed effects. The levels of audio and headphones are not just a random sample from a wider population of levels - they're a specific set of things we want to compare SDMT scores between.  \n\nCompare this with the participants - we don't care about if there is a difference in SDMT scores between e.g., \"PPT_03\" and \"PPT_28\". The participants themselves are just a sample of people that we have taken from a wider population. This makes thinking of \"by-participant random effects\" a sensible approach - we model differences between participants as a normal distribution of deviations around some average:    \n\n```\nlmer(SDMT ~ audio * headphones + (1 + ... | PID)  \n```\n\nThe minimum that we can include is the random intercept. What `(1|PID)` specifies is that \"participants vary in their SDMT scores\". This makes sense - we would expect some participants to have higher executive functioning (and so will tend to score high on the SDMT), and others to have lower functioning (and so tend to score lower).  \n\n\n`r solend()`\n`r solbegin(label=\"3 - random slopes\", slabel=F,show=T, toggle=params$TOGGLE)`\n\nWe can also include a random by-participant effect of `audio`.  \n`audio|PID` specifies that the effect of audio type on SDMT varies by participant. This seems feasible - music might be very distracting (and interfere a lot with the test) for some participants, but have a negligible effect for others.  \n\n```\nlmer(SDMT ~ audio * headphones + \n              (1 + audio | PID), data = efdat)\n```\n\n\n::: {.callout-tip collapse=\"true\"}\n#### Why can't we have `(headphones|PID)`?  \n\nWhy can we fit `(1 + audio | PID)` but not `(1 + headphones | PID)`, or both `(1 + audio + headphones | PID)` or `(1 + audio * headphones | PID)`?  \n\nRemember that `y ~ ... + (x | g)` is saying \"the slope of y~x varies by g\".  \nSuch a sentence only makes sense if each \"the slope of y~x\" is defined for every (or most) groups.  \n\nFor the `headphones` predictor, every participant is _either_ in the \"S\" (speakers) condition _or_ the \"H\" (headphones) condition.  \nThis means that \"the effect of headphones on SDMT\" _doesn't exist_ for any single participant! This means it makes no sense to try and think of the effect as 'varying by participant'.  \n\nCompare this to the `audio` predictor, for the effect _does_ exist for a single given participant, therefore it is possible to think of it as being different for different participants (e.g. PPT_30's performance improves with white noise, but PPT_16's performance does not).  \n\nThe plots below may help to cement this idea:  \n\n```{r}\n#| echo: false\nlibrary(lattice)\nbwplot(SDMT~headphones|PID, data = efdat, scales=list(x=list(rot=90)))\n\nbwplot(SDMT~audio|PID, data = efdat, scales=list(x=list(rot=90)))\n```\n\n:::\n\n`r solend()`\n\n\n\n`r qbegin(qcounter())`\nWe now have a model, but we don't have any p-values or confidence intervals or anything - i.e. we have no inferential criteria on which to draw conclusions. There are a whole load of different methods available for drawing inferences from multilevel models, which means it can be a bit of a never-ending rabbit hole. For now, we'll just use the 'quick and easy' approach provided by the **lmerTest** package seen in the lectures.  \n\nUsing the **lmerTest** package, re-fit your model, and you should now get some p-values! \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nIf you use `library(lmerTest)` to load the package, then *every single* model you fit will show p-values calculated with the Satterthwaite method.  \nPersonally, I would rather this is not the case, so I often opt to fit specific models with these p-values without ever loading the package:  \n`modp <- lmerTest::lmer(y ~ 1 + x + ....`  \n\n:::\n\n::: {.callout-caution collapse=\"true\"}\n#### optional: a model comparison\n\nIf we want to go down the model comparison route, we just need to isolate the relevant part(s) of the model that we are interested in.  \n\nRemember, model comparison is sometimes a useful way of testing a _set_ of coefficients. For instance, in this example the interaction involves estimating _two_ terms: \n`audiomusic:headphonesH` and `audiowhite_noise:headphonesH`.  \n\nTo test the interaction as a whole, we can create a model without the interaction, and then compare it. The `SATmodcomp()` function from the __pbkrtest__ package provides a way of conducting an F test with the same Satterthwaite method of approximating the degrees of freedom:  \n  \n```{r}\nsdmt_mod <- lmer(SDMT ~ audio * headphones + \n              (1 + audio | PID), data = efdat)\nsdmt_res <- lmer(SDMT ~ audio + headphones + \n                   (1 + audio | PID), data = efdat)\nlibrary(pbkrtest)\nSATmodcomp(largeModel = sdmt_mod, smallModel = sdmt_res)\n```\n\n:::\n\n\n\n`r qend()`\n\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\nsdmt_mod <- lmerTest::lmer(SDMT ~ audio * headphones + \n              (1 + audio | PID), data = efdat)\n\nsummary(sdmt_mod)\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\n\nWe've already seen in the example with the with the different types of toys (above) that we can visualise the fitted values (model predictions). But these were plotting all the cluster-specific values, and what we are really interested in are the estimates of (and uncertainty around) our *fixed effects* (i.e. estimates for clusters *on average*)  \n\nUsing tools like the __effects__ package can provide us with the values of the outcome across levels of a specific fixed predictor (holding other predictors at their mean).   \n\nThis should get you started:  \n```{r}\n#| eval: false\nlibrary(effects)\neffect(term = \"audio*headphones\", mod = sdmt_mod) |>\n  as.data.frame()\n```\n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nYou can see the effects package in [Chapter 2: MLM #visualising-models](https://uoepsy.github.io/lmm/02_lmm.html#visualising-models){target=\"_blank\"}. The logic is just the same as it was for USMR, it's just that the estimated effects are from an `lmer()` instead of an `lm()`/`glm()`.  \n\n:::\n\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n```{r}\nlibrary(effects)\neffect(term = \"audio*headphones\", mod = sdmt_mod) |>\n  as.data.frame() |>\n  ggplot(aes(x=audio,y=fit,\n             ymin=lower,ymax=upper,\n             col=headphones))+\n  geom_pointrange(size=1,lwd=1)\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nNow we have some p-values and a plot, try to create a short write-up of the analysis and results.   \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThink about the principles that have guided you during write-ups thus far. \n\nThe aim in writing a statistical report should be that a reader is able to more or less replicate your analyses **without** referring to your analysis code. Furthermore, it should be able for a reader to understand and replicate your work _even if they use something other than R_. This requires detailing all of the steps you took in conducting the analysis, but without simply referring to R code.   \n\n\n- Provide a description of the sample that is used in the analysis, and any steps that you took to get this sample (i.e. data cleaning/removal)\n- Describe the model/test and how it addresses the research question. What is the structure of the model, and how did you get to this model? *(You don't need a fancy model equation, you can describe in words!)*. \n- Present (visually and numerically) the key results of the coefficient tests or model comparisons, and explain what these mean in the context of the research question (this could be things like practical significance of the effect size, and the group-level variability in the effects). \n\n\n:::\n\n\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n:::imp\nNot a perfect write-up (there's not really any such thing!).  \n:::\n\n\n```{r}\n#| echo: false\nres = as.data.frame(parameters::model_parameters(sdmt_mod, ci_method=\"s\"))\nres[,c(2,3,5,6,7,8)] <- apply(res[,c(2,3,5,6,7,8)], 2, function(x) round(x, 2))\nres[,9] <- format.pval(res[,9],eps=.001,digits=2)\nres[,9][!grepl(\"<\",res[,9])] <- paste0(\"=\",res[,9][!grepl(\"<\",res[,9])])\n\nres2 = as.data.frame(VarCorr(sdmt_mod)) |> mutate(sdcor = round(sdcor,2))\n```\n\n:::int\nSDMT scores were modelled using linear mixed effects regression, with fixed effects of audio-type (no audio/white noise/music, treatment coded with no audio as the reference level), audio delivery (speakers vs ANC-headphones, treatment coded with speakers as the reference level) and their interaction. Participant-level random intercepts and random slopes of audio-type were also included. The inclusion of the interaction term between audio-type and audio-delivery was used to address the question of whether the interference of different audio on executive function depends on whether it is heard via noise-cancelling headphones. A model comparison was conducted between the full model and a restricted model that was identical to the full model with the exception that the interaction term was excluded. Models were fitted using the **lme4** package in R, and estimated with restricted estimation maximum likelihood (REML). Denominator degrees of freedom for all comparisons and tests were approximated using the Satterthwaite method.  \n\nInclusion of the interaction between headphones and audio-type was found to improve model fit ($F(2, 26.9) = 11.05, p < .001$), suggesting that the interference of different types of audio on executive functioning is dependent upon whether the audio is presented through ANC-headphones or through speakers.  \n\nParticipants not wearing headphones and presented with no audio scored on average `r res[1,2]` on the SDMT. For participants without headphones, listening to music via speakers was associated with lower scores compared to no audio ($b = `r res[2,2]`, t(`r res[2,8]`)=`r res[2,7]`, p `r res[2,9]`$), but there was no significant difference between white noise and no audio.   \n\nWith no audio playing, wearing ANC-headphones was associated with higher SDMT scores compared to those wearing no headphones ($b = `r res[4,2]`, t(`r res[4,8]`)=`r res[4,7]`, p `r res[4,9]`$).\nThe apparent detrimental effect of music on SDMT scores was not significantly different in the headphones condition compared to the no-headphones condition ($b = `r res[5,2]`, t(`r res[5,8]`)=`r res[5,7]`, p `r res[5,9]`$). Compared to those listening through speakers, white noise was associated with a greater increase in scores over no audio, when listening via ANC-heaphones ($b = `r res[6,2]`, t(`r res[6,8]`)=`r res[6,7]`, p `r res[6,9]`$).  \n\nThere was considerable variability in baseline (i.e. no-audio) SDMT scores across participants (SD = `r res2[1,5]`), with participants showing similar variability in the effects of music (SD = `r res2[2,5]`) and of white-noise (SD = `r res2[3,5]`). A weak negative correlation (`r res2[5,5]`) between participant-level intercepts and effects of white-noise indicated that people who score higher in the no-audio condition tended to be more negatively effect by white-noise. A similar weak negative correlation (`r res2[6,5]`) between music and white-noise effects suggests participants who were more positively affected by one type of audio tended to be more negatively affected by the other.  \n\nThese results suggest that music appears to interfere with executive functioning (lower SDMT scores) compared to listening to no audio, and this is not dependent upon whether is heard through headphones or speakers. When listening via speakers, white noise was not associated with differences in executive functioning compared to no audio, but this was different for those listening via headphones, in which white noise saw a greater increase in performance. Furthermore, there appear to be benefits for executive functioning from wearing ANC-headphones even when not-listening to audio, perhaps due to the noise cancellation. The pattern of findings are displayed in @fig-efplot.  \n\n\n```{r}\n#| label: fig-efplot\n#| fig-cap: \"Interaction between the type (no audio/white noise/music) and the delivery (speakers/ANC headphones) on executive functioning task (SDMT)\"\n#| echo: false\nplotfit <- effect(term = \"audio*headphones\", mod = sdmt_mod) |>\n  as.data.frame()\n\nggplot(efdat, aes(x=audio,y=SDMT,col=headphones))+\n  geom_jitter(height=0,width=.2,alpha=.3) +\n  geom_pointrange(data = plotfit, \n                  aes(y=fit,ymin=lower,ymax=upper),\n                  size=1,lwd=1) \n```\n\n```{r}\n#| echo: false\nsjPlot::tab_model(sdmt_mod,df.method=\"satterthwaite\",\n                  show.ci=F,show.stat=T,show.df=T)\n```\n\n\n:::\n`r solend()`\n\n<br>\n<div class=\"divider div-transparent div-dot\"></div>\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"include-in-header":["assets/toggling.html"],"number-sections":false,"output-file":"01ex.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","toc_float":true,"link-citations":true,"theme":["united","assets/style-labs.scss"],"title":"Week 1 Exercises: Intro to MLM","params":{"SHOW_SOLS":true,"TOGGLE":true},"editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}