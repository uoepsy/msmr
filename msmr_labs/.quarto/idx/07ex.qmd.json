{"title":"Week 7 Exercises: PCA & EFA","markdown":{"yaml":{"title":"Week 7 Exercises: PCA & EFA","params":{"SHOW_SOLS":true,"TOGGLE":true},"editor_options":{"chunk_output_type":"console"}},"headingText":"Project management","containsRefs":false,"markdown":"\n\n```{r}\n#| label: setup\n#| include: false\nsource('assets/setup.R')\nlibrary(xaringanExtra)\nlibrary(tidyverse)\nlibrary(patchwork)\nxaringanExtra::use_panelset()\nqcounter <- function(){\n  if(!exists(\"qcounter_i\")){\n    qcounter_i <<- 1\n  }else{\n    qcounter_i <<- qcounter_i + 1\n  }\n  qcounter_i\n}\n\nlibrary(psych)\n```\n\n```{r}\n#| include: false\n\n# Team-work\n# Analysing and evaluating information\n# Influencing others\n# Technical knowledge\n\nvarnames <- c(\"Deadline Consistency: Average discrepancy between 'Target Date' vs. 'Actual Completion Date' for assigned tasks.\",\n\"Scheduling: Frequency of updated timelines or revised milestones sent to the team.\",\n\"Resource Allocation: How well have they allocated resources to ensure efficient project execution?\",\n\"Risk Identification: Rate their proficiency in identifying and mitigating project risks.\",\n\"Project Updating: Frequency of weekly status emails/announcements on the project. \",\n\"Collaboration: Number of projects where they were a 'Collaborator' or 'Contributor' alongside others.\",\n\"Teamwork: Rate how well they have actively listened to and considered the ideas and opinions of others.\",\n\"Positivity: How effectively have they contributed to a positive team environment?\",\n\"Assistance: Frequency of being tagged for help on others' assigned tasks.\",\n\"Conflict: How well have they resolved conflicts and disagreements within the team?\",\n\"Info Gathering: How proficient have they been in gathering and synthesizing relevant data to inform decision-making?\",\n\"Critical Thinking: Rate their ability to critically evaluate the validity and reliability of information sources.\",\n\"Info Summarising: Frequency of contributions to the 'Executive Summary' sections of their team's submitted reports.\",\n\"Info Synthesis: Rate their skill in developing logical and evidence-based conclusions from analyzed information.\",\n\"Clarity: How well have they communicated their analysis and findings to others in a clear and concise manner?\",\n\"Rapport: Emails or notes from clients and partners praising the professional relationship.\",\n\"Persuasion: Number of project pitches that were granted budget or sign-off.\",\n\"Communication: How well have they adapted their communication style to resonate with different audiences?\",\n\"Negotiation: Rate their skill in negotiating win-win solutions in challenging situations.\",\n\"Inspiration: How effectively have they inspired and motivated others to take action or adopt new ideas?\",\n\"Technical Proficiency: The number of tasks sent back for 'Correction' versus those approved on the first pass.\",\n\"Technical Development: Number of completed internal or external training certifications. \",\n\"Problem Resolution: The average time between a 'Help Ticket' or 'Bug' being assigned and closed.\",\n\"Technical Communication: How well have they translated complex technical information into understandable terms for non-technical stakeholders?\",\n\"Technical Initiative: How well have they leveraged technical expertise for problem-solving?\")\n\n\n\n\nset.seed(223)\nmakeitems <- function(){\n  S = runif(5,.7,2)\n  f = runif(5,.7,.99)\n  R = f %*% t(f)\n  diag(R) = 1\n  items = MASS::mvrnorm(400, mu = rnorm(5,3,.6), Sigma=diag(S)%*%R%*%diag(S))\n  #apply(items, 2, function(x) pmin(7,pmax(1,x)))\n}\n\npcs = lapply(1:3, function(x) makeitems())\n\ndf = do.call(cbind, pcs)\n\n#pheatmap::pheatmap(cor(df))\n#plot(eigen(cor(df))$values,type=\"b\")\n\ndf <- as.data.frame(df)\n\nprincipal(df,nfactors=3,rotate=\"none\")$scores\n\n\nnames(df)<-varnames[c(1:10,21:25)]\n#df <- df[,sample(1:15)]\ndict = tibble(\n  variable = c(\"name\",paste0(\"q\",1:15)),\n  question = c(\"employee name\", names(df))\n)\n\ndf[,c(3,4,7,8,10,14,15)] <- apply(df[,c(3,4,7,8,10,14,15)],2,function(x) pmin(7,pmax(1,round(x))))\n\nnames(df) <- paste0(\"q\",1:15)\n\ndf$q1 <- round(-7.4 + scale(df$q1)[,1]*12)\ndf$q2 <- round(scale(df$q2)[,1]*.4,1)\ndf$q2 <- df$q2 + abs(min(df$q2))\ndf$q5 <- round(scale(df$q5)[,1]*.3,1)\ndf$q5 <- df$q5 + abs(min(df$q5))\ndf$q6 <- round(scale(df$q6)[,1]*5)\ndf$q6 <- df$q6 + abs(min(df$q6))\ndf$q9 <- round(scale(df$q9)[,1]*.02,2)\ndf$q9 <- df$q9 + abs(min(df$q9))\ndf$q11 <- round(scale(df$q11)[,1]*.16,2)\ndf$q11 <- df$q11 + abs(min(df$q11))\ndf$q12 <- round(2+scale(df$q12)[,1]*2)\ndf$q12 <- df$q12 + abs(min(df$q12))\ndf$q13 <- round(7.3+scale(df$q13)[,1]*8)\ndf$q13 <- df$q13 + abs(min(df$q13))\n\n\njobperf <- df |>\n  mutate(\n    name = randomNames::randomNames(nrow(df),\n                                    sample.with.replacement=F),\n    .before = 1\n  )\n\n#write_csv(jobperf,file=\"../../data/jobperfbonus.csv\")\n\n\n\n\nmakeitems <- function(){\n  S = runif(5,.4,2)\n  f = runif(5,.4,.99)\n  R = f %*% t(f)\n  diag(R) = 1\n  items = round(MASS::mvrnorm(400, mu = rnorm(5,3,.6), Sigma=diag(S)%*%R%*%diag(S)))\n  apply(items, 2, function(x) pmin(7,pmax(1,x)))\n}\neg_data = do.call(cbind,lapply(1, function(x) makeitems()))\neg_data[,4] <- max(eg_data[,4]) - eg_data[,4] + 1\neg_data[,5] <- max(eg_data[,5]) - eg_data[,5] + 1\neg_data <- as.data.frame(eg_data)\nnames(eg_data) <- paste0(\"item_\",1:5)\n```\n\n\n:::frame\n__New packages__  \n\nWe're going to be needing some different packages this week (no more lme4!).    \nMake sure you have these packages installed:  \n\n+ psych  \n+ GPArotation  \n+ car  \n\n:::\n\n# Reducing the dimensionality of job performance  \n\n:::frame\n__Data: jobperfbonus.csv__  \n\nA company has asked line managers to fill out a questionnaire that asks them to capture 'performance indicators' for each of their employees. These 15 indicators are a mix of metrics from the companies work management software, and questions about manager's perceptions of their employees' work over the last year.  \n\nThe company’s leadership team finds the 15-indicator report a bit confusing and overwhelming. They want to create a simplified \"Performance Dashboard\" that captures only the most important directions of variance in their employees.  \n\nIt can be downloaded at [https://uoepsy.github.io/data/jobperfbonus.csv](https://uoepsy.github.io/data/jobperfbonus.csv){target=\"_blank\"}\n\n```{r}\n#| echo: false\n#| label: tbl-jpdict\n#| tbl-cap: \"data dictionary for jobperfbonus.csv\"\ngt::gt(dict)\n```\n\n:::\n\n\n`r qbegin(qcounter())`\nLoad the data!  \n\nWe're going to want to reduce these 15 variables (or \"items\") down into a smaller set. Should we use PCA or EFA?  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\njobperf <- read_csv(\"https://uoepsy.github.io/data/jobperfbonus.csv\")\nhead(jobperf)\n```\n\nWe're probably going to want to use PCA, because it is hard to understand what an underlying latent dimension of 'performance' would be --- i.e., it makes more sense to think of any overall measure of 'performance' as just being the combination of all of those indicators.  \n\nOne way to reason about this is to task which of these makes more sense:  \n\n- A. If my 'job performance' increases, then my scores on the indicators will go up  \n- B. If my scores on the indicators go up, then my 'job performance' will increase  \n\nReally, we are just asking about the direction of the arrows. Which picture makes more sense?  \n\n![](images/perfpcaefa.png)\n\n`r solend()`\n\n`r qbegin(qcounter())`\nExplore the relationships between variables in the data.  \n\nYou're probably going to want to subset out _just_ the relevant variables (`q1` to `q15`).  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThere are lots of variables! There are various things we can do here. Try some of them to see what they do:  \n\n- `cor(data)`\n- `heatmap(cor(data))`\n- `pairs.panels(data)` (from the **psych** package)\n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nLet's keep the full data with the names, but make a new object that is just the performance data:  \n```{r}\nqperf <- jobperf |> select(-name)\n```\n\nIt looks like we've got some very strong groups of questions there - q1 to q5 are all highly related to one another, as are q6 to q10, and q11 to q15. Furthermore, the relations between those sets are very weak, suggesting 3 groups that are fairly distinct.  \n\n```{r}\nheatmap(cor(qperf))\n```\n\nYou'll probably have to zoom in when you do this yourself, as there are a lot of little plots there!  \n```{r}\nlibrary(psych)\npairs.panels(qperf)\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nHow much variance in the set of performance indicators will be captured by 15 principal components? \n\n*Note: We can figure this out without having to do anything - it's a theoretical question!*\n\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nAll of it!  \nThe right hand entry of the \"Cumulative Var\" row is 1 - it explains everything. \n```{r}\nprincipal(qperf, nfactors = 15, rotate = \"none\")\n```\n\n`r solend()`\n\n\n\n`r qbegin(qcounter())`\nRemember, the company is wanting us to simplify things down from having 15 indicators of 'job performance' to a smaller set, that captures the most important ways in which employees vary in their performance.  \n\nWe're going to use PCA.  \nHow many components should we keep?\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nSee scree plots, parallel analysis, MAP - [Chapter 2 - PCA walkthrough](https://uoepsy.github.io/lv/02_pca.html){target=\"_blank\"}.  \n:::\n\n`r qend()`\n`r solbegin(label=\"Kaiser\", slabel=F, show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nAccording to Kaiser's rule, we should keep 3 components\n```{r}\nprincipal(qperf, nfactors = 15, rotate = \"none\")$values\n```\n\n`r solend()`\n`r solbegin(label=\"Scree\", slabel=F, show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nAccording to the Scree plot, I would suggest keeping 3 components\n```{r}\nscree(qperf, factors = FALSE)\n```\n\n`r solend()`\n`r solbegin(label=\"MAP\", slabel=F, show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nAccording to the MAP, we should keep 3 components\n\n```{r}\nVSS(qperf, n = ncol(qperf), \n    rotate = \"none\", fm = \"pc\", plot = FALSE)\n```\n\n`r solend()`\n`r solbegin(label=\"Parallel Analysis\", slabel=F, show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nAccording to the parallel analysis, we should keep 3 components \n```{r}\nfa.parallel(qperf, fa=\"pc\", n.iter = 500)\n```\n\n`r solend()`\n`r solbegin(label=\"Making a decision\", slabel=F, show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nIn this case, everything agrees that we should retain 3 components:  \n```{r}\n#| echo: false\ntibble(\n  guides = c(\"Kaiser\",\"Scree\",\"MAP\",\"Parallel Analysis\"),\n  suggestion = rep(3,4)\n) |> gt::gt()\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nConduct a principal components analysis extracting the number of components you decided on from the previous question.  \n\nBe sure to set `rotate = \"none\"` (a conventional PCA does not use rotations - it is simply about data reduction. The line is a bit blurred here, but once we start introducing rotations, we are moving more towards a form of EFA).  \n\nExamine the loadings for the components. By thinking in relation to the questions that were asked (refer back to @tbl-jpdict), what do you think each component is capturing?  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nIt's rarely as neat as this, but we can see the patterns of higher loadings for the groups of 5 questions on each component. \n\n- PC1 has higher loadings for q1 to q5 \n- PC2 has higher loadings for q6 to q10 \n- PC3 has higher loadings for q11 to q15 \n\nLooking back at the questions in @tbl-jpdict, questions 1 to 5 were all about stuff related to 'project management'. Questions 6 to 10 were all about collaboration with team members, and questions 11 to 15 were all about technical skill. \n\n```{r}\nprincipal(qperf, nfactors = 3, rotate = \"none\")\n```\n\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nExtract the scores on the principal components.  \nThe company wants to reward teamwork. Pick 10 people they should give a bonus to.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nSee [Chapter 2#PCA-walkthrough - scores](https://uoepsy.github.io/lv/02_pca.html#scores){target=\"_blank\"} for how to extract scores (a score on each component for each row of our original dataset) using the `$scores` from the object fitted with `principal()`.  \n\nThis will contain as many sets of scores as there are components. One of these (given the previous question) might be of use here.  \n\nYou'll likely want to join them back to the column of names. So we can figure out who gets the bonus. `cbind()` or `bind_cols()` might help here.  \n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nThe second component seems to capture a lot of 'teamwork' related questions. So if we extract scores on that second component, we could then pick the 10 people for whom they are highest on that component.  \n\nThis will extract the scores:\n```{r}\n#| eval: false\nprincipal(qperf, nfactors = 3, rotate = \"none\")$scores\n```\n\nLet's combine them with the original data that contains the employee names, so we can figure out who to give bonuses to.  \nWe could do this with `cbind()`, or `bind_cols()`, \n```{r}\n# first we bind the columns of the scores, back to \n# the original data which contains the names\njobperf <- \n  bind_cols(\n    principal(qperf, nfactors = 3, rotate = \"none\")$scores,\n    jobperf\n  ) \n\n# we can then choose just the 10 people \n# who have the highest scores on PC2 (the teamwork component)\njobperf |> select(name, PC2) |>\n  arrange(desc(PC2))\n```\n\n`r solend()`\n\n<br>\n\n# Understanding Conduct Problems  \n\n\n:::frame\n__Data: Conduct Problems__  \n\nA researcher is developing a new brief measure of Conduct Problems. She has collected data from n=450 adolescents on 10 items, which cover the following behaviours:  \n\n1. Breaking curfew\n1. Vandalism\n1. Skipping school\n1. Bullying\n1. Spreading malicious rumours\n1. Fighting\n1. Lying\n1. Using a weapon \n1. Stealing\n1. Threatening others\n\n\nOur task is to use the dimension reduction techniques we learned about in the lecture to help inform how to organise the items she has developed into subscales.  \n\nThe data can be found at [https://uoepsy.github.io/data/conduct_probs_scale.csv](https://uoepsy.github.io/data/conduct_probs_scale.csv){target=\"_blank\"} \n\n:::\n\n`r qbegin(qcounter())`\nRead in the dataset.  \nCreate a correlation matrix for *the items*, and inspect the items to check their suitability for exploratory factor analysis (see [Chapter 3#EFA-initial checks](https://uoepsy.github.io/lv/03_efa.html#initial-checks){target=\"_blank\"}).  \n`r qend()` \n`r solbegin(show=params$SHOW, toggle=params$TOGGLE)`\n```{r}\ncpdata <- read.csv(\"https://uoepsy.github.io/data/conduct_probs_scale.csv\")\n# discard the first column\ncpdata <- cpdata[,-1]\n```\n\nHere's a correlation matrix. There's no obvious blocks of items here, but we can see that there are some fairly high correlations, as well as some weaker ones. All are positive.  \n```{r}\nheatmap(cor(cpdata))\n```\n\nThe Bartlett's test comes out with a p-value of 0 (which isn't possible, but it's been rounded for some reason). This suggests that we reject the null of this test (that our correlation matrix is proportional to the identity matrix). This is good. It basically means \"we have some non-zero correlations\"!  \n```{r}\ncortest.bartlett(cor(cpdata), n=450)\n```\n\nThe overall sampling adequacy is 0.87, which is pretty good! (or rather, which is 'meritorious'!).  MSA for all items is >.8\n```{r}\nKMO(cpdata)  \n```\n\nFinally, all the relationships here look fairly linear:\n```{r}\npairs.panels(cpdata)\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nHow many dimensions should be retained?  \n\nThis question can be answered in the same way as we did above for PCA - use a scree plot, parallel analysis, and MAP test to guide you.   \n\nYou can use `fa.parallel(data, fa = \"both\")` to conduct both parallel analysis and view the scree plot!   \n`r qend()` \n\n`r solbegin(label=\"Scree\", slabel=F, show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nThe scree plot shows a kink at 3, which suggests retaining 2 components. \n```{r}\nscree(cpdata)\n```\n\n`r solend()`\n`r solbegin(label=\"MAP\", slabel=F, show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nThe MAP suggests retaining 2 factors. I'm just extracting the actuall `map` values here to save having to show all the other output. We can see that the 2nd entry is the smallest: \n```{r}\nVSS(cpdata, plot = FALSE, n = ncol(cpdata))$map\n```\n\n\n`r solend()`\n`r solbegin(label=\"Parallel Analysis\", slabel=F, show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nParallel analysis suggests 2 factors as well:\n```{r}\nfa.parallel(cpdata, fa = \"both\")\n```\n\n`r solend()`\n`r solbegin(label=\"Making a decision\", slabel=F, show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nAgain, a quite clear picture that 2 factors is preferred:  \n```{r}\n#| echo: false\ntibble(\n  guides = c(\"Scree\",\"MAP\",\"Parallel Analysis\"),\n  suggestion = rep(2,3)\n) |> gt::gt()\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nUse the function `fa()` from the **psych** package to conduct and EFA to extract 2 factors (this is what *we* suggest based on the various tests above, but *you* might feel differently - the ideal number of factors is subjective!). Use a suitable rotation (`rotate = ?`) and extraction method (`fm = ?`).  \n```{r}\n#| eval: false\nmyfa <- fa(data, nfactors = ?, rotate = ?, fm = ?)\n```\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nWould you expect factors to be correlated? If so, you'll want an oblique rotation.  \n\nIf there are two+ underlying factors of 'conduct problems', if someone is higher on one of them, would we expect them to therefore be high/low on the other? If so, then we the two factors are correlated!   \n:::\n\n\n`r qend()` \n`r solbegin(show=params$SHOW, toggle=params$TOGGLE)`\nFor example, you could choose an oblimin rotation to allow factors to correlate and use ml as the extraction method.  \n```{r}\nconduct_efa <- fa(cpdata, nfactors=2, rotate='oblimin', fm=\"ml\")\n```\n`r solend()`\n\n`r qbegin(qcounter())`\nInspect your solution. Make sure to look at and think about the loadings, the variance accounted for, and the factor correlations (if estimated).  \n\nWhat we're doing here is essentially evaluating whether our solution looks theoretically coherent. A big part of this is a subjective decision about the groupings of items, but we would also like the numerical parts of our model to meet certain criteria (see [Chapter 3: EFA#what-makes-a-good-factor-solution](https://uoepsy.github.io/lv/03_efa.html#what-makes-a-good-factor-solution){target=\"_blank\"}).  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nJust printing an `fa` object:\n```{r}\n#| eval: false\nmyfa <- fa(data, ..... )\nmyfa\n```\nWill give you lots and lots of information.  \nYou can extract individual parts using:  \n\n- `myfa$loadings` for the loadings\n- `myfa$Vaccounted` for the variance accounted for by each factor\n- `myfa$Phi` for the factor correlation matrix\n\nYou can find a quick guide to reading the `fa` output here: [efa_output.pdf](https://uoepsy.github.io/msmr/2425/misc/efa_output.pdf){target=\"_blank\"}.  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nThings look pretty good here. Each item has a clear primary loading on to one of the factors, and the complexity for all items is 1 (meaning they're clearly link to just one of the factors). The `h2` column is showing that the 2 factor solution is explaining 38%+ of the variance in each item.  Both factors are well determined, having at least 3 salient loadings.  \n\nThe 2 factors together explain 57% of the variance in the data - both factors explain a similar amount (29% for factor 1, 28% for factor 2). \n\nWe can also see that there is a moderate correlation between the two factors. Use of an oblique rotation was appropriate - if the correlation had been very weak, then it might not have differed much from if we used an orthogonal rotation.  \n\n```{r}\n#| eval: false\nconduct_efa\n```\n```{r}\n#| echo: false\n.pp(conduct_efa, l=list(1:28))\n```\n\n\n`r solend()`\n\n\n\n`r qbegin(qcounter())`\nLook back to the description of the items, and suggest a name for your factors based on the patterns of loadings.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nTo sort the loadings, you can use\n```{r}\n#| eval: false\nprint(myfa$loadings, sort = TRUE)\n```\n\n:::\n\n`r qend()` \n`r solbegin(show=params$SHOW, toggle=params$TOGGLE)`\nYou can inspect the loadings using:\n```{r}\nprint(conduct_efa$loadings, sort=TRUE)\n```\nWe can see that, ordered like this, we have five items that have high loadings for one factor and another five items that have high loadings for the other.  \n  \nThe five items for factor 1 all have in common that they are non-aggressive forms of conduct problems. The five items for factor 2 are all more aggressive behaviours. We could, therefore, label our factors: ‘non-aggressive’ and ‘aggressive’ conduct problems.\n`r solend()`\n\n`r qbegin(qcounter())`\nCompare your three different solutions: \n\n1) your current solution from the previous questions\n2) one where you fit 1 more factor\n3) one where you fit 1 fewer factors   \n\nWhich one looks best?  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nWe're looking here to assess:  \n\n- how much variance is accounted for by each solution\n- do all factors load on 3+ items at a salient level?  \n- do all items have at least one loading at a salient level?\n- are there any \"Heywood cases\" (communalities or standardised loadings that are >1)?\n- should we perhaps remove some of the more complex items?\n- is the factor structure (items that load on to each factor) coherent, and does it make theoretical sense?\n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nThe 1-factor model explains 37% of the variance (as opposed to the 57% explained by the 2 factor solution), and all items load fairly high on the factor. The downside here is that we're not discerning between different types of conduct problems that we did in the 2 factor solution.  \n```{r}\nconduct_1 <- fa(cpdata, nfactors=1, fm=\"ml\")\nconduct_1\n```\n\nThe 3-factor model explains 60% of the variance (only 3% more than the 2-factor model). Notably, the third factor is not very clearly defined - it only has 1 salient loading (possibly 2 if we consider the 0.31 to be salient, but that item is primarily loaded on the 2nd factor). \n```{r}\nconduct_3 <- fa(cpdata, nfactors=3, rotate='oblimin', fm=\"ml\")\nconduct_3\n```\n\n\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nDrawing on your previous answers and conducting any additional analyses you believe would be necessary to identify an optimal factor structure for the 10 conduct problems, write some bullet points to summarise your methods and the results of your chosen optimal model.  \n\nRemember, the main principles governing the reporting of statistical methods are transparency and reproducibility (i.e., someone should be able to reproduce your analysis based on your description).\n\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n\nAn example summary would be:\n\n:::int \n\nFirst, the data were checked for their suitability for factor analysis. Normality was checked using visual inspection of histograms, linearity was checked through the inspection of the linear and lowess lines for the pairwise relations of the variables, and factorability was confirmed using a KMO test, which yielded an overall KMO of $.87$ with no variable KMOs $<.50$. \nAn exploratory factor analysis was conducted to inform the structure of a new conduct problems test. Inspection of a scree plot alongside parallel analysis (using principal components analysis; PA-PCA) and the MAP test were used to guide the number of factors to retain. All three methods suggested retaining two factors; however, a one-factor and three-factor solution were inspected to confirm that the two-factor solution was optimal from a substantive and practical perspective, e.g., that it neither blurred important factor distinctions nor included a minor factor that would be better combined with the other in a one-factor solution. These factor analyses were conducted using maximum likelihood estimation and (for the two- and three-factor solutions) an oblimin rotation, because it was expected that the factors would correlate. Inspection of the factor loadings and correlations reinforced that the two-factor solution was optimal: both factors were well-determined, including 5 loadings $>|0.3|$ and the one-factor model blurred the distinction between different forms of conduct problems. \nThe factor loadings are provided in @tbl-loadingtab^[You should provide the table of factor loadings. It is conventional to omit factor loadings $<|0.3|$; however, be sure to ensure that you mention this in a table note.]. Based on the pattern of factor loadings, the two factors were labelled 'aggressive conduct problems' and 'non-aggressive conduct problems'. These factors had a  correlation of $r=.43$. Overall, they accounted for 57% of the variance in the items, suggesting that a two-factor solution effectively summarised the over half of the variation in the items.\n\n\n```{r}\n#| label: tbl-loadingtab\n#| echo: false\n#| tbl-cap: \"Factor Loadings\"\nloadings = unclass(conduct_efa$loadings)\nloadings = round(loadings, 3)\nloadings = loadings[order(loadings[,1],decreasing = T),]\nloadings[abs(loadings) < 0.3] = NA\n# loadings[!is.na(loadings[,2]),] <- \n#   loadings[!is.na(loadings[,2]),][\n#     order(loadings[!is.na(loadings[,2]),2],decreasing = T),\n#   ]\nloadings\noptions(knitr.kable.NA = '')\nknitr::kable(loadings, digits = 2)\n```\n\n:::\n\n\n`r solend()`","srcMarkdownNoYaml":"\n\n```{r}\n#| label: setup\n#| include: false\nsource('assets/setup.R')\nlibrary(xaringanExtra)\nlibrary(tidyverse)\nlibrary(patchwork)\nxaringanExtra::use_panelset()\nqcounter <- function(){\n  if(!exists(\"qcounter_i\")){\n    qcounter_i <<- 1\n  }else{\n    qcounter_i <<- qcounter_i + 1\n  }\n  qcounter_i\n}\n\nlibrary(psych)\n```\n\n```{r}\n#| include: false\n\n# Project management\n# Team-work\n# Analysing and evaluating information\n# Influencing others\n# Technical knowledge\n\nvarnames <- c(\"Deadline Consistency: Average discrepancy between 'Target Date' vs. 'Actual Completion Date' for assigned tasks.\",\n\"Scheduling: Frequency of updated timelines or revised milestones sent to the team.\",\n\"Resource Allocation: How well have they allocated resources to ensure efficient project execution?\",\n\"Risk Identification: Rate their proficiency in identifying and mitigating project risks.\",\n\"Project Updating: Frequency of weekly status emails/announcements on the project. \",\n\"Collaboration: Number of projects where they were a 'Collaborator' or 'Contributor' alongside others.\",\n\"Teamwork: Rate how well they have actively listened to and considered the ideas and opinions of others.\",\n\"Positivity: How effectively have they contributed to a positive team environment?\",\n\"Assistance: Frequency of being tagged for help on others' assigned tasks.\",\n\"Conflict: How well have they resolved conflicts and disagreements within the team?\",\n\"Info Gathering: How proficient have they been in gathering and synthesizing relevant data to inform decision-making?\",\n\"Critical Thinking: Rate their ability to critically evaluate the validity and reliability of information sources.\",\n\"Info Summarising: Frequency of contributions to the 'Executive Summary' sections of their team's submitted reports.\",\n\"Info Synthesis: Rate their skill in developing logical and evidence-based conclusions from analyzed information.\",\n\"Clarity: How well have they communicated their analysis and findings to others in a clear and concise manner?\",\n\"Rapport: Emails or notes from clients and partners praising the professional relationship.\",\n\"Persuasion: Number of project pitches that were granted budget or sign-off.\",\n\"Communication: How well have they adapted their communication style to resonate with different audiences?\",\n\"Negotiation: Rate their skill in negotiating win-win solutions in challenging situations.\",\n\"Inspiration: How effectively have they inspired and motivated others to take action or adopt new ideas?\",\n\"Technical Proficiency: The number of tasks sent back for 'Correction' versus those approved on the first pass.\",\n\"Technical Development: Number of completed internal or external training certifications. \",\n\"Problem Resolution: The average time between a 'Help Ticket' or 'Bug' being assigned and closed.\",\n\"Technical Communication: How well have they translated complex technical information into understandable terms for non-technical stakeholders?\",\n\"Technical Initiative: How well have they leveraged technical expertise for problem-solving?\")\n\n\n\n\nset.seed(223)\nmakeitems <- function(){\n  S = runif(5,.7,2)\n  f = runif(5,.7,.99)\n  R = f %*% t(f)\n  diag(R) = 1\n  items = MASS::mvrnorm(400, mu = rnorm(5,3,.6), Sigma=diag(S)%*%R%*%diag(S))\n  #apply(items, 2, function(x) pmin(7,pmax(1,x)))\n}\n\npcs = lapply(1:3, function(x) makeitems())\n\ndf = do.call(cbind, pcs)\n\n#pheatmap::pheatmap(cor(df))\n#plot(eigen(cor(df))$values,type=\"b\")\n\ndf <- as.data.frame(df)\n\nprincipal(df,nfactors=3,rotate=\"none\")$scores\n\n\nnames(df)<-varnames[c(1:10,21:25)]\n#df <- df[,sample(1:15)]\ndict = tibble(\n  variable = c(\"name\",paste0(\"q\",1:15)),\n  question = c(\"employee name\", names(df))\n)\n\ndf[,c(3,4,7,8,10,14,15)] <- apply(df[,c(3,4,7,8,10,14,15)],2,function(x) pmin(7,pmax(1,round(x))))\n\nnames(df) <- paste0(\"q\",1:15)\n\ndf$q1 <- round(-7.4 + scale(df$q1)[,1]*12)\ndf$q2 <- round(scale(df$q2)[,1]*.4,1)\ndf$q2 <- df$q2 + abs(min(df$q2))\ndf$q5 <- round(scale(df$q5)[,1]*.3,1)\ndf$q5 <- df$q5 + abs(min(df$q5))\ndf$q6 <- round(scale(df$q6)[,1]*5)\ndf$q6 <- df$q6 + abs(min(df$q6))\ndf$q9 <- round(scale(df$q9)[,1]*.02,2)\ndf$q9 <- df$q9 + abs(min(df$q9))\ndf$q11 <- round(scale(df$q11)[,1]*.16,2)\ndf$q11 <- df$q11 + abs(min(df$q11))\ndf$q12 <- round(2+scale(df$q12)[,1]*2)\ndf$q12 <- df$q12 + abs(min(df$q12))\ndf$q13 <- round(7.3+scale(df$q13)[,1]*8)\ndf$q13 <- df$q13 + abs(min(df$q13))\n\n\njobperf <- df |>\n  mutate(\n    name = randomNames::randomNames(nrow(df),\n                                    sample.with.replacement=F),\n    .before = 1\n  )\n\n#write_csv(jobperf,file=\"../../data/jobperfbonus.csv\")\n\n\n\n\nmakeitems <- function(){\n  S = runif(5,.4,2)\n  f = runif(5,.4,.99)\n  R = f %*% t(f)\n  diag(R) = 1\n  items = round(MASS::mvrnorm(400, mu = rnorm(5,3,.6), Sigma=diag(S)%*%R%*%diag(S)))\n  apply(items, 2, function(x) pmin(7,pmax(1,x)))\n}\neg_data = do.call(cbind,lapply(1, function(x) makeitems()))\neg_data[,4] <- max(eg_data[,4]) - eg_data[,4] + 1\neg_data[,5] <- max(eg_data[,5]) - eg_data[,5] + 1\neg_data <- as.data.frame(eg_data)\nnames(eg_data) <- paste0(\"item_\",1:5)\n```\n\n\n:::frame\n__New packages__  \n\nWe're going to be needing some different packages this week (no more lme4!).    \nMake sure you have these packages installed:  \n\n+ psych  \n+ GPArotation  \n+ car  \n\n:::\n\n# Reducing the dimensionality of job performance  \n\n:::frame\n__Data: jobperfbonus.csv__  \n\nA company has asked line managers to fill out a questionnaire that asks them to capture 'performance indicators' for each of their employees. These 15 indicators are a mix of metrics from the companies work management software, and questions about manager's perceptions of their employees' work over the last year.  \n\nThe company’s leadership team finds the 15-indicator report a bit confusing and overwhelming. They want to create a simplified \"Performance Dashboard\" that captures only the most important directions of variance in their employees.  \n\nIt can be downloaded at [https://uoepsy.github.io/data/jobperfbonus.csv](https://uoepsy.github.io/data/jobperfbonus.csv){target=\"_blank\"}\n\n```{r}\n#| echo: false\n#| label: tbl-jpdict\n#| tbl-cap: \"data dictionary for jobperfbonus.csv\"\ngt::gt(dict)\n```\n\n:::\n\n\n`r qbegin(qcounter())`\nLoad the data!  \n\nWe're going to want to reduce these 15 variables (or \"items\") down into a smaller set. Should we use PCA or EFA?  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\n```{r}\njobperf <- read_csv(\"https://uoepsy.github.io/data/jobperfbonus.csv\")\nhead(jobperf)\n```\n\nWe're probably going to want to use PCA, because it is hard to understand what an underlying latent dimension of 'performance' would be --- i.e., it makes more sense to think of any overall measure of 'performance' as just being the combination of all of those indicators.  \n\nOne way to reason about this is to task which of these makes more sense:  \n\n- A. If my 'job performance' increases, then my scores on the indicators will go up  \n- B. If my scores on the indicators go up, then my 'job performance' will increase  \n\nReally, we are just asking about the direction of the arrows. Which picture makes more sense?  \n\n![](images/perfpcaefa.png)\n\n`r solend()`\n\n`r qbegin(qcounter())`\nExplore the relationships between variables in the data.  \n\nYou're probably going to want to subset out _just_ the relevant variables (`q1` to `q15`).  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nThere are lots of variables! There are various things we can do here. Try some of them to see what they do:  \n\n- `cor(data)`\n- `heatmap(cor(data))`\n- `pairs.panels(data)` (from the **psych** package)\n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nLet's keep the full data with the names, but make a new object that is just the performance data:  \n```{r}\nqperf <- jobperf |> select(-name)\n```\n\nIt looks like we've got some very strong groups of questions there - q1 to q5 are all highly related to one another, as are q6 to q10, and q11 to q15. Furthermore, the relations between those sets are very weak, suggesting 3 groups that are fairly distinct.  \n\n```{r}\nheatmap(cor(qperf))\n```\n\nYou'll probably have to zoom in when you do this yourself, as there are a lot of little plots there!  \n```{r}\nlibrary(psych)\npairs.panels(qperf)\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nHow much variance in the set of performance indicators will be captured by 15 principal components? \n\n*Note: We can figure this out without having to do anything - it's a theoretical question!*\n\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nAll of it!  \nThe right hand entry of the \"Cumulative Var\" row is 1 - it explains everything. \n```{r}\nprincipal(qperf, nfactors = 15, rotate = \"none\")\n```\n\n`r solend()`\n\n\n\n`r qbegin(qcounter())`\nRemember, the company is wanting us to simplify things down from having 15 indicators of 'job performance' to a smaller set, that captures the most important ways in which employees vary in their performance.  \n\nWe're going to use PCA.  \nHow many components should we keep?\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nSee scree plots, parallel analysis, MAP - [Chapter 2 - PCA walkthrough](https://uoepsy.github.io/lv/02_pca.html){target=\"_blank\"}.  \n:::\n\n`r qend()`\n`r solbegin(label=\"Kaiser\", slabel=F, show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nAccording to Kaiser's rule, we should keep 3 components\n```{r}\nprincipal(qperf, nfactors = 15, rotate = \"none\")$values\n```\n\n`r solend()`\n`r solbegin(label=\"Scree\", slabel=F, show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nAccording to the Scree plot, I would suggest keeping 3 components\n```{r}\nscree(qperf, factors = FALSE)\n```\n\n`r solend()`\n`r solbegin(label=\"MAP\", slabel=F, show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nAccording to the MAP, we should keep 3 components\n\n```{r}\nVSS(qperf, n = ncol(qperf), \n    rotate = \"none\", fm = \"pc\", plot = FALSE)\n```\n\n`r solend()`\n`r solbegin(label=\"Parallel Analysis\", slabel=F, show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nAccording to the parallel analysis, we should keep 3 components \n```{r}\nfa.parallel(qperf, fa=\"pc\", n.iter = 500)\n```\n\n`r solend()`\n`r solbegin(label=\"Making a decision\", slabel=F, show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nIn this case, everything agrees that we should retain 3 components:  \n```{r}\n#| echo: false\ntibble(\n  guides = c(\"Kaiser\",\"Scree\",\"MAP\",\"Parallel Analysis\"),\n  suggestion = rep(3,4)\n) |> gt::gt()\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nConduct a principal components analysis extracting the number of components you decided on from the previous question.  \n\nBe sure to set `rotate = \"none\"` (a conventional PCA does not use rotations - it is simply about data reduction. The line is a bit blurred here, but once we start introducing rotations, we are moving more towards a form of EFA).  \n\nExamine the loadings for the components. By thinking in relation to the questions that were asked (refer back to @tbl-jpdict), what do you think each component is capturing?  \n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nIt's rarely as neat as this, but we can see the patterns of higher loadings for the groups of 5 questions on each component. \n\n- PC1 has higher loadings for q1 to q5 \n- PC2 has higher loadings for q6 to q10 \n- PC3 has higher loadings for q11 to q15 \n\nLooking back at the questions in @tbl-jpdict, questions 1 to 5 were all about stuff related to 'project management'. Questions 6 to 10 were all about collaboration with team members, and questions 11 to 15 were all about technical skill. \n\n```{r}\nprincipal(qperf, nfactors = 3, rotate = \"none\")\n```\n\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nExtract the scores on the principal components.  \nThe company wants to reward teamwork. Pick 10 people they should give a bonus to.  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nSee [Chapter 2#PCA-walkthrough - scores](https://uoepsy.github.io/lv/02_pca.html#scores){target=\"_blank\"} for how to extract scores (a score on each component for each row of our original dataset) using the `$scores` from the object fitted with `principal()`.  \n\nThis will contain as many sets of scores as there are components. One of these (given the previous question) might be of use here.  \n\nYou'll likely want to join them back to the column of names. So we can figure out who gets the bonus. `cbind()` or `bind_cols()` might help here.  \n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nThe second component seems to capture a lot of 'teamwork' related questions. So if we extract scores on that second component, we could then pick the 10 people for whom they are highest on that component.  \n\nThis will extract the scores:\n```{r}\n#| eval: false\nprincipal(qperf, nfactors = 3, rotate = \"none\")$scores\n```\n\nLet's combine them with the original data that contains the employee names, so we can figure out who to give bonuses to.  \nWe could do this with `cbind()`, or `bind_cols()`, \n```{r}\n# first we bind the columns of the scores, back to \n# the original data which contains the names\njobperf <- \n  bind_cols(\n    principal(qperf, nfactors = 3, rotate = \"none\")$scores,\n    jobperf\n  ) \n\n# we can then choose just the 10 people \n# who have the highest scores on PC2 (the teamwork component)\njobperf |> select(name, PC2) |>\n  arrange(desc(PC2))\n```\n\n`r solend()`\n\n<br>\n\n# Understanding Conduct Problems  \n\n\n:::frame\n__Data: Conduct Problems__  \n\nA researcher is developing a new brief measure of Conduct Problems. She has collected data from n=450 adolescents on 10 items, which cover the following behaviours:  \n\n1. Breaking curfew\n1. Vandalism\n1. Skipping school\n1. Bullying\n1. Spreading malicious rumours\n1. Fighting\n1. Lying\n1. Using a weapon \n1. Stealing\n1. Threatening others\n\n\nOur task is to use the dimension reduction techniques we learned about in the lecture to help inform how to organise the items she has developed into subscales.  \n\nThe data can be found at [https://uoepsy.github.io/data/conduct_probs_scale.csv](https://uoepsy.github.io/data/conduct_probs_scale.csv){target=\"_blank\"} \n\n:::\n\n`r qbegin(qcounter())`\nRead in the dataset.  \nCreate a correlation matrix for *the items*, and inspect the items to check their suitability for exploratory factor analysis (see [Chapter 3#EFA-initial checks](https://uoepsy.github.io/lv/03_efa.html#initial-checks){target=\"_blank\"}).  \n`r qend()` \n`r solbegin(show=params$SHOW, toggle=params$TOGGLE)`\n```{r}\ncpdata <- read.csv(\"https://uoepsy.github.io/data/conduct_probs_scale.csv\")\n# discard the first column\ncpdata <- cpdata[,-1]\n```\n\nHere's a correlation matrix. There's no obvious blocks of items here, but we can see that there are some fairly high correlations, as well as some weaker ones. All are positive.  \n```{r}\nheatmap(cor(cpdata))\n```\n\nThe Bartlett's test comes out with a p-value of 0 (which isn't possible, but it's been rounded for some reason). This suggests that we reject the null of this test (that our correlation matrix is proportional to the identity matrix). This is good. It basically means \"we have some non-zero correlations\"!  \n```{r}\ncortest.bartlett(cor(cpdata), n=450)\n```\n\nThe overall sampling adequacy is 0.87, which is pretty good! (or rather, which is 'meritorious'!).  MSA for all items is >.8\n```{r}\nKMO(cpdata)  \n```\n\nFinally, all the relationships here look fairly linear:\n```{r}\npairs.panels(cpdata)\n```\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nHow many dimensions should be retained?  \n\nThis question can be answered in the same way as we did above for PCA - use a scree plot, parallel analysis, and MAP test to guide you.   \n\nYou can use `fa.parallel(data, fa = \"both\")` to conduct both parallel analysis and view the scree plot!   \n`r qend()` \n\n`r solbegin(label=\"Scree\", slabel=F, show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nThe scree plot shows a kink at 3, which suggests retaining 2 components. \n```{r}\nscree(cpdata)\n```\n\n`r solend()`\n`r solbegin(label=\"MAP\", slabel=F, show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nThe MAP suggests retaining 2 factors. I'm just extracting the actuall `map` values here to save having to show all the other output. We can see that the 2nd entry is the smallest: \n```{r}\nVSS(cpdata, plot = FALSE, n = ncol(cpdata))$map\n```\n\n\n`r solend()`\n`r solbegin(label=\"Parallel Analysis\", slabel=F, show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nParallel analysis suggests 2 factors as well:\n```{r}\nfa.parallel(cpdata, fa = \"both\")\n```\n\n`r solend()`\n`r solbegin(label=\"Making a decision\", slabel=F, show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nAgain, a quite clear picture that 2 factors is preferred:  \n```{r}\n#| echo: false\ntibble(\n  guides = c(\"Scree\",\"MAP\",\"Parallel Analysis\"),\n  suggestion = rep(2,3)\n) |> gt::gt()\n```\n\n`r solend()`\n\n`r qbegin(qcounter())`\nUse the function `fa()` from the **psych** package to conduct and EFA to extract 2 factors (this is what *we* suggest based on the various tests above, but *you* might feel differently - the ideal number of factors is subjective!). Use a suitable rotation (`rotate = ?`) and extraction method (`fm = ?`).  \n```{r}\n#| eval: false\nmyfa <- fa(data, nfactors = ?, rotate = ?, fm = ?)\n```\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nWould you expect factors to be correlated? If so, you'll want an oblique rotation.  \n\nIf there are two+ underlying factors of 'conduct problems', if someone is higher on one of them, would we expect them to therefore be high/low on the other? If so, then we the two factors are correlated!   \n:::\n\n\n`r qend()` \n`r solbegin(show=params$SHOW, toggle=params$TOGGLE)`\nFor example, you could choose an oblimin rotation to allow factors to correlate and use ml as the extraction method.  \n```{r}\nconduct_efa <- fa(cpdata, nfactors=2, rotate='oblimin', fm=\"ml\")\n```\n`r solend()`\n\n`r qbegin(qcounter())`\nInspect your solution. Make sure to look at and think about the loadings, the variance accounted for, and the factor correlations (if estimated).  \n\nWhat we're doing here is essentially evaluating whether our solution looks theoretically coherent. A big part of this is a subjective decision about the groupings of items, but we would also like the numerical parts of our model to meet certain criteria (see [Chapter 3: EFA#what-makes-a-good-factor-solution](https://uoepsy.github.io/lv/03_efa.html#what-makes-a-good-factor-solution){target=\"_blank\"}).  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nJust printing an `fa` object:\n```{r}\n#| eval: false\nmyfa <- fa(data, ..... )\nmyfa\n```\nWill give you lots and lots of information.  \nYou can extract individual parts using:  \n\n- `myfa$loadings` for the loadings\n- `myfa$Vaccounted` for the variance accounted for by each factor\n- `myfa$Phi` for the factor correlation matrix\n\nYou can find a quick guide to reading the `fa` output here: [efa_output.pdf](https://uoepsy.github.io/msmr/2425/misc/efa_output.pdf){target=\"_blank\"}.  \n\n:::\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nThings look pretty good here. Each item has a clear primary loading on to one of the factors, and the complexity for all items is 1 (meaning they're clearly link to just one of the factors). The `h2` column is showing that the 2 factor solution is explaining 38%+ of the variance in each item.  Both factors are well determined, having at least 3 salient loadings.  \n\nThe 2 factors together explain 57% of the variance in the data - both factors explain a similar amount (29% for factor 1, 28% for factor 2). \n\nWe can also see that there is a moderate correlation between the two factors. Use of an oblique rotation was appropriate - if the correlation had been very weak, then it might not have differed much from if we used an orthogonal rotation.  \n\n```{r}\n#| eval: false\nconduct_efa\n```\n```{r}\n#| echo: false\n.pp(conduct_efa, l=list(1:28))\n```\n\n\n`r solend()`\n\n\n\n`r qbegin(qcounter())`\nLook back to the description of the items, and suggest a name for your factors based on the patterns of loadings.  \n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nTo sort the loadings, you can use\n```{r}\n#| eval: false\nprint(myfa$loadings, sort = TRUE)\n```\n\n:::\n\n`r qend()` \n`r solbegin(show=params$SHOW, toggle=params$TOGGLE)`\nYou can inspect the loadings using:\n```{r}\nprint(conduct_efa$loadings, sort=TRUE)\n```\nWe can see that, ordered like this, we have five items that have high loadings for one factor and another five items that have high loadings for the other.  \n  \nThe five items for factor 1 all have in common that they are non-aggressive forms of conduct problems. The five items for factor 2 are all more aggressive behaviours. We could, therefore, label our factors: ‘non-aggressive’ and ‘aggressive’ conduct problems.\n`r solend()`\n\n`r qbegin(qcounter())`\nCompare your three different solutions: \n\n1) your current solution from the previous questions\n2) one where you fit 1 more factor\n3) one where you fit 1 fewer factors   \n\nWhich one looks best?  \n\n\n::: {.callout-tip collapse=\"true\"}\n#### Hints\n\nWe're looking here to assess:  \n\n- how much variance is accounted for by each solution\n- do all factors load on 3+ items at a salient level?  \n- do all items have at least one loading at a salient level?\n- are there any \"Heywood cases\" (communalities or standardised loadings that are >1)?\n- should we perhaps remove some of the more complex items?\n- is the factor structure (items that load on to each factor) coherent, and does it make theoretical sense?\n\n:::\n\n\n`r qend()`\n`r solbegin(show=params$SHOW_SOLS, toggle=params$TOGGLE)`\n\nThe 1-factor model explains 37% of the variance (as opposed to the 57% explained by the 2 factor solution), and all items load fairly high on the factor. The downside here is that we're not discerning between different types of conduct problems that we did in the 2 factor solution.  \n```{r}\nconduct_1 <- fa(cpdata, nfactors=1, fm=\"ml\")\nconduct_1\n```\n\nThe 3-factor model explains 60% of the variance (only 3% more than the 2-factor model). Notably, the third factor is not very clearly defined - it only has 1 salient loading (possibly 2 if we consider the 0.31 to be salient, but that item is primarily loaded on the 2nd factor). \n```{r}\nconduct_3 <- fa(cpdata, nfactors=3, rotate='oblimin', fm=\"ml\")\nconduct_3\n```\n\n\n\n`r solend()`\n\n\n`r qbegin(qcounter())`\nDrawing on your previous answers and conducting any additional analyses you believe would be necessary to identify an optimal factor structure for the 10 conduct problems, write some bullet points to summarise your methods and the results of your chosen optimal model.  \n\nRemember, the main principles governing the reporting of statistical methods are transparency and reproducibility (i.e., someone should be able to reproduce your analysis based on your description).\n\n`r qend()`\n`r solbegin(show=TRUE, toggle=params$TOGGLE)`\n\nAn example summary would be:\n\n:::int \n\nFirst, the data were checked for their suitability for factor analysis. Normality was checked using visual inspection of histograms, linearity was checked through the inspection of the linear and lowess lines for the pairwise relations of the variables, and factorability was confirmed using a KMO test, which yielded an overall KMO of $.87$ with no variable KMOs $<.50$. \nAn exploratory factor analysis was conducted to inform the structure of a new conduct problems test. Inspection of a scree plot alongside parallel analysis (using principal components analysis; PA-PCA) and the MAP test were used to guide the number of factors to retain. All three methods suggested retaining two factors; however, a one-factor and three-factor solution were inspected to confirm that the two-factor solution was optimal from a substantive and practical perspective, e.g., that it neither blurred important factor distinctions nor included a minor factor that would be better combined with the other in a one-factor solution. These factor analyses were conducted using maximum likelihood estimation and (for the two- and three-factor solutions) an oblimin rotation, because it was expected that the factors would correlate. Inspection of the factor loadings and correlations reinforced that the two-factor solution was optimal: both factors were well-determined, including 5 loadings $>|0.3|$ and the one-factor model blurred the distinction between different forms of conduct problems. \nThe factor loadings are provided in @tbl-loadingtab^[You should provide the table of factor loadings. It is conventional to omit factor loadings $<|0.3|$; however, be sure to ensure that you mention this in a table note.]. Based on the pattern of factor loadings, the two factors were labelled 'aggressive conduct problems' and 'non-aggressive conduct problems'. These factors had a  correlation of $r=.43$. Overall, they accounted for 57% of the variance in the items, suggesting that a two-factor solution effectively summarised the over half of the variation in the items.\n\n\n```{r}\n#| label: tbl-loadingtab\n#| echo: false\n#| tbl-cap: \"Factor Loadings\"\nloadings = unclass(conduct_efa$loadings)\nloadings = round(loadings, 3)\nloadings = loadings[order(loadings[,1],decreasing = T),]\nloadings[abs(loadings) < 0.3] = NA\n# loadings[!is.na(loadings[,2]),] <- \n#   loadings[!is.na(loadings[,2]),][\n#     order(loadings[!is.na(loadings[,2]),2],decreasing = T),\n#   ]\nloadings\noptions(knitr.kable.NA = '')\nknitr::kable(loadings, digits = 2)\n```\n\n:::\n\n\n`r solend()`"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"include-in-header":["assets/toggling.html",{"text":"<link rel=\"stylesheet\" href=\"https://uoepsy.github.io/assets/css/ccfooter.css\" />\n"}],"number-sections":false,"output-file":"07ex.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.42","toc_float":true,"link-citations":true,"theme":["united","assets/style-labs.scss"],"title":"Week 7 Exercises: PCA & EFA","params":{"SHOW_SOLS":true,"TOGGLE":true},"editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}