---
title: "PCA in 3D"
params: 
    SHOW_SOLS: TRUE
    TOGGLE: TRUE
---

```{r setup, include=FALSE}
source('assets/setup.R')
library(rgl)
library(psych)
set.seed(33)
S = runif(3,.4,2)
f = runif(3,.7,.99)
R = f %*% t(f)
diag(R) = 1
R[1,3] <- R[2,3] <- R[3,1] <- R[3,2] <- .1
Sigma = diag(S)%*%R%*%diag(S)
Mean <- rep(0,3)
x <- MASS::mvrnorm(500, Mean, Sigma)

```

Imagine we had 3 measured variables: y1, y2, and y3, as visualised in 3-dimensional space in @fig-scat  

```{r}
#| echo: false
#| label: fig-scat
#| fig-cap: "3 measured variables"
plot3d(x, box = FALSE, xlab="y1",ylab="y2",zlab="y3")
rglwidget()
```

The cloud of datapoints in @fig-scat has a shape - it is longer in one direction (sort of diagonally across y1 and y2), slightly shorter in another (across y3), and then quite narrow in another. You can imagine trying to characterise this shape as the ellipse in @fig-ellip


```{r}
#| echo: false
#| label: fig-ellip
#| fig-cap: "An ellipsis capturing the cloud of datapoints"
plot3d(x, box = FALSE, xlab="y1",ylab="y2",zlab="y3")
plot3d(ellipse3d(Sigma, centre = Mean), col = "#A41AE4", alpha = 0.4, add = TRUE)
rglwidget()
```

When faced with trying to characterise the shape of a 3-dimensional object, we might normally think about its length, width and depth. Imagine being given a ruler and being asked to give two numbers to provide a measurement of your smartphone. What do you pick? Chances are, you will measure its length and then its width. You're likely to ignore the depth because it is much less than the other two dimensions. This is what PCA is doing. 
If we take three perpendicular dimensions, we can see that the shape in @fig-ellip is longer in one dimension, then slightly shorter in another, and very short in another. These dimensions (seen in @fig-pca3) are our principal components!  Our scree plot (indicating the amount of variance captured by each component) would look like @fig-scree - we can see that each dimension captures less and less of the variance.  

```{r}
#| label: fig-scree
#| fig-cap: "Scree plot for PCA of 3 uncorrelated variables"
#| column: margin
#| echo: false
scree(x,factor=FALSE)
```

```{r}
#| echo: false
#| label: fig-pca3
#| fig-cap: "Principal components are the axes"
plot3d(x, box = FALSE, xlab="y1",ylab="y2",zlab="y3")
plot3d(ellipse3d(Sigma, centre = Mean), col = "#A41AE4", alpha = 0.4, add = TRUE)
plot3d(
  abclines3d(0,0,0,a=principal(x,nfactors=3,rotate="none")$loadings[,1]),
  col="green", lwd=2, add=TRUE)
plot3d(
  abclines3d(0,0,0,a=principal(x,nfactors=3,rotate="none")$loadings[,2]),
             col="red",lwd=2, add=TRUE)
plot3d(
  abclines3d(0,0,0,a=principal(x,nfactors=3,rotate="none")$loadings[,3]),
           col="blue", lwd=2, add=TRUE)
rglwidget()

```

Our principal components capture sequentially the largest dimensions of the shape, which reflect where the most variance is. If there was no correlation between any of our observed variables (i.e. they're all unrelated), then we would have a shape that was basically a sphere, and the no single dimension would capture much more variance than any other. This would look something like @fig-pcano. Our scree plot would look like @fig-scree2 - we can see that each component captures a similar amount. 

```{r}
#| label: fig-scree2
#| fig-cap: "Scree plot for PCA of 3 uncorrelated variables"
#| column: margin
#| echo: false
set.seed(33)
S = runif(3,.4,2)
f = runif(3,0,.1)
R = f %*% t(f)
diag(R) = 1
Sigma2 = diag(S)%*%R%*%diag(S)
Mean2 <- rep(0,3)
x2 <- MASS::mvrnorm(500, Mean2, Sigma2)
scree(x2,factor=FALSE)
```
```{r}
#| echo: false
#| label: fig-pcano
#| fig-cap: "Principal components for 3 uncorrelated variables"
plot3d(x2, box = FALSE, xlab="y1",ylab="y2",zlab="y3")
plot3d( ellipse3d(Sigma2, centre = Mean2), col = "#A41AE4", alpha = 0.4, add = TRUE)
plot3d(
  abclines3d(0,0,0,a=principal(x2,nfactors=3,rotate="none")$loadings[,1]),
           col="green", lwd=2, add=TRUE)
plot3d(
  abclines3d(0,0,0,a=principal(x2,nfactors=3,rotate="none")$loadings[,2]),
           col="red",lwd=2, add=TRUE)
plot3d(
  abclines3d(0,0,0,a=principal(x2,nfactors=3,rotate="none")$loadings[,3]),
           col="blue", lwd=2, add=TRUE)
rglwidget()
```


The "loadings" we get out of a PCA reflect the amount to which each variable changes across the component. Try rotating the plots in @fig-pca1 and @fig-pca2, which show the first principal component and second principal component respectively. 
You will see that the first component (the black line) is much more closely linked to changes in y1 and y2 than it is to changes in y3. The second component is the opposite. This reflected in the relative weight of the loadings below! 
```{r}
#| echo: false
xx = as.data.frame(x)
names(x)<-c("y1","y2","y3")
principal(xx,nfactors=3,rotate="none")$loadings
```



```{r}
#| echo: false
#| label: fig-pca1
#| fig-cap: "The first principal component"
plot3d(x, box = FALSE, xlab="y1",ylab="y2",zlab="y3")
plot3d(ellipse3d(Sigma, centre = Mean), col = "#A41AE4", alpha = 0.4, add = TRUE)
plot3d(
  abclines3d(0,0,0,a=principal(x,nfactors=3,rotate="none")$loadings[,1]),
  col="green", lwd=2, add=TRUE)
rglwidget()
```

```{r}
#| echo: false
#| label: fig-pca2
#| fig-cap: "The second principal component"
plot3d(x, box = FALSE, xlab="y1",ylab="y2",zlab="y3")
plot3d(ellipse3d(Sigma, centre = Mean), col = "#A41AE4", alpha = 0.4, add = TRUE)
plot3d(
  abclines3d(0,0,0,a=principal(x,nfactors=3,rotate="none")$loadings[,2]),
  col="green", lwd=2, add=TRUE)
rglwidget()
```



