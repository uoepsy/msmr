[
  {
    "objectID": "02exVORLICH.html",
    "href": "02exVORLICH.html",
    "title": "Week 2 Exercises: Logistic and Longitudinal",
    "section": "",
    "text": "Data: msmr_apespecies.csv & msmr_apeage.csv\nWe have data from a large sample of great apes who have been studied between the ages of 1 to 10 years old (i.e. during adolescence). Our data includes 4 species of great apes: Chimpanzees, Bonobos, Gorillas and Orangutans. Each ape has been assessed on a primate dominance scale at various ages. Data collection was not very rigorous, so apes do not have consistent assessment schedules (i.e., one may have been assessed at ages 1, 3 and 6, whereas another at ages 2 and 8).\nThe researchers are interested in examining how the adolescent development of dominance in great apes differs between species.\nData on the dominance scores of the apes are available at https://uoepsy.github.io/data/msmr_apeage.csv and the information about which species each ape is are in https://uoepsy.github.io/data/msmr_apespecies.csv.\n\n\n\n\n\n\nTable 1: Data Dictionary: msmr_apespecies.csv\n\n\n\n\n\n\n\n\n\nvariable\ndescription\n\n\n\n\nape\nApe Name\n\n\nspecies\nSpecies (Bonobo, Chimpanzee, Gorilla, Orangutan)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 2: Data Dictionary: msmr_apeage.csv\n\n\n\n\n\n\n\n\n\nvariable\ndescription\n\n\n\n\nape\nApe Name\n\n\nage\nAge at assessment (years)\n\n\ndominance\nDominance (Z-scored)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 1\n\n\nRead in the data and check over it. Do any relevant cleaning/wrangling that might be necessary.\n\n\n\n\n\n1 - reading and joining\n\n\n\nSolution 1. We’ll read in both datasets, and then join them together.\n\nlibrary(tidyverse)\nlibrary(lme4)\nape_species &lt;- read_csv(\"https://uoepsy.github.io/data/msmr_apespecies.csv\")\nape_age &lt;- read_csv(\"https://uoepsy.github.io/data/msmr_apeage.csv\")\n\nSometimes is handy to check that all our participants are in both datasets:\n\n# are all the apes in ape_age also in ape_species?\nall(ape_age$ape %in% ape_species$ape)\n\n[1] TRUE\n\n# and vice versa?\nall(ape_species$ape %in% ape_age$ape)\n\n[1] TRUE\n\n\n\n\n\n\n\n\noptional - working with sets!\n\n\n\n\n\nI often default to using %in% and asking several questions to carefully make sure I know what’s going on - i.e. “is all of A %in% B? and is all of B %in% A, … etc.”\nThere is actually a neat way to ask these questions both at once using some handy functions (that I often forget about) to perform operations on “sets” (i.e. collections of things). These include:\n\nunion(x,y) - return everything that is in set x or in set y (or both)\nintersect(x,y) - return everything that is in both x and y\nsetdiff(x,y) - return everything in x that is not in y (not there’s asymmetry here!)\nsetequal(x,y) - are sets x and y equal?\n\nSo we can use these to ask if, e.g., the two sets of apes in each dataset are equal:\n\nsetequal(ape_species$ape,ape_age$ape)\n\n[1] TRUE\n\n\nIf you want a fun1 challenge, there are lots of other (less concise ways) that we can ask the same thing. Try and come up with a few different ways.\nE.g.: “is there anything in the union of the two sets that is not in the intersection of the two sets?”\n\nsetdiff(union(ape_species$ape,ape_age$ape), \n        intersect(ape_species$ape,ape_age$ape))\n\ncharacter(0)\n\n\n\n\n\nOkay, both datasets contain data for the same set of apes.\nLet’s join them:\n\napedat &lt;- full_join(ape_age, ape_species)\nhead(apedat)\n\n# A tibble: 6 × 4\n  ape     age dominance species   \n  &lt;chr&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;     \n1 Joel      7       0.6 chimpanzee\n2 Joel      5       1.2 chimpanzee\n3 Joel      8       1.1 chimpanzee\n4 Joel      1       0.2 chimpanzee\n5 Joel      2       0.5 chimpanzee\n6 Joel      6       1   chimpanzee\n\n\n\n\n\n\n\n2 - identifying issues\n\n\n\nSolution 2. First off, we can see that we’ve got some weird typos. Some apes have been identified as “gorrila” but it is actually spelled “gorilla”.\nAlso, we’ve got people using two alternatives for the chimps: “chimp” and “chimpanzee”. We’ll need to combine those.\n\ntable(apedat$species)\n\n\n    bonobo      chimp chimpanzee    gorilla    gorrila  orangutan \n       187        146        127        211          2        157 \n\n\nAge looks like it has some weird values (possibly “-99”?), and there are possibly a few outliers in the dominance variable. Given that dominance is standardised, it is extremely unlikely that we would see values around 20.. They’re not “impossible”, but they’re so incredibly unlikely that I’d be more comfortable assuming they are typos:\n\nhist(apedat$age, breaks=20)\nhist(apedat$dominance, breaks=20)\n\n\n\n\n\n\n\n\nJust to see what the most extreme values of dominance are:\n\n# show the biggest 5 absolute values in dominance variable\nsort(abs(apedat$dominance), decreasing = TRUE)[1:5]\n\n[1] 21.2 19.4  3.9  2.9  2.9\n\n\n\n\n\n\n\n3 - cleaning up\n\n\n\nSolution 3. \n\napedat &lt;- apedat |&gt; \n  mutate(\n    # fix species typos\n    species = case_when(\n      species %in% c(\"chimp\",\"chimpanzee\") ~ \"chimp\",\n      species %in% c(\"gorilla\",\"gorrila\") ~ \"gorilla\",\n      TRUE ~ species\n    )\n  ) |&gt;\n    filter(\n      # get rid of ages -99\n      age &gt; 0, \n      # keep when dominance is between -5 and 5 \n      # (5 here is a slightly arbitrary choice, but you can see from\n      # our checks that this will only exclude the two extreme datapoints\n      # that are 21.2 and 19.4\n      (dominance &lt; 5 & dominance &gt; -5) \n    )\n\n\n\n\n\nQuestion 2\n\n\nHow is this data structure “hierarchical” (or “clustered”)? How many levels do we have, and what are the observational units at each level?\n\n\n\n\n\nSolution\n\n\n\nSolution 4. We have a random sample of \\(\\underbrace{\\text{timepoints}}_{\\text{level 1}}\\) from a random sample of \\(\\underbrace{\\text{apes}}_{\\text{level 2}}\\).\n\n\n\n\nQuestion 3\n\n\nFor how many apes do we have data? How many of each species?\nHow many datapoints does each ape have?\n\n\n\n\n\n\nHints\n\n\n\n\n\nWe’ve seen this last week too - counting the different levels in our data. See Chapter 4: logisticMLM - #getting-to-know-my-monkeys for an example (also about monkeys!)\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 5. We have 168 apes in our dataset:\n\nlength(unique(apedat$ape))\n\n[1] 168\n\n\nHere’s how many of each species:\n\napedat |&gt; \n  group_by(species) |&gt;\n  summarise(\n   n_apes = n_distinct(ape) \n  )\n\n# A tibble: 4 × 2\n  species   n_apes\n  &lt;chr&gt;      &lt;int&gt;\n1 bonobo        36\n2 chimp         56\n3 gorilla       46\n4 orangutan     30\n\n\nLet’s create a table of how many observations for each ape, and then we can create a table from that table, to show how many apes have 2 datapoints, how many have 3, 4, and so on:\n\ntable(apedat$ape) |&gt;\n  table() |&gt;\n  barplot()\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 4\n\n\nMake a plot to show how dominance changes for each ape as they get older.\n\n\n\n\n\n\nHints\n\n\n\n\n\nIn Chapter 5: Longitudinal MLM - #exploring-the-data we made a facet for each cluster (each participant). That was fine because we had only 20 people. In this dataset we have 168! That’s too many to facet. We could try using group aesthetic instead, to plot multiple lines on the same plot, or we could just plot a sample of our apes. This is all just an initial look at the data, after all.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 6. Here’s a line for each ape, and a facet for each species:\n\nggplot(apedat, aes(x = age, y = dominance, col = species))+\n  geom_line(aes(group = ape)) + \n  facet_wrap(~species) + \n  guides(col=\"none\")\n\n\n\n\n\n\n\n\nIt’s kind of hard to see the trend for each ape, so let’s also make a separate little linear model for each ape:\n\nggplot(apedat, aes(x = age, y = dominance, col = species))+\n  geom_smooth(aes(group = ape), method=lm, se=FALSE) + \n  facet_wrap(~species) + \n  guides(col=\"none\")\n\n\n\n\n\n\n\n\nAlternatively, let’s take a sample of apes, and plot the same stuff but facetted:\n\napedat |&gt;\n  # choose the rows where ape ID is one of a random sample of 16 ape IDs\n  filter(ape %in% sample(unique(apedat$ape), 16) ) |&gt;\n  ggplot(aes(x = age, y = dominance, col = species))+\n  geom_point() +\n  geom_smooth(method=lm, se=FALSE)+\n  facet_wrap(~ape)\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nRecenter the age variable on 1, which is the youngest ages that we’ve got data on for any of our species.\nThen fit a model that estimates the differences between primate species in how dominance changes over time.\n\n\n\n\n\n\nHints\n\n\n\n\n\nthink slowly about “differences between primate species in how dominance changes over time”.\n\n“how dominance changes over time” – sounds like dominance ~ time\nso differences between primate species in this would require the interaction dominance ~ time * species\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 7. \n\napedat$age = apedat$age-1 \n\nm.full &lt;- lmer(dominance ~ 1 + age * species + (1 + age | ape), data = apedat)\n\n\n\n\n\nQuestion 6\n\n\nDo primate species differ in the growth of dominance?\nPerform an appropriate test/comparison.\n\n\n\n\n\n\nHints\n\n\n\n\n\nThis is asking about the age*species interaction, which in our model is represented by 3 parameters. To assess the overall question, it might make more sense to do a model comparison.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 8. \n\nm.int &lt;- lmer(dominance ~ 1 + age + species + (1 + age | ape), data = apedat)\n\nanova(m.int, m.full)\n\nData: apedat\nModels:\nm.int: dominance ~ 1 + age + species + (1 + age | ape)\nm.full: dominance ~ 1 + age * species + (1 + age | ape)\n       npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)   \nm.int     9 806.67 849.11 -394.34   788.67                        \nm.full   12 801.16 857.74 -388.58   777.16 11.517  3   0.009237 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nSpecies differ in how dominance changes over adolescence (\\(\\chi^2(3) = 11.52, p = 0.009\\)).\n\n\n\n\n\nQuestion 7\n\n\nPlot the average model predicted values for each age.\nBefore you plot.. do you expect to see straight lines? (remember, not every ape is measured at age 2, or age 3, etc).\n\n\n\n\n\n\nHints\n\n\n\n\n\nThis is like taking predict() from the model, and then then grouping by age, and calculating the mean of those predictions. However, we can do this more easily using augment() and then some fancy stat_summary() in ggplot (see the lecture).\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 9. Averaging fitted values would give us straight lines if every ape had data at all ages, but in our study we have some apes with only 2 data points, and each ape has different set of ages (e.g., one ape might be measured at age 3, 6, and 10, another ape might be at ages 2 and 16).\n\nlibrary(broom.mixed)\n\naugment(m.full) |&gt;\nggplot(aes(age,dominance, color=species)) +\n  # the point ranges are our observations\n  stat_summary(fun.data=mean_se, geom=\"pointrange\") + \n  # the lines are our average predictions  \n  stat_summary(aes(y=.fitted, linetype=species), fun=mean, geom=\"line\")\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 8\n\n\nPlot the model based fixed effects:\n\n\n\n\n\nSolution\n\n\n\nSolution 10. \n\neffects::effect(\"age*species\", m.full, xlevels=10) |&gt;\n  as.data.frame() |&gt;\n  ggplot(aes(x=age+1,y=fit,col=species))+\n  geom_line(lwd=1)+\n  geom_ribbon(aes(ymin=lower,ymax=upper,fill=species),col=NA,alpha=.3) +  \n  scale_color_manual(values=c(\"grey30\",\"black\",\"grey50\",\"darkorange\")) +\n  scale_fill_manual(values=c(\"grey30\",\"black\",\"grey50\",\"darkorange\")) +\n  facet_wrap(~species) + \n  guides(col=\"none\",fill=\"none\") +\n  labs(x=\"Age (years)\")\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 9\n\n\nInterpret each of the fixed effects from the model (you might also want to get some p-values or confidence intervals).\n\n\n\n\n\n\nHints\n\n\n\n\n\nEach of the estimates should correspond to part of our plot from the previous question.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 11. Let’s get some confidence intervals:\n\nconfint(m.full, method=\"profile\",\n        parm = \"beta_\")\n\n                           2.5 %      97.5 %\n(Intercept)          -0.67066925 -0.17299177\nage                   0.02361398  0.08142209\nspecieschimp          0.13383485  0.77009884\nspeciesgorilla        0.28124162  0.94933844\nspeciesorangutan     -0.38909919  0.34257548\nage:specieschimp     -0.03973125  0.03392308\nage:speciesgorilla   -0.05012759  0.02799393\nage:speciesorangutan -0.10625760 -0.02167806\n\n\n\n\n\n\n\n\n\n\nterm\nest\nCI\ninterpretation\n\n\n\n\n(Intercept)\n-0.42\n[-0.67, -0.17]*\nestimated dominance of 1 year old bonobos (at left hand side of plot, bonobo line is lower than 0)\n\n\nage\n0.05\n[0.02, 0.08]*\nestimated change in dominance score for every year older a bonobo gets (slope of bonobo line)\n\n\nspecieschimp\n0.45\n[0.13, 0.77]*\nestimated difference in dominance scores at age 1 between bonobos and chimps (at left hand side of plot, chimp line is higher than bonobo line)\n\n\nspeciesgorilla\n0.62\n[0.28, 0.95]*\nestimated difference in dominance scores at age 1 between bonobos and gorillas (at left hand side of plot, gorilla line is higher than bonobo line)\n\n\nspeciesorangutan\n-0.02\n[-0.39, 0.34]\nno significant difference in dominance scores at age 1 between bonobos and orangutans (at the left hand side of our plot, orangutan line is similar height to bonobo line)\n\n\nage:specieschimp\n0.00\n[-0.04, 0.03]\nno significant difference between chimps and bonobos in the change in dominance for every year older (slope of chimp line is similar to slope of bonobo line)\n\n\nage:speciesgorilla\n-0.01\n[-0.05, 0.03]\nno significant difference between gorillas and bonobos in the change in dominance for every year older (slope of gorilla line is similar to slope of bonobo line)\n\n\nage:speciesorangutan\n-0.06\n[-0.11, -0.02]*\nestimated difference between orangutans and bonobos in the change in dominance for every year older (slope of orangutan line is less steep than slope of bonobo line)"
  },
  {
    "objectID": "02exVORLICH.html#footnotes",
    "href": "02exVORLICH.html#footnotes",
    "title": "Week 2 Exercises: Logistic and Longitudinal",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nreally!?!?↩︎"
  },
  {
    "objectID": "01ex.html",
    "href": "01ex.html",
    "title": "Week 1 Exercises: Intro to MLM",
    "section": "",
    "text": "New Packages!\n\n\n\n\n\nThese are the main packages we’re going to use in this block. It might make sense to install them now if you do not have them already\n\ntidyverse : for organising data\n\nlme4 : for fitting generalised linear mixed effects models\nbroom.mixed : tidying methods for mixed models\neffects : for tabulating and graphing effects in linear models\nlmerTest: for quick p-values from mixed models\nparameters: various inferential methods for mixed models",
    "crumbs": [
      "Week 1 Exercises: Intro to MLM"
    ]
  },
  {
    "objectID": "01ex.html#footnotes",
    "href": "01ex.html#footnotes",
    "title": "Week 1 Exercises: Intro to MLM",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage sources:http://tophatsasquatch.com/2012-tmnt-classics-action-figures/https://www.dezeen.com/2016/02/01/barbie-dolls-fashionista-collection-mattel-new-body-types/https://www.wish.com/product/5da9bc544ab36314cfa7f70chttps://www.worldwideshoppingmall.co.uk/toys/jumbo-farm-animals.asphttps://www.overstock.com/Sports-Toys/NJ-Croce-Scooby-Doo-5pc.-Bendable-Figure-Set-with-Scooby-Doo-Shaggy-Daphne-Velma-and-Fred/28534567/product.htmlhttps://tvtropes.org/pmwiki/pmwiki.php/Toys/Furbyhttps://www.fun.com/toy-story-4-figure-4-pack.htmlhttps://www.johnlewis.com/lego-minifigures-71027-series-20-pack/p5079461↩︎",
    "crumbs": [
      "Week 1 Exercises: Intro to MLM"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Multivariate Statistics and Methodology in R",
    "section": "",
    "text": "Multivariate Statistics and Methodology in R (MSMR) is an advanced semester-long course designed for Masters students in psychology seeking a deeper understanding of statistical techniques to analyze complex data sets with multiple sources of variation. Building on the foundation laid by the Univariate Statistics and Methodology in R (USMR) course, MSMR extends students’ analytical repertoire to encompass multilevel models, Principal Component Analysis (PCA), Exploratory Factor Analysis (EFA), Confirmatory Factor Analysis (CFA), and Structural Equation Modeling (SEM).\nThe initial half of the course introduces students to the intricacies of multilevel models, providing a solid theoretical framework for understanding hierarchical data structures. Students will gain practical insights into applying these models to address research questions involving nested data and varying sources of variation.\nThe second half of the course delves into methods such as PCA and EFA for reducing dimensionality of data, before moving to Confirmatory Factor models and subsequently Structural Equation Models as a means of modeling and testing our theories about psychological constructs."
  },
  {
    "objectID": "00ex.html",
    "href": "00ex.html",
    "title": "Extra Exercises: Regression Refresher",
    "section": "",
    "text": "Workplace Pride\n\nData: lmm_jsup.csv\nA questionnaire was sent to all UK civil service departments, and the lmm_jsup.csv dataset contains all responses that were received. Some of these departments work as hybrid or ‘virtual’ departments, with a mix of remote and office-based employees. Others are fully office-based.\nThe questionnaire included items asking about how much the respondent believe in the department and how it engages with the community, what it produces, how it operates and how treats its people. A composite measure of ‘workplace-pride’ was constructed for each employee. Employees in the civil service are categorised into 3 different roles: A, B and C. The roles tend to increase in responsibility, with role C being more managerial, and role A having less responsibility. We also have data on the length of time each employee has been in the department (sometimes new employees come straight in at role C, but many of them start in role A and work up over time).\nWe’re interested in whether the different roles are associated with differences in workplace-pride.\nDataset: https://uoepsy.github.io/data/lmm_jsup.csv.\n\n\n\n\n\n\n\n\nvariable\ndescription\n\n\n\n\ndepartment_name\nName of government department\n\n\ndept\nDepartment Acronym\n\n\nvirtual\nWhether the department functions as hybrid department with various employees working remotely (1), or as a fully in-person office (0)\n\n\nrole\nEmployee role (A, B or C)\n\n\nseniority\nEmployees seniority point. These map to roles, such that role A is 0-4, role B is 5-9, role C is 10-14. Higher numbers indicate more seniority\n\n\nemployment_length\nLength of employment in the department (years)\n\n\nwp\nComposite Measure of 'Workplace Pride'\n\n\n\n\n\n\n\n\n\nQuestion 1\n\n\nRead in the data and provide some descriptive statistics.\n\n\n\n\n\n\nHints\n\n\n\n\n\nDon’t remember how to do descriptives? Think back to previous courses - it’s time for some means, standard deviations, mins and maxes. For categorical variables we can do counts or proportions.\nWe’ve seen various functions such as summary(), and also describe() from the psych package.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 1. Here’s the dataset:\n\nlibrary(tidyverse) # for data wrangling\nlibrary(psych) \n\njsup &lt;- read_csv(\"https://uoepsy.github.io/data/lmm_jsup.csv\")\n\nLet’s take just the numeric variables and get some descriptives:\n\njsup |&gt; \n  select(employment_length, wp) |&gt; \n  describe()\n\n                  vars   n  mean   sd median trimmed  mad  min   max range\nemployment_length    1 295 12.62 4.28  13.00   12.60 4.45 0.00 30.00 30.00\nwp                   2 295 25.49 5.27  25.44   25.46 5.93 6.34 38.46 32.12\n                   skew kurtosis   se\nemployment_length  0.08     0.38 0.25\nwp                -0.05    -0.14 0.31\n\n\nAnd make frequency tables for the categorical ones:\n\ntable(jsup$role)\n\n\n  A   B   C \n109  95  91 \n\n\nI’m going to use dept rather than department_name as the output will be easier to see:\n\ntable(jsup$dept)\n\n\n   ACE    CMA    CPS    FSA    GLD   HMRC    NCA   NS&I  OFGEM OFQUAL OFSTED \n    17     21     13     25     17     16     20     20     15      5     17 \n OFWAT    ORR    SFO   UKSA   UKSC \n    16     17     18     45     13 \n\ntable(jsup$virtual)\n\n\n  0   1 \n175 120 \n\n\n\n\n\n\nQuestion 2\n\n\nAre there differences in ‘workplace-pride’ between people in different roles?\n\n\n\n\n\n\nHints\n\n\n\n\n\ndoes y [continuous variable] differ by x [three groups]? lm(y ~ x)?\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 2. \n\nmod1 &lt;- lm(wp ~ role, data = jsup)\n\nRather than doing summary(model) - I’m just going to use the broom package to pull out some of the stats in nice tidy dataframes.\nThe glance() function will give us things like the \\(R^2\\) values and \\(F\\)-statistic (basically all the stuff that is at the bottom of the summary()):\n\nlibrary(broom)\nglance(mod1)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.216         0.211  4.68      40.3 3.44e-16     2  -872. 1753. 1768.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\nThe tidy() function will give us the coefficients, standard errors, t-statistics and p-values. It’s the same information, just neater!\n\ntidy(mod1)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    28.1      0.448     62.6  3.66e-171\n2 roleB          -2.24     0.657     -3.41 7.33e-  4\n3 roleC          -5.95     0.665     -8.95 4.38e- 17\n\n\nAlternatively, we can get some quick confidence intervals for our coefficients:\n\nconfint(mod1)\n\n                2.5 %     97.5 %\n(Intercept) 27.167804 28.9329302\nroleB       -3.536088 -0.9494885\nroleC       -7.255030 -4.6382319\n\n\nIt looks like roles do differ in their workplace pride. Specifically, compared to people in role A, people who are in roles B and C on average report less pride in the workplace.\n\n\n\n\n\nQuestion 3\n\n\nIs it something about the roles that make people report differences in workplace-pride, or is it possibly just that people who are newer to the company tend to feel more pride than those who have been there for a while (they’re all jaded), and the people in role A tend to be much newer to the company (making it look like the role A results in taking more pride). In other words, if we were to compare people in role A vs role B vs role C but hold constant their employment_length, we might see something different?\nFit another model to find out.\nTo help with interpreting the model, make a plot that shows all of the relevant variables that are in the model in one way or another.\n\n\n\n\n\n\nHints\n\n\n\n\n\nSo we want to adjust for how long people have been part of the company..\nRemember - if we want to estimate the effect of x on y while adjusting for z, we can do lm(y ~ z + x).\nFor the plot - put something on the x, something on the y, and colour it by the other variable.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 3. \n\nmod2 &lt;- lm(wp ~ employment_length + role, data = jsup)\n\ntidy(mod2)\n\n# A tibble: 4 × 5\n  term              estimate std.error statistic   p.value\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)         36.1      0.709     50.9   6.90e-147\n2 employment_length   -0.834    0.0637   -13.1   4.32e- 31\n3 roleB                0.510    0.563      0.906 3.65e-  1\n4 roleC               -0.704    0.663     -1.06  2.89e-  1\n\n\nNote that, after adjusting for employment length, there are no significant differences in wp between roles B or C compared to A.\nIf we plot the data to show all these variables together, we can kind of see why! Given the pattern of wp against employment_length, the wp for different roles are pretty much where we would expect them to be if role doesn’t make any difference (i.e., if role doesn’t shift your wp up or down).\n\nggplot(jsup, aes(x=employment_length,y=wp,col=role))+\n  geom_point(size=3,alpha=.3)\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 4\n\n\nDo roles differ in their workplace-pride, when adjusting for time in the company?\n\n\n\n\n\n\nHints\n\n\n\n\n\nThis may feel like a repeat of the previous question, but note that this is not a question about specific group differences. It is about whether, overall, the role groups differ. So it’s wanting to test the joint effect of the two additional parameters we’ve just added to our model. (hint hint model comparison!)\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 4. \n\nmod2a &lt;- lm(wp ~ employment_length, data = jsup)\nmod2 &lt;- lm(wp ~ employment_length + role, data = jsup)\n\nanova(mod2a, mod2)\n\nAnalysis of Variance Table\n\nModel 1: wp ~ employment_length\nModel 2: wp ~ employment_length + role\n  Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)\n1    293 4090.8                           \n2    291 4028.9  2    61.864 2.2342 0.1089\n\n\nThis is no surprise given the previous question, we just now have a single test to report if we wanted to - after accounting for employment length, role does not explain a significant amount of variance in workplace pride.\n\n\n\n\nQuestion 5\n\n\nLet’s take a step back and remember what data we actually have. We’ve got 295 people in our dataset, from 16 departments.\nDepartments may well differ in the general amount of workplace-pride people report. People love to say that they work in the “National Crime Agency”, but other departments might not elicit such pride (*cough* HM Revenue & Customs *cough*). We need to be careful not to mistake department differences as something else (like differences due to the job role).\nMake a couple of plots to look at:\n\nhow many of each role we have from each department\nhow departments differ in their employees’ pride in their workplace\n\n\n\n\n\n\nSolution\n\n\n\nSolution 5. \n\nggplot(jsup, aes(x = role)) + \n  geom_bar()+\n  facet_wrap(~dept)\n\n\n\n\n\n\n\n\nIn this case, it looks like most of the departments have similar numbers of each role, apart from the UKSA (“UK Statistics Authority”), where we’ve got loads more of role A, and very few role C..\nNote also that in the plot below, the UKSA is, on average, full of employees who take a lot of pride in their work. Is this due to the high proportion of people in role A? or is the effect of role we’re seeing more due to differences in departments?\n\nggplot(jsup, aes(x = dept, y = wp)) +\n  geom_boxplot() +\n  scale_x_discrete(labels = label_wrap_gen(35)) + \n  coord_flip()\n\n\n\n\n\n\n\n\nEven if we had perfectly equal numbers of roles in each department, we’re also adjusting for other things such as employment_length, and the extent to which this differs by department can have trickle-on effects on our coefficient of interest (the role coefficients).\n\n\n\n\nQuestion 6\n\n\nAdjusting for both length of employment and department, are there differences in ‘workplace-pride’ between the different roles?\nCan you make a plot of all four of the variables involved in our model?\n\n\n\n\n\n\nHints\n\n\n\n\n\nMaking the plot might take some thinking. We’ve now added dept into the mix, so a nice way might be to use facet_wrap() to make the same plot as the one we did previously, but for each department.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 6. \n\nmod3 &lt;- lm(wp ~ employment_length + dept + role, data = jsup)\ntidy(mod3)\n\n# A tibble: 19 × 5\n   term              estimate std.error statistic   p.value\n   &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)        36.4       0.631    57.6    7.17e-156\n 2 employment_length  -0.882     0.0344  -25.7    4.71e- 75\n 3 deptCMA            -3.80      0.649    -5.85   1.39e-  8\n 4 deptCPS            -0.217     0.730    -0.298  7.66e-  1\n 5 deptFSA             4.74      0.625     7.60   4.71e- 13\n 6 deptGLD             0.0582    0.682     0.0853 9.32e-  1\n 7 deptHMRC           -3.79      0.692    -5.47   1.02e-  7\n 8 deptNCA            -3.85      0.655    -5.88   1.18e-  8\n 9 deptNS&I           -0.574     0.654    -0.878  3.81e-  1\n10 deptOFGEM          -0.648     0.705    -0.919  3.59e-  1\n11 deptOFQUAL         -4.94      1.01     -4.89   1.71e-  6\n12 deptOFSTED         -5.88      0.683    -8.61   5.52e- 16\n13 deptOFWAT          -1.21      0.692    -1.75   8.17e-  2\n14 deptORR            -2.85      0.681    -4.18   3.98e-  5\n15 deptSFO            -1.36      0.672    -2.02   4.47e-  2\n16 deptUKSA            4.28      0.576     7.43   1.32e- 12\n17 deptUKSC           -2.31      0.732    -3.16   1.77e-  3\n18 roleB               1.42      0.303     4.68   4.47e-  6\n19 roleC               1.31      0.366     3.59   3.92e-  4\n\n\nIn a way, adding predictors to our model is kind of like splitting up our plots by that predictor to see the patterns. This becomes more and more difficult (/impossible) as we get more variables, but right now we can split the data into all the constituent parts.\n\nggplot(jsup, aes(x = employment_length, y = wp, col = role)) +\n  geom_point(size=3,alpha=.4)+\n  facet_wrap(~dept)\n\n\n\n\n\n\n\n\nThe association between wp and employment_length is clear in all these little sub-plots - there’s a downward trend. The department differences can be seen too: UKSA is generally a bit higher, HMRC and UKSC a bit lower, and so on. By default, the model captures these coefficients as ‘differences from the reference group’, so all these coefficients are in relation to the “ACE” department.\nSeeing the role differences is a bit harder in this plot, but think about what you would expect to see if there were no differences in roles (i.e. imagine if they were all in role A). Take for instance the FSA department, where this is easiest to see - for the people who are in role C, for people of their employment length we would expect their wp to be lower if they were in role A. Likewise for those in role B. Across all these departments, the people in role B and C (green and blue dots respectively) are a bit higher than we would expect. This is what the model coefficients tell us!\n\n\n\n\nQuestion 7\n\n\nNow we’re starting to acknowledge the grouped structure of our data - these people in our dataset are related to one another in that some belong to dept 1, some dept 2, and so on..\nLet’s try to describe our sample in a bit more detail.\n\nhow many participants do we have, and from how many departments?\nhow many participants are there, on average, from each department? what is the minimum and maximum?\nwhat is the average employment length for our participants?\nhow many departments are ‘virtual departments’ vs office-based?\n\nwhat is the overall average reported workplace-pride?\nhow much variation in workplace-pride is due to differences between departments?\n\n\n\n\n\n\n\nHints\n\n\n\n\n\nThe first lot of these questions can be answered using things like count(), summary(), table(), mean(), min() etc. See 1: Clustered Data #determining-sample-sizes\nFor the last one, we can use the ICC! See 1: Clustered Data #icc\n\n\n\n\n\n\n\n\nSolution\n\n\n\nSolution 7. How many respondents do we have, and from how many departments?\n\nnrow(jsup)\n\n[1] 295\n\nlength(table(jsup$dept))\n\n[1] 16\n\n\nHow many respondents are there, on average, from each dept? What is the minimum and maximum number of people in any one department?\n\njsup |&gt;\n  count(dept) |&gt; \n  summarise(min=min(n),\n            max=max(n),\n            median=median(n)\n  )\n\n# A tibble: 1 × 3\n    min   max median\n  &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;\n1     5    45     17\n\n\nWhat is the average employment length of respondents?\n\nmean(jsup$employment_length)\n\n[1] 12.61695\n\n\nHow many departments are virtual vs office based? This requires a bit more than just table(jsup$virtual), because we are describing a variable at the department level.\n\njsup |&gt; \n  group_by(virtual) |&gt;\n  summarise(\n    ndept = n_distinct(dept)\n  )\n\n# A tibble: 2 × 2\n  virtual ndept\n    &lt;dbl&gt; &lt;int&gt;\n1       0    11\n2       1     5\n\n\nWhat is the overall average ‘workplace-pride’? What is the standard deviation?\n\nmean(jsup$wp)\n\n[1] 25.49373\n\nsd(jsup$wp)\n\n[1] 5.270847\n\n\nFinally, how much variation in workplace-pride is attributable to department-level differences?\n\nICC::ICCbare(x = dept, y = wp, data = jsup)\n\n[1] 0.4394114\n\n\n\n\n\n\nQuestion 8\n\n\nWhat if we would like to know whether, when adjusting for differences due to employment length and roles, workplace-pride differs between people working in virtual-departments compared to office-based ones?\nCan you add this to the model? What happens?\n\n\n\n\n\nSolution\n\n\n\nSolution 8. Let’s add the virtual predictor to our model. Note that we don’t actually get a coefficient here - it is giving us an NA!\n\nmod4 &lt;- lm(wp ~ employment_length + dept + role + virtual, data = jsup)\n\nsummary(mod4)\n\n\nCall:\nlm(formula = wp ~ employment_length + dept + role + virtual, \n    data = jsup)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.6901 -1.4040 -0.0269  1.1782  5.0542 \n\nCoefficients: (1 not defined because of singularities)\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       36.35219    0.63098  57.612  &lt; 2e-16 ***\nemployment_length -0.88169    0.03436 -25.658  &lt; 2e-16 ***\ndeptCMA           -3.79695    0.64901  -5.850 1.39e-08 ***\ndeptCPS           -0.21732    0.73037  -0.298 0.766271    \ndeptFSA            4.74482    0.62453   7.597 4.71e-13 ***\ndeptGLD            0.05816    0.68221   0.085 0.932117    \ndeptHMRC          -3.78587    0.69236  -5.468 1.02e-07 ***\ndeptNCA           -3.85033    0.65486  -5.880 1.18e-08 ***\ndeptNS&I          -0.57367    0.65372  -0.878 0.380951    \ndeptOFGEM         -0.64794    0.70497  -0.919 0.358850    \ndeptOFQUAL        -4.94134    1.01041  -4.890 1.71e-06 ***\ndeptOFSTED        -5.88455    0.68314  -8.614 5.52e-16 ***\ndeptOFWAT         -1.20866    0.69172  -1.747 0.081692 .  \ndeptORR           -2.84522    0.68127  -4.176 3.98e-05 ***\ndeptSFO           -1.35503    0.67189  -2.017 0.044689 *  \ndeptUKSA           4.28197    0.57593   7.435 1.32e-12 ***\ndeptUKSC          -2.31312    0.73248  -3.158 0.001765 ** \nroleB              1.41790    0.30286   4.682 4.47e-06 ***\nroleC              1.31478    0.36632   3.589 0.000392 ***\nvirtual                 NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.982 on 276 degrees of freedom\nMultiple R-squared:  0.8673,    Adjusted R-squared:  0.8587 \nF-statistic: 100.2 on 18 and 276 DF,  p-value: &lt; 2.2e-16\n\n\nSo what is happening? If we think about it, if we separate out “differences due to departments” then there is nothing left to compare between departments that are virtual vs office based. Adding the between-department predictor of virtual doesn’t explain anything more - the residual sums of squares doesn’t decrease at all:\n\nanova(\n  lm(wp ~ employment_length + dept + role, data = jsup),\n  lm(wp ~ employment_length + dept + role + virtual, data = jsup)\n)\n\nAnalysis of Variance Table\n\nModel 1: wp ~ employment_length + dept + role\nModel 2: wp ~ employment_length + dept + role + virtual\n  Res.Df    RSS Df Sum of Sq F Pr(&gt;F)\n1    276 1083.8                      \n2    276 1083.8  0         0         \n\n\nAnother way of thinking about this: knowing the average workplace-pride for the department that someone is in tells me what to expect about that person’s workplace pride. But once I know their department’s average workplace-pride, knowing whether it is ‘virtual’ or ‘office-based’ doesn’t tell me anything new, for the very fact that the virtual/office-based distinction comes from comparing different departments.\nBut we’re not really interested in these departments specifically! What would be nice would be if we can look at the relevant effects of interest (things like role and virtual), but then just think of the department differences as just some sort of random variation. So we want to think of departments in a similar way to how we think of our individual employees - they vary randomly around what we expect - only they’re at a different level of observation. Such an approach is what we will learn about this semester - “multilevel models”!",
    "crumbs": [
      "Extra Exercises: Regression Refresher"
    ]
  },
  {
    "objectID": "02ex.html",
    "href": "02ex.html",
    "title": "Week 2 Exercises: Logistic and Longitudinal",
    "section": "",
    "text": "Data: msmr_apespecies.csv & msmr_apeage.csv\nWe have data from a large sample of great apes who have been studied between the ages of 1 to 10 years old (i.e. during adolescence). Our data includes 4 species of great apes: Chimpanzees, Bonobos, Gorillas and Orangutans. Each ape has been assessed on a primate dominance scale at various ages. Data collection was not very rigorous, so apes do not have consistent assessment schedules (i.e., one may have been assessed at ages 1, 3 and 6, whereas another at ages 2 and 8).\nThe researchers are interested in examining how the adolescent development of dominance in great apes differs between species.\nData on the dominance scores of the apes are available at https://uoepsy.github.io/data/msmr_apeage.csv and the information about which species each ape is are in https://uoepsy.github.io/data/msmr_apespecies.csv.\n\n\n\n\n\n\nTable 1: Data Dictionary: msmr_apespecies.csv\n\n\n\n\n\n\n\n\n\nvariable\ndescription\n\n\n\n\nape\nApe Name\n\n\nspecies\nSpecies (Bonobo, Chimpanzee, Gorilla, Orangutan)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 2: Data Dictionary: msmr_apeage.csv\n\n\n\n\n\n\n\n\n\nvariable\ndescription\n\n\n\n\nape\nApe Name\n\n\nage\nAge at assessment (years)\n\n\ndominance\nDominance (Z-scored)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 1\n\n\nRead in the data and check over it. Do any relevant cleaning/wrangling that might be necessary.\n\n\n\n\n\n1 - reading and joining\n\n\n\nSolution 1. We’ll read in both datasets, and then join them together.\n\nlibrary(tidyverse)\nlibrary(lme4)\nape_species &lt;- read_csv(\"https://uoepsy.github.io/data/msmr_apespecies.csv\")\nape_age &lt;- read_csv(\"https://uoepsy.github.io/data/msmr_apeage.csv\")\n\nSometimes is handy to check that all our participants are in both datasets:\n\n# are all the apes in ape_age also in ape_species?\nall(ape_age$ape %in% ape_species$ape)\n\n[1] TRUE\n\n# and vice versa?\nall(ape_species$ape %in% ape_age$ape)\n\n[1] TRUE\n\n\n\n\n\n\n\n\noptional - working with sets!\n\n\n\n\n\nI often default to using %in% and asking several questions to carefully make sure I know what’s going on - i.e. “is all of A %in% B? and is all of B %in% A, … etc.”\nThere is actually a neat way to ask these questions both at once using some handy functions (that I often forget about) to perform operations on “sets” (i.e. collections of things). These include:\n\nunion(x,y) - return everything that is in set x or in set y (or both)\nintersect(x,y) - return everything that is in both x and y\nsetdiff(x,y) - return everything in x that is not in y (not there’s asymmetry here!)\nsetequal(x,y) - are sets x and y equal?\n\nSo we can use these to ask if, e.g., the two sets of apes in each dataset are equal:\n\nsetequal(ape_species$ape,ape_age$ape)\n\n[1] TRUE\n\n\nIf you want a fun1 challenge, there are lots of other (less concise ways) that we can ask the same thing. Try and come up with a few different ways.\nE.g.: “is there anything in the union of the two sets that is not in the intersection of the two sets?”\n\nsetdiff(union(ape_species$ape,ape_age$ape), \n        intersect(ape_species$ape,ape_age$ape))\n\ncharacter(0)\n\n\n\n\n\nOkay, both datasets contain data for the same set of apes.\nLet’s join them:\n\napedat &lt;- full_join(ape_age, ape_species)\nhead(apedat)\n\n# A tibble: 6 × 4\n  ape     age dominance species   \n  &lt;chr&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;     \n1 Joel      7       0.6 chimpanzee\n2 Joel      5       1.2 chimpanzee\n3 Joel      8       1.1 chimpanzee\n4 Joel      1       0.2 chimpanzee\n5 Joel      2       0.5 chimpanzee\n6 Joel      6       1   chimpanzee\n\n\n\n\n\n\n\n2 - identifying issues\n\n\n\nSolution 2. First off, we can see that we’ve got some weird typos. Some apes have been identified as “gorrila” but it is actually spelled “gorilla”.\nAlso, we’ve got people using two alternatives for the chimps: “chimp” and “chimpanzee”. We’ll need to combine those.\n\ntable(apedat$species)\n\n\n    bonobo      chimp chimpanzee    gorilla    gorrila  orangutan \n       187        146        127        211          2        157 \n\n\nAge looks like it has some weird values (possibly “-99”?), and there are possibly a few outliers in the dominance variable. Given that dominance is standardised, it is extremely unlikely that we would see values around 20.. They’re not “impossible”, but they’re so incredibly unlikely that I’d be more comfortable assuming they are typos:\n\nhist(apedat$age, breaks=20)\nhist(apedat$dominance, breaks=20)\n\n\n\n\n\n\n\n\nJust to see what the most extreme values of dominance are:\n\n# show the biggest 5 absolute values in dominance variable\nsort(abs(apedat$dominance), decreasing = TRUE)[1:5]\n\n[1] 21.2 19.4  3.9  2.9  2.9\n\n\n\n\n\n\n\n3 - cleaning up\n\n\n\nSolution 3. \n\napedat &lt;- apedat |&gt; \n  mutate(\n    # fix species typos\n    species = case_when(\n      species %in% c(\"chimp\",\"chimpanzee\") ~ \"chimp\",\n      species %in% c(\"gorilla\",\"gorrila\") ~ \"gorilla\",\n      TRUE ~ species\n    )\n  ) |&gt;\n    filter(\n      # get rid of ages -99\n      age &gt; 0, \n      # keep when dominance is between -5 and 5 \n      # (5 here is a slightly arbitrary choice, but you can see from\n      # our checks that this will only exclude the two extreme datapoints\n      # that are 21.2 and 19.4\n      (dominance &lt; 5 & dominance &gt; -5) \n    )\n\n\n\n\n\nQuestion 2\n\n\nHow is this data structure “hierarchical” (or “clustered”)? How many levels do we have, and what are the observational units at each level?\n\n\n\n\nWe have a random sample of \\(\\underbrace{\\text{timepoints}}_{\\text{level 1}}\\) from a random sample of \\(\\underbrace{\\text{apes}}_{\\text{level 2}}\\).\n\n\n\n\nQuestion 3\n\n\nFor how many apes do we have data? How many of each species?\nHow many datapoints does each ape have?\n\n\n\n\n\n\nHints\n\n\n\n\n\nWe’ve seen this last week too - counting the different levels in our data. See Chapter 4: logisticMLM - #getting-to-know-my-monkeys for an example (also about monkeys!)\n\n\n\n\n\n\n\nWe have 168 apes in our dataset:\n\nlength(unique(apedat$ape))\n\n[1] 168\n\n\nHere’s how many of each species:\n\napedat |&gt; \n  group_by(species) |&gt;\n  summarise(\n   n_apes = n_distinct(ape) \n  )\n\n# A tibble: 4 × 2\n  species   n_apes\n  &lt;chr&gt;      &lt;int&gt;\n1 bonobo        36\n2 chimp         56\n3 gorilla       46\n4 orangutan     30\n\n\nLet’s create a table of how many observations for each ape, and then we can create a table from that table, to show how many apes have 2 datapoints, how many have 3, 4, and so on:\n\ntable(apedat$ape) |&gt;\n  table() |&gt;\n  barplot()\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 4\n\n\nMake a plot to show how dominance changes for each ape as they get older.\n\n\n\n\n\n\nHints\n\n\n\n\n\nIn Chapter 5: Longitudinal MLM - #exploring-the-data we made a facet for each cluster (each participant). That was fine because we had only 20 people. In this dataset we have 168! That’s too many to facet. We could try using group aesthetic instead, to plot multiple lines on the same plot, or we could just plot a sample of our apes. This is all just an initial look at the data, after all.\n\n\n\n\n\n\n\nHere’s a line for each ape, and a facet for each species:\n\nggplot(apedat, aes(x = age, y = dominance, col = species))+\n  geom_line(aes(group = ape)) + \n  facet_wrap(~species) + \n  guides(col=\"none\")\n\n\n\n\n\n\n\n\nIt’s kind of hard to see the trend for each ape, so let’s also make a separate little linear model for each ape:\n\nggplot(apedat, aes(x = age, y = dominance, col = species))+\n  geom_smooth(aes(group = ape), method=lm, se=FALSE) + \n  facet_wrap(~species) + \n  guides(col=\"none\")\n\n\n\n\n\n\n\n\nAlternatively, let’s take a sample of apes, and plot the same stuff but facetted:\n\napedat |&gt;\n  # choose the rows where ape ID is one of a random sample of 16 ape IDs\n  filter(ape %in% sample(unique(apedat$ape), 16) ) |&gt;\n  ggplot(aes(x = age, y = dominance, col = species))+\n  geom_point() +\n  geom_smooth(method=lm, se=FALSE)+\n  facet_wrap(~ape)\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 5\n\n\nRecenter the age variable on 1, which is the youngest ages that we’ve got data on for any of our species.\nThen fit a model that estimates the differences between primate species in how dominance changes over time.\n\n\n\n\n\n\nHints\n\n\n\n\n\nthink slowly about “differences between primate species in how dominance changes over time”.\n\n“how dominance changes over time” – sounds like dominance ~ time\nso differences between primate species in this would require the interaction dominance ~ time * species\n\n\n\n\n\n\n\n\n\napedat$age = apedat$age-1 \n\nm.full &lt;- lmer(dominance ~ 1 + age * species + (1 + age | ape), data = apedat)\n\n\n\n\n\nQuestion 6\n\n\nDo primate species differ in the growth of dominance?\nPerform an appropriate test/comparison.\n\n\n\n\n\n\nHints\n\n\n\n\n\nThis is asking about the age*species interaction, which in our model is represented by 3 parameters. To assess the overall question, it might make more sense to do a model comparison.\n\n\n\n\n\n\n\n\nm.int &lt;- lmer(dominance ~ 1 + age + species + (1 + age | ape), data = apedat)\n\nanova(m.int, m.full)\n\nData: apedat\nModels:\nm.int: dominance ~ 1 + age + species + (1 + age | ape)\nm.full: dominance ~ 1 + age * species + (1 + age | ape)\n       npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)   \nm.int     9 806.67 849.11 -394.34   788.67                        \nm.full   12 801.16 857.74 -388.58   777.16 11.517  3   0.009237 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nSpecies differ in how dominance changes over adolescence (\\(\\chi^2(3) = 11.52, p = 0.009\\)).\n\n\n\n\n\nQuestion 7\n\n\nPlot the average model predicted values for each age.\nBefore you plot.. do you expect to see straight lines? (remember, not every ape is measured at age 2, or age 3, etc).\n\n\n\n\n\n\nHints\n\n\n\n\n\nThis is like taking predict() from the model, and then then grouping by age, and calculating the mean of those predictions. However, we can do this more easily using augment() and then some fancy stat_summary() in ggplot (see the lecture).\n\n\n\n\n\n\n\nAveraging fitted values would give us straight lines if every ape had data at all ages, but in our study we have some apes with only 2 data points, and each ape has different set of ages (e.g., one ape might be measured at age 3, 6, and 10, another ape might be at ages 2 and 16).\n\nlibrary(broom.mixed)\n\naugment(m.full) |&gt;\nggplot(aes(age,dominance, color=species)) +\n  # the point ranges are our observations\n  stat_summary(fun.data=mean_se, geom=\"pointrange\") + \n  # the lines are our average predictions  \n  stat_summary(aes(y=.fitted, linetype=species), fun=mean, geom=\"line\")\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 8\n\n\nPlot the model based fixed effects:\n\n\n\n\n\neffects::effect(\"age*species\", m.full, xlevels=10) |&gt;\n  as.data.frame() |&gt;\n  ggplot(aes(x=age+1,y=fit,col=species))+\n  geom_line(lwd=1)+\n  geom_ribbon(aes(ymin=lower,ymax=upper,fill=species),col=NA,alpha=.3) +  \n  scale_color_manual(values=c(\"grey30\",\"black\",\"grey50\",\"darkorange\")) +\n  scale_fill_manual(values=c(\"grey30\",\"black\",\"grey50\",\"darkorange\")) +\n  facet_wrap(~species) + \n  guides(col=\"none\",fill=\"none\") +\n  labs(x=\"Age (years)\")\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 9\n\n\nInterpret each of the fixed effects from the model (you might also want to get some p-values or confidence intervals).\n\n\n\n\n\n\nHints\n\n\n\n\n\nEach of the estimates should correspond to part of our plot from the previous question.\n\n\n\n\n\n\n\nLet’s get some confidence intervals:\n\nconfint(m.full, method=\"profile\",\n        parm = \"beta_\")\n\n                           2.5 %      97.5 %\n(Intercept)          -0.67066925 -0.17299177\nage                   0.02361398  0.08142209\nspecieschimp          0.13383485  0.77009884\nspeciesgorilla        0.28124162  0.94933844\nspeciesorangutan     -0.38909919  0.34257548\nage:specieschimp     -0.03973125  0.03392308\nage:speciesgorilla   -0.05012759  0.02799393\nage:speciesorangutan -0.10625760 -0.02167806\n\n\n\n\n\n\n\n\n\n\nterm\nest\nCI\ninterpretation\n\n\n\n\n(Intercept)\n-0.42\n[-0.67, -0.17]*\nestimated dominance of 1 year old bonobos (at left hand side of plot, bonobo line is lower than 0)\n\n\nage\n0.05\n[0.02, 0.08]*\nestimated change in dominance score for every year older a bonobo gets (slope of bonobo line)\n\n\nspecieschimp\n0.45\n[0.13, 0.77]*\nestimated difference in dominance scores at age 1 between bonobos and chimps (at left hand side of plot, chimp line is higher than bonobo line)\n\n\nspeciesgorilla\n0.62\n[0.28, 0.95]*\nestimated difference in dominance scores at age 1 between bonobos and gorillas (at left hand side of plot, gorilla line is higher than bonobo line)\n\n\nspeciesorangutan\n-0.02\n[-0.39, 0.34]\nno significant difference in dominance scores at age 1 between bonobos and orangutans (at the left hand side of our plot, orangutan line is similar height to bonobo line)\n\n\nage:specieschimp\n0.00\n[-0.04, 0.03]\nno significant difference between chimps and bonobos in the change in dominance for every year older (slope of chimp line is similar to slope of bonobo line)\n\n\nage:speciesgorilla\n-0.01\n[-0.05, 0.03]\nno significant difference between gorillas and bonobos in the change in dominance for every year older (slope of gorilla line is similar to slope of bonobo line)\n\n\nage:speciesorangutan\n-0.06\n[-0.11, -0.02]*\nestimated difference between orangutans and bonobos in the change in dominance for every year older (slope of orangutan line is less steep than slope of bonobo line)",
    "crumbs": [
      "Week 2 Exercises: Logistic and Longitudinal"
    ]
  },
  {
    "objectID": "02ex.html#footnotes",
    "href": "02ex.html#footnotes",
    "title": "Week 2 Exercises: Logistic and Longitudinal",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nreally!?!?↩︎",
    "crumbs": [
      "Week 2 Exercises: Logistic and Longitudinal"
    ]
  }
]