<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Revision &amp; Individual Differences</title>

<script src="site_libs/header-attrs-2.8/header-attrs.js"></script>
<script src="site_libs/jquery-3.5.1/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<link href="site_libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="site_libs/datatables-binding-0.18/datatables.js"></script>
<link href="site_libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="site_libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="site_libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="site_libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="site_libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);
e.style.display = ((e.style.display!='none') ? 'none' : 'block');
if(f.classList.contains('fa-plus')) {
    f.classList.add('fa-minus')
    f.classList.remove('fa-plus')
} else {
    f.classList.add('fa-plus')
    f.classList.remove('fa-minus')
}
}
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<link rel="stylesheet" href="assets/style-labs.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"><strong>MSMR</strong></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fas fa-home"></span>
     
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Mixed Effects Models
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="01_intromlm.html">1: Intro to Multi-Level Modelling</a>
    </li>
    <li>
      <a href="02_lmm_log.html">2: Logistic | Longitudinal (linear)</a>
    </li>
    <li>
      <a href="03_nonlin.html">3: Longitudinal (non-linear)</a>
    </li>
    <li>
      <a href="04_other_ranef.html">4: Other Random Effect Structures</a>
    </li>
    <li>
      <a href="05_multilevel_recap.html">5: Recap | Individual Differences</a>
    </li>
    <li>
      <a href="06_rev.html">Break Week</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Data Reduction &amp; SEM
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="07_efapca.html">PCA | EFA</a>
    </li>
    <li>
      <a href="08_cfa.html">CFA</a>
    </li>
    <li>
      <a href="09_path.html">Path Analysis</a>
    </li>
    <li>
      <a href="10_sem1.html">SEM 1</a>
    </li>
    <li>
      <a href="11_sem2.html">SEM 2</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fas fa-info-circle"></span>
     
    Help
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="00_tidyverse_markdown.html">Recap - Tidyverse &amp; Markdown</a>
    </li>
    <li>
      <a href="zz_writeuplogistic.html">Write-up &amp; Logistic GCA</a>
    </li>
    <li>
      <a href="zz_assumpts.html">MLM Assumptions &amp; Diagnostics</a>
    </li>
  </ul>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Revision &amp; Individual Differences</h1>

</div>


<pre class="r"><code>require(tidyverse)
require(lme4)
library(lmerTest)
# library(effects)</code></pre>
<div id="recap-of-multilevel-models" class="section level1">
<h1>Recap of multilevel models</h1>
<blockquote>
<p>Do children scores in maths improve more in school 2020 vs school 2040?</p>
</blockquote>
<p>Consider the following data, representing longitudinal measurements on 10 students from an urban public primary school. The outcome of interest is mathematics achievement.
The data were collected at the end of first grade and annually thereafter up to sixth grade, but not all students have six observations. The variable year has been mean-centred to have mean 0 so that results will have as baseline the average.</p>
<p><br></p>
<div id="htmlwidget-6fde741e932eb7d5c480" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-6fde741e932eb7d5c480">{"x":{"filter":"none","data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56","57","58","59","60","61","62","63","64","65","66","67","68","69","70","71","72","73","74","75","76","77","78","79","80","81","82","83","84","85","86","87","88","89","90","91","92","93","94","95","96","97","98","99","100","101","102","103","104","105","106","107","108","109","110","111","112","113","114","115","116","117","118","119","120","121","122","123","124","125","126","127","128","129","130","131","132","133","134","135","136","137","138","139","140","141","142","143","144","145","146","147","148","149","150","151","152","153","154","155","156","157","158","159","160","161","162","163","164","165","166","167","168","169","170","171","172","173","174","175","176","177","178","179","180","181","182","183","184","185","186"],["2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2020","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040","2040"],["273026452","273026452","273026452","273030991","273030991","273030991","273030991","273030991","273059461","273059461","273059461","273059461","273059461","278058841","278058841","278058841","278058841","278058841","292017571","292017571","292017571","292020281","292020281","292020281","292020281","292020281","292020281","292020361","292020361","292020361","292020361","292020361","292020361","292025081","292025081","292025081","292025081","292025081","292026211","292026211","292026211","292026211","292026211","292027291","292027291","292027291","292027291","292027291","292027531","292027531","292027531","292027531","292027531","292028181","292028181","292028181","292028181","292028181","292028931","292028931","292028931","292028931","292028931","292029071","292029071","292029071","292029071","292029071","292029901","292029901","292029901","292029901","292029901","292033851","292033851","292033851","292033851","292033851","295341521","295341521","295341521","295341521","295341521","295341521","298046562","298046562","298046562","301853741","301853741","301853741","307407931","307407931","307407931","307694141","307694141","307694141","307694141","253404261","253404261","253404261","253404261","253404261","253404261","253413681","253413681","253413681","270199271","270199271","270199271","285939962","285939962","285939962","288699161","288699161","288699161","288699161","288699161","289970511","289970511","289970511","289970511","289970511","292772811","292772811","292772811","293550291","293550291","293550291","293550291","299680041","299680041","299680041","299680041","299680041","303652591","303652591","303652591","303652591","303652591","303653561","303653561","303653561","303654611","303654611","303654611","303654611","303654611","303658951","303658951","303658951","303660691","303660691","303660691","303660691","303662391","303662391","303662391","303662391","303662391","303662391","303663601","303663601","303663601","303663601","303663601","303663601","303668751","303668751","303668751","303668751","303668751","303671891","303671891","303671891","303671891","303671891","303672001","303672001","303672001","303672861","303672861","303672861","303673321","303673321","303673321","303673321"],[0.5,1.5,2.5,-1.5,-0.5,0.5,1.5,2.5,-1.5,-0.5,0.5,1.5,2.5,-1.5,-0.5,0.5,1.5,2.5,-1.5,-0.5,0.5,-2.5,-1.5,-0.5,0.5,1.5,2.5,-2.5,-1.5,-0.5,0.5,1.5,2.5,-1.5,-0.5,0.5,1.5,2.5,-1.5,-0.5,0.5,1.5,2.5,-1.5,-0.5,0.5,1.5,2.5,-1.5,-0.5,0.5,1.5,2.5,-1.5,-0.5,0.5,1.5,2.5,-1.5,-0.5,0.5,1.5,2.5,-1.5,-0.5,0.5,1.5,2.5,-1.5,-0.5,0.5,1.5,2.5,-1.5,-0.5,0.5,1.5,2.5,-2.5,-1.5,-0.5,0.5,1.5,2.5,0.5,1.5,2.5,-1.5,-0.5,0.5,-1.5,-0.5,0.5,-1.5,-0.5,0.5,1.5,-2.5,-1.5,-0.5,0.5,1.5,2.5,-1.5,-0.5,0.5,-1.5,0.5,1.5,-0.5,0.5,1.5,-1.5,-0.5,0.5,1.5,2.5,-1.5,-0.5,0.5,1.5,2.5,-1.5,-0.5,0.5,-1.5,-0.5,0.5,1.5,-1.5,-0.5,0.5,1.5,2.5,-1.5,-0.5,0.5,1.5,2.5,-2.5,-1.5,-0.5,-1.5,-0.5,0.5,1.5,2.5,-1.5,-0.5,0.5,-1.5,-0.5,0.5,1.5,-2.5,-1.5,-0.5,0.5,1.5,2.5,-2.5,-1.5,-0.5,0.5,1.5,2.5,-1.5,-0.5,0.5,1.5,2.5,-2.5,-1.5,-0.5,0.5,1.5,-1.5,-0.5,0.5,-1.5,-0.5,0.5,-1.5,0.5,1.5,2.5],[1.14600002765656,1.13399994373322,2.29999995231628,-1.30299997329712,0.439000010490417,2.4300000667572,2.25399994850159,3.87299990653992,-1.38399994373322,0.337999999523163,1.14600002765656,1.83899998664856,3.0550000667572,-0.732999980449677,1.04299998283386,2.14000010490417,2.81399989128113,3.54399991035461,-0.732999980449677,0.148000001907349,2.78999996185303,-3.06800007820129,-1.12999999523163,-0.921000003814697,0.462999999523163,0.0209999997168779,2.03500008583069,-2.73200011253357,-2.09699988365173,-0.987999975681305,0.226999998092651,0.402999997138977,1.62300002574921,-1.83000004291534,-0.785000026226044,0.716000020503998,1.20200002193451,3.0550000667572,-1.54100000858307,-0.273000001907349,-0.522000014781952,0.458999991416931,2.09899997711182,-1.75999999046326,-0.921000003814697,0.851999998092651,1.74800002574921,2.59999990463257,-1.83000004291534,-0.500999987125397,0.114000000059605,1.66100001335144,2.16400003433228,-2.3510000705719,-1.50499999523163,-0.725000023841858,0.0209999997168779,1.51400005817413,-1.21800005435944,-0.273000001907349,0.462999999523163,0.573000013828278,1.73599994182587,-1.96599996089935,-0.574000000953674,0.226999998092651,1.74800002574921,2.23099994659424,-2.71799993515015,-1.37800002098083,-0.623000025749207,0.810999989509583,1.97300004959106,-2.96000003814697,-1.25,-0.725000023841858,0.128000006079674,1.51400005817413,-2.73200011253357,-1.89800000190735,-0.921000003814697,0.587000012397766,1.57799994945526,2.29999995231628,0.00300000002607703,0.573000013828278,1.14800000190735,-0.732999980449677,-0.644999980926514,1.14600002765656,-0.732999980449677,-0.112000003457069,1.14600002765656,-2.47399997711182,-1.50499999523163,-0.623000025749207,-0.349999994039536,-2.18799996376038,-1.54100000858307,-0.351000010967255,1.30900001525879,1.4210000038147,2.68199992179871,-3.39499998092651,-3.23200011253357,-2.05299997329712,-1.98699998855591,-0.418999999761581,-0.244000002741814,-0.785000026226044,0.587000012397766,1.4210000038147,-2.16199994087219,0.24099999666214,0.226999998092651,1.27300000190735,3.0550000667572,-1.83000004291534,-1.18499994277954,0.851999998092651,0.573000013828278,1.73599994182587,-3.14400005340576,-2.09699988365173,-0.316000014543533,-2.09699988365173,-1.31400001049042,0.00300000002607703,0.181999996304512,-1.53799998760223,-0.941999971866608,-0.522000014781952,0.632000029087067,1.7940000295639,-1.89800000190735,-0.716000020503998,0.716000020503998,1.06599998474121,2.37100005149841,-3.23200011253357,-2.18799996376038,-1.46399998664856,-1.98699998855591,-1.61600005626678,-1.66499996185303,-0.349999994039536,1.04700005054474,-1.77199995517731,-0.194000005722046,1.67799997329712,-2.18799996376038,-1.567999958992,-1.23599994182587,-0.244000002741814,-3.39499998092651,-2.47399997711182,-1.96599996089935,-0.927999973297119,0.181999996304512,0.797999978065491,-3.23200011253357,-2.53500008583069,-0.785000026226044,0.342999994754791,0.573000013828278,1.30200004577637,-1.27600002288818,0.337999999523163,0.851999998092651,0.128000006079674,2.29999995231628,-3.23200011253357,-2.22499990463257,-0.987999975681305,-1.23599994182587,0.0209999997168779,-1.12999999523163,-0.426999986171722,0.995000004768372,-2.37700009346008,-0.426999986171722,0.995000004768372,-2.37700009346008,-1.23599994182587,-0.725000023841858,0.649999976158142]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>schoolid<\/th>\n      <th>childid<\/th>\n      <th>year<\/th>\n      <th>math<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":10,"columnDefs":[{"targets":4,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 2, 3, \",\", \".\");\n  }"},{"className":"dt-right","targets":[3,4]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":["options.columnDefs.0.render"],"jsHooks":[]}</script>
<p>How many students in each school?</p>
<pre><code>## schoolid
## 2020 2040  Sum 
##   21   21   42</code></pre>
<p>We have 42 students, 21 in school with id 2020 and 21 in school with id 2040:</p>
<p>The number of observations per child are as follows.</p>
<pre class="r"><code>table(data$childid)</code></pre>
<pre><code>## 
## 253404261 253413681 270199271 273026452 273030991 273059461 278058841 285939962 
##         6         3         3         3         5         5         5         3 
## 288699161 289970511 292017571 292020281 292020361 292025081 292026211 292027291 
##         5         5         3         6         6         5         5         5 
## 292027531 292028181 292028931 292029071 292029901 292033851 292772811 293550291 
##         5         5         5         5         5         5         3         4 
## 295341521 298046562 299680041 301853741 303652591 303653561 303654611 303658951 
##         6         3         5         3         5         3         5         3 
## 303660691 303662391 303663601 303668751 303671891 303672001 303672861 303673321 
##         4         6         6         5         5         3         3         4 
## 307407931 307694141 
##         3         4</code></pre>
<p>We can see that for some children we have fewer than the 6 observations: some have 3, 4, or 5.</p>
<div id="school-2020" class="section level2">
<h2>School 2020</h2>
<p>Let’s start by considering only the children in school 2020. The mathematics achievement over time is shown, for each student, in the plot below:</p>
<pre class="r"><code>data2020 &lt;- data %&gt;% 
  filter(schoolid == 2020)

ggplot(data2020, aes(x = year, y = math)) +
  geom_point() +
  facet_wrap(~ childid, labeller = label_both) +
  labs(x = &quot;Year (mean centred)&quot;, y = &quot;Maths achievement score&quot;)</code></pre>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-6-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Clearly, the measurements of mathematics achievement related to each student are <em>grouped data</em> as they refer to the same entity.</p>
<p>If we were to ignore this grouping and consider all children as one single population, we would obtain misleading results.The observations for the same student are clearly correlated. Some students consistently have a much better performance than other students, perhaps due to underlying numerical skills.</p>
<p>A fundamental assumption of linear regression models is that the residuals, and hence the data too, should be uncorrelated. In this example this is not the case.</p>
<p>The following plot considers all data as a single population</p>
<pre class="r"><code>ggplot(data2020, aes(x = year, y = math)) +
    geom_point() +
    geom_smooth(method = lm, se = FALSE) +
    labs(x = &quot;Year (mean centred)&quot;, y = &quot;Maths achievement score&quot;)</code></pre>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-7-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>This is a simple linear regression model for the mathematics measurement of individual <span class="math inline">\(i\)</span> on occasion <span class="math inline">\(j\)</span>:
<span class="math display">\[
\text{math}_{ij} = \beta_0 + \beta_1 \ \text{year}_{ij} + \epsilon_{ij} 
\]</span></p>
<p>where the subscript <span class="math inline">\(ij\)</span> denotes the <span class="math inline">\(j\)</span>th measurement from child <span class="math inline">\(i\)</span>.</p>
<p>Let’s fit this in R</p>
<pre class="r"><code>m0 &lt;- lm(math ~ year, data = data2020)
summary(m0)</code></pre>
<pre><code>## 
## Call:
## lm(formula = math ~ year, data = data2020)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.6478 -0.6264 -0.1101  0.4543  2.4529 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.14323    0.08493  -1.687    0.095 .  
## year         0.96072    0.05662  16.968   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.8126 on 95 degrees of freedom
## Multiple R-squared:  0.7519, Adjusted R-squared:  0.7493 
## F-statistic: 287.9 on 1 and 95 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The intercept and slope of this model can be visually represented as:</p>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-9-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="random-intercept-and-slopes" class="section level2">
<h2>Random intercept and slopes</h2>
<p>In reality, we see that each student has their own line, with a different intercept and slope.
In other words, they all have different values of maths achievement when year = 0 and they also differ in their learning rate.</p>
<pre class="r"><code>ggplot(data2020, aes(x = year, y = math, color = childid)) +
    geom_point() +
    geom_smooth(method = lm, se = FALSE, fullrange = TRUE, 
                size = 0.5) +
    labs(x = &quot;Year (mean centred)&quot;, y = &quot;Maths achievement score&quot;) +
    theme(legend.position = &#39;bottom&#39;)</code></pre>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-10-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Let’s now write a model where each student has their own intercept and slope:
<span class="math display">\[
\begin{aligned}
\text{math}_{ij} 
&amp;= \beta_{0i} + \beta_{1i} \ \text{year}_{ij} + \epsilon_{ij} \\
&amp;= (\text{intercept for child } i) + (\text{slope for child } i) \ \text{year}_{ij} + \epsilon_{ij} \\
&amp;= (\gamma_{00} + \zeta_{0i}) + (\gamma_{10} + \zeta_{1i}) \ \text{year}_{ij} + \epsilon_{ij}
\end{aligned}
\]</span></p>
<p>where</p>
<ul>
<li><p><span class="math inline">\(\beta_{0i}\)</span> is the intercept of the line for child <span class="math inline">\(i\)</span></p></li>
<li><p><span class="math inline">\(\beta_{1i}\)</span> is the slope of the line for child <span class="math inline">\(i\)</span></p></li>
<li><p><span class="math inline">\(\epsilon_{ij}\)</span> are the deviations of each child’s measurement <span class="math inline">\(\text{math}_{ij}\)</span> from the line of child <span class="math inline">\(i\)</span></p></li>
</ul>
<p><br></p>
<p>We can think each child-specific intercept (respectively, slope) as being made up of two components: an “overall” intercept <span class="math inline">\(\gamma_{00}\)</span> (slope <span class="math inline">\(\gamma_{10}\)</span>) and a child-specific deviation from the overall intercept <span class="math inline">\(\zeta_{0i}\)</span> (slope <span class="math inline">\(\zeta_{1i}\)</span>):</p>
<ul>
<li><p><span class="math inline">\(\beta_{0i} = \gamma_{00} + \zeta_{0i} = \text{(overall intercept) + (deviation for child }i)\)</span></p></li>
<li><p><span class="math inline">\(\beta_{1i} = \gamma_{10} + \zeta_{1i} = \text{(overall slope) + (deviation for child }i)\)</span></p></li>
</ul>
<p><img src="images/un_lmm.png" width="100%" style="display: block; margin: auto;" /></p>
<div class="yellow">
<p><strong>FACT</strong></p>
<p><strong>Deviations from the mean average to zero (and sum to zero too!)</strong></p>
<p>As you know, deviations from the mean average to 0.</p>
<p>This holds for the errors <span class="math inline">\(\epsilon_{ij}\)</span>, as well as the deviations <span class="math inline">\(\zeta_{0i}\)</span> from the overall intercept, and the deviations <span class="math inline">\(\zeta_{1i}\)</span> from the overall slope.</p>
<p>Think of data <span class="math inline">\(y_1, ..., y_n\)</span> and their mean <span class="math inline">\(\bar y\)</span>. The average of the deviations from the mean is
<span class="math display">\[
\begin{aligned}
\frac{\sum_i (y_i - \bar y)}{n} 
= \frac{\sum_i y_i }{n} - \frac{\sum_i \bar y}{n} 
= \bar y - \frac{n * \bar y}{n} 
= \bar y - \bar y 
= 0
\end{aligned}
\]</span></p>
</div>
<p><br></p>
<p>The child-specific deviations <span class="math inline">\(\zeta_{0i}\)</span> from the overall intercept are normally distributed with mean <span class="math inline">\(0\)</span> and variance <span class="math inline">\(\sigma_0^2\)</span>. Similarly, the deviations <span class="math inline">\(\zeta_{1i}\)</span> of the slope for child <span class="math inline">\(i\)</span> from the overall slope come from a normal distribution with mean <span class="math inline">\(0\)</span> and variance <span class="math inline">\(\sigma_1^2\)</span>. The correlation between random intercepts and slopes is <span class="math inline">\(\rho = \text{Cor}(\zeta_{0i}, \zeta_{1i}) = \frac{\sigma_{01}}{\sigma_0 \sigma_1}\)</span>:</p>
<p><span class="math display">\[
\begin{bmatrix} \zeta_{0i} \\ \zeta_{1i} \end{bmatrix} 
\sim N
\left(
    \begin{bmatrix} 0 \\ 0 \end{bmatrix}, 
    \begin{bmatrix} 
        \sigma_0^2 &amp; \rho \sigma_0 \sigma_1 \\
        \rho \sigma_0 \sigma_1 &amp; \sigma_1^2
    \end{bmatrix}
\right)
\]</span></p>
<p>The random errors, independently from the random effects, are distributed
<span class="math display">\[
\epsilon_{ij} \sim N(0, \sigma_\epsilon^2)
\]</span></p>
<p>This is fitted using <code>lmer()</code>:</p>
<pre class="r"><code>library(lme4)
library(lmerTest)

m1 &lt;- lmer(math ~ 1 + year + (1 + year | childid), data = data2020)
summary(m1)</code></pre>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: math ~ 1 + year + (1 + year | childid)
##    Data: data2020
## 
## REML criterion at convergence: 166.6
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.3119 -0.6125 -0.0726  0.6002  2.4197 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr
##  childid  (Intercept) 0.50065  0.7076       
##           year        0.01131  0.1063   0.82
##  Residual             0.16345  0.4043       
## Number of obs: 97, groups:  childid, 21
## 
## Fixed effects:
##             Estimate Std. Error      df t value Pr(&gt;|t|)    
## (Intercept)  -0.1091     0.1605 19.7831   -0.68    0.505    
## year          0.9940     0.0381 13.1895   26.09 9.71e-13 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##      (Intr)
## year 0.433</code></pre>
<p>The summary of the <code>lmer</code> output returns estimated values for</p>
<p>Fixed effects:</p>
<ul>
<li><span class="math inline">\(\widehat \gamma_{00} = -0.109\)</span></li>
<li><span class="math inline">\(\widehat \gamma_{10} = 0.994\)</span></li>
</ul>
<p>Variability of random effects:</p>
<ul>
<li><span class="math inline">\(\widehat \sigma_{0} = 0.708\)</span></li>
<li><span class="math inline">\(\widehat \sigma_{1} = 0.106\)</span></li>
</ul>
<p>Correlation of random effects:</p>
<ul>
<li><span class="math inline">\(\widehat \rho = 0.816\)</span></li>
</ul>
<p>Residuals:</p>
<ul>
<li><span class="math inline">\(\widehat \sigma_\epsilon = 0.404\)</span></li>
</ul>
<p>Check normality of random effects:</p>
<pre class="r"><code>par(mfrow = c(1,2))
qqnorm(ranef(m1)$childid[, 1], main = &quot;Random intercept&quot;)
qqline(ranef(m1)$childid[, 1])

qqnorm(ranef(m1)$childid[, 2], main = &quot;Random slope&quot;)
qqline(ranef(m1)$childid[, 2])</code></pre>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-14-1.png" width="95%" style="display: block; margin: auto;" /></p>
<p>Check normality and independence of errors:</p>
<pre class="r"><code>par(mfrow = c(1,2))
qqnorm(resid(m1), main = &quot;Residuals&quot;)
qqline(resid(m1))

plot(fitted(m1), resid(m1), ylab = &quot;Residuals&quot;, xlab = &quot;Fitted values&quot;)
abline(h=0)</code></pre>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-15-1.png" width="95%" style="display: block; margin: auto;" /></p>
<p>Visually inspect the correlation between the random intercept and slopes:</p>
<pre class="r"><code>ggplot(ranef(m1)$childid,
       aes(x = `(Intercept)`, y = year)) +
    geom_smooth(method = lm, se = FALSE, 
                color = &#39;gray&#39;, size = 0.5) +
    geom_point()</code></pre>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-16-1.png" width="80%" style="display: block; margin: auto;" /></p>
<!-- HIDE??? -->
<!-- ## Schools 2020 and 2040 -->
<!-- Consider now the case where you want a fixed effect for the two schools, to compare the average mathematics achievement among those 2 particular schools. This would take the form of a fixed effect: -->
<!-- ```{r} -->
<!-- m2 <- lmer(math ~ 1 + year + schoolid + (1 + year | childid), data = data) -->
<!-- summary(m2) -->
<!-- ``` -->
<!-- Check normality of random effects: -->
<!-- ```{r, fig.width=8, fig.height = 4, out.width = '95%'} -->
<!-- par(mfrow = c(1,2)) -->
<!-- qqnorm(ranef(m2)$childid[, 1], main = "Random intercept") -->
<!-- qqline(ranef(m2)$childid[, 1]) -->
<!-- qqnorm(ranef(m2)$childid[, 2], main = "Random slope") -->
<!-- qqline(ranef(m2)$childid[, 2]) -->
<!-- ``` -->
<!-- Check normality and independence of errors: -->
<!-- ```{r, fig.width=8, fig.height = 4, out.width = '95%'} -->
<!-- par(mfrow = c(1,2)) -->
<!-- qqnorm(resid(m2), main = "Residuals") -->
<!-- qqline(resid(m2)) -->
<!-- plot(fitted(m2), resid(m2), ylab = "Residuals", xlab = "Fitted values") -->
<!-- abline(h=0) -->
<!-- ``` -->
<!-- Visually inspect the correlation between the random intercept and slopes: -->
<!-- ```{r} -->
<!-- ggplot(ranef(m2)$childid, -->
<!--        aes(x = `(Intercept)`, y = year)) + -->
<!--     geom_smooth(method = lm, se = FALSE,  -->
<!--                 color = 'gray', size = 0.5) + -->
<!--     geom_point() -->
<!-- ``` -->
<!-- We see from `summary` and the plot above, that the correlation between the random intercept and slope is equal to 1. -->
<!-- We also notice the following message: -->
<!-- ``` -->
<!-- Model failed to converge with max|grad| = 0.00288304 (tol = 0.002, component 1) -->
<!-- ``` -->
<!-- It basically is saying that the gradient stopping criterion at the termination was not smaller than the specified threshold of 0.002.  -->
<!-- We can try uncorrelating the random intercept and slope, i.e. setting $\rho = 0$ by either using `||`:  -->
<!-- ```{r} -->
<!-- m2a <- lmer(math ~ 1 + year + schoolid + (1 + year || childid), data = data) -->
<!-- summary(m2a) -->
<!-- ``` -->
<!-- or: -->
<!-- ```{r} -->
<!-- m2b <- lmer(math ~ 1 + year + schoolid +(1 | childid) + (0 + year | childid), data = data) -->
<!-- summary(m2b) -->
<!-- ``` -->
<!-- The two above will return the same results. -->
<!-- Check normality of random effects: -->
<!-- ```{r, fig.width=8, fig.height = 4, out.width = '95%'} -->
<!-- par(mfrow = c(1,2)) -->
<!-- qqnorm(ranef(m2a)$childid[, 1], main = "Random intercept") -->
<!-- qqline(ranef(m2a)$childid[, 1]) -->
<!-- qqnorm(ranef(m2a)$childid[, 2], main = "Random slope") -->
<!-- qqline(ranef(m2a)$childid[, 2]) -->
<!-- ``` -->
<!-- Check normality and independence of errors: -->
<!-- ```{r, fig.width=8, fig.height = 4, out.width = '95%'} -->
<!-- par(mfrow = c(1,2)) -->
<!-- qqnorm(resid(m2a), main = "Residuals") -->
<!-- qqline(resid(m2a)) -->
<!-- plot(fitted(m2a), resid(m2a), ylab = "Residuals", xlab = "Fitted values") -->
<!-- abline(h=0) -->
<!-- ``` -->
<!-- Visually inspect the correlation between the random intercept and slopes: -->
<!-- ```{r} -->
<!-- ggplot(ranef(m2a)$childid, -->
<!--        aes(x = `(Intercept)`, y = year)) + -->
<!--     geom_smooth(method = lm, se = FALSE,  -->
<!--                 color = 'gray', size = 0.5) + -->
<!--     geom_point() -->
<!-- ``` -->
</div>
</div>
<div id="flashcards-lm-to-lmer" class="section level1">
<h1>Flashcards: <code>lm</code> to <code>lmer</code></h1>
<p>In a simple linear regression, there is only considered to be one source of random variability: any variability left unexplained by a set of predictors (which are modelled as fixed estimates) is captured in the model residuals.</p>
<p>Multi-level (or ‘mixed-effects’) approaches involve modelling more than one source of random variability - as well as variance resulting from taking a random sample of observations, we can identify random variability across different groups of observations. For example, if we are studying a patient population in a hospital, we would expect there to be variability across the our sample of patients, but also across the doctors who treat them.</p>
<p>We can account for this variability by allowing the outcome to be lower/higher for each group (a random intercept) and by allowing the estimated effect of a predictor vary across groups (random slopes).</p>
<div class="blue">
<p>Before you expand each of the boxes below, think about how comfortable you feel with each concept.<br />
This content is very cumulative, which means often going back to try to isolate the place which we need to focus efforts in learning.</p>
</div>
<div class="optional-begin">
Simple Linear Regression<span id="opt-start-79" class="fa fa-plus optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-79&#39;, &#39;opt-start-79&#39;)"></span>
</div>
<div id="opt-body-79" class="optional-body" style="display: none;">
<div class="frame">
<p><strong>Formula:</strong></p>
<ul>
<li><span class="math inline">\(y_i = \beta_0 + \beta_1 x_i + \epsilon_i\)</span></li>
</ul>
<p><strong>R command:</strong></p>
<ul>
<li><code>lm(outcome ~ predictor, data = dataframe)</code></li>
</ul>
<p><em>Note:</em> this is the same as <code>lm(outcome ~ 1 + predictor, data = dataframe)</code>. The <code>1 +</code> is always there unless we specify otherwise (e.g., by using <code>0 +</code>).</p>
</div>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-18-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
Clustered (multi-level) data<span id="opt-start-80" class="fa fa-plus optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-80&#39;, &#39;opt-start-80&#39;)"></span>
</div>
<div id="opt-body-80" class="optional-body" style="display: none;">
<p>When our data is clustered (or ‘grouped’) such that datapoints are no longer independent, but belong to some grouping such as that of multiple observations from the same subject, we have multiple sources of random variability. A simple regression does not capture this.</p>
<p>If we separate out our data to show an individual plot for each subject, we can see how the fitted regression line from <code>lm()</code> is assumed to be the same for each subject.</p>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-19-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
Random intercepts<span id="opt-start-81" class="fa fa-plus optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-81&#39;, &#39;opt-start-81&#39;)"></span>
</div>
<div id="opt-body-81" class="optional-body" style="display: none;">
<p>By including a random-intercept term, we are letting our model estimate random variability around an average parameter (represented by the fixed effects) for the clusters.</p>
<div class="frame">
<p><strong>Formula:</strong><br />
Level 1:</p>
<ul>
<li><span class="math inline">\(y_{ij} = \beta_{0i} + \beta_{1i} x_{ij} + \epsilon_{ij}\)</span></li>
</ul>
<p>Level 2:</p>
<ul>
<li><span class="math inline">\(\beta_{0i} = \gamma_{00} + \zeta_{0i}\)</span></li>
</ul>
<p>Where the expected values of <span class="math inline">\(\zeta_{0}\)</span>, and <span class="math inline">\(\epsilon\)</span> are 0, and their variances are <span class="math inline">\(\sigma_{0}^2\)</span> and <span class="math inline">\(\sigma_\epsilon^2\)</span> respectively. We will further assume that these are normally distributed.</p>
<p>We can now see that the intercept estimate <span class="math inline">\(\beta_{0i}\)</span> for a particular group <span class="math inline">\(i\)</span> is represented by the combination of a mean estimate for the parameter (<span class="math inline">\(\gamma_{00}\)</span>) and a random effect for that group (<span class="math inline">\(\zeta_{0i}\)</span>).</p>
<p><strong>R command:</strong></p>
<ul>
<li><code>lmer(outcome ~ predictor + (1 | grouping), data = dataframe)</code></li>
</ul>
</div>
<p>Notice how the fitted line of the random intercept model has an adjustment for each subject.<br />
Each subject’s line has been moved up or down accordingly.</p>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-20-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
Shrinkage<span id="opt-start-82" class="fa fa-plus optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-82&#39;, &#39;opt-start-82&#39;)"></span>
</div>
<div id="opt-body-82" class="optional-body" style="display: none;">
<p>If you think about it, we might have done a similar thing with the tools we already had at our disposal, by using <code>lm(y~x+subject)</code>.
This would give us a coefficient for the difference between each subject and the reference level intercept, or we could extend this to <code>lm(y~x*subject)</code> to give us an adjustment to the slope for each subject.</p>
<p>However, the estimate of these models will be slightly different:</p>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-21-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><strong>Why?</strong> One of the benefits of multi-level models is that our cluster-level estimates are shrunk towards the average depending on a) the level of across-cluster variation and b) the number of datapoints in clusters.</p>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
Random slopes<span id="opt-start-83" class="fa fa-plus optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-83&#39;, &#39;opt-start-83&#39;)"></span>
</div>
<div id="opt-body-83" class="optional-body" style="display: none;">
<div class="frame">
<p><strong>Formula:</strong><br />
Level 1:</p>
<ul>
<li><span class="math inline">\(y_{ij} = \beta_{0i} + \beta_{1i} x_{ij} + \epsilon_{ij}\)</span></li>
</ul>
<p>Level 2:</p>
<ul>
<li><span class="math inline">\(\beta_{0i} = \gamma_{00} + \zeta_{0i}\)</span><br />
</li>
<li><span class="math inline">\(\beta_{1i} = \gamma_{10} + \zeta_{1i}\)</span></li>
</ul>
<p>Where the expected values of <span class="math inline">\(\zeta_0\)</span>, <span class="math inline">\(\zeta_1\)</span>, and <span class="math inline">\(\epsilon\)</span> are 0, and their variances are <span class="math inline">\(\sigma_{0}^2\)</span>, <span class="math inline">\(\sigma_{1}^2\)</span>, <span class="math inline">\(\sigma_\epsilon^2\)</span> respectively. We will further assume that these are normally distributed.</p>
<p>As with the intercept <span class="math inline">\(\beta_{0i}\)</span>, the slope of the predictor <span class="math inline">\(\beta_{1i}\)</span> is now modelled by a mean <span class="math inline">\(\gamma_{10}\)</span> and a random effect for each group (<span class="math inline">\(\zeta_{1i}\)</span>).</p>
<p><strong>R command:</strong></p>
<ul>
<li><code>lmer(outcome ~ predictor + (1 + predictor | grouping), data = dataframe)</code></li>
</ul>
<p><em>Note:</em> this is the same as <code>lmer(outcome ~ predictor + (predictor | grouping), data = dataframe)</code> . Like in the fixed-effects part, the <code>1 +</code> is assumed in the random-effects part.</p>
</div>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-22-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
Polynomials!<span id="opt-start-84" class="fa fa-plus optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-84&#39;, &#39;opt-start-84&#39;)"></span>
</div>
<div id="opt-body-84" class="optional-body" style="display: none;">
<p>Sometimes, data have a clear non-linear pattern, such as a curvilinear trend. In such case, it is reasonable to try modelling the outcome <em>not</em> as a linear function of the variable, but as a curvilinear function of it.</p>
<p>The following plots show data (as black dots) where the outcome <span class="math inline">\(y\)</span> has a nonlinear and decreasing dependence on <span class="math inline">\(x\)</span>. That is, as <span class="math inline">\(x\)</span> varies from 1 to 10, the outcome <span class="math inline">\(y\)</span> decreases in a non-linear fashion.
Superimposed to the same data, you can see a linear fit (red line) and a cubic fit (blue).</p>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-23-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>The residuals corresponding to each fit are:
<img src="05_multilevel_recap_files/figure-html/unnamed-chunk-24-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Clearly, a linear fit doesn’t capture the real trend in the data, and any leftover systematic pattern that the model doesn’t explicity account for always ends up in the residuals as the red points show.</p>
<p>On the other hand, once we account for the nonlinear trend, that systematic pattern in the residuals disappears.</p>
<p>The secret is to use instead of <span class="math inline">\(x\)</span> as a predictor, the corresponding polynomial up to a specific order:</p>
<p><span class="math display">\[
y = \beta_0 + \beta_1 x + \beta_2 x^2 + \beta_3 x^3 + \epsilon
\]</span></p>
<p>Consider the following example data. You can add polynomials up to order 3, for example, of a predictor “time” by saying:</p>
<pre><code>## # A tibble: 5 x 3
##   subject reaction  time
##     &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt;
## 1       1    0.428     1
## 2       1    0.427     2
## 3       1    0.211     3
## 4       1    0.585     4
## 5       1    0.127     5</code></pre>
<pre class="r"><code>source(&quot;https://uoepsy.github.io/msmr/functions/code_poly.R&quot;)

code_poly(df, predictor = &#39;time&#39;, poly.order = 3, draw.poly = FALSE)</code></pre>
<pre><code>## # A tibble: 5 x 7
##   subject reaction  time time.Index  poly1  poly2     poly3
##     &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;
## 1       1    0.428     1          1 -0.632  0.535 -3.16e- 1
## 2       1    0.427     2          2 -0.316 -0.267  6.32e- 1
## 3       1    0.211     3          3  0     -0.535 -4.10e-16
## 4       1    0.585     4          4  0.316 -0.267 -6.32e- 1
## 5       1    0.127     5          5  0.632  0.535  3.16e- 1</code></pre>
<p>and use those terms when specifying your linear model, for example:</p>
<pre><code>lmer(reaction ~ poly1 + poly2 + poly3 + (1 | subject))</code></pre>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
Fixed effects<span id="opt-start-85" class="fa fa-plus optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-85&#39;, &#39;opt-start-85&#39;)"></span>
</div>
<div id="opt-body-85" class="optional-body" style="display: none;">
<p>We can extract the <em>fixed effects</em> using the <code>fixef()</code> function:</p>
<p>These are the overall intercept and slope.</p>
<pre class="r"><code>fixef(random_slopes_model)</code></pre>
<pre><code>## (Intercept)          x1 
## 405.7897675  -0.6722654</code></pre>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
Random effects<span id="opt-start-86" class="fa fa-plus optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-86&#39;, &#39;opt-start-86&#39;)"></span>
</div>
<div id="opt-body-86" class="optional-body" style="display: none;">
<p>The plots below show the fitted values for each subject from each model that we have gone through in these expandable boxes (simple linear regression, random intercept, and random intercept &amp; slope):</p>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-28-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>In the random-intercept model (center panel), the differences from each of the subjects’ intercepts to the fixed intercept (thick green line) have mean 0 and standard deviation <span class="math inline">\(\sigma_0\)</span>. The standard deviation (and variance, which is <span class="math inline">\(\sigma_0^2\)</span>) is what we see in the random effects part of our model summary (or using the <code>VarCorr()</code> function).</p>
<p><img src="images/varcors.PNG" width="400px" style="display: block; margin: auto;" /></p>
<p>In the random-slope model (right panel), the same is true for the differences from each subjects’ slope to the fixed slope.
We can extract the deviations for each group from the fixed effect estimates using the <code>ranef()</code> function.</p>
<p>These are the deviations from the overall intercept (<span class="math inline">\(\widehat \gamma_{00} = 405.79\)</span>) and slope (<span class="math inline">\(\widehat \gamma_{10} = -0.672\)</span>) for each subject <span class="math inline">\(i\)</span>.</p>
<pre class="r"><code>ranef(random_slopes_model)</code></pre>
<pre><code>## $subject
##         (Intercept)          x1
## sub_308   31.327291 -1.43995253
## sub_309  -28.832219  0.41839420
## sub_310    2.711822  0.05993766
## sub_330   59.398971  0.38526670
## sub_331   74.958481  0.17391602
## sub_332   91.086535 -0.23461836
## sub_333   97.852988 -0.19057838
## sub_334  -54.185688 -0.55846794
## sub_335  -16.902018  0.92071637
## sub_337   52.217859 -1.16602280
## sub_349  -67.760246 -0.68438960
## sub_350   -5.821271 -1.23788002
## sub_351   61.198823  0.05499816
## sub_352   -7.905596 -0.66495059
## sub_369  -47.636645 -0.46810258
## sub_370  -33.121093 -1.11001234
## sub_371   77.576205 -0.20402571
## sub_372  -36.389281 -0.45829505
## sub_373 -197.579562  1.79897904
## sub_374  -52.195357  4.60508775
## 
## with conditional variances for &quot;subject&quot;</code></pre>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
Group-level coefficients<span id="opt-start-87" class="fa fa-plus optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-87&#39;, &#39;opt-start-87&#39;)"></span>
</div>
<div id="opt-body-87" class="optional-body" style="display: none;">
<p>We can also see the actual intercept and slope for each subject <span class="math inline">\(i\)</span> directly, using the <code>coef()</code> function.</p>
<pre class="r"><code>coef(random_slopes_model)</code></pre>
<pre><code>## $subject
##         (Intercept)         x1
## sub_308    437.1171 -2.1122179
## sub_309    376.9575 -0.2538712
## sub_310    408.5016 -0.6123277
## sub_330    465.1887 -0.2869987
## sub_331    480.7482 -0.4983494
## sub_332    496.8763 -0.9068837
## sub_333    503.6428 -0.8628438
## sub_334    351.6041 -1.2307333
## sub_335    388.8877  0.2484510
## sub_337    458.0076 -1.8382882
## sub_349    338.0295 -1.3566550
## sub_350    399.9685 -1.9101454
## sub_351    466.9886 -0.6172672
## sub_352    397.8842 -1.3372160
## sub_369    358.1531 -1.1403680
## sub_370    372.6687 -1.7822777
## sub_371    483.3660 -0.8762911
## sub_372    369.4005 -1.1305604
## sub_373    208.2102  1.1267137
## sub_374    353.5944  3.9328224
## 
## attr(,&quot;class&quot;)
## [1] &quot;coef.mer&quot;</code></pre>
<p>Notice that the above are the fixed effects + random effects estimates, i.e. the overall intercept and slope + deviations for each subject.</p>
<pre class="r"><code>coef(random_intercept_model)</code></pre>
<pre><code>## $subject
##         (Intercept)         x1
## sub_308    384.0955 -0.9135829
## sub_309    406.5426 -0.9135829
## sub_310    421.8658 -0.9135829
## sub_330    492.0476 -0.9135829
## sub_331    498.0868 -0.9135829
## sub_332    496.0130 -0.9135829
## sub_333    504.6193 -0.9135829
## sub_334    338.5855 -0.9135829
## sub_335    440.3964 -0.9135829
## sub_337    416.7346 -0.9135829
## sub_349    319.6674 -0.9135829
## sub_350    356.3696 -0.9135829
## sub_351    479.2943 -0.9135829
## sub_352    379.5162 -0.9135829
## sub_369    349.0152 -0.9135829
## sub_370    335.0869 -0.9135829
## sub_371    484.0427 -0.9135829
## sub_372    360.5322 -0.9135829
## sub_373    293.6168 -0.9135829
## sub_374    511.3440 -0.9135829
## 
## attr(,&quot;class&quot;)
## [1] &quot;coef.mer&quot;</code></pre>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
Plotting random effects<span id="opt-start-88" class="fa fa-plus optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-88&#39;, &#39;opt-start-88&#39;)"></span>
</div>
<div id="opt-body-88" class="optional-body" style="display: none;">
<p>The quick and easy way to plot your random effects is to use the <code>dotplot.ranef.mer()</code> function in <code>lme4</code>.</p>
<pre class="r"><code>randoms &lt;- ranef(random_slopes_model, condVar=TRUE)
dotplot.ranef.mer(randoms)</code></pre>
<pre><code>## $subject</code></pre>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-33-1.png" width="80%" style="display: block; margin: auto;" /></p>
<div class="optional-begin">
Completely optional - extracting them for plotting in ggplot<span id="opt-start-89" class="fa fa-plus optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-89&#39;, &#39;opt-start-89&#39;)"></span>
</div>
<div id="opt-body-89" class="optional-body" style="display: none;">
<p>Sometimes, however, we might want to have a bit more control over our plotting, we can extract the estimates and correlations for each subject:</p>
<pre class="r"><code>#we can get the random effects:
#(note that we use $subject because there might be other groupings, and the ranef() function will give us a list, with one element for each grouping variable)
randoms &lt;-
  ranef(random_slopes_model)$subject %&gt;%
  mutate(subject = row.names(.)) %&gt;%  # the subject IDs are stored in the rownames, so lets add them as a variable
  pivot_longer(cols=1:2, names_to=&quot;term&quot;,values_to=&quot;estimate&quot;) # finally, let&#39;s reshape it for plotting

#and the same for the standard errors (from the arm package):
randoms_se &lt;-
  arm::se.ranef(random_slopes_model)$subject %&gt;%
  as.data.frame() %&gt;%
  mutate(subject = row.names(.)) %&gt;%
  pivot_longer(cols=1:2, names_to=&quot;term&quot;,values_to=&quot;se&quot;)

# join them together:
ranefs_plotting &lt;- left_join(randoms, randoms_se)

# it&#39;s easier for plotting if we
ggplot(ranefs_plotting, aes(y=subject, x=estimate))+
  geom_errorbarh(aes(xmin=estimate-2*se, xmax=estimate+2*se))+
  facet_wrap(~term, scales=&quot;free_x&quot;)</code></pre>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-34-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<p class="optional-end">
</p>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
Nested and Crossed structures<span id="opt-start-90" class="fa fa-plus optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-90&#39;, &#39;opt-start-90&#39;)"></span>
</div>
<div id="opt-body-90" class="optional-body" style="display: none;">
<p>The same principle we have seen for one level of clustering can be extended to clustering at different levels (for instance, observations are clustered within subjects, which are in turn clustered within groups).</p>
<p>Consider the example where we have observations for each student in every class within a number of schools:</p>
<p><img src="images/structure_id.png" width="1200px" style="display: block; margin: auto;" /></p>
<p><strong>Question:</strong> Is “Class 1” in “School 1” the same as “Class 1” in “School 2?”</p>
<p>No.<br />
The classes in one school are distinct from the classes in another <strong>even though they are named the same</strong>.</p>
<p>The classes-within-schools example is a good case of <strong>nested random effects</strong> - one factor level (one group in a grouping varible) appears <em>only within</em> a particular level of another grouping variable.</p>
<p>In R, we can specify this using:</p>
<p><code>(1 | school) + (1 | class:school)</code></p>
<p>or, more succinctly:</p>
<p><code>(1 | school/class)</code></p>
<p>Consider another example, where we administer the same set of tasks at multiple time-points for every participant.</p>
<p><strong>Question:</strong> Are tasks nested within participants?</p>
<p>No.<br />
Tasks are seen by multiple participants (and participants see multiple tasks).</p>
<p>We could visualise this as the below:<br />
<img src="images/structure_crossed.png" width="400px" style="display: block; margin: auto;" /></p>
<p>In the sense that these are not nested, they are <strong>crossed</strong> random effects.</p>
<p>In R, we can specify this using:</p>
<p><code>(1 | subject) + (1 | task)</code></p>
<div class="blue">
<p><strong>Nested vs Crossed</strong></p>
<p><em>Nested:</em> Each group belongs uniquely to a higher-level group.</p>
<p><em>Crossed:</em> Not-nested.</p>
</div>
<p>Note that in the schools and classes example, had we changed data such that the classes had unique IDs (e.g., see below), then the structures <code>(1 | school) + (1 | class)</code> and <code>(1 | school/class)</code> would give the same results.<br />
<img src="images/structure_nested.png" width="1200px" style="display: block; margin: auto;" /></p>
</div>
<p class="optional-end">
</p>
</div>
<div id="exercise-a" class="section level1">
<h1>Exercise A</h1>
<div class="question-begin">
Question A1
</div>
<div class="question-body">
<p>Research question:</p>
<blockquote>
<p>Do children scores in maths improve more in school 2020 vs school 2040?</p>
</blockquote>
<p>Load into R the data from the beginning of this lab, on mathematics performance in two schools. These can be found at the following link: <a href="https://uoepsy.github.io/data/MathsAchievement.csv" class="uri">https://uoepsy.github.io/data/MathsAchievement.csv</a></p>
<p>Make sure that variables encoding groups are stored as factors!</p>
<p>Recall that the data represent longitudinal measurements on 42 students from two different schools, with id 2020 and 2040 (21 students from each school). The outcome of interest is mathematics achievement.
The data were collected at the end of first grade and annually thereafter up to sixth grade, but not all students have six observations.
The variable year has been mean-centred to have mean 0 so that results will have as baseline the average.</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-91" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-91&#39;, &#39;sol-start-91&#39;)"></span>
</div>
<div id="sol-body-91" class="solution-body" style="display: none;">
<pre class="r"><code>library(tidyverse)

schools &lt;- read_csv(&#39;https://uoepsy.github.io/data/MathsAchievement.csv&#39;)
schools &lt;- schools %&gt;%
  mutate(schoolid = factor(schoolid),
         childid = factor(childid))

head(schools)</code></pre>
<pre><code>## # A tibble: 6 x 4
##   schoolid childid    year   math
##   &lt;fct&gt;    &lt;fct&gt;     &lt;dbl&gt;  &lt;dbl&gt;
## 1 2020     273026452   0.5  1.15 
## 2 2020     273026452   1.5  1.13 
## 3 2020     273026452   2.5  2.30 
## 4 2020     273030991  -1.5 -1.30 
## 5 2020     273030991  -0.5  0.439
## 6 2020     273030991   0.5  2.43</code></pre>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question A2
</div>
<div class="question-body">
<p>Fit the appropriate model to answer the research question.</p>
<p>Think carefully - what is the question concerning? Where should you include <code>schoolid</code>? as a grouping level, or as a fixed effect?</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-92" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-92&#39;, &#39;sol-start-92&#39;)"></span>
</div>
<div id="sol-body-92" class="solution-body" style="display: none;">
<pre class="r"><code>modschools &lt;- lmer(math ~ 1 + year + schoolid + (1 + year | childid), data = data)
summary(modschools)</code></pre>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: math ~ 1 + year + schoolid + (1 + year | childid)
##    Data: data
## 
## REML criterion at convergence: 332
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -2.85909 -0.67031 -0.06586  0.61547  2.34212 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr
##  childid  (Intercept) 0.50671  0.7118       
##           year        0.01184  0.1088   1.00
##  Residual             0.18643  0.4318       
## Number of obs: 186, groups:  childid, 42
## 
## Fixed effects:
##              Estimate Std. Error       df t value Pr(&gt;|t|)    
## (Intercept)  -0.21077    0.15101 45.36068  -1.396   0.1696    
## year          0.94972    0.02886 24.11700  32.903   &lt;2e-16 ***
## schoolid2040 -0.36306    0.19294 34.82271  -1.882   0.0683 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) year  
## year         0.416       
## schoold2040 -0.650 -0.008
## optimizer (nloptwrap) convergence code: 0 (OK)
## Model failed to converge with max|grad| = 0.00288304 (tol = 0.002, component 1)</code></pre>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question A3
</div>
<div class="question-body">
<ol style="list-style-type: decimal">
<li>extract the overall intercept and slope.</li>
<li>extract the deviations from the overall intercept and slope for each child.<br />
</li>
<li>extract the actual intercept and slope for the line of child <span class="math inline">\(i\)</span><br />
</li>
<li>how do you compute the intercept and slope for the line of child 273030991 using the output from (1) and (2)? Does it agree with (3)?</li>
</ol>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-93" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-93&#39;, &#39;sol-start-93&#39;)"></span>
</div>
<div id="sol-body-93" class="solution-body" style="display: none;">
<pre class="r"><code>fixef(modschools)</code></pre>
<pre><code>##  (Intercept)         year schoolid2040 
##   -0.2107673    0.9497207   -0.3630573</code></pre>
<pre class="r"><code>ranef(modschools)</code></pre>
<pre><code>## $childid
##           (Intercept)         year
## 253404261  0.72336027  0.110392519
## 253413681 -1.74737801 -0.266897951
## 270199271 -0.46293088 -0.070839752
## 273026452  0.21024435  0.032061728
## 273030991  1.13643797  0.173706066
## 273059461  0.63945161  0.097684691
## 278058841  1.28024832  0.195489717
## 285939962  0.43254617  0.066098841
## 288699161  0.57365519  0.087740369
## 289970511  0.09341064  0.014202873
## 292017571  1.40710797  0.215048838
## 292020281 -0.22959172 -0.035153534
## 292020361 -0.37031396 -0.056606784
## 292025081  0.22852401  0.035086662
## 292026211 -0.22032149 -0.033764305
## 292027291  0.24685794  0.037851698
## 292027531  0.06396375  0.009822580
## 292028181 -0.74083925 -0.113102127
## 292028931 -0.07202067 -0.011242204
## 292029071  0.08721703  0.013423313
## 292029901 -0.49863173 -0.075921828
## 292033851 -0.75692101 -0.115459647
## 292772811 -0.70105345 -0.106958259
## 293550291 -0.23040136 -0.035244582
## 295341521  0.06975094  0.010825237
## 298046562 -0.49962987 -0.076393306
## 299680041 -0.04367604 -0.006780972
## 301853741  0.56571795  0.086387594
## 303652591  0.36200112  0.055329846
## 303653561 -0.32092014 -0.049005531
## 303654611 -0.73777527 -0.112808984
## 303658951  0.96735708  0.147887549
## 303660691 -0.71248408 -0.108948838
## 303662391 -0.67733173 -0.103452008
## 303663601 -0.13283943 -0.020263644
## 303668751  0.41668023  0.063369197
## 303671891 -0.52149751 -0.079781383
## 303672001  0.81414597  0.124350637
## 303672861  0.49095808  0.075129264
## 303673321 -0.90990542 -0.139093117
## 307407931  0.73125608  0.111666621
## 307694141 -0.95442964 -0.145837082
## 
## with conditional variances for &quot;childid&quot;</code></pre>
<pre class="r"><code>coef(modschools)</code></pre>
<pre><code>## $childid
##             (Intercept)      year schoolid2040
## 253404261  0.5125929533 1.0601132   -0.3630573
## 253413681 -1.9581453272 0.6828228   -0.3630573
## 270199271 -0.6736981926 0.8788810   -0.3630573
## 273026452 -0.0005229579 0.9817824   -0.3630573
## 273030991  0.9256706545 1.1234268   -0.3630573
## 273059461  0.4286842938 1.0474054   -0.3630573
## 278058841  1.0694810056 1.1452104   -0.3630573
## 285939962  0.2217788532 1.0158195   -0.3630573
## 288699161  0.3628878762 1.0374611   -0.3630573
## 289970511 -0.1173566687 0.9639236   -0.3630573
## 292017571  1.1963406577 1.1647695   -0.3630573
## 292020281 -0.4403590352 0.9145672   -0.3630573
## 292020361 -0.5810812731 0.8931139   -0.3630573
## 292025081  0.0177566996 0.9848074   -0.3630573
## 292026211 -0.4310888043 0.9159564   -0.3630573
## 292027291  0.0360906280 0.9875724   -0.3630573
## 292027531 -0.1468035589 0.9595433   -0.3630573
## 292028181 -0.9516065645 0.8366186   -0.3630573
## 292028931 -0.2827879859 0.9384785   -0.3630573
## 292029071 -0.1235502786 0.9631440   -0.3630573
## 292029901 -0.7093990434 0.8737989   -0.3630573
## 292033851 -0.9676883244 0.8342611   -0.3630573
## 292772811 -0.9118207676 0.8427624   -0.3630573
## 293550291 -0.4411686754 0.9144761   -0.3630573
## 295341521 -0.1410163713 0.9605459   -0.3630573
## 298046562 -0.7103971846 0.8733274   -0.3630573
## 299680041 -0.2544433495 0.9429397   -0.3630573
## 301853741  0.3549506383 1.0361083   -0.3630573
## 303652591  0.1512338057 1.0050506   -0.3630573
## 303653561 -0.5316874534 0.9007152   -0.3630573
## 303654611 -0.9485425779 0.8369117   -0.3630573
## 303658951  0.7565897654 1.0976083   -0.3630573
## 303660691 -0.9232513879 0.8407719   -0.3630573
## 303662391 -0.8880990428 0.8462687   -0.3630573
## 303663601 -0.3436067474 0.9294571   -0.3630573
## 303668751  0.2059129127 1.0130899   -0.3630573
## 303671891 -0.7322648190 0.8699393   -0.3630573
## 303672001  0.6033786603 1.0740713   -0.3630573
## 303672861  0.2801907677 1.0248500   -0.3630573
## 303673321 -1.1206727310 0.8106276   -0.3630573
## 307407931  0.5204887711 1.0613873   -0.3630573
## 307694141 -1.1651969571 0.8038836   -0.3630573
## 
## attr(,&quot;class&quot;)
## [1] &quot;coef.mer&quot;</code></pre>
<pre class="r"><code>fixef(modschools) + ranef(modschools)$childid[&#39;273030991&#39;, ]</code></pre>
<pre><code>##           (Intercept)     year
## 273030991   0.9256707 1.123427</code></pre>
<pre class="r"><code>coef(modschools)$childid[&#39;273030991&#39;, ]</code></pre>
<pre><code>##           (Intercept)     year schoolid2040
## 273030991   0.9256707 1.123427   -0.3630573</code></pre>
</div>
<p class="solution-end">
</p>
</div>
<div id="exercise-b" class="section level1">
<h1>Exercise B</h1>
<div id="the-data" class="section level2">
<h2>The data</h2>
<div class="optional-begin">
Data codebook<span id="opt-start-94" class="fa fa-plus optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-94&#39;, &#39;opt-start-94&#39;)"></span>
</div>
<div id="opt-body-94" class="optional-body" style="display: none;">
<p>44 participants across 4 groups (between-subjects) were tested 5 times (waves) in 11 domains.
In each wave, participants received a score (on a 20-point scale) for each domain and a set of questions which were they answered either correctly or incorrectly.</p>
<pre class="r"><code>load(url(&quot;https://uoepsy.github.io/data/msmr_lab5.RData&quot;))

summary(dat5)</code></pre>
<pre><code>##  Anonymous_Subject_ID   IndivDiff          Wave          Domain         
##  Length:2011          Min.   :39.30   Min.   :1.000   Length:2011       
##  Class :character     1st Qu.:69.20   1st Qu.:2.000   Class :character  
##  Mode  :character     Median :79.70   Median :3.000   Mode  :character  
##                       Mean   :77.73   Mean   :2.712                     
##                       3rd Qu.:88.10   3rd Qu.:4.000                     
##                       Max.   :95.20   Max.   :5.000                     
##                       NA&#39;s   :1474                                      
##     Correct           Error            Group               Score     
##  Min.   : 0.000   Min.   :0.00000   Length:2011        Min.   : 0.0  
##  1st Qu.: 4.000   1st Qu.:0.00000   Class :character   1st Qu.: 8.0  
##  Median : 8.000   Median :0.00000   Mode  :character   Median :14.0  
##  Mean   : 9.904   Mean   :0.06216                      Mean   :12.2  
##  3rd Qu.:12.000   3rd Qu.:0.00000                      3rd Qu.:17.0  
##  Max.   :45.000   Max.   :1.00000                      Max.   :20.0  
## </code></pre>
</div>
<p class="optional-end">
</p>
</div>
<div id="exercise-ba." class="section level2">
<h2>Exercise Ba.</h2>
<blockquote>
<p>Research question
Did the groups differ in overall performance?</p>
</blockquote>
<p>There are different ways to test this: use the 20-point score or the accuracy? Keep the domains separate or calculate an aggregate across all domains? Which way makes the most sense to you?</p>
<div class="question-begin">
Question B1
</div>
<div class="question-body">
<p>Make a plot that corresponds to the reseach question. Does it look like there’s a difference?</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-95" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-95&#39;, &#39;sol-start-95&#39;)"></span>
</div>
<div id="sol-body-95" class="solution-body" style="display: none;">
<p>Lots of options for this one, here is one that shows Group and Domain differences:</p>
<pre class="r"><code>ggplot(dat5, aes(Domain, Score, color=Group)) +
  stat_summary(fun.data=mean_se, geom=&quot;pointrange&quot;) +
  coord_flip()</code></pre>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-45-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Looks like there are group differences and domain differences, but not much in the way of group-by-domain differences.</p>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question B2
</div>
<div class="question-body">
<p>Use a mixed-effects model to test the difference.</p>
<ul>
<li>Will you use a linear or logistic model?</li>
<li>What should the fixed(s) effect be?</li>
<li>What should the random effect(s) be? We have observations clustered by subjects and by domains - are they nested?</li>
</ul>
<p><em>Tip:</em> For now, forget about the longitudinal aspect to the data.</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-96" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-96&#39;, &#39;sol-start-96&#39;)"></span>
</div>
<div id="sol-body-96" class="solution-body" style="display: none;">
<p>We’re interested in the amount to which Groups vary in their overall performance, so we want a fixed effect of Group. Subjects and Domains are not nested - each subject sees different domains, and each domain is seen by multiple subjects.</p>
<pre class="r"><code># maximal model doesn&#39;t converge, removed random Group slopes for Domain
mod_grp &lt;- lmer(Score ~ Group + 
                   (1 | Anonymous_Subject_ID) + 
                   (1 | Domain), 
                 data=dat5, REML=FALSE)
summary(mod_grp)</code></pre>
<pre><code>## Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s
##   method [lmerModLmerTest]
## Formula: Score ~ Group + (1 | Anonymous_Subject_ID) + (1 | Domain)
##    Data: dat5
## 
##      AIC      BIC   logLik deviance df.resid 
##  10398.2  10437.5  -5192.1  10384.2     2004 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -5.0251 -0.4981  0.0639  0.6338  3.2779 
## 
## Random effects:
##  Groups               Name        Variance Std.Dev.
##  Anonymous_Subject_ID (Intercept) 19.486   4.414   
##  Domain               (Intercept)  1.064   1.031   
##  Residual                          9.122   3.020   
## Number of obs: 2011, groups:  Anonymous_Subject_ID, 44; Domain, 11
## 
## Fixed effects:
##             Estimate Std. Error     df t value Pr(&gt;|t|)    
## (Intercept)   15.832      1.121 50.067  14.122  &lt; 2e-16 ***
## GroupB        -4.159      2.262 44.369  -1.839   0.0727 .  
## GroupC        -3.621      1.768 43.968  -2.048   0.0465 *  
## GroupW        -7.270      1.673 44.042  -4.345 8.09e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##        (Intr) GroupB GroupC
## GroupB -0.457              
## GroupC -0.585  0.290       
## GroupW -0.618  0.306  0.392</code></pre>
<p>Yes, substantial Group differences: overall, group A does the best, groups B and C next, and group W does the worst.</p>
</div>
<p class="solution-end">
</p>
</div>
<div id="exercise-bb" class="section level2">
<h2>Exercise Bb</h2>
<blockquote>
<p>Research question
Did performance change over time (across waves)? Did the groups differ in pattern of change?</p>
</blockquote>
<div class="question-begin">
Question B3
</div>
<div class="question-body">
<p>Make a plot that corresponds to the research question. Does it look like there was a change? A group difference?</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-97" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-97&#39;, &#39;sol-start-97&#39;)"></span>
</div>
<div id="sol-body-97" class="solution-body" style="display: none;">
<pre class="r"><code>ggplot(dat5, aes(Wave, Score, color=Group, fill=Group)) +
  stat_summary(fun.data=mean_se, geom=&quot;ribbon&quot;, alpha=0.3, color=NA) +
  stat_summary(fun.y=mean, geom=&quot;line&quot;)</code></pre>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-47-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Yes, looks like groups A, C, and W are improving, but group B is getting worse.</p>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question B4
</div>
<div class="question-body">
<p>Use mixed-effects model(s) to test this.<br />
<br>
<em>Hint:</em> Fit a baseline model in which scores change over time (wave), then assess improvement in model fit due to inclusion of overall group effect and finally the interaction of group with time.</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-98" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-98&#39;, &#39;sol-start-98&#39;)"></span>
</div>
<div id="sol-body-98" class="solution-body" style="display: none;">
<pre class="r"><code>mod_wv &lt;- lmer(Score ~ Wave + 
                   (1 + Wave | Anonymous_Subject_ID) + 
                   (1 + Wave | Domain), 
                 data=dat5, REML=FALSE,
                 lmerControl(optimizer = &quot;bobyqa&quot;))

mod_wv_grp &lt;- lmer(Score ~ Wave+Group + 
                   (1 + Wave | Anonymous_Subject_ID) + 
                   (1 + Wave | Domain), 
                 data=dat5, REML=FALSE,
                 lmerControl(optimizer = &quot;bobyqa&quot;))

mod_wv_x_grp &lt;- lmer(Score ~ Wave*Group + 
                   (1 + Wave | Anonymous_Subject_ID) + 
                   (1 + Wave | Domain), 
                 data=dat5, REML=FALSE,
                 lmerControl(optimizer = &quot;bobyqa&quot;))

anova(mod_wv, mod_wv_grp, mod_wv_x_grp)</code></pre>
<pre><code>## Data: dat5
## Models:
## mod_wv: Score ~ Wave + (1 + Wave | Anonymous_Subject_ID) + (1 + Wave | Domain)
## mod_wv_grp: Score ~ Wave + Group + (1 + Wave | Anonymous_Subject_ID) + (1 + Wave | Domain)
## mod_wv_x_grp: Score ~ Wave * Group + (1 + Wave | Anonymous_Subject_ID) + (1 + Wave | Domain)
##              npar    AIC    BIC  logLik deviance   Chisq Df Pr(&gt;Chisq)   
## mod_wv          9 9719.6 9770.1 -4850.8   9701.6                         
## mod_wv_grp     12 9710.3 9777.6 -4843.1   9686.3 15.3456  3   0.001544 **
## mod_wv_x_grp   15 9710.5 9794.6 -4840.2   9680.5  5.8105  3   0.121204   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(mod_wv_x_grp)</code></pre>
<pre><code>## Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite&#39;s
##   method [lmerModLmerTest]
## Formula: Score ~ Wave * Group + (1 + Wave | Anonymous_Subject_ID) + (1 +  
##     Wave | Domain)
##    Data: dat5
## Control: lmerControl(optimizer = &quot;bobyqa&quot;)
## 
##      AIC      BIC   logLik deviance df.resid 
##   9710.5   9794.6  -4840.2   9680.5     1996 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -5.0053 -0.5764  0.0049  0.6132  3.7519 
## 
## Random effects:
##  Groups               Name        Variance Std.Dev. Corr 
##  Anonymous_Subject_ID (Intercept) 22.36604 4.7293        
##                       Wave         0.74787 0.8648   -0.34
##  Domain               (Intercept)  2.05332 1.4329        
##                       Wave         0.02189 0.1479   -0.99
##  Residual                          6.06856 2.4634        
## Number of obs: 2011, groups:  Anonymous_Subject_ID, 44; Domain, 11
## 
## Fixed effects:
##             Estimate Std. Error       df t value Pr(&gt;|t|)    
## (Intercept) 12.77276    1.24928 52.57242  10.224 4.23e-14 ***
## Wave         1.25475    0.23886 44.74521   5.253 4.00e-06 ***
## GroupB      -1.36480    2.47446 45.83802  -0.552  0.58393    
## GroupC      -4.14669    1.91661 43.86581  -2.164  0.03599 *  
## GroupW      -6.31853    1.81665 44.18633  -3.478  0.00115 ** 
## Wave:GroupB -1.14231    0.52920 50.14297  -2.159  0.03570 *  
## Wave:GroupC -0.03687    0.36863 36.73490  -0.100  0.92087    
## Wave:GroupW -0.50887    0.35468 38.78415  -1.435  0.15937    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) Wave   GroupB GroupC GroupW Wv:GrB Wv:GrC
## Wave        -0.412                                          
## GroupB      -0.444  0.175                                   
## GroupC      -0.574  0.226  0.290                            
## GroupW      -0.605  0.239  0.306  0.395                     
## Wave:GroupB  0.157 -0.436 -0.389 -0.102 -0.108              
## Wave:GroupC  0.225 -0.625 -0.114 -0.366 -0.155  0.282       
## Wave:GroupW  0.234 -0.650 -0.118 -0.153 -0.370  0.293  0.421</code></pre>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question B5
</div>
<div class="question-body">
<p>Plot the group-level data (see Question B3) and model fitted values for each group from your final model from Question B4.<br />
<br>
<em>Hint:</em> using <code>broom.mixed::augment(model)</code> as your starting point will help.</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-99" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-99&#39;, &#39;sol-start-99&#39;)"></span>
</div>
<div id="sol-body-99" class="solution-body" style="display: none;">
<pre class="r"><code>broom.mixed::augment(mod_wv_x_grp) %&gt;%
  ggplot(., aes(Wave, Score, color=Group)) +
  stat_summary(fun.data=mean_se, geom=&quot;pointrange&quot;) +
  stat_summary(aes(y=.fitted), fun=mean, geom=&quot;line&quot;)</code></pre>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-49-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><em>We fit a linear model, but the model fit lines are not straight lines. Why is that?</em></p>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question B6
</div>
<div class="question-body">
<p>Create individual subject plots for the data and the model’s fitted values. Will these show straight lines?<br />
<br>
<em>Hint:</em> make use of <code>facet_wrap()</code> to create a different panel for each level of a grouping variable.</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-100" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-100&#39;, &#39;sol-start-100&#39;)"></span>
</div>
<div id="sol-body-100" class="solution-body" style="display: none;">
<pre class="r"><code>broom.mixed::augment(mod_wv_x_grp) %&gt;%
  ggplot(., aes(Wave, Score, color=Group)) +
  facet_wrap(~ Anonymous_Subject_ID) +
  stat_summary(fun.data=mean_se, geom=&quot;pointrange&quot;) +
  stat_summary(aes(y=.fitted), fun.y=mean, geom=&quot;line&quot;)</code></pre>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-50-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>The individual subject plots show linear fits, which is a better match to the model. But now we see the missing data – some participants only completed the first few waves.</p>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question B7
</div>
<div class="question-body">
<p>Make a plot of the actual (linear) model prediction.<br />
<br>
<em>Hint:</em> Use the <code>effect()</code> function from the <code>effects</code> package.</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-101" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-101&#39;, &#39;sol-start-101&#39;)"></span>
</div>
<div id="sol-body-101" class="solution-body" style="display: none;">
<pre class="r"><code>library(effects)
ef &lt;- as.data.frame(effect(&quot;Wave:Group&quot;, mod_wv_x_grp))
ggplot(ef, aes(Wave, fit, color=Group, fill=Group)) +
  geom_ribbon(aes(ymax=fit+se, ymin=fit-se), color=NA, alpha=0.1) +
  geom_line()</code></pre>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-51-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question B8
</div>
<div class="question-body">
<p>What important things are different between the plot from question B7 and that from question B5?<br />
You can see the plots we created for these questions below:</p>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-52-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-102" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-102&#39;, &#39;sol-start-102&#39;)"></span>
</div>
<div id="sol-body-102" class="solution-body" style="display: none;">
<p><em>Group B was not actually getting worse. The appearance that it was getting worse is an artifact of selective drop-out: there’s only a few people in this group and the better-performing ones only did the first few waves so they are not represented in the later waves, but the worse-performing ones are contributing to the later waves. The model estimates how the better-performing ones would have done in later waves based on their early-wave performance and the pattern of performance of other participants in the study.</em></p>
<pre class="r"><code>summary(mod_wv_x_grp)$coefficients</code></pre>
<pre><code>##                Estimate Std. Error       df    t value     Pr(&gt;|t|)
## (Intercept) 12.77275565  1.2492775 52.57242 10.2241143 4.233953e-14
## Wave         1.25474611  0.2388610 44.74521  5.2530381 3.998024e-06
## GroupB      -1.36479858  2.4744579 45.83802 -0.5515546 5.839325e-01
## GroupC      -4.14668919  1.9166107 43.86581 -2.1635532 3.598767e-02
## GroupW      -6.31853259  1.8166464 44.18633 -3.4781301 1.146411e-03
## Wave:GroupB -1.14230833  0.5292011 50.14297 -2.1585523 3.569665e-02
## Wave:GroupC -0.03687025  0.3686301 36.73490 -0.1000196 9.208726e-01
## Wave:GroupW -0.50887203  0.3546769 38.78415 -1.4347482 1.593740e-01</code></pre>
<p>Note that the Group A slope (coefficient for <code>Wave</code>) is 1.255 and, relative to that slope, the Group B slope is -1.142 (coefficient for <code>Wave:GroupB</code>). This means that the model-estimated slope for Group B is 0.112, which is very slightly positive, not strongly negative as appeared in the initial plots.</p>
<p>One of the valuable things about mixed-effects (aka multilevel) modeling is that individual-level and group-level trajectories are estimated. This helps the model overcome missing data in a sensible way. In fact, MLM/MLR models are sometimes used for imputing missing data. However, one has to think carefully about <em>why</em> data are missing. Group B is small and it might just be a coincidence that the better-performing participants dropped out after the first few waves, which would make it easier to generalize the patterns to them. On the other hand, it might be the case that there is something about the study that makes better-performing members of Group B drop out, which should make us suspicious of generalizing to them.</p>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question B9
</div>
<div class="question-body">
<p>Create a plot of the subject and domain random effects.
Notice the pattern between the random intercept and random slope estimates for the 11 domains - what in our model is this pattern representing?</p>
<p class="question-end">
</p>
</div>
<div class="solution-begin">
Solution <span id="sol-start-103" class="fa fa-plus solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-103&#39;, &#39;sol-start-103&#39;)"></span>
</div>
<div id="sol-body-103" class="solution-body" style="display: none;">
<pre class="r"><code>randoms &lt;- ranef(mod_wv_x_grp, condVar=TRUE)
dotplot.ranef.mer(randoms)</code></pre>
<pre><code>## $Anonymous_Subject_ID</code></pre>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-55-1.png" width="80%" style="display: block; margin: auto;" /></p>
<pre><code>## 
## $Domain</code></pre>
<p><img src="05_multilevel_recap_files/figure-html/unnamed-chunk-55-2.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Notice that the domains with the lower relative intercept tend to have a higher relative slope (and vice versa). This is the negative correlation between random intercepts and slopes for domain in our model:</p>
<pre class="r"><code>VarCorr(mod_wv_x_grp)</code></pre>
<pre><code>##  Groups               Name        Std.Dev. Corr  
##  Anonymous_Subject_ID (Intercept) 4.72927        
##                       Wave        0.86479  -0.336
##  Domain               (Intercept) 1.43294        
##                       Wave        0.14795  -0.993
##  Residual                         2.46344</code></pre>
<p>Try removing the correlation (hint: use the <code>||</code>) to see what happens. Does it make sense that these would be correlated? (Answer: we don’t really know enough about the study, but it’s something to think about!)</p>
</div>
<p class="solution-end">
</p>
<!-- Formatting -->
<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;">

</div>
</div>
</div>

<link rel="stylesheet" href="https://uoepsy.github.io/assets/css/ccfooter.css" />
<div class="ccfooter"></div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
