<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Longitudinal Mixed Models (linear growth) | Logistic Mixed Models</title>

<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);
e.style.display = ((e.style.display!='none') ? 'none' : 'block');
if(f.classList.contains('fa-chevron-circle-right')) {
    f.classList.add('fa-chevron-circle-down')
    f.classList.remove('fa-chevron-circle-right')
} else {
    f.classList.add('fa-chevron-circle-right')
    f.classList.remove('fa-chevron-circle-down')
}
}
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="assets/style-labs.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"><strong>MSMR</strong></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Mixed Effects Models
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="01_intromlm.html">1: Intro to Multi-Level Modelling</a>
    </li>
    <li>
      <a href="02_lmm_log.html">2: Logistic | Longitudinal (linear)</a>
    </li>
    <li>
      <a href="03_nonlin.html">3: Longitudinal (non-linear)</a>
    </li>
    <li>
      <a href="04_ranef.html">4: Random Effect Structures</a>
    </li>
    <li>
      <a href="05_multilevel_recap.html">5: Multilevel Modelling Recap</a>
    </li>
    <li class="dropdown-header">FLW: Flexible Learning Week</li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Data Reduction &amp; SEM
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="06_efapca.html">6: PCA | EFA</a>
    </li>
    <li>
      <a href="07_cfa.html">7: CFA</a>
    </li>
    <li>
      <a href="08_path.html">8: Path Analysis</a>
    </li>
    <li>
      <a href="09_sem1.html">9: SEM 1</a>
    </li>
    <li>
      <a href="10_sem2.html">10: SEM 2</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-info-circle"></span>
     
    Extras
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="00_tidyverse_markdown.html">Recap - Tidyverse &amp; Markdown</a>
    </li>
  </ul>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Longitudinal Mixed Models (linear growth) | Logistic Mixed Models</h1>

</div>


<div class="blue">
<p><strong>Preliminaries</strong></p>
<ol style="list-style-type: decimal">
<li><p>Open Rstudio, create a new R Script or RMarkdown document (whichever you prefer working with) and give it a title for this week.</p></li>
<li><p>Load any of the packages you think you might be using today.<br />
By now you may have started get into a sort of routine with R, and you might know what functions you like, and which you don’t. Because there are so many alternatives for doing the same thing, the packages and functions you use are very much up to you.<br />
If I’m planning on doing some multi-level modelling, I will tend to load these by default at the top:</p>
<pre class="r"><code>library(tidyverse) # for everything
library(lme4) # for fitting models
library(broom.mixed) # for tidying model output</code></pre></li>
</ol>
</div>
<!-- # Exercises: Longitudinal Models -->
<!-- Last week when we introduced multilevel models (or "mixed effects models" or whatever we're calling them!), we saw in the lectures a little bit about the idea of having datapoints from the same participant _over time_. This kind of data tends to get termed "longitudinal" (mainly used to refer to studies which follow-up participants over the course of months or years). The lectures this week have also introduced this idea of 'change over time' by looking at some data from Public Health England.    -->
<!-- Let's work our way through an example.  -->
<!-- :::frame -->
<!-- __WeightMaintain Data Codebook__   -->
<!-- The weight maintenance data (`WeightMaintain3`), a made-up data set based on Lowe et al. (2014, Obesity, 22, 94-100), contains information on overweight participants who completed a 12-week weight loss program, and were then randomly assigned to one of three weight maintenance conditions: -->
<!-- * None (Control)   -->
<!-- * MR (meal replacements): use MR to replace one meal and snack per day   -->
<!-- * ED (energy density intervention): book and educational materials on purchasing and preparing foods lower in ED (reducing fat content and/or increasing water content of foods)   -->
<!-- Weight was assessed on day 1 of maintenance, 12 months post, 24 months post, and 36 months post. -->
<!-- It is available, in **.rda** format, at https://uoepsy.github.io/data/WeightMaintain3.rda   -->
<!-- ```{r echo=FALSE} -->
<!-- load(url("https://uoepsy.github.io/data/WeightMaintain3.rda")) -->
<!-- data.frame( -->
<!--   variable = names(WeightMaintain3), -->
<!--   description = c("Participant ID","Weight Maintenance Condition ('None' = No maintenance program, 'MR' = Meal replacement, 'ED' = Energy Density intervention)", "Assessment number (0 = Day 1, 1 = 12 months, 2 = 24 months, 3 = 36 months)", "Difference in weight (lbs) from end of 12-week weight loss program") -->
<!-- ) %>% knitr::kable() -->
<!-- ``` -->
<!-- ::: -->
<!-- 

<div class='question-begin'>Question A1</div><div class='question-body'>

 -->
<!-- Load the data, and take a look at what is in there. Hopefully it should match the description above.   -->
<!-- **Hint:** `load(url("https://uoepsy.github.io/data/WeightMaintain3.rda"))` -->
<!-- 

</div><p class="question-end"></p>

 -->
<!-- 

<div class="solution-begin"><span id='sol-start-35' class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility('sol-body-35', 'sol-start-35')">  Solution </span></div><div class="solution-body" id = "sol-body-35" style="display: none;">

 -->
<!-- ```{r} -->
<!-- load(url("https://uoepsy.github.io/data/WeightMaintain3.rda")) -->
<!-- summary(WeightMaintain3) -->
<!-- head(WeightMaintain3) -->
<!-- ``` -->
<!-- 

</div><p class="solution-end"></p>

 -->
<!-- 

<div class='question-begin'>Question A2</div><div class='question-body'>

   -->
<!-- > Q: Overall, did the participants maintain their weight loss or did their weights change? -->
<!-- We need to remember that each of our participants has measurements at 4 assessments. We have randomly sampled participants, and then within them have measured multiple observations. So our observations are __not independent__. We're not interested in estimating differences between specific participants - our participants are just a random sample of people. But we do want to account for the dependency they introduce in our data. This is why we would want to fit a multilevel model and incorporate participant-level variation into our model structure.    -->
<!-- 1. Fit an "intercept-only" model.  -->
<!-- 2. Fit a model with weight change predicted by assessment.   -->
<!-- 3. Compare the two models (use `anova(model1, model2)` to conduct a likelihood ratio test). -->
<!-- Things to think about:   -->
<!-- - We _cannot_ compare models that differ in both the fixed *and* random parts.   -->
<!-- - __For now__, ignore messages saying `boundary (singular) fit: see ?isSingular` (that comes in a couple of questions' time).     -->
<!-- 

</div><p class="question-end"></p>

 -->
<!-- 

<div class="solution-begin"><span id='sol-start-36' class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility('sol-body-36', 'sol-start-36')">  Solution </span></div><div class="solution-body" id = "sol-body-36" style="display: none;">

 -->
<!-- This is our null model: -->
<!-- ```{r} -->
<!-- m.null <- lmer(WeightChange ~ 1 + (1 | ID), data=WeightMaintain3) -->
<!-- summary(m.null) -->
<!-- ``` -->
<!-- We can see the `3.77 / (3.77 + 6.43)`, or 0.37 of the total variance is attributable to participant-level variation.  -->
<!-- Now lets suppose we want to compare this null model with a model with an effect of `Assessment` (to assess whether there is overall change over time). -->
<!-- Which model should we compare `m.null` to?   -->
<!-- ```{r} -->
<!-- modA <- lmer(WeightChange ~ 1 + Assessment + (1 + Assessment | ID), data=WeightMaintain3) -->
<!-- modB <- lmer(WeightChange ~ 1 + Assessment + (1 | ID), data=WeightMaintain3) -->
<!-- ``` -->
<!-- A comparison between these `m.null` and `modA` will not be assessing the influence of _only_ the fixed effect of Assessment. Remember, we shouldn't compare models with different random effect structures.    -->
<!-- However, `modB` doesn't include our by-participant random effects of assessment, so comparing this to `m.null` is potentially going to misattribute random deviations in participants' change to being an overall effect of assessment.   -->
<!-- If we want to conduct a model comparison to isolate the effect of overall change over time (a fixed effect of `Assessment`), we _might_ want to compare these two models: -->
<!-- ```{r} -->
<!-- m.base0 <- lmer(WeightChange ~ 1 + (1 + Assessment | ID), data=WeightMaintain3) -->
<!-- m.base <- lmer(WeightChange ~ 1 + Assessment + (1 + Assessment | ID), data=WeightMaintain3) -->
<!-- ``` -->
<!-- The first of these models is a bit weird to think about - how can we have by-participant random deviations of `Assessment` if we don't have a fixed effect of `Assessment`? That makes very little sense. What it is actually fitting is a model where there is assumed to be __no overall effect__ of Assessment. So the fixed effect is 0.  -->
<!-- ```{r} -->
<!-- # Straightforward LRT -->
<!-- anova(m.base0, m.base) -->
<!-- ``` -->
<!-- This suggests that the inclusion Assessment does improve model fit, indicating that participants' weights changed over course of 36 month assessment period.  -->
<!-- 

</div><p class="solution-end"></p>

 -->
<!-- 

<div class='question-begin'>Question A3</div><div class='question-body'>

 -->
<!-- > Q: Did the experimental condition groups differ in overall weight change and rate of weight change (non-maintenance)?   -->
<!-- *Hint:* It helps to break it down. There are two questions here:   -->
<!--   1. do groups differ overall?   -->
<!--   2. do groups differ over time?   -->
<!-- We can begin to see that we're asking two questions about the `Condition` variable here: "is there an effect of Condition?" and "Is there an interaction between Assessment and Condition?".   -->
<!-- Try fitting two more models which incrementally build these levels of complexity, and compare them (perhaps to one another, perhaps to models from the previous question - think about what each comparison is testing!)   -->
<!-- 

</div><p class="question-end"></p>

 -->
<!-- 

<div class="solution-begin"><span id='sol-start-37' class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility('sol-body-37', 'sol-start-37')">  Solution </span></div><div class="solution-body" id = "sol-body-37" style="display: none;">

 -->
<!-- ```{r} -->
<!-- m.int <- lmer(WeightChange ~ Assessment + Condition + (1 + Assessment | ID),  -->
<!--               data=WeightMaintain3) -->
<!-- m.full <- lmer(WeightChange ~ Assessment*Condition + (1 + Assessment | ID),  -->
<!--                data=WeightMaintain3) -->
<!-- ``` -->
<!-- We're going to compare each model to the previous one to examine the improvement in fit due to inclusion of each parameter.  -->
<!-- We could do this quickly with -->
<!-- ```{r} -->
<!-- anova(m.base0, m.base, m.int, m.full) -->
<!-- ``` -->
<!-- - Conditions differed overall in weight change $\chi^2(2)=9.4, p = .009$   -->
<!-- - Conditions differed in change over assessment period $\chi^2(2)=40.4, p < .001$ -->
<!-- 

</div><p class="solution-end"></p>

 -->
<!-- :::frame -->
<!-- __`boundary (singular) fit: see ?isSingular`__   -->
<!-- Okay. Let's talk about those "singular fits" messages we keep getting.   -->
<!-- By now, you have hopefully fitted a number of models which incrementally add predictors. Ours are below:   -->
<!-- ```{r} -->
<!-- m.base0 <- lmer(WeightChange ~ 1 + (1 + Assessment | ID), data=WeightMaintain3) -->
<!-- m.base <- lmer(WeightChange ~ Assessment + (1 + Assessment | ID), data=WeightMaintain3) -->
<!-- m.int <- lmer(WeightChange ~ Assessment + Condition + (1 + Assessment | ID), data=WeightMaintain3) -->
<!-- m.full <- lmer(WeightChange ~ Assessment * Condition + (1 + Assessment | ID), data=WeightMaintain3) -->
<!-- ``` -->
<!-- And many of these models were singular fits, and we just ignored them. __We shouldn't have.__   -->
<!-- __What is the warning message telling us?__   -->
<!-- The warning is telling us that our model has resulted in a 'singular fit'. The easiest way to think of this is to think of it as indicating that the model is 'overfitted' - that there is _not enough variation in our data_ for our model to be estimated properly.   -->
<!-- __What can we do?__   -->
<!-- In many cases, perhaps the most intuitive advice would be remove the most complex part of the random effects structure (i.e. random slopes). This leads to a simpler model that is not over-fitted. In other words, start simplifying from the top (where the most complexity is) to the bottom (where the lowest complexity is). -->
<!-- Additionally, when variance estimates are very low for a specific random effect term, this indicates that the model is not estimating this parameter to differ much between the levels of your grouping variable. It might, in some experimental designs, be perfectly acceptable to remove this or simply include it as a fixed effect. -->
<!-- A key point here is that when fitting a mixed model, __we should think about how the data are generated.__ Asking yourself questions such as "do we have good reason to assume subjects might vary over time, or to assume that they will have different starting points (i.e., different intercepts)?" can help you in specifying your random effect structure -->
<!-- You can read in depth about what this means by reading the help documentation for `?isSingular`. For our purposes, a relevant section is copied below:   -->
<!-- *... intercept-only models, or 2-dimensional random effects such as intercept + slope models, singularity is relatively easy to detect because it leads to random-effect variance estimates of (nearly) zero, or estimates of correlations that are (almost) exactly -1 or 1.* -->
<!-- ::: -->
<!-- 

<div class='question-begin'>Question A4</div><div class='question-body'>

 -->
<!-- Re-read the description of the data, then ask yourself this question:   -->
<!-- Do we think participants will vary in:   -->
<!--   a. their _starting_ weight differences `(1|ID)`? -->
<!--   b. their weight change over the course of the assessment period `(0 + Assessment | ID)`? -->
<!--   c. both `(1 + Assessment | ID)`?   -->
<!-- _Hint:_  What do we think the baseline weight should be? Should it be the same for everyone? If so, might we want to remove the random intercept, which we do by setting it to 0 -->
<!-- Can you re-fit your models without encountering singular fits?    -->
<!-- 

</div><p class="question-end"></p>

 -->
<!-- 

<div class="solution-begin"><span id='sol-start-38' class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility('sol-body-38', 'sol-start-38')">  Solution </span></div><div class="solution-body" id = "sol-body-38" style="display: none;">

 -->
<!-- In this very specific research design, it may actually make a lot of sense to not model by-participant variation around the intercept.   -->
<!-- As baseline is at the very start of the weight maintenance, it makes sense that we wouldn't have very much (if any) participant variation in change at this point.  -->
<!-- Note that by removing the estimation of this parameter, our models now converge! -->
<!-- ```{r} -->
<!-- m.base0 <- lmer(WeightChange ~ 1 + (0 + Assessment | ID), data=WeightMaintain3) -->
<!-- m.base <- lmer(WeightChange ~ 1 + Assessment + (0 + Assessment | ID), data=WeightMaintain3) -->
<!-- m.int <- lmer(WeightChange ~ 1 + Assessment + Condition + (0 + Assessment | ID), data=WeightMaintain3) -->
<!-- m.full <- lmer(WeightChange ~ 1 + Assessment * Condition + (0 + Assessment | ID), data=WeightMaintain3) -->
<!-- ``` -->
<!-- We can check if a model has a singular fit:   -->
<!-- ```{r} -->
<!-- isSingular(m.base) -->
<!-- ``` -->
<!-- 

</div><p class="solution-end"></p>

 -->
<!-- 

<div class='question-begin'>Question A5</div><div class='question-body'>

 -->
<!-- Make a graph of the model fit *and* the observed means and standard errors at each time point for each condition.   -->
<!-- Try using the **effects** package (hint, does this help: `as.data.frame(effect("Assessment:Condition", model))`?) -->
<!-- 

</div><p class="question-end"></p>

 -->
<!-- 

<div class="solution-begin"><span id='sol-start-39' class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility('sol-body-39', 'sol-start-39')">  Solution </span></div><div class="solution-body" id = "sol-body-39" style="display: none;">

 -->
<!-- ```{r} -->
<!-- library(effects) -->
<!-- ef <- as.data.frame(effect("Assessment:Condition", m.full)) -->
<!-- ggplot(ef, aes(Assessment, fit, color=Condition)) +  -->
<!--   geom_line() + -->
<!--   stat_summary(data=WeightMaintain3, aes(y=WeightChange),  -->
<!--                fun.data=mean_se, geom="pointrange", size=1) + -->
<!--   theme_bw() -->
<!-- ``` -->
<!-- 

</div><p class="solution-end"></p>

 -->
<!-- 

<div class='question-begin'>Question A6</div><div class='question-body'>

 -->
<!-- Now let's move to interpreting the coefficients.  -->
<!-- Remember, we can get the coefficients using `fixef(model)`.  -->
<!-- We can also use `tidy(model)`, and similar to models fitted with `lm()`, we can pull out the bit of the `summary()` using:   -->
<!-- ```{r eval=FALSE} -->
<!-- summary(model)$coefficients -->
<!-- ``` -->
<!-- From your model from the previous question which investigates whether conditions differed in their rate of weight change, examine the parameter estimates and interpret them (i.e., what does each parameter represent?) -->
<!-- 

</div><p class="question-end"></p>

 -->
<!-- 

<div class="solution-begin"><span id='sol-start-40' class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility('sol-body-40', 'sol-start-40')">  Solution </span></div><div class="solution-body" id = "sol-body-40" style="display: none;">

 -->
<!-- ```{r} -->
<!-- round(coef(summary(m.full)), 3) -->
<!-- ``` -->
<!-- * `(Intercept)` ==> weight change at baseline in None group -->
<!-- * `Assessment`  ==> slope of weight change in None group -->
<!-- * `ConditionED` ==> baseline weight change in ED group relative to None group -->
<!-- * `ConditionMR` ==> baseline weight change in MR group relative to None group -->
<!-- * `Assessment:ConditionED`  ==> slope of weight change in ED group relative to None group -->
<!-- * `Assessment:ConditionMR`  ==> slope of weight change in MR groups relative to None group -->
<!-- 

</div><p class="solution-end"></p>

 -->
<!-- 

<div class='question-begin'>Question A7</div><div class='question-body'>

 -->
<!-- Can you state how the conditions differed?   -->
<!-- 

</div><p class="question-end"></p>

 -->
<!-- 

<div class="solution-begin"><span id='sol-start-41' class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility('sol-body-41', 'sol-start-41')">  Solution </span></div><div class="solution-body" id = "sol-body-41" style="display: none;">

 -->
<!-- ```{r} -->
<!-- summary(m.full)$coefficients -->
<!-- ``` -->
<!-- :::int -->
<!-- Compared to no intervention, weight (re)gain was 1.75 lbs/year slower for the ED intervention and 0.84 lbs/year slower for the MR intervention. -->
<!-- ::: -->
<!-- 

</div><p class="solution-end"></p>

 -->
<div id="exercises-logistic-mlm" class="section level1">
<h1>Exercises: Logistic MLM</h1>
<div class="frame">
<p><strong>Don’t forget to look back at other materials!</strong></p>
<p>Back in USMR, we introduced logistic regression in week 10. The lectures followed the example of some <a href="https://uoepsy.github.io/usmr/lectures/lecture_9.html#1">singing aliens that either survived or were splatted</a>, and the exercises used some simulated data based on a hypothetical study <a href="https://uoepsy.github.io/usmr/labs/09_glm.html">about inattentional blindness</a>.
That content will provide a lot of the groundwork for this week, so we recommend revisiting it if you feel like it might be useful.</p>
</div>
<div class="rtip">
<p><strong>lmer() &gt;&gt; glmer()</strong></p>
<p>Remember how we simply used <code>glm()</code> and could specify the <code>family = "binomial"</code> in order to fit a logistic regression? Well it’s much the same thing for multi-level models!</p>
<ul>
<li>Gaussian model:
<ul>
<li><code>lmer(y ~ x1 + x2 + (1 | g), data = data)</code><br />
</li>
</ul></li>
<li>Binomial model:
<ul>
<li><code>glmer(y ~ x1 + x2 + (1 | g), data = data, family = binomial(link='logit'))</code></li>
<li>or just <code>glmer(y ~ x1 + x2 + (1 | g), data = data, family = "binomial")</code></li>
<li>or <code>glmer(y ~ x1 + x2 + (1 | g), data = data, family = binomial)</code></li>
</ul></li>
</ul>
<div class="optional-begin">
<span id="opt-start-42" class="fa fa-chevron-circle-right optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-42&#39;, &#39;opt-start-42&#39;)"> Binary? Binomial? Huh?</span>
</div>
<div id="opt-body-42" class="optional-body" style="display: none;">
<p>Very briefly in the USMR materials we made the distinction between <strong>binary</strong> and <strong>binomial</strong>. This wasn’t hugely relevant at the time just because we only looked at binary outcomes.</p>
<p>For binary regression, all the data in our outcome variable has to be a 0 or a 1.<br />
For example, the <code>correct</code> variable below:<br />
<br></p>
<div id="djjopiozsh" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#djjopiozsh .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#djjopiozsh .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#djjopiozsh .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#djjopiozsh .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#djjopiozsh .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#djjopiozsh .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#djjopiozsh .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#djjopiozsh .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#djjopiozsh .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#djjopiozsh .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#djjopiozsh .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#djjopiozsh .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#djjopiozsh .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#djjopiozsh .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#djjopiozsh .gt_from_md > :first-child {
  margin-top: 0;
}

#djjopiozsh .gt_from_md > :last-child {
  margin-bottom: 0;
}

#djjopiozsh .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#djjopiozsh .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#djjopiozsh .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#djjopiozsh .gt_row_group_first td {
  border-top-width: 2px;
}

#djjopiozsh .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#djjopiozsh .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#djjopiozsh .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#djjopiozsh .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#djjopiozsh .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#djjopiozsh .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#djjopiozsh .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#djjopiozsh .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#djjopiozsh .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#djjopiozsh .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-left: 4px;
  padding-right: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#djjopiozsh .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#djjopiozsh .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#djjopiozsh .gt_left {
  text-align: left;
}

#djjopiozsh .gt_center {
  text-align: center;
}

#djjopiozsh .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#djjopiozsh .gt_font_normal {
  font-weight: normal;
}

#djjopiozsh .gt_font_bold {
  font-weight: bold;
}

#djjopiozsh .gt_font_italic {
  font-style: italic;
}

#djjopiozsh .gt_super {
  font-size: 65%;
}

#djjopiozsh .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 75%;
  vertical-align: 0.4em;
}

#djjopiozsh .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#djjopiozsh .gt_indent_1 {
  text-indent: 5px;
}

#djjopiozsh .gt_indent_2 {
  text-indent: 10px;
}

#djjopiozsh .gt_indent_3 {
  text-indent: 15px;
}

#djjopiozsh .gt_indent_4 {
  text-indent: 20px;
}

#djjopiozsh .gt_indent_5 {
  text-indent: 25px;
}
</style>
<table class="gt_table">
  
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="participant">participant</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="question">question</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="correct">correct</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="participant" class="gt_row gt_right">1</td>
<td headers="question" class="gt_row gt_right">1</td>
<td headers="correct" class="gt_row gt_right">1</td></tr>
    <tr><td headers="participant" class="gt_row gt_right">1</td>
<td headers="question" class="gt_row gt_right">2</td>
<td headers="correct" class="gt_row gt_right">0</td></tr>
    <tr><td headers="participant" class="gt_row gt_right">1</td>
<td headers="question" class="gt_row gt_right">3</td>
<td headers="correct" class="gt_row gt_right">1</td></tr>
    <tr><td headers="participant" class="gt_row gt_right">...</td>
<td headers="question" class="gt_row gt_right">...</td>
<td headers="correct" class="gt_row gt_right">...</td></tr>
  </tbody>
  
  
</table>
</div>
<p><br>
But we can re-express this information in a different way, when we know the total number of questions asked:</p>
<div id="frqhgneycr" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#frqhgneycr .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#frqhgneycr .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#frqhgneycr .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#frqhgneycr .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#frqhgneycr .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#frqhgneycr .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#frqhgneycr .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#frqhgneycr .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#frqhgneycr .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#frqhgneycr .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#frqhgneycr .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#frqhgneycr .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#frqhgneycr .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#frqhgneycr .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#frqhgneycr .gt_from_md > :first-child {
  margin-top: 0;
}

#frqhgneycr .gt_from_md > :last-child {
  margin-bottom: 0;
}

#frqhgneycr .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#frqhgneycr .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#frqhgneycr .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#frqhgneycr .gt_row_group_first td {
  border-top-width: 2px;
}

#frqhgneycr .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#frqhgneycr .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#frqhgneycr .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#frqhgneycr .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#frqhgneycr .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#frqhgneycr .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#frqhgneycr .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#frqhgneycr .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#frqhgneycr .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#frqhgneycr .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-left: 4px;
  padding-right: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#frqhgneycr .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#frqhgneycr .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#frqhgneycr .gt_left {
  text-align: left;
}

#frqhgneycr .gt_center {
  text-align: center;
}

#frqhgneycr .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#frqhgneycr .gt_font_normal {
  font-weight: normal;
}

#frqhgneycr .gt_font_bold {
  font-weight: bold;
}

#frqhgneycr .gt_font_italic {
  font-style: italic;
}

#frqhgneycr .gt_super {
  font-size: 65%;
}

#frqhgneycr .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 75%;
  vertical-align: 0.4em;
}

#frqhgneycr .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#frqhgneycr .gt_indent_1 {
  text-indent: 5px;
}

#frqhgneycr .gt_indent_2 {
  text-indent: 10px;
}

#frqhgneycr .gt_indent_3 {
  text-indent: 15px;
}

#frqhgneycr .gt_indent_4 {
  text-indent: 20px;
}

#frqhgneycr .gt_indent_5 {
  text-indent: 25px;
}
</style>
<table class="gt_table">
  
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="participant">participant</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="questions_correct">questions_correct</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="questions_incorrect">questions_incorrect</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="participant" class="gt_row gt_right">1</td>
<td headers="questions_correct" class="gt_row gt_right">2</td>
<td headers="questions_incorrect" class="gt_row gt_right">1</td></tr>
    <tr><td headers="participant" class="gt_row gt_right">2</td>
<td headers="questions_correct" class="gt_row gt_right">1</td>
<td headers="questions_incorrect" class="gt_row gt_right">2</td></tr>
    <tr><td headers="participant" class="gt_row gt_right">3</td>
<td headers="questions_correct" class="gt_row gt_right">3</td>
<td headers="questions_incorrect" class="gt_row gt_right">0</td></tr>
    <tr><td headers="participant" class="gt_row gt_right">...</td>
<td headers="questions_correct" class="gt_row gt_right">...</td>
<td headers="questions_incorrect" class="gt_row gt_right">...</td></tr>
  </tbody>
  
  
</table>
</div>
<p><br><br />
To model data when it is in this form, we can express our outcome as <code>cbind(questions_correct, questions_incorrect)</code></p>
</div>
<p class="optional-end">
</p>
</div>
<div class="frame">
<p><strong>Novel Word Learning: Data Codebook</strong></p>
<pre class="r"><code>load(url(&quot;https://uoepsy.github.io/msmr/data/nwl.RData&quot;))</code></pre>
<p>In the <code>nwl</code> data set (accessed using the code above), participants with aphasia are separated into two groups based on the general location of their brain lesion: anterior vs. posterior. There is data on the numbers of correct and incorrect responses participants gave in each of a series of experimental blocks. There were 7 learning blocks, immediately followed by a test. Finally, participants also completed a follow-up test.<br />
<br>
Data were also collect from healthy controls.
<br>
Figure <a href="#fig:nwl-fig">1</a> shows the differences between groups in the average proportion of correct responses at each point in time (i.e., each block, test, and follow-up)</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:nwl-fig"></span>
<img src="02_lmm_log_files/figure-html/nwl-fig-1.png" alt="Differences between groups in the average proportion of correct responses at each block" width="80%" />
<p class="caption">
Figure 1: Differences between groups in the average proportion of correct responses at each block
</p>
</div>
<table>
<colgroup>
<col width="9%" />
<col width="90%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">variable</th>
<th align="left">description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">group</td>
<td align="left">Whether participant is a stroke patient (‘patient’) or a healthy control (‘control’)</td>
</tr>
<tr class="even">
<td align="left">lesion_location</td>
<td align="left">Location of brain lesion: anterior vs posterior</td>
</tr>
<tr class="odd">
<td align="left">block</td>
<td align="left">Experimental block (1-9). Blocks 1-7 were learning blocks, immediately followed by a test in block 8. Block 9 was a follow-up test at a later point</td>
</tr>
<tr class="even">
<td align="left">PropCorrect</td>
<td align="left">Proportion of 30 responses in a given block that the participant got correct</td>
</tr>
<tr class="odd">
<td align="left">NumCorrect</td>
<td align="left">Number of responses (out of 30) in a given block that the participant got correct</td>
</tr>
<tr class="even">
<td align="left">NumError</td>
<td align="left">Number of responses (out of 30) in a given block that the participant got incorrect</td>
</tr>
<tr class="odd">
<td align="left">ID</td>
<td align="left">Participant Identifier</td>
</tr>
<tr class="even">
<td align="left">Phase</td>
<td align="left">Experimental phase, corresponding to experimental block(s): ‘Learning’, ‘Immediate’,‘Follow-up’</td>
</tr>
</tbody>
</table>
</div>
<div class="question-begin">
Question B1
</div>
<div class="question-body">
<p>Load the data. Take a look around. Any missing values? Can you think of why?</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-43" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-43&#39;, &#39;sol-start-43&#39;)"> Solution </span>
</div>
<div id="sol-body-43" class="solution-body" style="display: none;">
<pre class="r"><code>load(url(&quot;https://uoepsy.github.io/msmr/data/nwl.RData&quot;))
summary(nwl)</code></pre>
<pre><code>##      group      lesion_location     block    PropCorrect       NumCorrect   
##  control:126   anterior : 45    Min.   :1   Min.   :0.2000   Min.   : 6.00  
##  patient:117   posterior: 63    1st Qu.:3   1st Qu.:0.5333   1st Qu.:16.00  
##                NA&#39;s     :135    Median :5   Median :0.7000   Median :21.00  
##                                 Mean   :5   Mean   :0.6822   Mean   :20.47  
##                                 3rd Qu.:7   3rd Qu.:0.8333   3rd Qu.:25.00  
##                                 Max.   :9   Max.   :1.0000   Max.   :30.00  
##                                                                             
##     NumError              ID         Phase          
##  Min.   : 0.000   control1 :  9   Length:243        
##  1st Qu.: 5.000   control10:  9   Class :character  
##  Median : 9.000   control11:  9   Mode  :character  
##  Mean   : 9.535   control12:  9                     
##  3rd Qu.:14.000   control13:  9                     
##  Max.   :24.000   control14:  9                     
##                   (Other)  :189</code></pre>
<p>The only missing vales are in the lesion location, and it’s probably because the healthy controls don’t have any lesions.</p>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question B2
</div>
<div class="question-body">
<p>Our broader research aim today is to compare two groups (those with anterior vs. posterior lesions) with respect to their accuracy of responses over the course of the study.</p>
<ol style="list-style-type: decimal">
<li>What is our outcome?</li>
</ol>
<p><em>Hint:</em> Think carefully: there might be several variables which either fully or partly express the information we are considering the “outcome” here.</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-44" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-44&#39;, &#39;sol-start-44&#39;)"> Solution </span>
</div>
<div id="sol-body-44" class="solution-body" style="display: none;">
<ol style="list-style-type: decimal">
<li>The outcome here is (in words) “the proportion of correct answers in each block”. This makes it tempting to look straight to the variable called <code>PropCorrect</code>. Unfortunately, this is encoded as a proportion (i.e., is bounded by 0 and 1), and of the models we have learned about so far, we don’t definitely have the necessary tools to model this.
<ul>
<li>linear regression = continuous <em>unbounded</em> outcome variable<br />
</li>
<li>logistic regression = binomial, expressed as <code>0</code> or <code>1</code> if the number of trials per observation is 1, and expressed as <code>cbind(num_successes, num_failures)</code> if the number of trials per observation is &gt;1.</li>
</ul></li>
</ol>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question B3
</div>
<div class="question-body">
<blockquote>
<p><strong>Research Question 1:</strong><br />
Is the learning rate (training blocks) different between these two groups?</p>
</blockquote>
<p><strong>Hints</strong>:</p>
<ul>
<li><p>Do we want <code>cbind(num_successes, num_failures)</code>?</p></li>
<li><p>Make sure we’re running models on only the data we are actually interested in.<br />
</p></li>
<li><p>Think back to what we did in the exercises above using model comparison via likelihood ratio tests (using <code>anova(model1, model2, model3, ...)</code>. We could use this approach for this question, to compare:</p>
<ul>
<li>A model with just the change over the sequence of blocks</li>
<li>A model with the change over the sequence of blocks <em>and</em> an overall difference between groups</li>
<li>A model with groups differing with respect to their change over the sequence of blocks</li>
</ul></li>
<li><p>What about the random effects part?</p>
<ol style="list-style-type: decimal">
<li>What are our observations grouped by?</li>
<li>What variables can vary within these groups?</li>
<li>What do you want your model to allow to vary within these groups?</li>
</ol></li>
</ul>
<div class="optional-begin">
<span id="opt-start-45" class="fa fa-chevron-circle-right optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-45&#39;, &#39;opt-start-45&#39;)"> Suggested answers to the hints if you don’t know where to start</span>
</div>
<div id="opt-body-45" class="optional-body" style="display: none;">
<ul>
<li>Make sure we’re running models on only the data we are actually interested in.
<ul>
<li>We want only the learning blocks, and none of the healthy controls.</li>
<li>You might want to store this data in a separate object, but in the code for the solutio we will just use <code>filter()</code> <em>inside</em> the <code>glmer()</code>.</li>
</ul></li>
<li>A model with just the change over the sequence of blocks:
<ul>
<li><strong>outcome ~ block</strong></li>
</ul></li>
<li>A model with the change over the sequence of blocks <em>and</em> an overall difference between groups:
<ul>
<li><strong>outcome ~ block + lesion_location</strong></li>
</ul></li>
<li>A model with groups differing with respect to their change *over the sequence of blocks:
<ul>
<li><strong>outcome ~ block * lesion_location</strong></li>
</ul></li>
<li>What are our observations grouped by?
<ul>
<li>repeated measures by-participant. i.e., the <code>ID</code> variable</li>
</ul></li>
<li>What variables can vary within these groups?
<ul>
<li><code>Block</code> and <code>Phase</code>. Be careful though - you can create the <code>Phase</code> variable out of the <code>Block</code> variable, so really this is just one piece of information, encoded differently in two variables.</li>
<li>The other variables (<code>lesion_location</code> and <code>group</code>) do <strong>not</strong> vary for each ID. Lesions don’t suddenly change where they are located, nor do participants swap between being a patient vs a control (we don’t need the group variable anyway as we are excluding the controls).<br />
What do you want your model to allow to vary within these groups?</li>
<li>Do you think the change over the course of the blocks is <strong>the same</strong> for everybody? Or do you think it varies? Is this variation important to think about in terms of your research question?</li>
</ul></li>
</ul>
</div>
<p class="optional-end">
</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-46" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-46&#39;, &#39;sol-start-46&#39;)"> Solution </span>
</div>
<div id="sol-body-46" class="solution-body" style="display: none;">
<pre class="r"><code>m.base &lt;- glmer(cbind(NumCorrect, NumError) ~ block + (block | ID), 
                data = filter(nwl, block &lt; 8, !is.na(lesion_location)),
                family=binomial)
m.loc0 &lt;- glmer(cbind(NumCorrect, NumError) ~ block + lesion_location + (block | ID), 
                data=filter(nwl, block &lt; 8, !is.na(lesion_location)),
                family=binomial)
m.loc1 &lt;- glmer(cbind(NumCorrect, NumError) ~ block * lesion_location + (block | ID), 
                data=filter(nwl, block &lt; 8, !is.na(lesion_location)),
                family=binomial)
#summary(m.loc1)
anova(m.base, m.loc0, m.loc1, test=&quot;Chisq&quot;)</code></pre>
<pre><code>## Data: filter(nwl, block &lt; 8, !is.na(lesion_location))
## Models:
## m.base: cbind(NumCorrect, NumError) ~ block + (block | ID)
## m.loc0: cbind(NumCorrect, NumError) ~ block + lesion_location + (block | ID)
## m.loc1: cbind(NumCorrect, NumError) ~ block * lesion_location + (block | ID)
##        npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)
## m.base    5 454.12 466.27 -222.06   444.12                     
## m.loc0    6 454.66 469.25 -221.33   442.66 1.4572  1     0.2274
## m.loc1    7 454.47 471.48 -220.23   440.47 2.1974  1     0.1382</code></pre>
<div class="int">
<p>No significant difference in learning rate between groups (<span class="math inline">\(\chi^2(1)=2.2, p = 0.138\)</span>).</p>
</div>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question B4
</div>
<div class="question-body">
<blockquote>
<p><strong>Research Question 2</strong><br />
In the testing phase, does performance on the immediate test differ between lesion location groups, and does their retention from immediate to follow-up test differ?</p>
</blockquote>
<p>Let’s try a different approach to this. Instead of fitting various models and comparing them via likelihood ratio tests, just fit the one model which could answer both parts of the question above.</p>
<p><strong>Hints:</strong></p>
<ul>
<li>This might required a bit more data-wrangling before hand. Think about the order of your factor levels
(alphabetically speaking, “Follow-up” comes before “Immediate”)!</li>
</ul>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-47" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-47&#39;, &#39;sol-start-47&#39;)"> Solution </span>
</div>
<div id="sol-body-47" class="solution-body" style="display: none;">
<pre class="r"><code>nwl_test &lt;- filter(nwl, block &gt; 7, !is.na(lesion_location)) %&gt;%
  mutate(
    Phase = fct_relevel(factor(Phase),&quot;Immediate&quot;)
  )

m.recall.loc &lt;- glmer(cbind(NumCorrect, NumError) ~ Phase * lesion_location + (Phase | ID), 
                  nwl_test, family=&quot;binomial&quot;)

summary(m.recall.loc)</code></pre>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: cbind(NumCorrect, NumError) ~ Phase * lesion_location + (Phase |  
##     ID)
##    Data: nwl_test
## 
##      AIC      BIC   logLik deviance df.resid 
##    142.6    150.9    -64.3    128.6       17 
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -1.31708 -0.45014  0.03291  0.46924  1.09355 
## 
## Random effects:
##  Groups Name           Variance Std.Dev. Corr 
##  ID     (Intercept)    0.47660  0.6904        
##         PhaseFollow-up 0.02539  0.1593   -1.00
## Number of obs: 24, groups:  ID, 12
## 
## Fixed effects:
##                                         Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)                             -0.11375    0.35128  -0.324    0.746  
## PhaseFollow-up                          -0.02452    0.24634  -0.100    0.921  
## lesion_locationposterior                 0.99918    0.46868   2.132    0.033 *
## PhaseFollow-up:lesion_locationposterior -0.25437    0.33904  -0.750    0.453  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##             (Intr) PhsFl- lsn_lc
## PhaseFllw-p -0.578              
## lsn_lctnpst -0.750  0.435       
## PhsFllw-p:_  0.421 -0.729 -0.589
## optimizer (Nelder_Mead) convergence code: 0 (OK)
## boundary (singular) fit: see help(&#39;isSingular&#39;)</code></pre>
</div>
<p class="solution-end">
</p>
<div class="frame">
<p><strong>Interpreting coefficients in logistic regression</strong><br />
Take some time to remind yourself from USMR of the <a href="https://uoepsy.github.io/usmr/labs/09_glm.html#Introducing_GLM">interpretation of logistic regression coefficients</a>.</p>
<p>The interpretation of the fixed effects of a logistic multi-level model is not very different.<br />
We can obtain the fixed effects from our model by using:</p>
<ul>
<li><code>fixef(model)</code></li>
<li><code>summary(model)$coefficients</code><br />
</li>
<li><code>coef(summary(model))</code></li>
<li><code>tidy(model)</code> from the <strong>broom.mixed</strong> package<br />
</li>
<li>(there are probably more ways, but I can’t think of them right now!)</li>
</ul>
<p>It’s just that for multi-level models, we can model by-cluster random variation around these effects.</p>
</div>
<div class="question-begin">
Question B5
</div>
<div class="question-body">
<ol style="list-style-type: decimal">
<li>In <code>family = binomial(link='logit')</code>. What function is used to relate the linear predictors in the model to the expected value of the response variable?<br />
</li>
<li>How do we convert this into something more interpretable?</li>
</ol>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-48" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-48&#39;, &#39;sol-start-48&#39;)"> Solution </span>
</div>
<div id="sol-body-48" class="solution-body" style="display: none;">
<ol style="list-style-type: decimal">
<li><p>The link function is the <code>logit</code>, or log-odds (other link functions are available).</p></li>
<li><p>To convert log-odds to odds, we can use <code>exp()</code>, to get odds and odds ratios.</p></li>
</ol>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question B6
</div>
<div class="question-body">
<p>Make sure you pay attention to trying to interpret each fixed effect from your models.<br />
These can be difficult, especially when it’s logistic, and especially when there are interactions.</p>
<ul>
<li>What is the increase in the odds of answering correctly in the immediate test for someone with a posterior legion compared to someone with an anterior legion?</li>
</ul>
<!-- 

<div class="optional-begin"><span id='opt-start-49' class="fa fa-chevron-circle-right optional-icon clickable" onclick="toggle_visibility('opt-body-49', 'opt-start-49')">  Optional help: Our Solution to B4</span></div><div class="optional-body" id = "opt-body-49" style="display: none;">

 -->
<!-- ```{r eval=F} -->
<!-- nwl_test <- filter(nwl, block > 7, !is.na(lesion_location)) %>% -->
<!--   mutate( -->
<!--     Phase = fct_relevel(factor(Phase),"Immediate") -->
<!--   ) -->
<!-- m.recall.loc <- glmer(cbind(NumCorrect, NumError) ~ Phase * lesion_location + (Phase | ID),  -->
<!--                   nwl_test, family="binomial") -->
<!-- ``` -->
<!-- 

</div><p class="optional-end"></p>

 -->
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-50" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-50&#39;, &#39;sol-start-50&#39;)"> Solution </span>
</div>
<div id="sol-body-50" class="solution-body" style="display: none;">
<ul>
<li><code>(Intercept)</code> ==&gt; Anterior lesion group performance in immediate test. This is the log-odds of them answering correctly in the immediate test.</li>
<li><code>PhaseFollow-up</code> ==&gt; Change in performance (for the anterior lesion group) from immediate to follow-up test.</li>
<li><code>lesion_locationposterior</code> ==&gt; Posterior lesion group performance in immediate test relative to anterior lesion group performance in immediate test</li>
<li><code>PhaseFollow-up:lesion_locationposterior</code> ==&gt; Change in performance from immediate to follow-up test, posterior lesion group relative to anterior lesion group</li>
</ul>
<pre><code>## lesion_locationposterior 
##                 2.716057</code></pre>
<div class="int">
<p>Those with posterior lesions have 2.72 times the odds of answering correctly in the immediate test compared to someone with an anterior lesion.</p>
</div>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
OPTIONAL: B7
</div>
<div class="question-body">
<p>Recreate the visualisation in Figure <a href="#fig:nwl-fig2">2</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:nwl-fig2"></span>
<img src="02_lmm_log_files/figure-html/nwl-fig2-1.png" alt="Differences between groups in the average proportion of correct responses at each block" width="80%" />
<p class="caption">
Figure 2: Differences between groups in the average proportion of correct responses at each block
</p>
</div>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-51" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-51&#39;, &#39;sol-start-51&#39;)"> Solution </span>
</div>
<div id="sol-body-51" class="solution-body" style="display: none;">
<pre class="r"><code>ggplot(filter(nwl, !is.na(lesion_location)), aes(block, PropCorrect, 
                                            color=lesion_location, 
                                            shape=lesion_location)) +
  #geom_line(aes(group=ID),alpha=.2) + 
  stat_summary(fun.data=mean_se, geom=&quot;pointrange&quot;) + 
  stat_summary(data=filter(nwl, !is.na(lesion_location), block &lt;= 7), 
                           fun=mean, geom=&quot;line&quot;) + 
  geom_hline(yintercept=0.5, linetype=&quot;dashed&quot;) + 
  geom_vline(xintercept=c(7.5, 8.5), linetype=&quot;dashed&quot;) + 
  scale_x_continuous(breaks=1:9, labels=c(1:7, &quot;Test&quot;, &quot;Follow-Up&quot;)) + 
  theme_bw(base_size=10) + 
  labs(x=&quot;Block&quot;, y=&quot;Proportion Correct&quot;, shape=&quot;Lesion\nLocation&quot;, color=&quot;Lesion\nLocation&quot;)</code></pre>
<p><img src="02_lmm_log_files/figure-html/unnamed-chunk-10-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<p class="solution-end">
</p>
<div class="frame">
<p><strong>Coding Schemes for Categorical Predictors</strong></p>
<p>Remember that categorical predictors get inputted into our model as a series of variables which are 0s and 1s? Previously the variable in our model for lesion location was actually being coded with 0 representing one level, and 1 representing the other. This is known as “treatment coding”.</p>
<p>There are lots of other ways we might encode our categorical predictors. One common approach is to use “effects coding”. In the case where we have a binary predictor, this makes zero the mid-point between the two - i.e., the overall mean (this is a bit like mean-centering a continuous predictor).</p>
<p>If we recall that the intercept is “when all predictors are zero”, and that when we have an interaction <code>Y~A+B+A*B</code> in our model, the individual coefficients for <code>A</code> and <code>B</code> are estimated “when the other variable is zero”, then we can start to understand how these different ways of encoding our categorical predictors can change what we are getting out of our model. (Note, they don’t actually change anything about the model fit, but they change what information we are estimating from the model).</p>
<p><img src="02_lmm_log_files/figure-html/unnamed-chunk-11-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>If you want to understand this a little more, take a look <a href="zz_quickcontrasts.html">here</a>.</p>
</div>
<div class="question-begin">
Question B8
</div>
<div class="question-body">
<p>This code is that we used to answer question B4 above, only we have edited it to change lesion location to be fitted with “effects coding”.</p>
<pre class="r"><code>nwl_test &lt;- filter(nwl, block &gt; 7, !is.na(lesion_location)) %&gt;%
  mutate(
    Phase = fct_relevel(factor(Phase),&quot;Immediate&quot;)
  )

m.recall.loc.effcoding &lt;- glmer(cbind(NumCorrect, NumError) ~ Phase * lesion_location + (Phase | ID), 
                      contrasts = list(lesion_location = &quot;contr.sum&quot;),
                  nwl_test, family=&quot;binomial&quot;)</code></pre>
<p>The interpretation of this is going to get pretty tricky - we have a logistic regression, and we have different coding scheme for our categorical predictor, and we have an interaction.. 🤯</p>
<p>Can you work out the interpretation of the fixed effects estimates?</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-52" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-52&#39;, &#39;sol-start-52&#39;)"> Solution </span>
</div>
<div id="sol-body-52" class="solution-body" style="display: none;">
<ul>
<li><code>(Intercept)</code> ==&gt; Overall performance in immediate test. This is the overall log-odds of answering correctly in the immediate test.</li>
<li><code>PhaseFollow-up</code> ==&gt; Average change in performance from immediate to follow-up test.</li>
<li><code>lesion_location1</code> ==&gt; Anterior lesion group performance in immediate test relative to <em>overall average</em> performance in immediate test</li>
<li><code>PhaseFollow-up:lesion_location1</code> ==&gt; Change in performance from immediate to follow-up test, anterior lesion group relative to overall average</li>
</ul>
<p><strong>???</strong><br />
How do we know that <code>lesion_location1</code> is the <em>anterior</em> and not the <em>posterior</em> lesion group?
We need to check the what the contrasts look like:</p>
<pre class="r"><code>contrasts(nwl_test$lesion_location) &lt;- &quot;contr.sum&quot;
contrasts(nwl_test$lesion_location)</code></pre>
<pre><code>##           [,1]
## anterior     1
## posterior   -1</code></pre>
<p>Because there are only two levels to this variable, the estimate will simply flip sign (positive/negative) depending on which way the contrast is leveled.</p>
<div class="optional-begin">
<span id="opt-start-53" class="fa fa-chevron-circle-right optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-53&#39;, &#39;opt-start-53&#39;)"> Optional: I liked my coefficients being named properly</span>
</div>
<div id="opt-body-53" class="optional-body" style="display: none;">
<pre class="r"><code>colnames(contrasts(nwl_test$lesion_location)) &lt;- &quot;PeppaPig&quot;

contrasts(nwl_test$lesion_location)</code></pre>
<pre><code>##           PeppaPig
## anterior         1
## posterior       -1</code></pre>
<pre class="r"><code>modeltest &lt;- glmer(cbind(NumCorrect, NumError) ~ Phase * lesion_location + (Phase | ID),
                  nwl_test, family=&quot;binomial&quot;)
summary(modeltest)$coefficients</code></pre>
<pre><code>##                                          Estimate Std. Error    z value
## (Intercept)                             0.3858449  0.2341574  1.6478019
## PhaseFollow-up                         -0.1517019  0.1688879 -0.8982400
## lesion_locationPeppaPig                -0.4995882  0.2343374 -2.1319180
## PhaseFollow-up:lesion_locationPeppaPig  0.1271798  0.1695166  0.7502495
##                                          Pr(&gt;|z|)
## (Intercept)                            0.09939333
## PhaseFollow-up                         0.36905762
## lesion_locationPeppaPig                0.03301359
## PhaseFollow-up:lesion_locationPeppaPig 0.45310448</code></pre>
</div>
<p class="optional-end">
</p>
</div>
<p class="solution-end">
</p>
<div class="frame">
<p><strong>Hang on.. p-values are back?!</strong></p>
<p>We noted at the end of last week that we don’t have p-values for <code>lmer()</code><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>, but you might notice that we do now have them when we’ve fitted a model with <code>glmer()</code>?</p>
<p>The reason is partly just one of convention. There is a standard practice for determining the statistical significance of parameters in the generalised linear model, relying on asymptotic Wald tests which evaluate differences in log-likelihood.</p>
</div>
</div>
<div id="reading-inference-in-mlm" class="section level1">
<h1>Reading: Inference in MLM</h1>
<p>In USMR, we fitted various simple linear models using <code>lm()</code>, and we could get out either a table of coefficients (for example, <a href="#tab:lmcoeftab">1</a>) or a table of the reduction in sums of squared residuals (for example, <a href="#tab:lmanovtab">2</a>). In both of these cases we had a nice set of p-values for us to look at (in R, we often find the p-values in the column named something like <code>Pr(&gt;F)</code>).</p>
<div class="statbox">
<p><strong>A quick reminder:</strong> a p-value is the probability of observing results as or more extreme than the data, <em>if the data were really generated by a hypothesised chance process</em>).</p>
</div>
<table>
<caption><span id="tab:lmcoeftab">Table 1: </span>t-tests for slope coefficients for predictors in a linear model</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Estimate</th>
<th align="right">Std. Error</th>
<th align="right">t value</th>
<th align="right">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">5.3703775</td>
<td align="right">4.3205141</td>
<td align="right">1.242995</td>
<td align="right">0.2238259</td>
</tr>
<tr class="even">
<td align="left">outdoor_time</td>
<td align="right">0.5923673</td>
<td align="right">0.1689445</td>
<td align="right">3.506284</td>
<td align="right">0.0014995</td>
</tr>
<tr class="odd">
<td align="left">social_int</td>
<td align="right">1.8034489</td>
<td align="right">0.2690982</td>
<td align="right">6.701825</td>
<td align="right">0.0000002</td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:lmanovtab">Table 2: </span>F-tests for predictors in a linear model</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Df</th>
<th align="right">Sum Sq</th>
<th align="right">Mean Sq</th>
<th align="right">F value</th>
<th align="right">Pr(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">outdoor_time</td>
<td align="right">1</td>
<td align="right">1427.938</td>
<td align="right">1427.9375</td>
<td align="right">37.77483</td>
<td align="right">1.1e-06</td>
</tr>
<tr class="even">
<td align="left">social_int</td>
<td align="right">1</td>
<td align="right">1697.825</td>
<td align="right">1697.8249</td>
<td align="right">44.91446</td>
<td align="right">2.0e-07</td>
</tr>
<tr class="odd">
<td align="left">Residuals</td>
<td align="right">29</td>
<td align="right">1096.238</td>
<td align="right">37.8013</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
</tbody>
</table>
<p>We could get p-values for these models because we know what the distribution of test statistics of interest (e.g. <span class="math inline">\(F\)</span>-statistics and <span class="math inline">\(t\)</span>-statistics), will look like if the null hypothesis were true (i.e., we can describe what they look like in terms of <span class="math inline">\(F\)</span> and <span class="math inline">\(t\)</span> distributions with specific degrees of freedom (look back to the <a href="https://uoepsy.github.io/usmr/labs/07_regression.html#More_Model_Evaluation">USMR materials for a formula</a>).</p>
<p>Unfortunately, the same is not true of multilevel models. For the multilevel model, we can think of it as having residuals at multiple levels: we have the random variation of clusters around the fixed effects, and then random variation of observations around the cluster-level effects (more on this in Week 4).<br />
In the rare occasion that you have a perfectly balanced experimental design, then ratios of sums of squares for multi-level models follow an <span class="math inline">\(F\)</span>-distribution, in which we know the numerator and denominator degrees of freedom (this means we can work out the degrees of freedom for the <span class="math inline">\(t\)</span>-test of our fixed effect parameters). Unfortunately, in the real world where things are not often perfectly balanced, determining the denominator degrees of freedom becomes unclear.</p>
<p>Last week, we mentioned a couple of approaches that we might take for drawing inferences, finding ways to compute p-values or confidence intervals.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> We’re going to now extend this to include a few more, and discuss the strengths and limitations of the different approaches.</p>
<div class="frame">
<p><strong>For these examples… </strong></p>
<p>For the following examples, we’re going to return to our dataset of various toys, and we are going to be concerned with whether practice (the <code>hrs_week</code> variable) is associated with changes in reading ages (<code>R_AGE</code> variable).<br />
To accommodate for the clustered nature of the data, we are going to fit a model with both intercepts and slopes varying by toy-type.</p>
<pre class="r"><code>toys_read &lt;- read_csv(&quot;https://uoepsy.github.io/data/toyexample.csv&quot;)
full_model &lt;- lmer(R_AGE ~ hrs_week + (1 + hrs_week | toy_type), data = toys_read)</code></pre>
</div>
<div class="optional-begin">
<span id="opt-start-54" class="fa fa-chevron-circle-right optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-54&#39;, &#39;opt-start-54&#39;)"> Use a normal approximation (not advisable)</span>
</div>
<div id="opt-body-54" class="optional-body" style="display: none;">
<p>Remember that the <span class="math inline">\(t\)</span> distribution starts to look more and more like the <span class="math inline">\(z\)</span> (“normal”) distribution when degrees of freedom increase? We could just assume we have infinite degrees of freedom in our test statistics, and pretend that the <span class="math inline">\(t\)</span>-values we get are actually <span class="math inline">\(z\)</span>-values. This is “anti-conservative” inasmuch as it is not a very cautious approach, and we are likely to have a higher false positive rate (e.g. more chance of saying “there <strong>is</strong> an effect!” when there actually isn’t.)</p>
<pre class="r"><code>coefs &lt;- as.data.frame(summary(full_model)$coefficients)
coefs$p.z &lt;- 2 * (1 - pnorm(abs(coefs[,3])))
coefs</code></pre>
<pre><code>##             Estimate Std. Error  t value          p.z
## (Intercept) 1.755943  0.9610348 1.827138 0.0676790647
## hrs_week    1.143508  0.2956875 3.867286 0.0001100533</code></pre>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-55" class="fa fa-chevron-circle-right optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-55&#39;, &#39;opt-start-55&#39;)"> Satterthwaite df approximation</span>
</div>
<div id="opt-body-55" class="optional-body" style="display: none;">
<p>There have been a couple of methods proposed to estimate the degrees of freedom in order to provide a better approximation to the null distribution of our tests. The way the Satterthwaite method has been implemented in R will just add a column for p-values to your <code>summary(model)</code> output).</p>
<p>Load the <strong>lmerTest</strong> package, refit the model, and voila!</p>
<pre class="r"><code>library(lmerTest)
full_model &lt;- lmer(R_AGE ~ hrs_week + (1 + hrs_week | toy_type), data = toys_read)
summary(full_model)$coefficients</code></pre>
<pre><code>##             Estimate Std. Error       df  t value    Pr(&gt;|t|)
## (Intercept) 1.755943  0.9610348 16.19251 1.827138 0.086168780
## hrs_week    1.143508  0.2956875 17.51503 3.867286 0.001178702</code></pre>
<div class="int">
<p><strong>Reporting</strong></p>
<p>To account for the extra uncertainty brought by the inclusion of random effects in the model, the degrees of freedom in the coefficients tests have been corrected via Satterthwaite’s method.<br />
…<br />
…<br />
Weekly hours of reading practice was associated increased reading age (<span class="math inline">\(\beta = 1.14,\ SE = 0.30,\ t(17.52^*) = 3.87,\ p = .001\)</span>).</p>
</div>
<p><strong>Note:</strong> if you have the <strong>lmerTest</strong> package loaded, then all the models you fit with <code>lmer()</code> will show p-values! If you want to stop this, then you will have to detach/unload the package, and refit the model.</p>
<pre class="r"><code>detach(&quot;package:lmerTest&quot;, unload=TRUE)</code></pre>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-56" class="fa fa-chevron-circle-right optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-56&#39;, &#39;opt-start-56&#39;)"> Kenward Rogers df approximations</span>
</div>
<div id="opt-body-56" class="optional-body" style="display: none;">
<p>The Kenward-Rogers approach is slightly more conservative than the Satterthwaite method, and has been implemented for model comparison between a full model and a restricted model (a model without the parameter of interest), using the KR adjustment for the denominator degrees of freedom in the <span class="math inline">\(F\)</span>-test.<br />
For this, models must be fitted with REML, <strong>not</strong> ML. The function <code>KRmodcomp()</code> will take care of this and re-fit them for you.</p>
<pre class="r"><code>library(pbkrtest)
restricted_model &lt;- lmer(R_AGE ~ 1 + (1 + hrs_week | toy_type), data = toys_read)
full_model &lt;- lmer(R_AGE ~ hrs_week + (1 + hrs_week | toy_type), data = toys_read)
KRmodcomp(full_model, restricted_model)</code></pre>
<pre><code>## large : R_AGE ~ hrs_week + (1 + hrs_week | toy_type)
## small : R_AGE ~ 1 + (1 + hrs_week | toy_type)
##         stat    ndf    ddf F.scaling  p.value   
## Ftest 14.637  1.000 17.738         1 0.001266 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="int">
<p><strong>Reporting</strong></p>
<p>To account for the extra uncertainty brought by the inclusion of random effects in the model, the denominator degrees of freedom in have been corrected via Kenward-Rogers’ method.<br />
…<br />
…<br />
Inclusion of weekly hours of reading practice as a predictor was associated with an improvement in model fit (<span class="math inline">\(F(1,17.74^*) = 14.64,\ p = .001\)</span>).</p>
</div>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-57" class="fa fa-chevron-circle-right optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-57&#39;, &#39;opt-start-57&#39;)"> Likelihood Ratio Test (LRT)</span>
</div>
<div id="opt-body-57" class="optional-body" style="display: none;">
<p>Conduct a model comparison between your model and a restricted model (a model without the parameter of interest), evaluating the change in log-likelihood.</p>
<div class="statbox">
<p><strong>Likelihood</strong></p>
<p>“likelihood” is a function that associates to a parameter the probability (or probability density) of observing the given sample data.<br />
In simpler terms, the likelihood is the probability of the model given that we have this data.</p>
<p>The intuition behind likelihood:</p>
<ol style="list-style-type: decimal">
<li>I toss a coin 10 time and observed 8 Heads.<br />
</li>
<li>We can think of a ‘model’ of the process that governs the coin’s behaviour in terms of just one number: a parameter that indicates the probability of the coin landing on heads.<br />
I have two models:</li>
</ol>
<ul>
<li>Model 1: The coin will land on heads 20% of the time. <span class="math inline">\(P(Heads)=0.2\)</span><br />
</li>
<li>Model 2: The coin will land on heads 70% of the time. <span class="math inline">\(P(Heads)=0.7\)</span><br />
</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>Given the data I observe (see 1, above), we can (hopefully) intuit that Model 2 is more likely than Model 1.</li>
</ol>
<p>For a (slightly) more detailed explanation, see <a href="lvp.html">here</a>.</p>
</div>
<p>This method assumes that the ratio of two likelihoods will (as sample size increases) become closer to being <span class="math inline">\(\chi^2\)</span> distributed, and so may be unreliable for small samples.</p>
<p>Models must be fitted with ML, <strong>not</strong> REML. The function <code>anova()</code> will re-fit them for you.</p>
<pre class="r"><code>restricted_model &lt;- lmer(R_AGE ~ 1 + (1 + hrs_week | toy_type), data = toys_read)
full_model &lt;- lmer(R_AGE ~ hrs_week + (1 + hrs_week | toy_type), data = toys_read)
anova(restricted_model, full_model, test = &quot;Chisq&quot;)</code></pre>
<pre><code>## refitting model(s) with ML (instead of REML)</code></pre>
<pre><code>## Data: toys_read
## Models:
## restricted_model: R_AGE ~ 1 + (1 + hrs_week | toy_type)
## full_model: R_AGE ~ hrs_week + (1 + hrs_week | toy_type)
##                  npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)    
## restricted_model    5 660.32 674.73 -325.16   650.32                         
## full_model          6 650.51 667.80 -319.25   638.51 11.813  1   0.000588 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="int">
<p><strong>Reporting</strong></p>
<p>A likelihood ratio test indicated that the inclusion of weekly hours of reading practice as a predictor was associated with an improvement in model fit (<span class="math inline">\(\chi^2(1) = 11.81, p &lt; .001\)</span>).</p>
</div>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-58" class="fa fa-chevron-circle-right optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-58&#39;, &#39;opt-start-58&#39;)"> Optional: Parametric Bootstrap LRT</span>
</div>
<div id="opt-body-58" class="optional-body" style="display: none;">
<p>There are also various “bootstrapping” methods which it is worth looking into. Think back to USMR when we first learned about hypothesis testing. Remember that we did lots of simulating data, so that we can compare what we actually observe with what we would expect if the null hypothesis were true? By doing this, we were essentially <em>creating</em> a null distribution, so that our calculating a p-value can become an issue of summarising data (e.g. calculate the proportion of our simulated null distribution that is more extreme than our observed statistic)</p>
<p>Instead of assuming that the likelihood ratio test statistics are <span class="math inline">\(\chi^2\)</span>-distributed, we can bootstrap this test instead. This approach simulates data from the simpler model, fits both the simple model and the complex model and evaluates the change in log-likelihood. By doing this over and over again, we build a distribution of what changes in log-likelihood we would be likely to see if the more complex model is not any better. In this way it actually constructs a distribution reflecting our null hypothesis, against which we can then compare our actual observed effect</p>
<pre class="r"><code>library(pbkrtest)
PBmodcomp(full_model, restricted_model, nsim=1000)</code></pre>
<div class="int">
<p><strong>Reporting</strong></p>
<p>A parametric bootstrap likelihood ratio test (R = 1000) indicated that the inclusion of weekly hours of reading practice as a predictor was associated with an improvement in model fit (<span class="math inline">\(LRT = 11.79, p = .004\)</span>).</p>
</div>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-59" class="fa fa-chevron-circle-right optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-59&#39;, &#39;opt-start-59&#39;)"> Optional: Parametric Bootstrap Confidence Intervals</span>
</div>
<div id="opt-body-59" class="optional-body" style="display: none;">
<p>Much the same as above, but with just one model we simulate data many times and refit the model, so that we get an empirical distribution that we can use to construct confidence intervals for our effects.</p>
<pre class="r"><code>confint(full_model, method=&quot;boot&quot;)  </code></pre>
<div class="int">
<p><strong>Reporting</strong></p>
<p>95% Confidence Intervals were obtained via parametric bootstrapping with 1000 iterations.<br />
…<br />
…<br />
Weekly hours of reading practice was associated increased reading age (<span class="math inline">\(\beta = 1.14,\ 95%\ CI\ [0.58 -- 1.73]\)</span>).</p>
</div>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-60" class="fa fa-chevron-circle-right optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-60&#39;, &#39;opt-start-60&#39;)"> Optional: Case-based Bootstrap Confidence Intervals</span>
</div>
<div id="opt-body-60" class="optional-body" style="display: none;">
<p>It’s worth noting that there are many different types of bootstrapping that we can conduct. Different methods of bootstrapping vary with respect to the assumptions we will have to make when using them for drawing inferences. For instance, the parametric bootstrap discussed above assumes that explanatory variables are fixed and that model specification and the distributions such as <span class="math inline">\(\zeta_i \sim N(0,\sigma_{\zeta})\)</span> and <span class="math inline">\(\varepsilon_i \sim N(0,\sigma_{\varepsilon})\)</span> are correct.<br />
An alternative is to generate a distribution by <strong>resampling with replacement</strong> from our data, fitting our model to the resample, and then repeating this over and over. This doesn’t have to rely on assumptions about the shape of the distributions of <span class="math inline">\(\zeta_i\)</span> and <span class="math inline">\(\varepsilon_i\)</span> - we just need to ensure that we correctly specify the hierarchical dependency of data. It does, however, require the decision of at which levels to resample (this is discussed more in week 4, and is what the <strong>lmeresampler</strong> package is all about).</p>
</div>
<p class="optional-end">
</p>
<div class="frame">
<p>If you want more information (not required reading for this course), then Julian Faraway has a page <a href="https://people.bath.ac.uk/jjf23/mixchange/index.html">here</a> with links to some worked examples, and Ben Bolker has a wealth of information on his <a href="http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#why-doesnt-lme4-display-denominator-degrees-of-freedomp-values-what-other-options-do-i-have">GLMM FAQ pages</a>.</p>
</div>
<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;">

</div>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>We also didn’t get <span class="math inline">\(R^2\)</span>. Check out <a href="http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#how-do-i-compute-a-coefficient-of-determination-r2-or-an-analogue-for-glmms">http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#how-do-i-compute-a-coefficient-of-determination-r2-or-an-analogue-for-glmms</a><a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>It’s always important to note that aiming for a p-value or confidence interval to make a dichotomous decision is only <em>one approach</em> to doing statistics. If you continue to develop your learning of statistics after this course (which we hope you will!), then you will find that there are other schools of thought that bring different benefits.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>

<link rel="stylesheet" href="https://uoepsy.github.io/assets/css/ccfooter.css" />
<div class="ccfooter"></div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
