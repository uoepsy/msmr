<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Random Effect Structures</title>

<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);
e.style.display = ((e.style.display!='none') ? 'none' : 'block');
if(f.classList.contains('fa-chevron-circle-right')) {
    f.classList.add('fa-chevron-circle-down')
    f.classList.remove('fa-chevron-circle-right')
} else {
    f.classList.add('fa-chevron-circle-right')
    f.classList.remove('fa-chevron-circle-down')
}
}
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="assets/style-labs.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"><strong>MSMR</strong></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Mixed Effects Models
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="01_intromlm.html">1: Introduction to Multilevel Models</a>
    </li>
    <li>
      <a href="02_lmm_log.html">2: Logistic Multilevel Models</a>
    </li>
    <li>
      <a href="03_nonlin.html">3: Longitudinal Nonlinear Models</a>
    </li>
    <li>
      <a href="04_ranef.html">4: Random Effect Structures</a>
    </li>
    <li>
      <a href="05_multilevel_recap.html">5: Multilevel Modelling Recap</a>
    </li>
    <li class="dropdown-header">FLW: Flexible Learning Week</li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Data Reduction &amp; SEM
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="06_efapca.html">6: PCA | EFA</a>
    </li>
    <li>
      <a href="07_cfa.html">7: CFA</a>
    </li>
    <li>
      <a href="08_path.html">8: Path Analysis</a>
    </li>
    <li>
      <a href="09_sem1.html">9: SEM 1</a>
    </li>
    <li>
      <a href="10_sem2.html">10: SEM 2</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-info-circle"></span>
     
    Extras
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="zz_tidyverse_markdown.html">Tidyverse &amp; Markdown Recap</a>
    </li>
    <li>
      <a href="zz_binary_binomial.html">Binary vs Binomial Data</a>
    </li>
    <li>
      <a href="zz_quickcontrasts.html">Contrasts: a Quick Overview</a>
    </li>
    <li>
      <a href="zz_lvp.html">Likelihood vs Probability</a>
    </li>
  </ul>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Random Effect Structures</h1>

</div>


<div class="blue">
<p><strong>Preliminaries</strong></p>
<p>Create a new R Script or RMarkdown document (whichever you prefer working with) and give it a title for this week.</p>
<p><strong>Some extra background reading</strong></p>
<ul>
<li><a href="https://doi.org/10.1016/j.jml.2007.12.005">Baayen et al., 2008</a><br />
</li>
<li><a href="https://doi.org/10.1016/j.jml.2012.11.001">Barr et al., 2013</a><br />
</li>
<li><a href="https://doi.org/10.1016/j.jml.2017.01.001">Matuschek et al., 2017</a></li>
</ul>
</div>
<div class="imp">
<p>Now that we’ve had a few weeks to get used to the syntax of <strong>lme4</strong>, we’re going to hide the solutions again until the end of the week.</p>
</div>
<div id="random-effects" class="section level1">
<h1>Random effects</h1>
<div id="what-are-random-effects" class="section level2">
<h2>What are “Random Effects”?</h2>
<p>A frequent cause of confusion when learning about multilevel models is the use of the term “random effect”. Does it refer to the the grouping variable, or to the effects that we allow to vary by-groups? The answer is really both. For example, in the model <code>lmer(R_AGE ~ 1 + hrs_week + (1 + hrs_week | toy_type), data = toys_read)</code>, the “random effects” refers to the <code>(1 + hrs_week | toy_type)</code>. We are specifying by-toy type random intercepts and by-toy type effects of hrs_week.</p>
<div class="statbox">
<p><strong>Should I fit a fixed effect: <code>y ~ ... + group</code> or random effect: <code>y ~ ... + (1 | group)</code>?</strong></p>
<p>When specifying a random effects model, think about the data you have and how they fit in the following table:</p>
<table>
<colgroup>
<col width="11%" />
<col width="37%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>Criterion:</th>
<th>Repetition: <br> <em>If the experiment were repeated:</em></th>
<th>Desired inference: <br> <em>The conclusions refer to:</em></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Fixed effects</td>
<td>Same levels would be used</td>
<td>The levels used</td>
</tr>
<tr class="even">
<td>Random effects</td>
<td>Different levels would be used</td>
<td>A population from which the levels used are just a (random) sample</td>
</tr>
</tbody>
</table>
<div class="optional-begin">
<span id="opt-start-54" class="fa fa-chevron-circle-right optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-54&#39;, &#39;opt-start-54&#39;)"> Examples</span>
</div>
<div id="opt-body-54" class="optional-body" style="display: none;">
<p>For example, applying the criteria to the following questions:</p>
<ul>
<li><p>Do dogs learn faster with higher rewards?</p>
<p>FIXED: reward</p>
<p>RANDOM: dog</p></li>
<li><p>Do students read faster at higher temperatures?</p>
<p>FIXED: temperature</p>
<p>RANDOM: student</p></li>
<li><p>Do people speaking one language speak faster than another?</p>
<p>FIXED: the language</p>
<p>RANDOM: the people speaking that language</p></li>
</ul>
</div>
<p class="optional-end">
</p>
<p><br></p>
<p>Sometimes, after simplifying the model, you find that there isn’t much variability in a specific random effect and, if it still leads to singular fits or convergence warnings, it is common to just model that variable as a fixed effect.</p>
<p>Other times, you don’t have sufficient data or levels to estimate the random effect variance, and you are forced to model it as a fixed effect.
This is similar to trying to find the “best-fit” line passing through a single point… You can’t because you need two points!</p>
</div>
</div>
<div id="nested-crossed-structures" class="section level2">
<h2>Nested &amp; Crossed Structures</h2>
<p>Most of the examples we have seen up to now have had only one level of clustering in the data (e.g. participants). But what happens if we have multiple different clusters? The same principle we have seen for one level of clustering can be extended to clustering at different levels, but we have to be considerate of how those levels of clustering are related.</p>
<div class="frame">
<p><strong>Nested Structures</strong></p>
<p>Take an example where we have observations for each student in every class within a number of schools:</p>
<p><img src="images/structure_id.png" width="1200px" style="display: block; margin: auto;" /></p>
<p><strong>Question:</strong> Is “Class 1” in “School 1” the same as “Class 1” in “School 2”?</p>
<p>No.<br />
The classes in one school are distinct from the classes in another <strong>even though they are named the same</strong>.</p>
<p>The classes-within-schools example is a good case of <strong>nested random effects</strong> - one factor level (one group in a grouping varible) appears <em>only within</em> a particular level of another grouping variable.</p>
<p>In R, we can specify this using:</p>
<p><code>(1 | school) + (1 | class:school)</code></p>
<p>or, more succinctly:</p>
<p><code>(1 | school/class)</code></p>
<div class="optional-begin">
<span id="opt-start-55" class="fa fa-chevron-circle-right optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-55&#39;, &#39;opt-start-55&#39;)"> The labels matter!</span>
</div>
<div id="opt-body-55" class="optional-body" style="display: none;">
<p>Had we changed data such that the classes had unique IDs (e.g., see below), then we could also use <code>(1 | school) + (1 | class)</code>.</p>
<p><img src="images/structure_nested.png" width="1200px" style="display: block; margin: auto;" /></p>
<table>
<colgroup>
<col width="70%" />
<col width="30%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">Are the lower cluster labels unique?</th>
<th align="right">equivalent structures</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">Yes</td>
<td align="right"><code>(1 | school/class)</code><br><code>(1 | school) + (1 | class:school)</code><br><code>(1 | school) + (1 | class)</code></td>
</tr>
<tr class="even">
<td align="right">No</td>
<td align="right"><code>(1 | school/class)</code><br><code>(1 | school) + (1 | class:school)</code></td>
</tr>
</tbody>
</table>
</div>
<p class="optional-end">
</p>
</div>
<div class="frame">
<p><strong>Crossed Structures</strong></p>
<p>Consider another example, where we administer the same set of tasks at multiple time-points for every participant.</p>
<p><strong>Question:</strong> Are tasks nested within participants?</p>
<p>No.<br />
Tasks are seen by multiple participants (and participants see multiple tasks).</p>
<p>We could visualise this as the below:<br />
<img src="images/structure_crossed.png" width="400px" style="display: block; margin: auto;" /></p>
<p>In the sense that these are not nested, they are <strong>crossed</strong> random effects.</p>
<p>In R, we can specify this using:</p>
<p><code>(1 | subject) + (1 | task)</code></p>
</div>
<div class="blue">
<p><strong>Nested vs Crossed</strong></p>
<p><em>Nested:</em> Each group belongs uniquely to a higher-level group.</p>
<p><em>Crossed:</em> Not-nested.</p>
</div>
</div>
<div id="random-effects-in-lme4" class="section level2">
<h2>Random Effects in lme4</h2>
<div class="rtip">
<p><strong>Fitting Random effects in lme4</strong></p>
<p>Below are a selection of different formulas for specifying different random effect structures, taken from the <a href="https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf">lme4 vignette</a>. This might look like a lot, but over time and repeated use of multilevel models you will get used to reading these in a similar way to getting used to reading the formula structure of <code>y ~ x1 + x2</code> in all our linear models.
<br></p>
<table>
<colgroup>
<col width="29%" />
<col width="41%" />
<col width="29%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">Formula</th>
<th align="right">Alternative</th>
<th align="right">Meaning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><span class="math inline">\(\text{(1 | g)}\)</span></td>
<td align="right"><span class="math inline">\(\text{1 + (1 | g)}\)</span></td>
<td align="right">Random intercept with fixed mean</td>
</tr>
<tr class="even">
<td align="right"><span class="math inline">\(\text{0 + offset(o) + (1 | g)}\)</span></td>
<td align="right"><span class="math inline">\(\text{-1 + offset(o) + (1 | g)}\)</span></td>
<td align="right">Random intercept with <em>a priori</em> means</td>
</tr>
<tr class="odd">
<td align="right"><span class="math inline">\(\text{(1 | g1/g2)}\)</span></td>
<td align="right"><span class="math inline">\(\text{(1 | g1) + (1 | g1:g2)}\)</span></td>
<td align="right">Intercept varying among <span class="math inline">\(g1\)</span> and <span class="math inline">\(g2\)</span> within <span class="math inline">\(g1\)</span></td>
</tr>
<tr class="even">
<td align="right"><span class="math inline">\(\text{(1 | g1) + (1 | g2)}\)</span></td>
<td align="right"><span class="math inline">\(\text{1 + (1 | g1) + (1 | g2)}\)</span></td>
<td align="right">Intercept varying among <span class="math inline">\(g1\)</span> and <span class="math inline">\(g2\)</span></td>
</tr>
<tr class="odd">
<td align="right"><span class="math inline">\(\text{x + (x | g)}\)</span></td>
<td align="right"><span class="math inline">\(\text{1 + x + (1 + x | g)}\)</span></td>
<td align="right">Correlated random intercept and slope</td>
</tr>
<tr class="even">
<td align="right"><span class="math inline">\(\text{x + (x || g)}\)</span></td>
<td align="right"><span class="math inline">\(\text{1 + x + (x | g) + (0 + x | g)}\)</span></td>
<td align="right">Uncorrelated random intercept and slope</td>
</tr>
</tbody>
</table>
<p><strong>Table 1:</strong> Examples of the right-hand-sides of mixed effects model formulas. <span class="math inline">\(g\)</span>, <span class="math inline">\(g1\)</span>, <span class="math inline">\(g2\)</span> are grouping factors, covariates and <em>a priori</em> known offsets are <span class="math inline">\(x\)</span> and <span class="math inline">\(o\)</span>.</p>
</div>
<div class="rtip">
<p><strong>Extracting random effects with lme4</strong></p>
<p>In models fitted with <strong>lme4</strong>, there are some key functions to keep in mind for extracting different parts of the model.</p>
<ul>
<li><code>fixef()</code> gives us the fixed effects (in Figure <a href="#fig:mlmfrc">1</a> this is the intercept and slope of the blue line).<br />
</li>
<li><code>ranef()</code> gives us the group-level deviations from the fixed effects (in Figure <a href="#fig:mlmfrc">1</a>, this is the differences from each of the green lines to the blue line, and these are denoted by <span class="math inline">\(\zeta_{0i}\)</span> and <span class="math inline">\(\zeta_{1i}\)</span>).<br />
</li>
<li><code>coef()</code> gives us the intercepts and slopes of the group-level effects (in Figure <a href="#fig:mlmfrc">1</a>, these are the intercepts and slopes of the green lines). We can also get to these because <code>fixef() + ranef() = coef()</code>.<br />
</li>
<li><code>VarCorr()</code> will give us the estimated variance and standard deviation of the random effects (what we get from <code>ranef()</code>).</li>
</ul>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:mlmfrc"></span>
<img src="images/lmmwodot.png" alt="multilevel model with group i highlighted" width="80%" />
<p class="caption">
Figure 1: multilevel model with group i highlighted
</p>
</div>
</div>
<div class="optional-begin">
<span id="opt-start-56" class="fa fa-chevron-circle-right optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-56&#39;, &#39;opt-start-56&#39;)"> Some quick examples</span>
</div>
<div class="optional-body" id = "opt-body-56" style="display: none;">



<pre class="r"><code>toys_read &lt;- read_csv(&quot;https://uoepsy.github.io/data/toyexample.csv&quot;)
rs_model &lt;- lmer(R_AGE ~ 1 + hrs_week + (1 + hrs_week | toy_type), data = toys_read)</code></pre>
<p><strong>Q:</strong> Which toy type shows the least improvement in reading age as practice increases, and which shows the greatest improvement?</p>
<pre class="r"><code>ranef(rs_model)</code></pre>
<pre><code>## $toy_type
##                              (Intercept)    hrs_week
## Barbie                         0.0855596  0.16463252
## Farm Animals                  -2.1303034 -1.72532126
## Furby                          0.8940478  0.79109745
## G.I.Joe                        1.8601170  1.05745304
## Lego Minifigures              -1.0963190 -0.92548279
## Minecraft                      0.3930185  0.43342754
## My Little Pony                -0.9557181 -0.97937536
## Peppa Pig                      0.1742980 -0.03882159
## Playmobil                     -0.7780752 -0.33556416
## Polly Pocket                   0.7147074  0.66199641
## Power Rangers                  0.1076182  0.07541960
## Rugrats                       -0.2959716 -0.04537848
## Scooby Doo                     2.3654608  1.61665908
## Sock Puppets                  -0.5225530 -0.33068125
## Star Wars                      1.2020393  0.84628213
## Stretch Armstrong             -0.1397913  0.20314258
## SuperZings                    -0.1976937 -0.41191503
## Teenage Mutant Ninja Turtles  -1.3163768 -0.91247162
## Toy Story                      0.9701905  0.88966357
## Transformers                  -1.3342550 -1.03476237
## 
## with conditional variances for &quot;toy_type&quot;</code></pre>
<p><strong>A:</strong> It looks like the Farm Animals have the least improvement, and Scooby Doo shows the most improvement</p>
<hr>
<p><strong>Q:</strong> What is the estimated reading age for sock puppets with zero hours of practice per week, and what is their estimated change in reading age for every hour per week increase in practice?</p>
<pre class="r"><code>coef(rs_model)</code></pre>
<pre><code>## $toy_type
##                              (Intercept)   hrs_week
## Barbie                         1.8415026  1.3081408
## Farm Animals                  -0.3743604 -0.5818130
## Furby                          2.6499908  1.9346058
## G.I.Joe                        3.6160599  2.2009613
## Lego Minifigures               0.6596239  0.2180255
## Minecraft                      2.1489614  1.5769358
## My Little Pony                 0.8002248  0.1641329
## Peppa Pig                      1.9302409  1.1046867
## Playmobil                      0.9778678  0.8079441
## Polly Pocket                   2.4706504  1.8055047
## Power Rangers                  1.8635611  1.2189279
## Rugrats                        1.4599714  1.0981298
## Scooby Doo                     4.1214037  2.7601674
## Sock Puppets                   1.2333900  0.8128271
## Star Wars                      2.9579822  1.9897904
## Stretch Armstrong              1.6161517  1.3466509
## SuperZings                     1.5582493  0.7315933
## Teenage Mutant Ninja Turtles   0.4395661  0.2310367
## Toy Story                      2.7261335  2.0331719
## Transformers                   0.4216880  0.1087459
## 
## attr(,&quot;class&quot;)
## [1] &quot;coef.mer&quot;</code></pre>
<p><strong>A:</strong> Sock puppets with zero practice are estimated to have a reading age of 1.2, which increases by 0.81 for every hour of practice per week.
<img src="images/sockpuppet.gif" width="100px" style="display: block; margin: auto;" /></p>
</div>
<p class="optional-end">
</p>
</div>
</div>
<div id="model-checks" class="section level1">
<h1>Model Checks</h1>
<div id="a-note-on-convergence-warnings" class="section level2">
<h2>A Note on Convergence warnings</h2>
<div class="rtip">
<p>When we start to move to more complex random effect structures, issues of “singular fits” and “non-convergence” become ever more relevant. We’ve already talked about singular fits (see the <a href="02_lmm_log.html">Week 2 exercises</a>), but we haven’t said much about how to deal with non-convergence.<br />
It may help to look back on <a href="01_intromlm.html#estimation">Week 1’s section on estimation</a>.</p>
<p>Issues of non-convergence can be caused by many things. If you’re model doesn’t converge, it does <em>not necessarily</em> mean the fit is incorrect, however it is <strong>is cause for concern</strong>, and should be addressed, else you may end up reporting inferences which do not hold.</p>
<p>There are lots of different things which you could do which <em>might</em> help your model to converge. A select few are detailed below:</p>
<ul>
<li><p>double-check the model specification and the data</p></li>
<li><p>adjust stopping (convergence) tolerances for the nonlinear optimizer, using the optCtrl argument to [g]lmerControl. (see <code>?convergence</code> for convergence controls).</p>
<ul>
<li>What is “tolerance”? Remember that our optimizer is the the method by which the computer finds the best fitting model, by iteratively assessing and trying to maximise the likelihood (or minimise the loss).
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-8"></span>
<img src="images/tolerance.png" alt="An optimizer will stop after a certain number of iterations, or when it meets a tolerance threshold" width="80%" />
<p class="caption">
Figure 2: An optimizer will stop after a certain number of iterations, or when it meets a tolerance threshold
</p>
</div></li>
</ul></li>
<li><p>center and scale continuous predictor variables (e.g. with <code>scale</code>)</p></li>
<li><p>Change the optimization method (for example, here we change it to <code>bobyqa</code>):
<code>lmer(..., control = lmerControl(optimizer="bobyqa"))</code><br />
<code>glmer(..., control = glmerControl(optimizer="bobyqa"))</code></p></li>
<li><p>Increase the number of optimization steps:
<code>lmer(..., control = lmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000))</code><br />
<code>glmer(..., control = glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=50000))</code></p></li>
<li><p>Use <code>allFit()</code> to try the fit with all available optimizers. This will of course be slow, but is considered ‘the gold standard’; <em>“if all optimizers converge to values that are practically equivalent, then we would consider the convergence warnings to be false positives.”</em></p></li>
<li><p>Consider simplifying your model, for example by removing random effects with the smallest variance (but be careful to not simplify more than necessary, and ensure that your write up details these changes)</p></li>
</ul>
</div>
</div>
<div id="assumptions" class="section level2">
<h2>Assumptions</h2>
<div class="statbox">
<p>Hopefully by now you are getting comfortable with the idea that all our models are simplifications, and so there is always going to be some difference between a model and real-life. This difference - the <em>residual</em> - will hopefully just be randomness, and we assess this by checking for systematic patterns in the residual term.</p>
<p>Not much is different in the multilevel model - we simply now have “residuals” on multiple levels. We are assuming that our group-level differences represent one level of randomness, and that our observations represent another level. We can see these two levels in Figure <a href="#fig:lmmfigres">3</a>, with the group-level deviations from the fixed effects (<span class="math inline">\(\zeta_{0i}\)</span> and <span class="math inline">\(\zeta_{1i}\)</span>) along with the observation-level deviations from that groups line (<span class="math inline">\(\varepsilon_{ij}\)</span>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:lmmfigres"></span>
<img src="images/lmmwdot.png" alt="Multilevel model with group i highlighted" width="80%" />
<p class="caption">
Figure 3: Multilevel model with group i highlighted
</p>
</div>
</div>
<div class="optional-begin">
<span id="opt-start-57" class="fa fa-chevron-circle-right optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-57&#39;, &#39;opt-start-57&#39;)"> Examining Residuals (Level 1)</span>
</div>
<div id="opt-body-57" class="optional-body" style="display: none;">
<pre class="r"><code>toys_read &lt;- read_csv(&quot;https://uoepsy.github.io/data/toyexample.csv&quot;)
rs_model &lt;- lmer(R_AGE ~ 1 + hrs_week + (1 + hrs_week | toy_type), data = toys_read)</code></pre>
<p>We can get the level 1 (observation-level) residuals the same way we used to do for <code>lm()</code> - by just using <code>resid()</code> or <code>residuals()</code>. Additionally, there are a few useful techniques for plotting these which we have listed below:</p>
<ul>
<li><p>We can plot the residuals vs fitted model, and assess the extend to which the assumption holds that the residuals are zero mean.<br />
<em>(we want the blue smoothed line to be fairly close to zero across the plot)</em></p>
<pre class="r"><code>plot(rs_model, type=c(&quot;p&quot;,&quot;smooth&quot;))</code></pre>
<p><img src="04_ranef_files/figure-html/unnamed-chunk-10-1.png" width="80%" style="display: block; margin: auto;" /></p></li>
<li><p>We can construct a scale-location plot. This is where the square-root of the absolute value of the standardised residuals is plotted against the fitted values, and allows you to more easily assess the assumption of constant variance.<br />
<em>(we want the blue smoothed line to be close to horizontal across the plot)</em></p>
<pre class="r"><code>plot(rs_model,
     form = sqrt(abs(resid(.))) ~ fitted(.),
     type = c(&quot;p&quot;,&quot;smooth&quot;))</code></pre>
<p><img src="04_ranef_files/figure-html/unnamed-chunk-11-1.png" width="80%" style="display: block; margin: auto;" /></p></li>
<li><p>We can also examine the normality the level 1 residuals:<br />
<em>(we want the datapoints to follow close to the diagonal line)</em></p>
<pre class="r"><code>qqnorm(resid(rs_model)); qqline(resid(rs_model))</code></pre>
<p><img src="04_ranef_files/figure-html/unnamed-chunk-12-1.png" width="80%" style="display: block; margin: auto;" /></p></li>
</ul>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-58" class="fa fa-chevron-circle-right optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-58&#39;, &#39;opt-start-58&#39;)"> Examining Residuals (Level 2+)</span>
</div>
<div id="opt-body-58" class="optional-body" style="display: none;">
<pre class="r"><code>toys_read &lt;- read_csv(&quot;https://uoepsy.github.io/data/toyexample.csv&quot;)
rs_model &lt;- lmer(R_AGE ~ 1 + hrs_week + (1 + hrs_week | toy_type), data = toys_read)</code></pre>
<p>To get out the level 2 residuals (the random effects) we need to do a bit of indexing. <code>ranef(rs_model)</code> will give us a list with an item for each grouping. In each item we have a set of columns, one for each thing which is varying by that grouping.</p>
<pre class="r"><code>qqnorm(ranef(rs_model)$toy_type[,1]); qqline(ranef(rs_model)$toy_type[,1])</code></pre>
<p><img src="04_ranef_files/figure-html/unnamed-chunk-14-1.png" width="80%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>qqnorm(ranef(rs_model)$toy_type[,2]); qqline(ranef(rs_model)$toy_type[,2])</code></pre>
<p><img src="04_ranef_files/figure-html/unnamed-chunk-14-2.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<p class="optional-end">
</p>
<div class="frame">
<p><strong>What can we do if we’re worried about assumptions</strong></p>
<ul>
<li>Model mis-specification
<ul>
<li>Is the model appropriate (e.g. is the assumed conditional distribution of y appropriate for your outcome (the <code>family = ??? (link = ???))</code> bit).<br />
</li>
<li>Might we be missing important theoretical predictors, or missing possible interactions?</li>
</ul></li>
<li>Could/Should you transform your outcome variable?
<ul>
<li>There are many different transformations we can apply to our outcome variable to enable us to fit a model in which the residuals are more close to being normally distributed (<code>log(y)</code>, <code>1/y</code>, <code>sqrt(y)</code>, <code>forecast::BoxCox(y, lambda="auto")</code>). However, this comes at the expense of interpretation, because we are now getting coefficients of “change in transformed y”, and it is not always possible to turn that into a meaningful quantity.</li>
</ul></li>
<li>What about Bootstrapping?
<ul>
<li><p>The basic idea of bootstrapping is to fit your model structure to lots and lots of samples, in order to obtain a distribution of the parameter estimate of interest (and then compute a confidence interval for that estimate).</p></li>
<li><p>There are different approaches to how we create the “lots and lots of samples”, and these allow us to relax certain assumptions on our modelling.</p></li>
<li><p>Re-sampling with replacement from our original data allows us to have minimal assumptions, but needs careful consideration about which levels to re-sample at.</p>
<pre class="r"><code>library(lmeresampler)
# the resample argument is whether we want to resample each level
# (from highest to lowest)
bootstrap(model, .f = fixef, type=&quot;case&quot;, resample=c(TRUE,FALSE))</code></pre></li>
<li><p>Bootstrapping is not a panacea for all models that cause you worry.</p></li>
</ul></li>
</ul>
</div>
</div>
<div id="influence" class="section level2">
<h2>Influence</h2>
<div class="statbox">
<p>Just like having residuals are multiple levels, we can also consider the influence of data at different levels on our model. For instance, we might have a specific datapoint being highly influential, but we might be just as interested in thinking about specific clusters as exerting influence on our results.<br />
A very useful package for assessing influence in multilevel models is <strong>HLMdiag</strong>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-16"></span>
<img src="04_ranef_files/figure-html/unnamed-chunk-16-1.png" alt="Influence in MLM" width="80%" />
<p class="caption">
Figure 4: Influence in MLM
</p>
</div>
</div>
<div class="optional-begin">
<span id="opt-start-59" class="fa fa-chevron-circle-right optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-59&#39;, &#39;opt-start-59&#39;)"> Examining Influence (Level 1)</span>
</div>
<div id="opt-body-59" class="optional-body" style="display: none;">
<p>Which toy in the dataset has the greatest influence on our model?</p>
<p><strong>Hint:</strong> as well as <code>hlm_influence()</code> in the <strong>HLMdiag</strong> package there is another nice function, <code>hlm_augment()</code></p>
<div class="imp">
<p>We can often end up in confusion because the <span class="math inline">\(i^{th}\)</span> observation inputted to our model (and therefore the <span class="math inline">\(i^{th}\)</span> observation of <code>hlm_influence()</code> output) <strong>might not be</strong> the <span class="math inline">\(i^{th}\)</span> observation in our original dataset - there may be missing data!</p>
</div>
<p>(Luckily, we have no missing data in the Toy dataset).</p>
<pre class="r"><code>library(HLMdiag)
l1_inf &lt;- hlm_influence(rs_model,level=1)
dotplot_diag(l1_inf$cooksd, cutoff=&quot;internal&quot;)+
  ylim(0,.15)</code></pre>
<p><img src="04_ranef_files/figure-html/unnamed-chunk-17-1.png" width="80%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>hlm_augment(rs_model, level=1) %&gt;% arrange(desc(cooksd))</code></pre>
<pre><code>## # A tibble: 132 × 15
##       id  R_AGE hrs_week toy_type .resid .fitted .ls.r…¹ .ls.f…² .mar.…³ .mar.…⁴
##    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
##  1    81  2.91      6.28 SuperZi…  -3.24    6.15 -1.60     4.51   -6.03     8.93
##  2    65 14.0       2.44 G.I.Joe    4.98    8.99  2.69    11.3     9.43     4.55
##  3   115  0.735     1.70 Stretch…  -3.17    3.91 -0.182    0.917  -2.97     3.70
##  4    46 11.6       5.70 Star Wa…  -2.68   14.3  -2.50    14.1     3.34     8.27
##  5    55  1.47      2.77 SuperZi…  -2.11    3.58 -3.36     4.84   -3.45     4.92
##  6   104  2.68      2.74 Rugrats   -1.79    4.47  0.0279   2.65   -2.21     4.89
##  7    23  0.838     1.74 Playmob…  -1.55    2.39  0.585    0.253  -2.91     3.75
##  8    30  5.33      2.99 Furby     -3.10    8.43 -2.72     8.04    0.156    5.17
##  9   130  3.79      2.73 Lego Mi…   2.54    1.25  1.94     1.85   -1.08     4.87
## 10    36  3.16      2.99 My Litt…   1.87    1.29 -0.508    3.66   -2.02     5.18
## # … with 122 more rows, 5 more variables: cooksd &lt;dbl&gt;, mdffits &lt;dbl&gt;,
## #   covtrace &lt;dbl&gt;, covratio &lt;dbl&gt;, leverage.overall &lt;dbl&gt;, and abbreviated
## #   variable names ¹​.ls.resid, ²​.ls.fitted, ³​.mar.resid, ⁴​.mar.fitted</code></pre>
<p>Greatest influence:
<img src="images/ace.png" width="100px" style="display: block; margin: auto;" /></p>
<p>For which toy is the model fit the worst (i.e., who has the highest residual?)</p>
<pre class="r"><code>hlm_augment(rs_model, level=1) %&gt;% arrange(desc(abs(.resid)))</code></pre>
<pre><code>## # A tibble: 132 × 15
##       id  R_AGE hrs_week toy_type .resid .fitted .ls.r…¹ .ls.f…² .mar.…³ .mar.…⁴
##    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
##  1    93  7.78      4.28 G.I.Joe   -5.26  13.0     -4.62  12.4      1.13    6.65
##  2    65 14.0       2.44 G.I.Joe    4.98   8.99     2.69  11.3      9.43    4.55
##  3    56 -3.17      3.47 Lego Mi…  -4.59   1.42    -4.69   1.52    -8.89    5.72
##  4   102 -2.91      5.12 My Litt…  -4.56   1.64    -3.96   1.04   -10.5     7.62
##  5    43 -2.99      3.96 Transfo…  -3.84   0.853   -3.79   0.800   -9.28    6.29
##  6    16  8.41      3.89 G.I.Joe   -3.76  12.2     -3.75  12.2      2.21    6.20
##  7    22  0.763     3.97 Sock Pu…  -3.70   4.46    -3.65   4.42    -5.54    6.30
##  8    62  4.31      3.61 Minecra…  -3.54   7.85    -2.53   6.84    -1.58    5.89
##  9   129  5.00      4.84 My Litt…   3.41   1.60     3.61   1.39    -2.29    7.29
## 10    14 16.4       4.26 G.I.Joe    3.39  13.0      3.99  12.4      9.76    6.63
## # … with 122 more rows, 5 more variables: cooksd &lt;dbl&gt;, mdffits &lt;dbl&gt;,
## #   covtrace &lt;dbl&gt;, covratio &lt;dbl&gt;, leverage.overall &lt;dbl&gt;, and abbreviated
## #   variable names ¹​.ls.resid, ²​.ls.fitted, ³​.mar.resid, ⁴​.mar.fitted</code></pre>
<pre class="r"><code>toys_read[93, ]</code></pre>
<pre><code>## # A tibble: 1 × 5
##   toy_type toy        hrs_week   age R_AGE
##   &lt;chr&gt;    &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 G.I.Joe  Cold Front     4.28  7.35  7.78</code></pre>
<p><img src="images/coldfront.png" width="100px" style="display: block; margin: auto;" /></p>
</div>
<p class="optional-end">
</p>
<div class="optional-begin">
<span id="opt-start-60" class="fa fa-chevron-circle-right optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-60&#39;, &#39;opt-start-60&#39;)"> Examining Influence (Level 2+)</span>
</div>
<div id="opt-body-60" class="optional-body" style="display: none;">
<p>Which <em>type</em> of toy has the greatest influence on our model?</p>
<p>Either this way:</p>
<pre class="r"><code>hlm_augment(rs_model, level=&quot;toy_type&quot;) %&gt;% arrange(desc(cooksd))</code></pre>
<pre><code>## # A tibble: 20 × 10
##    toy_type      .rane…¹ .rane…² .ls.i…³ .ls.h…⁴  cooksd mdffits covtr…⁵ covra…⁶
##    &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
##  1 G.I.Joe        1.86    1.06     9.29   -0.889 1.60e-1 1.50e-1  0.114     1.12
##  2 Scooby Doo     2.37    1.62     8.35    0.336 1.33e-1 1.27e-1  0.110     1.11
##  3 Farm Animals  -2.13   -1.73     0.314  -2.40  1.22e-1 1.15e-1  0.131     1.14
##  4 My Little Po… -0.956  -0.979    6.82   -2.72  8.50e-2 8.08e-2  0.0947    1.10
##  5 Stretch Arms… -0.140   0.203   -4.65    1.47  8.09e-2 7.64e-2  0.112     1.12
##  6 SuperZings    -0.198  -0.412    4.57   -1.58  6.48e-2 5.99e-2  0.137     1.14
##  7 Playmobil     -0.778  -0.336   -3.72    0.487 6.24e-2 5.84e-2  0.117     1.12
##  8 Toy Story      0.970   0.890   -0.388   1.14  4.77e-2 4.50e-2  0.115     1.12
##  9 Transformers  -1.33   -1.03     1.44   -1.79  4.13e-2 3.92e-2  0.0629    1.06
## 10 Teenage Muta… -1.32   -0.912   -4.24   -0.510 3.96e-2 3.79e-2  0.0923    1.09
## 11 Lego Minifig… -1.10   -0.925    2.55   -1.94  3.81e-2 3.64e-2  0.101     1.10
## 12 Furby          0.894   0.791    0.235   0.948 3.29e-2 3.12e-2  0.122     1.13
## 13 Star Wars      1.20    0.846    3.70    0.245 3.27e-2 3.10e-2  0.128     1.13
## 14 Rugrats       -0.296  -0.0454  -3.46    0.545 2.68e-2 2.56e-2  0.102     1.10
## 15 Polly Pocket   0.715   0.662   -1.30    1.23  2.66e-2 2.55e-2  0.0979    1.10
## 16 Peppa Pig      0.174  -0.0388   4.04   -0.973 2.54e-2 2.36e-2  0.129     1.13
## 17 Minecraft      0.393   0.433  -20.2     5.84  1.97e-2 1.94e-2  0.0601    1.06
## 18 Barbie         0.0856  0.165   -0.843   0.359 8.94e-3 8.50e-3  0.105     1.11
## 19 Sock Puppets  -0.523  -0.331   -3.98    0.490 8.13e-3 7.83e-3  0.0677    1.07
## 20 Power Rangers  0.108   0.0754   1.44   -0.296 2.65e-4 2.51e-4  0.116     1.12
## # … with 1 more variable: leverage.overall &lt;dbl&gt;, and abbreviated variable
## #   names ¹​.ranef.intercept, ²​.ranef.hrs_week, ³​.ls.intercept, ⁴​.ls.hrs_week,
## #   ⁵​covtrace, ⁶​covratio</code></pre>
<p>Or the plot. Note, the <strong>only</strong> reason we using the <code>cutoff = .15</code> is to make the labels appear.</p>
<pre class="r"><code>inftoytype &lt;- hlm_influence(rs_model,level=&quot;toy_type&quot;)
dotplot_diag(inftoytype$cooksd, index=inftoytype$toy_type, cutoff=.15) +
  ylim(0,.2)</code></pre>
<p><img src="04_ranef_files/figure-html/unnamed-chunk-22-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<p class="optional-end">
</p>
</div>
</div>
<div id="exercises-three-level-nesting" class="section level1">
<h1>Exercises: Three-level nesting</h1>
<div class="frame">
<p><strong>Data: Treatment Effects</strong></p>
<p>Synthetic data from a RCT treatment study: 5 therapists randomly assigned participants to control or treatment group and monitored the participants’ performance over time. There was a baseline test, then 6 weeks of treatment, with test sessions every week (7 total sessions).</p>
<p>The following code will load in your R session an object already called <code>tx</code> with the data:</p>
<pre class="r"><code>load(url(&quot;https://uoepsy.github.io/msmr/data/tx.Rdata&quot;))</code></pre>
You can find a data dictionary below:
<table>
<thead>
<tr>
<th style="text-align:left;">
variable
</th>
<th style="text-align:left;">
description
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
group
</td>
<td style="text-align:left;">
Whether the participant is in the Treatment or Control group
</td>
</tr>
<tr>
<td style="text-align:left;">
session
</td>
<td style="text-align:left;">
Session number (1-7)
</td>
</tr>
<tr>
<td style="text-align:left;">
therapist
</td>
<td style="text-align:left;">
Therapist Identifier (A, B, C, D or E
</td>
</tr>
<tr>
<td style="text-align:left;">
Score
</td>
<td style="text-align:left;">
Score on test (Mean = 0.63, SD = 0.15)
</td>
</tr>
<tr>
<td style="text-align:left;">
PID
</td>
<td style="text-align:left;">
Participant Identifier. Labels take the form &lt;Therapist&gt;<em>&lt;Group&gt;</em>&lt;Participant number&gt;. For instance, if Therapist A’s 6th Participant is in the Treatment group, then their label is A_treatment_6
</td>
</tr>
</tbody>
</table>
</div>
<div class="question-begin">
Question A1
</div>
<div class="question-body">
<p>Load and visualise the data. Does it look like the treatment had an effect on the performance score?</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-61" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-61&#39;, &#39;sol-start-61&#39;)"> Solution </span>
</div>
<div id="sol-body-61" class="solution-body" style="display: none;">
<pre class="r"><code>ggplot(tx, aes(session, Score, color=group)) +
  stat_summary(fun.data = mean_se, geom=&quot;pointrange&quot;) +
  stat_smooth() +
  theme_classic()</code></pre>
<p><img src="04_ranef_files/figure-html/unnamed-chunk-25-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Just for fun, let’s add on the individual participant scores, and also make a plot for each therapist.</p>
<pre class="r"><code>ggplot(tx, aes(session, Score, color=group)) +
  stat_summary(fun.data = mean_se, geom = &quot;pointrange&quot;) +
  stat_smooth() +
  theme_classic() +
  geom_line(aes(group = PID), alpha = .2) + 
  facet_wrap(~therapist)</code></pre>
<p><img src="04_ranef_files/figure-html/unnamed-chunk-26-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question A2
</div>
<div class="question-body">
<p>Test whether the treatment had an effect using multilevel modelling.<br />
Try to fit the <strong>maximal</strong> model.<br />
Does it converge? Is it singular?</p>
<p>Consider these questions when you’re designing your model(s) and use your answers to motivate your model design and interpretation of results:</p>
<ul>
<li>What have we randomly sampled here?
<ul>
<li>We have randomly sampled some therapists, and within them have random sampled some participants. Each participant then has a sample of observations.<br />
</li>
</ul></li>
<li>What are the levels of nesting? How should that be reflected in the random effect structure?
<ul>
<li>Each participant is associated with just one therapist. Participants are nested within therapists.<br />
</li>
</ul></li>
<li>What is the shape of change over time? Do you need polynomials to model this shape? If yes, what order polynomials?
<ul>
<li>Looks like linear change, don’t need polynomials. And it doesn’t look like there are any baseline differences.</li>
</ul></li>
<li>We are wanting to examine how time (<code>session</code>) varies between treatment groups (<code>group</code>), so we want an interaction <code>session * group</code> in the model. Participants have multiple sessions, but belong to only one group. Therapists have multiple sessions <em>and</em> participants in different groups.</li>
<li>Do we want to allow the same effects to vary by participants and by therapists?
<ul>
<li>If so, we can specify <code>(1 + .... | therapist/PID)</code>.</li>
<li>If not, and we want to have some effects vary by therapist but <em>not</em> by participant (or vice versa), then we will need to specify these separately.<br />
</li>
</ul></li>
<li>Do the participants have labels that uniquely associate them with one higher up group (i.e., one therapist?).
<ul>
<li>If so, we can have <code>(1..... | PID) + (1.... | therapist)</code>.</li>
<li>If not, then we need to tell the model that patients are nested in therapists, and have <code>(1..... | therapist:PID) + (1.... | therapist)</code>.</li>
</ul></li>
</ul>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-62" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-62&#39;, &#39;sol-start-62&#39;)"> Solution </span>
</div>
<div id="sol-body-62" class="solution-body" style="display: none;">
<pre class="r"><code>library(lme4)

# start with maximal model
m1 &lt;- lmer(Score ~ session * group + 
             (1 + session | PID) + 
             (1 + session * group | therapist),
           data=tx,
           control = lmerControl(optimizer=&quot;bobyqa&quot;))

isSingular(m1)</code></pre>
<pre><code>## [1] TRUE</code></pre>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question A3
</div>
<div class="question-body">
<p>Try adjusting your model by removing random effects or correlations, examine the model again, and so on..</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-63" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-63&#39;, &#39;sol-start-63&#39;)"> Solution </span>
</div>
<div id="sol-body-63" class="solution-body" style="display: none;">
<pre class="r"><code>VarCorr(m1)</code></pre>
<pre><code>##  Groups    Name                 Std.Dev.  Corr                
##  PID       (Intercept)          0.1180167                     
##            session              0.0315636 -0.603              
##  therapist (Intercept)          0.0063406                     
##            session              0.0038115 -1.000              
##            groupcontrol         0.0175915 -1.000  1.000       
##            session:groupcontrol 0.0034114  1.000 -1.000 -1.000
##  Residual                       0.0732696</code></pre>
<p>There’s a correlation of exactly -1 between the random intercepts and slopes for therapists, and the standard deviation estimate for <code>session|therapist</code> is pretty small. Let’s remove it.</p>
<pre class="r"><code>m2 &lt;- lmer(Score ~ session * group + 
             (1 + session | PID) + 
             (1 + group | therapist),
           data=tx,
           control = lmerControl(optimizer=&quot;bobyqa&quot;))
VarCorr(m2)</code></pre>
<pre><code>##  Groups    Name         Std.Dev. Corr  
##  PID       (Intercept)  0.118271       
##            session      0.031661 -0.602
##  therapist (Intercept)  0.000000       
##            groupcontrol 0.004469   NaN 
##  Residual               0.073270</code></pre>
<pre class="r"><code>m2a &lt;- lmer(Score ~ session * group + 
             (1 + session | PID) + 
             (1 | therapist),
           data=tx,
           control = lmerControl(optimizer=&quot;bobyqa&quot;))
VarCorr(m2a)</code></pre>
<pre><code>##  Groups    Name        Std.Dev. Corr  
##  PID       (Intercept) 0.118298       
##            session     0.031661 -0.602
##  therapist (Intercept) 0.000000       
##  Residual              0.073270</code></pre>
<p>It now looks like estimates for random intercepts for therapists is now 0. If we remove this, our model finally is non-singular:</p>
<pre class="r"><code>m3 &lt;- lmer(Score ~ session * group + 
             (1 + session | PID),
           data=tx,
           control = lmerControl(optimizer=&quot;bobyqa&quot;))

summary(m3)</code></pre>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: Score ~ session * group + (1 + session | PID)
##    Data: tx
## Control: lmerControl(optimizer = &quot;bobyqa&quot;)
## 
## REML criterion at convergence: -1633.6
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -2.63302 -0.58619  0.01599  0.55406  2.88095 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr 
##  PID      (Intercept) 0.013994 0.11830       
##           session     0.001002 0.03166  -0.60
##  Residual             0.005368 0.07327       
## Number of obs: 945, groups:  PID, 135
## 
## Fixed effects:
##                       Estimate Std. Error t value
## (Intercept)           0.526849   0.015959  33.012
## session               0.033688   0.004130   8.156
## groupcontrol          0.018136   0.023000   0.789
## session:groupcontrol -0.020138   0.005952  -3.383
## 
## Correlation of Fixed Effects:
##             (Intr) sessin grpcnt
## session     -0.655              
## groupcontrl -0.694  0.454       
## sssn:grpcnt  0.454 -0.694 -0.655</code></pre>
<p>Lastly, it’s then a good idea to check that the parameter estimates and SE are not radically different across these models (they are virtually identical)</p>
<pre class="r"><code># extract and column bind the fixed effect estimates
cbind(
  summary(m1)$coefficients[,1],
  summary(m2)$coefficients[,1],
  summary(m2a)$coefficients[,1],
  summary(m3)$coefficients[,1]
)</code></pre>
<pre><code>##                             [,1]        [,2]        [,3]        [,4]
## (Intercept)           0.52684907  0.52684907  0.52684907  0.52684907
## session               0.03368821  0.03368821  0.03368821  0.03368821
## groupcontrol          0.01813605  0.01813605  0.01813605  0.01813605
## session:groupcontrol -0.02013829 -0.02013829 -0.02013829 -0.02013829</code></pre>
<pre class="r"><code># extract and column bind the fixed effect SEs
cbind(
  summary(m1)$coefficients[,2],
  summary(m2)$coefficients[,2],
  summary(m2a)$coefficients[,2],
  summary(m3)$coefficients[,2]
)</code></pre>
<pre><code>##                             [,1]        [,2]        [,3]        [,4]
## (Intercept)          0.016179962 0.015956448 0.015959300 0.015959303
## session              0.004458345 0.004130320 0.004130320 0.004130320
## groupcontrol         0.024267514 0.023082376 0.022999799 0.022999803
## session:groupcontrol 0.006129886 0.005952425 0.005952425 0.005952425</code></pre>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question A4: Optional
</div>
<div class="question-body">
<p>Try the code below to use the <code>allFit()</code> function to fit your final model with all the available optimizers.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<ul>
<li>You might need to install the <code>dfoptim</code> package to get one of the optimizers</li>
</ul>
<pre class="r"><code>sumfits &lt;- allFit(yourmodel)
summary(sumfits)</code></pre>
</div>
<p class="question-end">
</p>
</div>
<div id="exercises-crossed-random-effects" class="section level1">
<h1>Exercises: Crossed random effects</h1>
<div class="frame">
<p><strong>Data: Test-enhanced learning</strong></p>
<p>An experiment was run to conceptually replicate “test-enhanced learning” (Roediger &amp; Karpicke, 2006): two groups of 25 participants were presented with material to learn. One group studied the material twice (<code>StudyStudy</code>), the other group studied the material once then did a test (<code>StudyTest</code>). Recall was tested immediately (one minute) after the learning session and one week later. The recall tests were composed of 175 items identified by a keyword (<code>Test_word</code>). One of the researchers’ questions concerned how test-enhanced learning influences time-to-recall.</p>
<p>The critical (replication) prediction is that the <code>StudyStudy</code> group should perform somewhat better on the immediate recall test, but the <code>StudyTest</code> group will retain the material better and thus perform better on the 1-week follow-up test.</p>
<p>The following code loads the data into your R environment by creating a variable called <code>tel</code>:</p>
<pre class="r"><code>load(url(&quot;https://uoepsy.github.io/data/testenhancedlearning.RData&quot;))</code></pre>
<table>
<thead>
<tr>
<th style="text-align:left;">
variable
</th>
<th style="text-align:left;">
description
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Subject_ID
</td>
<td style="text-align:left;">
Unique Participant Identifier
</td>
</tr>
<tr>
<td style="text-align:left;">
Group
</td>
<td style="text-align:left;">
Group denoting whether the participant studied the material twice (StudyStudy), or studied it once then did a test (StudyTest)
</td>
</tr>
<tr>
<td style="text-align:left;">
Delay
</td>
<td style="text-align:left;">
Time of recall test (‘min’ = Immediate, ‘week’ = One week later)
</td>
</tr>
<tr>
<td style="text-align:left;">
Test_word
</td>
<td style="text-align:left;">
Word being recalled (175 different test words)
</td>
</tr>
<tr>
<td style="text-align:left;">
Correct
</td>
<td style="text-align:left;">
Whether or not the word was correctly recalled
</td>
</tr>
<tr>
<td style="text-align:left;">
Rtime
</td>
<td style="text-align:left;">
Time to recall word (milliseconds)
</td>
</tr>
</tbody>
</table>
</div>
<div class="question-begin">
Question B1
</div>
<div class="question-body">
<p>Load and plot the data. Does it look like the effect was replicated?</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-64" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-64&#39;, &#39;sol-start-64&#39;)"> Solution </span>
</div>
<div id="sol-body-64" class="solution-body" style="display: none;">
<p>We have a choice to make - whether we focus on recall time or on the correct responses. The choice is yours to make!</p>
<p>You can make use of <code>stat_summary()</code> again!</p>
<pre class="r"><code>ggplot(tel, aes(Delay, Rtime, col=Group)) + 
  stat_summary(fun.data=mean_se, geom=&quot;pointrange&quot;)+
  theme_light()</code></pre>
<p>It’s more work, but some people might rather calculate the numbers and then plot them directly. It does just the same thing:</p>
<pre class="r"><code>tel %&gt;% 
  group_by(Delay, Group) %&gt;%
  summarise(
    mean = mean(Rtime),
    se = sd(Rtime)/sqrt(n())
  ) %&gt;%
  ggplot(., aes(x=Delay, col = Group)) +
  geom_pointrange(aes(y=mean, ymin=mean-se, ymax=mean+se))+
  theme_light() +
  labs(y = &quot;Response Time (ms)&quot;)</code></pre>
<p><img src="04_ranef_files/figure-html/unnamed-chunk-36-1.png" width="80%" style="display: block; margin: auto;" />
That looks like test-enhanced learning to me!</p>
<p>Let’s also do it quickly for the proportion of correct responses:</p>
<pre class="r"><code>ggplot(tel, aes(Delay, Correct, col=Group)) + 
  stat_summary(fun.data=mean_se, geom=&quot;pointrange&quot;)+
  theme_light()</code></pre>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question B2
</div>
<div class="question-body">
<p>Test the critical hypothesis using a mixed-effects model. Fit the maximal random effect structure supported by the experimental design.</p>
<p>Some questions to consider:</p>
<ul>
<li><p>There are two outcomes to consider here: recall time, and accuracy. Which will you use? (Feel free to fit models to both!)</p></li>
<li><p>Item accuracy is a binary variable. If you choose this as your outcome variable here, what kind of model will you use?<br />
</p></li>
<li><p>We can expect variability across subjects (some people are better at learning than others) and across items (some of the recall items are harder than others). How should this be represented in the random effects?</p></li>
<li><p>If a model takes ages to fit, you might want to cancel it by pressing the escape key. It is normal for complex models to take time, but for the purposes of this task, give up after a couple of minutes, and try simplifying your model.</p></li>
</ul>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-65" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-65&#39;, &#39;sol-start-65&#39;)"> Solution </span>
</div>
<div id="sol-body-65" class="solution-body" style="display: none;">
<div class="imp">
<p>We’re going to use recall time as our outcome here. For our purposes here, there is no specific reason to choose one over the other. If this were your own research project you would likely model both, because they will represent different aspects of the recall process.</p>
<p><strong>Remember</strong> - as research designs get more complex, there are an ever-increasing number of different viable and defensible approaches that we might take in analysing the data. The solutions provided here are not “<em>the</em> answer”, they are simply “<em>an</em> answer”.</p>
</div>
<p>This one will probably take a little bit of time:</p>
<pre class="r"><code>m &lt;- lmer(Rtime ~ Delay*Group +
             (1 + Delay | Subject_ID) +
             (1 + Delay * Group | Test_word),
           data=tel, control=lmerControl(optimizer = &quot;bobyqa&quot;))</code></pre>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question B3
</div>
<div class="question-body">
<p>The model with maximal random effects will probably not converge, or will obtain a singular fit. Simplify the model until you achieve convergence.<br />
<br>
What we’re aiming to do here is to follow <a href="https://doi.org/10.1016/j.jml.2012.11.001">Barr et al.’s</a> advice of defining our maximal model and then removing only the terms to allow a non-singular fit.<br />
<br>
<strong>Note:</strong> This strategy - starting with the maximal random effects structure and removing terms until obtaining model convergence, is just <em>one</em> approach, and there are drawbacks (see <a href="https://doi.org/10.1016/j.jml.2017.01.001">Matuschek et al., 2017</a>). There is no consensus on what approach is best (see <code>?isSingular</code>).<br />
<br>
<br>
<em>Tip:</em> you can look at the variance estimates and correlations easily by using the <code>VarCorr()</code> function. What jumps out?</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-66" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-66&#39;, &#39;sol-start-66&#39;)"> Solution </span>
</div>
<div id="sol-body-66" class="solution-body" style="display: none;">
<p>There’s a correlation of .999 for some of the random effects by-item!</p>
<pre class="r"><code>VarCorr(m)</code></pre>
<pre><code>##  Groups     Name                     Std.Dev. Corr                
##  Test_word  (Intercept)               17.8642                     
##             Delayweek                 13.2793 -0.251              
##             GroupStudyTest            18.0270 -0.797 -0.385       
##             Delayweek:GroupStudyTest  13.1273  0.972 -0.016 -0.917
##  Subject_ID (Intercept)               40.5201                     
##             Delayweek                  7.4486 -0.038              
##  Residual                            240.3113</code></pre>
<p>lets remove the interaction in the by-word random effects:</p>
<pre class="r"><code>m1 &lt;- lmer(Rtime ~ Delay*Group +
             (1 + Delay | Subject_ID) +
             (1 + Delay + Group | Test_word),
           data=tel, control=lmerControl(optimizer = &quot;bobyqa&quot;))
VarCorr(m1)</code></pre>
<pre><code>##  Groups     Name           Std.Dev. Corr         
##  Test_word  (Intercept)     14.5561              
##             Delayweek       14.6914  0.152       
##             GroupStudyTest  12.3210 -0.612 -0.875
##  Subject_ID (Intercept)     40.5190              
##             Delayweek        7.4365 -0.038       
##  Residual                  240.3436</code></pre>
<pre class="r"><code>isSingular(m1)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>We still have a singular fit here, and the correlation is just slightly different (0.998). Thinking about the study, if we are going to remove <strong>one</strong> of the by-testword random effects (<code>Delay</code> or <code>Group</code>), which one do we consider to be more theoretically justified? Is the effect of Delay likely to vary by test-words? More so than the effect of group is likely to vary by test-words? Quite possibly - there’s no obvious reason for <em>certain</em> words to be more memorable for people in one group vs another. But there is reason for words to vary in the effect that delay of one week has - how familiar a word is will likely influence the amount to which a week’s delay has on recall.</p>
<p>Let’s remove the by-testword random effect of group.</p>
<pre class="r"><code>m2 &lt;- lmer(Rtime ~ Delay*Group +
             (1 + Delay | Subject_ID) +
             (1 + Delay | Test_word),
           data=tel, control=lmerControl(optimizer = &quot;bobyqa&quot;))
isSingular(m2)</code></pre>
<pre><code>## [1] FALSE</code></pre>
<pre class="r"><code>VarCorr(m2)</code></pre>
<pre><code>##  Groups     Name        Std.Dev. Corr  
##  Test_word  (Intercept)  11.6972       
##             Delayweek    13.5689 -0.236
##  Subject_ID (Intercept)  40.5156       
##             Delayweek     7.4001 -0.037
##  Residual               240.4432</code></pre>
<p>Hooray, the model converged!</p>
<pre class="r"><code>summary(m2)</code></pre>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: Rtime ~ Delay * Group + (1 + Delay | Subject_ID) + (1 + Delay |  
##     Test_word)
##    Data: tel
## Control: lmerControl(optimizer = &quot;bobyqa&quot;)
## 
## REML criterion at convergence: 241671.3
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.8200 -0.6685 -0.0096  0.6760  4.0783 
## 
## Random effects:
##  Groups     Name        Variance Std.Dev. Corr 
##  Test_word  (Intercept)   136.82  11.70        
##             Delayweek     184.12  13.57   -0.24
##  Subject_ID (Intercept)  1641.52  40.52        
##             Delayweek      54.76   7.40   -0.04
##  Residual               57812.93 240.44        
## Number of obs: 17498, groups:  Test_word, 175; Subject_ID, 50
## 
## Fixed effects:
##                          Estimate Std. Error t value
## (Intercept)               744.047      8.925  83.363
## Delayweek                  26.766      5.448   4.913
## GroupStudyTest            -18.032     12.560  -1.436
## Delayweek:GroupStudyTest  -17.647      7.566  -2.332
## 
## Correlation of Fixed Effects:
##             (Intr) Delywk GrpStT
## Delayweek   -0.285              
## GropStdyTst -0.704  0.200       
## Dlywk:GrpST  0.202 -0.694 -0.288</code></pre>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question B4
</div>
<div class="question-body">
<p>Load the <strong>effects</strong> package, and try running this code:</p>
<pre class="r"><code>library(effects)
ef &lt;- as.data.frame(effect(&quot;Delay:Group&quot;, model))</code></pre>
<p>What is <code>ef</code>? and how can you use it to plot the model-estimated condition means and variability?</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-67" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-67&#39;, &#39;sol-start-67&#39;)"> Solution </span>
</div>
<div id="sol-body-67" class="solution-body" style="display: none;">
<pre class="r"><code>ggplot(ef, aes(Delay, fit, color=Group)) + 
  geom_pointrange(aes(ymax=upper, ymin=lower), position=position_dodge(width = 0.2))+
  theme_classic() # just for a change :)</code></pre>
<p><img src="04_ranef_files/figure-html/unnamed-chunk-45-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question B5
</div>
<div class="question-body">
<p>Can we get a similar plot using <code>plot_model()</code> from the <strong>sjPlot</strong> package?</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-68" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-68&#39;, &#39;sol-start-68&#39;)"> Solution </span>
</div>
<div id="sol-body-68" class="solution-body" style="display: none;">
<pre class="r"><code>library(sjPlot)
plot_model(m2, type=&quot;int&quot;)</code></pre>
<p><img src="04_ranef_files/figure-html/unnamed-chunk-46-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question B6
</div>
<div class="question-body">
<p>What should we do with this information? How can we apply test-enhanced learning to learning R and statistics?</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-69" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-69&#39;, &#39;sol-start-69&#39;)"> Solution </span>
</div>
<div id="sol-body-69" class="solution-body" style="display: none;">
<p>You’ll get the benefits of test-enhanced learning if you try yourself before looking at the solutions! If you don’t test yourself, you’re more likely to forget it in the long run.</p>
</div>
<p class="solution-end">
</p>
</div>
<div id="exercises-boston-naming-test" class="section level1">
<h1>Exercises: Boston Naming Test</h1>
<div class="frame">
<p><strong>Data: Naming</strong></p>
<p>72 children from 10 schools were administered the full Boston Naming Test (BNT-60) on a yearly basis for 5 years to examine development of word retrieval. Five of the schools taught lessons in a bilingual setting with English as one of the languages, and the remaining five schools taught in monolingual English.</p>
<p>The data is available at <a href="https://uoepsy.github.io/data/bntmono.csv">https://uoepsy.github.io/data/bntmono.csv</a>.</p>
<table style="width:61%;">
<colgroup>
<col width="18%" />
<col width="43%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">variable</th>
<th align="center">description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">child_id</td>
<td align="center">unique child identifier</td>
</tr>
<tr class="even">
<td align="center">school_id</td>
<td align="center">unique school identifier</td>
</tr>
<tr class="odd">
<td align="center">BNT60</td>
<td align="center">score on the Boston Naming
Test-60. Scores range from 0
to 60</td>
</tr>
<tr class="even">
<td align="center">schoolyear</td>
<td align="center">Year of school</td>
</tr>
<tr class="odd">
<td align="center">mlhome</td>
<td align="center">Mono/Bi-lingual School. 0 =
Bilingual, 1 = Monolingual</td>
</tr>
</tbody>
</table>
</div>
<div class="question-begin">
Question C1
</div>
<div class="question-body">
<p>Fit a model examining the interaction between the effects of school year and mono/bilingual teaching on word retrieval, with random intercepts only for children and schools.<br />
<strong>tip:</strong> make sure your variables are of the right type first - e.g. numeric, factor etc<br />
<br>
Examine the fit and consider your model assumptions, and assess what might be done to improve the model in order to make better statistical inferences.</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-70" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-70&#39;, &#39;sol-start-70&#39;)"> Solution </span>
</div>
<div id="sol-body-70" class="solution-body" style="display: none;">
<pre class="r"><code>bnt &lt;- bnt %&gt;% mutate(across(c(mlhome, school_id, child_id), factor))
bntm0 &lt;- lmer(BNT60 ~ schoolyear * mlhome + (1 | school_id/child_id), data = bnt)</code></pre>
<p>Residuals don’t look zero mean:</p>
<pre class="r"><code>plot(bntm0, type=c(&quot;p&quot;,&quot;smooth&quot;))</code></pre>
<p><img src="04_ranef_files/figure-html/unnamed-chunk-49-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>It looks a little like, compared to our model (black lines below) the children’s scores (coloured lines) are more closely clustered together when they start school, and then they are more spread out by the end of the study.
The fact that we’re fitting the same slope for each child is restricting us here, so we should try fitting random effects of schoolyear.</p>
<pre class="r"><code>augment(bntm0) %&gt;%
  ggplot(aes(x=schoolyear, col=child_id)) + 
  geom_point(aes(y = BNT60))+
  geom_path(aes(y = BNT60))+
  geom_path(aes(y = .fitted), col=&quot;black&quot;, alpha=.3)+
  guides(col=&quot;none&quot;)+
  facet_wrap(~school_id)</code></pre>
<p><img src="04_ranef_files/figure-html/unnamed-chunk-50-1.png" width="80%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>bntm1 &lt;- lmer(BNT60 ~ schoolyear * mlhome + (1 + schoolyear | school_id/child_id), data = bnt)
plot(bntm1, type=c(&quot;p&quot;,&quot;smooth&quot;))</code></pre>
<p><img src="04_ranef_files/figure-html/unnamed-chunk-51-1.png" width="80%" style="display: block; margin: auto;" />
Much better!</p>
<p>Let’s do some quick diagnostic checks for influence:</p>
<pre class="r"><code>inf1 &lt;- hlm_influence(bntm1, level=1)
dotplot_diag(inf1$cooksd, cutoff = &quot;internal&quot;)</code></pre>
<p><img src="04_ranef_files/figure-html/unnamed-chunk-52-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>If you check in the help for <code>dotplot_diag()</code>, it tells you that</p>
<ol style="list-style-type: lower-alpha">
<li>we can add an index for the labels, and</li>
<li>the coordinates (x,y) are flipped. We’re telling R to change the limits of the y axis, but actually it is the x axis. This is just because we want to see the label for that point out to the right.</li>
</ol>
<pre class="r"><code>infchild &lt;- hlm_influence(bntm1, level=&quot;child_id:school_id&quot;)
dotplot_diag(infchild$cooksd, cutoff = &quot;internal&quot;, index = infchild$`child_id:school_id`) + 
  scale_y_continuous(limits=c(0,.05))</code></pre>
<p><img src="04_ranef_files/figure-html/unnamed-chunk-53-1.png" width="80%" style="display: block; margin: auto;" />
And then we can examine the effects to the fixed effects and our standard errors when we remove this child:</p>
<pre class="r"><code>del94 &lt;- case_delete(bntm1, level=&quot;child_id:school_id&quot;, delete = &quot;ID94:SC9&quot;)
cbind(del94$fixef.original, del94$fixef.delete)</code></pre>
<pre><code>##                         [,1]       [,2]
## (Intercept)         6.265626  6.2627962
## schoolyear          6.371168  6.3639335
## mlhome1             0.138711 -0.3052998
## schoolyear:mlhome1 -2.603763 -2.3701181</code></pre>
<div class="optional-begin">
<span id="opt-start-71" class="fa fa-chevron-circle-right optional-icon clickable" onclick="toggle_visibility(&#39;opt-body-71&#39;, &#39;opt-start-71&#39;)"> Optional: Case deletion influence on standard errors</span>
</div>
<div id="opt-body-71" class="optional-body" style="display: none;">
<p>We can examine the influence that deleting a case has on the standard errors.
The standard errors are the square-root of the diagonal of the model-implied variance-covariance matrix:</p>
<pre class="r"><code>cbind( 
  sqrt(diag(del94$vcov.original)),
  sqrt(diag(del94$vcov.delete))
)</code></pre>
<pre><code>##                         [,1]      [,2]
## (Intercept)        1.0413285 0.9557645
## schoolyear         0.7719321 0.6717837
## mlhome1            1.4683927 1.3525492
## schoolyear:mlhome1 1.0875897 0.9498207</code></pre>
</div>
<p class="optional-end">
</p>
<pre class="r"><code>infschool &lt;- hlm_influence(bntm1, level=&quot;school_id&quot;)
dotplot_diag(infschool$cooksd, cutoff = &quot;internal&quot;, index = infschool$school_id)</code></pre>
<p><img src="04_ranef_files/figure-html/unnamed-chunk-56-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<p class="solution-end">
</p>
<div class="question-begin">
Question C2
</div>
<div class="question-body">
<p>Using a method of your choosing, conduct inferences from your model and write up the results.</p>
</div>
<p class="question-end">
</p>
<div class="solution-begin">
<span id="sol-start-72" class="fa fa-chevron-circle-right solution-icon clickable" onclick="toggle_visibility(&#39;sol-body-72&#39;, &#39;sol-start-72&#39;)"> Solution </span>
</div>
<div class="solution-body" id = "sol-body-72" style="display: none;">



<pre class="r"><code>bnt_null &lt;- lmer(BNT60 ~ 1 +  (1 | school_id/child_id), data = bnt)
as.data.frame(VarCorr(bnt_null)) %&gt;%
    select(grp, vcov) %&gt;%
    mutate(
        icc = cumsum(vcov)/sum(vcov)*100
    )</code></pre>
<pre><code>##                  grp     vcov       icc
## 1 child_id:school_id 36.52302  22.21657
## 2          school_id 28.76157  39.71194
## 3           Residual 99.11079 100.00000</code></pre>
<p>We’re going to construct some case-based bootstrapped confidence intervals around our fixed effects here.<br />
This took quite a while to run:</p>
<pre class="r"><code>library(lmeresampler)
bntm1BS &lt;- bootstrap(bntm1, .f=fixef, type = &quot;case&quot;, B = 2000, resample = c(FALSE,TRUE,FALSE))
confint(bntm1BS, type = &quot;perc&quot;)</code></pre>
<pre><code>## # A tibble: 4 × 6
##   term               estimate lower upper type  level
##   &lt;chr&gt;                 &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;
## 1 (Intercept)           6.27   5.43  7.12 perc   0.95
## 2 schoolyear            6.37   5.72  7.02 perc   0.95
## 3 mlhome1               0.139 -1.12  1.40 perc   0.95
## 4 schoolyear:mlhome1   -2.60  -3.51 -1.59 perc   0.95</code></pre>
<div class="int">
<p>Multilevel level linear regression was used to investigate childrens’ development of word retrieval over 5 years of school, and whether development was dependent upon the school teaching classes monolingually or bilingually.
Initial evaluation of the intercept-only model indicated that the clustering of multiple observations from children within schools accounted for 39.7% of the variance in scores on the Boston Naming Task (BNT60, range 0 to 60).
BNT60 scores were modelled with fixed effects of school year (1-5) and monolingual teaching (monolingual vs bilingual, treatment coded with monolingual as the reference level). Random intercepts and slopes of school year were included for schools and for children nested within schools. The model was fitting with maximum likelihood estimation using the default optimiser from the <strong>lme4</strong> package (Bates et al., 2015).<br />
95% Confidence for fixed effect estimates were constructed by case-based bootstrapping with 2000 bootstraps in which children, (but neither observations within children nor the schools within which children were nested) were resampled.
Results indicated that children’s scores on the BNT60 increased over the 5 years in which they were studied, with children from bilingual schools increasing in scores by 6.37 ([5.72 – 7.02]) every school year. There was a significant interaction between mono/bilingual schools and the changes over school year, with children from monolingual schools increasing -2.6 ([-3.51 – -1.59]) less than those from bilingual schools for every additional year of school. Full model results can be found in Table 1.</p>
</div>
Table 1
<table>
<tr>
<th class="thead firsttablerow firsttablecol col1">
 
</th>
<th colspan="2" class="thead firsttablerow">
BNT 60
</th>
</tr>
<tr>
<td class="depvarhead firsttablerow firsttablecol col1">
Predictors
</td>
<td class="depvarhead firsttablerow col2">
Estimates
</td>
<td class="depvarhead firsttablerow col3">
95% CI<br>bootstrap
</td>
</tr>
<tr>
<td class="tdata firsttablecol col1">
Intercept
</td>
<td class="tdata centeralign modelcolumn1 col2">
6.27
</td>
<td class="tdata centeralign modelcolumn1 col3">
5.43 – 7.12
</td>
</tr>
<tr>
<td class="tdata firsttablecol col1">
School Year
</td>
<td class="tdata centeralign modelcolumn1 col2">
6.37
</td>
<td class="tdata centeralign modelcolumn1 col3">
4.85 – 7.89
</td>
</tr>
<tr>
<td class="tdata firsttablecol col1">
MonolingualSchool [1]
</td>
<td class="tdata centeralign modelcolumn1 col2">
0.14
</td>
<td class="tdata centeralign modelcolumn1 col3">
-2.75 – 3.03
</td>
</tr>
<tr>
<td class="tdata firsttablecol col1">
School<br>Year:MonolingualSchool<br>[1]
</td>
<td class="tdata centeralign modelcolumn1 col2">
-2.60
</td>
<td class="tdata centeralign modelcolumn1 col3">
-4.74 – -0.46
</td>
</tr>
<tr>
<td colspan="3" class="randomparts">
Random Effects
</td>
</tr>
<tr>
<td class="tdata leftalign summary">
σ<sup>2</sup>
</td>
<td class="tdata summary summarydata" colspan="2">
8.64
</td>
</tr>
<tr>
<td class="tdata leftalign summary">
τ<sub>00</sub> <sub>child_id:school_id</sub>
</td>
<td class="tdata summary summarydata" colspan="2">
1.77
</td>
<tr>
<td class="tdata leftalign summary">
τ<sub>00</sub> <sub>school_id</sub>
</td>
<td class="tdata summary summarydata" colspan="2">
3.83
</td>
<tr>
<td class="tdata leftalign summary">
τ<sub>11</sub> <sub>child_id:school_id.schoolyear</sub>
</td>
<td class="tdata summary summarydata" colspan="2">
6.83
</td>
<tr>
<td class="tdata leftalign summary">
τ<sub>11</sub> <sub>school_id.schoolyear</sub>
</td>
<td class="tdata summary summarydata" colspan="2">
1.89
</td>
<tr>
<td class="tdata leftalign summary">
ρ<sub>01</sub> <sub>child_id:school_id</sub>
</td>
<td class="tdata summary summarydata" colspan="2">
-0.42
</td>
<tr>
<td class="tdata leftalign summary">
ρ<sub>01</sub> <sub>school_id</sub>
</td>
<td class="tdata summary summarydata" colspan="2">
-0.39
</td>
<tr>
<td class="tdata leftalign summary">
ICC
</td>
<td class="tdata summary summarydata" colspan="2">
0.91
</td>
<tr>
<td class="tdata leftalign summary">
N <sub>child_id</sub>
</td>
<td class="tdata summary summarydata" colspan="2">
74
</td>
<tr>
<td class="tdata leftalign summary">
N <sub>school_id</sub>
</td>
<td class="tdata summary summarydata" colspan="2">
10
</td>
<tr>
<td class="tdata leftalign summary firstsumrow">
Observations
</td>
<td class="tdata summary summarydata firstsumrow" colspan="2">
370
</td>
</tr>
<tr>
<td class="tdata leftalign summary">
Marginal R<sup>2</sup> / Conditional R<sup>2</sup>
</td>
<td class="tdata summary summarydata" colspan="2">
0.420 / 0.947
</td>
</tr>
</table>
</div>
<p class="solution-end">
</p>
<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;">

</div>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>If you have an older version of <code>lme4</code>, then <code>allFit()</code> might not be directly available, and you will need to run the following: <code>source(system.file("utils", "allFit.R", package="lme4"))</code>.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>

<link rel="stylesheet" href="https://uoepsy.github.io/assets/css/ccfooter.css" />
<div class="ccfooter"></div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "site_libs/mathjax-local/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
